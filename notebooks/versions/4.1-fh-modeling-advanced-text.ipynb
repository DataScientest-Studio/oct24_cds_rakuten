{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61313f60e32f472dabaf4e3359f5d5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1a5dfeeef874dea8f13917fe5f230bc",
              "IPY_MODEL_fba9e01e8aea49d8b8525f7a25cc783d",
              "IPY_MODEL_8a320124ec614f22a68460e4b8ec1478"
            ],
            "layout": "IPY_MODEL_a699e7e67a904945a7323be8cca911d1"
          }
        },
        "b1a5dfeeef874dea8f13917fe5f230bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e13081aede444a6be5c73f398f522cc",
            "placeholder": "​",
            "style": "IPY_MODEL_f4e69bbd58214bc6b214591f8893da66",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "fba9e01e8aea49d8b8525f7a25cc783d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02d46c6f0b14d0bb5c50e8be70dbe21",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d2f1ffbe41648e9887ace8247f3274b",
            "value": 25
          }
        },
        "8a320124ec614f22a68460e4b8ec1478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_299d870982c94d24a3b059de5ce84d4d",
            "placeholder": "​",
            "style": "IPY_MODEL_5f48b36d0b8944978a9b78c672cd092f",
            "value": " 25.0/25.0 [00:00&lt;00:00, 2.94kB/s]"
          }
        },
        "a699e7e67a904945a7323be8cca911d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e13081aede444a6be5c73f398f522cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e69bbd58214bc6b214591f8893da66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e02d46c6f0b14d0bb5c50e8be70dbe21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2f1ffbe41648e9887ace8247f3274b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "299d870982c94d24a3b059de5ce84d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f48b36d0b8944978a9b78c672cd092f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eecd9f9ac25141a9bd0777887cb33d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ad3ab9ccef64c408eea809afb7aa30b",
              "IPY_MODEL_3fb0fcf05c214c2f9c3776e3d3320c59",
              "IPY_MODEL_d3db0e2676b94966ac5f809b7be8eb13"
            ],
            "layout": "IPY_MODEL_91a4d37c575840339f4e59f9c3bdd6fd"
          }
        },
        "3ad3ab9ccef64c408eea809afb7aa30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ef7c7cfeb234f7c9e94c3c19aebec28",
            "placeholder": "​",
            "style": "IPY_MODEL_850bdd0b4b7a444c978c5ff22da6f0e4",
            "value": "sentencepiece.bpe.model: 100%"
          }
        },
        "3fb0fcf05c214c2f9c3776e3d3320c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77eb5f4f7d994b14a4b6aadb66f0b19c",
            "max": 810912,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f6e09fb777f4f7dbfdfe3e1be6e2047",
            "value": 810912
          }
        },
        "d3db0e2676b94966ac5f809b7be8eb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7646c179f2884009b5a937dad192cf2c",
            "placeholder": "​",
            "style": "IPY_MODEL_7353f7b643524ce3b5b5800cd70b027e",
            "value": " 811k/811k [00:00&lt;00:00, 3.93MB/s]"
          }
        },
        "91a4d37c575840339f4e59f9c3bdd6fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ef7c7cfeb234f7c9e94c3c19aebec28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850bdd0b4b7a444c978c5ff22da6f0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77eb5f4f7d994b14a4b6aadb66f0b19c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f6e09fb777f4f7dbfdfe3e1be6e2047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7646c179f2884009b5a937dad192cf2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7353f7b643524ce3b5b5800cd70b027e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efebe00af2d74c72b6cd900422c7e0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7afbb240534f41c5bd321156045eaacd",
              "IPY_MODEL_c974d28be2d34d49a91098d6f86da04e",
              "IPY_MODEL_51cd090672174645a125e59fbc19b9b6"
            ],
            "layout": "IPY_MODEL_5a3aae5999854d2d8afd1e419a6309b7"
          }
        },
        "7afbb240534f41c5bd321156045eaacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80097b9f2244fb0b4d2114c5aca781b",
            "placeholder": "​",
            "style": "IPY_MODEL_876a02eb0f1f40819095d4a7341ca7ac",
            "value": "tokenizer.json: 100%"
          }
        },
        "c974d28be2d34d49a91098d6f86da04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e4cac2e3aca433a9ff02a411293f8ef",
            "max": 1395301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11f0527cb37447fe8e3fa59b34d037cc",
            "value": 1395301
          }
        },
        "51cd090672174645a125e59fbc19b9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd7c561ea4b4601a925bf346ce85876",
            "placeholder": "​",
            "style": "IPY_MODEL_2f23f20ca48040ec8b41a35ef4edf596",
            "value": " 1.40M/1.40M [00:00&lt;00:00, 9.88MB/s]"
          }
        },
        "5a3aae5999854d2d8afd1e419a6309b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80097b9f2244fb0b4d2114c5aca781b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876a02eb0f1f40819095d4a7341ca7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e4cac2e3aca433a9ff02a411293f8ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f0527cb37447fe8e3fa59b34d037cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dd7c561ea4b4601a925bf346ce85876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f23f20ca48040ec8b41a35ef4edf596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cf192631e3e406b88920ddeb70fb9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b82512f20f243e0b9b418222565d95e",
              "IPY_MODEL_3741a177f9c1441e82e45ec113a2a78e",
              "IPY_MODEL_0d9cf78259ec49b3b8b3f43a591aa198"
            ],
            "layout": "IPY_MODEL_6bafd113898541a194826cfde7550e6e"
          }
        },
        "1b82512f20f243e0b9b418222565d95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2277dbd38b8a43eba940356aab330e97",
            "placeholder": "​",
            "style": "IPY_MODEL_c6019bd0cf2b492bb6e2cbb897b3e737",
            "value": "config.json: 100%"
          }
        },
        "3741a177f9c1441e82e45ec113a2a78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c00adaffb34426b6cb6728d037d07b",
            "max": 508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc07d8706cac4ec7b088af5b3e49c0b9",
            "value": 508
          }
        },
        "0d9cf78259ec49b3b8b3f43a591aa198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_737a4fab8f634a849b72749b74397498",
            "placeholder": "​",
            "style": "IPY_MODEL_a5811802cf2f4a20917e4eaf7a81c9f9",
            "value": " 508/508 [00:00&lt;00:00, 61.3kB/s]"
          }
        },
        "6bafd113898541a194826cfde7550e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2277dbd38b8a43eba940356aab330e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6019bd0cf2b492bb6e2cbb897b3e737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c00adaffb34426b6cb6728d037d07b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc07d8706cac4ec7b088af5b3e49c0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "737a4fab8f634a849b72749b74397498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5811802cf2f4a20917e4eaf7a81c9f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65b22565b5c449dc8bb1a3c0afeefc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db2041ea7a034d618b75d9bec3d505ff",
              "IPY_MODEL_51159bfc46c74617bb51f2f5215f8074",
              "IPY_MODEL_5f1fa2c96d5a46e79ed4cf816d2a77f4"
            ],
            "layout": "IPY_MODEL_20386684ac6d4fe5bcb0768ea3ebdac0"
          }
        },
        "db2041ea7a034d618b75d9bec3d505ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_317cc458abe8481b8975ff5624b9cee8",
            "placeholder": "​",
            "style": "IPY_MODEL_e1c9194d4e0242fea8b5af3d94212731",
            "value": "model.safetensors: 100%"
          }
        },
        "51159bfc46c74617bb51f2f5215f8074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a9bdf15113844dab6eafe897252b0f0",
            "max": 445008750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c32819e9b1094c05bfffde7b63b4251e",
            "value": 445008750
          }
        },
        "5f1fa2c96d5a46e79ed4cf816d2a77f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513d4098fdaf437cba4276ce69194307",
            "placeholder": "​",
            "style": "IPY_MODEL_bd344cb63a7146caa95681f89f5bc7d1",
            "value": " 445M/445M [00:01&lt;00:00, 323MB/s]"
          }
        },
        "20386684ac6d4fe5bcb0768ea3ebdac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317cc458abe8481b8975ff5624b9cee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1c9194d4e0242fea8b5af3d94212731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a9bdf15113844dab6eafe897252b0f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32819e9b1094c05bfffde7b63b4251e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "513d4098fdaf437cba4276ce69194307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd344cb63a7146caa95681f89f5bc7d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8641fd56d8874a8a8ac103413663571a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7f2f916ef7140d386ffd3c405fa91ab",
              "IPY_MODEL_631a576369e342d386bb545cb2d91162",
              "IPY_MODEL_a19870d611754e8e870727bac8761454"
            ],
            "layout": "IPY_MODEL_5c8ce7813a6e46e6be10e9a3c53fb0ea"
          }
        },
        "c7f2f916ef7140d386ffd3c405fa91ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11a09ee3e47842ee9a72f07d24217abf",
            "placeholder": "​",
            "style": "IPY_MODEL_b18f54cd43f142c09bfc3411955ff504",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "631a576369e342d386bb545cb2d91162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4151fc8fd5ae494fafe2c324c9b5e7f3",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be20494f54ec46c897a4a951e45d6c8e",
            "value": 72
          }
        },
        "a19870d611754e8e870727bac8761454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee29f4ca614b4635825c10403422041e",
            "placeholder": "​",
            "style": "IPY_MODEL_f4390a9799de46b28467ac809949eeb6",
            "value": " 72.0/72.0 [00:00&lt;00:00, 8.64kB/s]"
          }
        },
        "5c8ce7813a6e46e6be10e9a3c53fb0ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a09ee3e47842ee9a72f07d24217abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b18f54cd43f142c09bfc3411955ff504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4151fc8fd5ae494fafe2c324c9b5e7f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be20494f54ec46c897a4a951e45d6c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee29f4ca614b4635825c10403422041e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4390a9799de46b28467ac809949eeb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4728596336842dd8a44995f92224886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47f2cd21d10b455eb3b1103004d799d6",
              "IPY_MODEL_52e17bae70a14a838492b6f0ae7d712a",
              "IPY_MODEL_6398eb464fa74b488684fad0fed265b4"
            ],
            "layout": "IPY_MODEL_de4573e8306548a78be2d3b670675dab"
          }
        },
        "47f2cd21d10b455eb3b1103004d799d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4ca18c38fa6482ea258cadaa157237b",
            "placeholder": "​",
            "style": "IPY_MODEL_dc0816b0179d4a64a8d3d3e18d06caa0",
            "value": "vocab.json: 100%"
          }
        },
        "52e17bae70a14a838492b6f0ae7d712a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56c974b738034c50b495ab931f3eef95",
            "max": 1561415,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9916e3187d3488590fdf5c06fe52d6c",
            "value": 1561415
          }
        },
        "6398eb464fa74b488684fad0fed265b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f071a366ed743c39c90f19494d0f409",
            "placeholder": "​",
            "style": "IPY_MODEL_0c85fd10258a4844a9a4521d3bf43885",
            "value": " 1.56M/1.56M [00:00&lt;00:00, 3.40MB/s]"
          }
        },
        "de4573e8306548a78be2d3b670675dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ca18c38fa6482ea258cadaa157237b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc0816b0179d4a64a8d3d3e18d06caa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56c974b738034c50b495ab931f3eef95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9916e3187d3488590fdf5c06fe52d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f071a366ed743c39c90f19494d0f409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c85fd10258a4844a9a4521d3bf43885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88d442047c574385be53cc08078927e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8d1bc4706fe422d9f465b2eca3ed5d4",
              "IPY_MODEL_1e467404879b4db89e8363bf4f7e43a4",
              "IPY_MODEL_4d3d4dbbe6ee4d2985a068884d1c8ae8"
            ],
            "layout": "IPY_MODEL_bfacb6f470c54cfcbc74c5c1b53897a6"
          }
        },
        "b8d1bc4706fe422d9f465b2eca3ed5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1daec2a6a19f43ffb1b6a428f53d97e4",
            "placeholder": "​",
            "style": "IPY_MODEL_6d85810f013640d9a7404929820d6694",
            "value": "merges.txt: 100%"
          }
        },
        "1e467404879b4db89e8363bf4f7e43a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8e560e491f4917b844798cca108eb1",
            "max": 895731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12e1e3fba1ac44e5965f6af7255c7286",
            "value": 895731
          }
        },
        "4d3d4dbbe6ee4d2985a068884d1c8ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8295ba0db6c84f5b957ad6beaf9d7040",
            "placeholder": "​",
            "style": "IPY_MODEL_efca43122d034434856fb35f36963d73",
            "value": " 896k/896k [00:00&lt;00:00, 42.4MB/s]"
          }
        },
        "bfacb6f470c54cfcbc74c5c1b53897a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1daec2a6a19f43ffb1b6a428f53d97e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d85810f013640d9a7404929820d6694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8e560e491f4917b844798cca108eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e1e3fba1ac44e5965f6af7255c7286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8295ba0db6c84f5b957ad6beaf9d7040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efca43122d034434856fb35f36963d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2642806dcd5f441d928bcd6c1014053f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52ec42cb1bfc47da9d49da5fa380c3e6",
              "IPY_MODEL_8ea60278b9cb4fef834ccab908c93700",
              "IPY_MODEL_9b0e64b8c82a46c88a4f1c91f0f93062"
            ],
            "layout": "IPY_MODEL_bb1153306e9b4fb9b795437b32da5642"
          }
        },
        "52ec42cb1bfc47da9d49da5fa380c3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2a397cfaa8d477db62b8f0872a4cdf9",
            "placeholder": "​",
            "style": "IPY_MODEL_a2fae01286a84d83a24ccb59989c7142",
            "value": "config.json: 100%"
          }
        },
        "8ea60278b9cb4fef834ccab908c93700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8da7be480e648dd8aa3a084e0394188",
            "max": 1496,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c960b4d5b3974468b8b1d3b3bc373b5f",
            "value": 1496
          }
        },
        "9b0e64b8c82a46c88a4f1c91f0f93062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63922b565d0d4ed28ca44a7a165b10d3",
            "placeholder": "​",
            "style": "IPY_MODEL_37ab7c45c1f14e35b7f79963d10ce395",
            "value": " 1.50k/1.50k [00:00&lt;00:00, 174kB/s]"
          }
        },
        "bb1153306e9b4fb9b795437b32da5642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a397cfaa8d477db62b8f0872a4cdf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2fae01286a84d83a24ccb59989c7142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8da7be480e648dd8aa3a084e0394188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c960b4d5b3974468b8b1d3b3bc373b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63922b565d0d4ed28ca44a7a165b10d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ab7c45c1f14e35b7f79963d10ce395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ac096e74dd34a6396b716c171ef2dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7a23612be20438884846a91aa726a99",
              "IPY_MODEL_d8381bbcefe446f2a88e59f3ac6eddc3",
              "IPY_MODEL_81888e73ca7d4e93ba80dce3e04824ce"
            ],
            "layout": "IPY_MODEL_9d8baf4217944d3e9c4e3dbe74bcdcb7"
          }
        },
        "d7a23612be20438884846a91aa726a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30f018bee4b14ac393a6560e438f3d7e",
            "placeholder": "​",
            "style": "IPY_MODEL_095ef07abcbd42939d1472cd4fdb8834",
            "value": "model.safetensors: 100%"
          }
        },
        "d8381bbcefe446f2a88e59f3ac6eddc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c933cc217688481b81a9ba27f0a53327",
            "max": 553227860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72535b242ae24d4894a66edfa6197c2d",
            "value": 553227860
          }
        },
        "81888e73ca7d4e93ba80dce3e04824ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a7ddb88d1c4b93b2c952a244af1188",
            "placeholder": "​",
            "style": "IPY_MODEL_3651e0b457b6419e97275160a1f62734",
            "value": " 553M/553M [00:03&lt;00:00, 200MB/s]"
          }
        },
        "9d8baf4217944d3e9c4e3dbe74bcdcb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f018bee4b14ac393a6560e438f3d7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095ef07abcbd42939d1472cd4fdb8834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c933cc217688481b81a9ba27f0a53327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72535b242ae24d4894a66edfa6197c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2a7ddb88d1c4b93b2c952a244af1188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3651e0b457b6419e97275160a1f62734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e455079d782c499ca98f78a9b89ccafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25981d34bcd943028702bb7bb8e717a1",
              "IPY_MODEL_9052d53cba8a4f79a52808dd0c9cd7d4",
              "IPY_MODEL_2babc4ae64934b8888c58872478999a1"
            ],
            "layout": "IPY_MODEL_92e6d97ecdd641d9a94345703b3f052a"
          }
        },
        "25981d34bcd943028702bb7bb8e717a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_426ecf9bcd624d018a8f90df0e033c00",
            "placeholder": "​",
            "style": "IPY_MODEL_b9fda17193df4b86a5d758dcdd5a4be5",
            "value": "Best trial: 54. Best value: 0.097395: 100%"
          }
        },
        "9052d53cba8a4f79a52808dd0c9cd7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_744857648ce0462e82d692bfe6a8cd4e",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dde4582ab7842b498e6b771dde02dee",
            "value": 200
          }
        },
        "2babc4ae64934b8888c58872478999a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5b4eee927e24e309f2493eafb6f77df",
            "placeholder": "​",
            "style": "IPY_MODEL_256db103db2547e5aa4fbd9d65fde207",
            "value": " 200/200 [00:03&lt;00:00, 55.99it/s]"
          }
        },
        "92e6d97ecdd641d9a94345703b3f052a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "426ecf9bcd624d018a8f90df0e033c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9fda17193df4b86a5d758dcdd5a4be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "744857648ce0462e82d692bfe6a8cd4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dde4582ab7842b498e6b771dde02dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5b4eee927e24e309f2493eafb6f77df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256db103db2547e5aa4fbd9d65fde207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bb1ec5a4fa64afc80cdf95acc8d2a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a17648f18c6489e853cff28038bc438",
              "IPY_MODEL_72331e7de505463e8b8ecb311e7ad540",
              "IPY_MODEL_8a5830f03165479684c2df2e274af4f6"
            ],
            "layout": "IPY_MODEL_c5fb723e2d2f4fba882855fa37035478"
          }
        },
        "8a17648f18c6489e853cff28038bc438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e343ee4f9acb4c11b9c236ac82decfac",
            "placeholder": "​",
            "style": "IPY_MODEL_1ccc75f2b6234829a7ae9f2aac8fbf8b",
            "value": "Best trial: 7. Best value: 0.965864: 100%"
          }
        },
        "72331e7de505463e8b8ecb311e7ad540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1de2c09621bf46fc93ccebfed40d7d98",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_687690832850490f85e884e6ff53e2d5",
            "value": 50
          }
        },
        "8a5830f03165479684c2df2e274af4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25ee4626ce6a42f48a10a49e109fcd0d",
            "placeholder": "​",
            "style": "IPY_MODEL_2051fec5c624465aaea6e7cccc9a5ee2",
            "value": " 50/50 [05:19&lt;00:00,  4.98s/it]"
          }
        },
        "c5fb723e2d2f4fba882855fa37035478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e343ee4f9acb4c11b9c236ac82decfac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ccc75f2b6234829a7ae9f2aac8fbf8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1de2c09621bf46fc93ccebfed40d7d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "687690832850490f85e884e6ff53e2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25ee4626ce6a42f48a10a49e109fcd0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2051fec5c624465aaea6e7cccc9a5ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c57b0cf67cf24b59a7d5a9e661ecee1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35ab650a5310460abdc1891088d7a088",
              "IPY_MODEL_ff918278e512433898183b2d48cffb84",
              "IPY_MODEL_6da7aff15c5a4fe58c86b7ededc8a487"
            ],
            "layout": "IPY_MODEL_84c62c43c2004eb4b99e37384c848474"
          }
        },
        "35ab650a5310460abdc1891088d7a088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da9e8314a1a4e13aee5fcd1cbae3388",
            "placeholder": "​",
            "style": "IPY_MODEL_60ba36e9556241eaac8713f2e8c94e9d",
            "value": "Best trial: 21. Best value: 0.966661: 100%"
          }
        },
        "ff918278e512433898183b2d48cffb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_563ca0f9ac9f4e03a5701f8f4d2e3354",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f35da0f88ac647c3bec4bb816577fe96",
            "value": 50
          }
        },
        "6da7aff15c5a4fe58c86b7ededc8a487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad8d72b7fa6a4159b0ecbcc3afb30008",
            "placeholder": "​",
            "style": "IPY_MODEL_8f728a81c4c64ffd817b96e23e8ca6a1",
            "value": " 50/50 [16:01&lt;00:00, 19.28s/it]"
          }
        },
        "84c62c43c2004eb4b99e37384c848474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da9e8314a1a4e13aee5fcd1cbae3388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60ba36e9556241eaac8713f2e8c94e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "563ca0f9ac9f4e03a5701f8f4d2e3354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35da0f88ac647c3bec4bb816577fe96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad8d72b7fa6a4159b0ecbcc3afb30008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f728a81c4c64ffd817b96e23e8ca6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1d3fa9bd79548928c3e4e909f7f4dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57c279f64bcd4833a3214543ed6bf05d",
              "IPY_MODEL_bd69695d261b470ea7f90b65798cfcca",
              "IPY_MODEL_01f3b828ed3241a18112aa9e18b01f69"
            ],
            "layout": "IPY_MODEL_622303db12a144839031c631c14c35e1"
          }
        },
        "57c279f64bcd4833a3214543ed6bf05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6487e4e90ec44745966106de5cf2edcc",
            "placeholder": "​",
            "style": "IPY_MODEL_f7d80b201bc9495fb8ae16a8f82bfe47",
            "value": "Best trial: 15. Best value: 0.0340034: 100%"
          }
        },
        "bd69695d261b470ea7f90b65798cfcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1845f4b29384daa9581038dfeaf5ac5",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee580faba59b4dbf8fc1d07877745c15",
            "value": 50
          }
        },
        "01f3b828ed3241a18112aa9e18b01f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_569e1347d586425e99b7fdf0e74cfb48",
            "placeholder": "​",
            "style": "IPY_MODEL_e791569ee01c4533888bc67a7673f37f",
            "value": " 50/50 [00:01&lt;00:00, 32.68it/s]"
          }
        },
        "622303db12a144839031c631c14c35e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6487e4e90ec44745966106de5cf2edcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d80b201bc9495fb8ae16a8f82bfe47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1845f4b29384daa9581038dfeaf5ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee580faba59b4dbf8fc1d07877745c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "569e1347d586425e99b7fdf0e74cfb48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e791569ee01c4533888bc67a7673f37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f4c843fd8d44d909f4cc5f7ef21f488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f18612751a745dda4717a910e7e950d",
              "IPY_MODEL_554c6572e73547c1a04886bc1f1e78b5",
              "IPY_MODEL_51a6e53f45cd421e881f873f83bb1f67"
            ],
            "layout": "IPY_MODEL_5764ee18f3274535a74a952dc9096f5a"
          }
        },
        "3f18612751a745dda4717a910e7e950d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_581c5396e1e1401fb91eddcae8ff93aa",
            "placeholder": "​",
            "style": "IPY_MODEL_126b4858c3c7443ea19182bfc874f80d",
            "value": "Best trial: 26. Best value: 0.966962: 100%"
          }
        },
        "554c6572e73547c1a04886bc1f1e78b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f003cb60fd2445ca777e72739974511",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da1cc9727ea542bb8ba86c30ef107a34",
            "value": 50
          }
        },
        "51a6e53f45cd421e881f873f83bb1f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_757b3e78ab5b40f7aed222e2b6de996f",
            "placeholder": "​",
            "style": "IPY_MODEL_ffc6bf7178a24cf6a580dd99a332f213",
            "value": " 50/50 [06:11&lt;00:00,  5.79s/it]"
          }
        },
        "5764ee18f3274535a74a952dc9096f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "581c5396e1e1401fb91eddcae8ff93aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "126b4858c3c7443ea19182bfc874f80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f003cb60fd2445ca777e72739974511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da1cc9727ea542bb8ba86c30ef107a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "757b3e78ab5b40f7aed222e2b6de996f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffc6bf7178a24cf6a580dd99a332f213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0a58d2288f04311a86b423384df1a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a51f028b2c148f8aecd5796c6f689a2",
              "IPY_MODEL_dca02eb6d54d447988b2ccc89e0719e5",
              "IPY_MODEL_947897e06a464e55a6ba84ba74a5ae10"
            ],
            "layout": "IPY_MODEL_f5fc211f96674bf099a9b2ea213b2d3f"
          }
        },
        "8a51f028b2c148f8aecd5796c6f689a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0371ffde5ab49bb9209e7a86b052763",
            "placeholder": "​",
            "style": "IPY_MODEL_2bcbee936a6e4945a02ef84ed6fb8194",
            "value": "Best trial: 26. Best value: 0.966157: 100%"
          }
        },
        "dca02eb6d54d447988b2ccc89e0719e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa401062448e41ff8d375684461a1be9",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba6b087b61864665958c80a88fbc0317",
            "value": 50
          }
        },
        "947897e06a464e55a6ba84ba74a5ae10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ffc32be611f47e6aac24ec697bc5637",
            "placeholder": "​",
            "style": "IPY_MODEL_81c836fd86904217952c76d0b6065cfb",
            "value": " 50/50 [15:54&lt;00:00, 19.13s/it]"
          }
        },
        "f5fc211f96674bf099a9b2ea213b2d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0371ffde5ab49bb9209e7a86b052763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bcbee936a6e4945a02ef84ed6fb8194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa401062448e41ff8d375684461a1be9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba6b087b61864665958c80a88fbc0317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ffc32be611f47e6aac24ec697bc5637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81c836fd86904217952c76d0b6065cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "043809372410486f85b81affdaa9013a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b13a580a65a045c18b74c316f10c705b",
              "IPY_MODEL_c1caa38f7eaa400bbe8b678601098327",
              "IPY_MODEL_972fd4f5b7744fb4a25550b9110654c0"
            ],
            "layout": "IPY_MODEL_5098f1d27071491989472544ae4c863f"
          }
        },
        "b13a580a65a045c18b74c316f10c705b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68506a9b303b487294785b68570401de",
            "placeholder": "​",
            "style": "IPY_MODEL_e5ead5d245fe4819bce164c5fbe9b21d",
            "value": "Best trial: 39. Best value: 0.0324798: 100%"
          }
        },
        "c1caa38f7eaa400bbe8b678601098327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c33e10a2ef634f55a88cd1a2e7ca7eb9",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f5fb5196fa642b085d8da27b6058323",
            "value": 50
          }
        },
        "972fd4f5b7744fb4a25550b9110654c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e9e8f4dfec749778f954878d0af2393",
            "placeholder": "​",
            "style": "IPY_MODEL_9b8231cdee23450eaf94ae5627e52d22",
            "value": " 50/50 [00:01&lt;00:00, 29.91it/s]"
          }
        },
        "5098f1d27071491989472544ae4c863f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68506a9b303b487294785b68570401de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ead5d245fe4819bce164c5fbe9b21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c33e10a2ef634f55a88cd1a2e7ca7eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5fb5196fa642b085d8da27b6058323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e9e8f4dfec749778f954878d0af2393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b8231cdee23450eaf94ae5627e52d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3aa289ff41a4531bc77e7f658bb551a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_385dbc0dbf544d61a0c783ca77324e66",
              "IPY_MODEL_d98e80d0823045aea9dc9c5d3f2d58df",
              "IPY_MODEL_0bfb5c91911f4698965162d880a8ef3d"
            ],
            "layout": "IPY_MODEL_ba433c21dde04a91bf88d6df41a3a746"
          }
        },
        "385dbc0dbf544d61a0c783ca77324e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7017f2d6cbf943d3a895b17cee26c709",
            "placeholder": "​",
            "style": "IPY_MODEL_6fbacec13c2944ad873431c1a95322cc",
            "value": "Best trial: 21. Best value: 0.966876: 100%"
          }
        },
        "d98e80d0823045aea9dc9c5d3f2d58df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04ac6856a2a4270862f197d0f85ca24",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e8d29b1be034d848fa843461c968a5a",
            "value": 50
          }
        },
        "0bfb5c91911f4698965162d880a8ef3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4124eec6426f432082244136014e905b",
            "placeholder": "​",
            "style": "IPY_MODEL_cb2bbe7f363d4dc892415c6526c3b1a4",
            "value": " 50/50 [05:59&lt;00:00,  5.11s/it]"
          }
        },
        "ba433c21dde04a91bf88d6df41a3a746": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7017f2d6cbf943d3a895b17cee26c709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fbacec13c2944ad873431c1a95322cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a04ac6856a2a4270862f197d0f85ca24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e8d29b1be034d848fa843461c968a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4124eec6426f432082244136014e905b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb2bbe7f363d4dc892415c6526c3b1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00a15e7b18de474fa1d27d75097a38fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46381340a51b4f06a545ec05e3d2592f",
              "IPY_MODEL_c164819badb448299adee6f96a26455b",
              "IPY_MODEL_91491491f638499cb0cbc4d7e36ac9bd"
            ],
            "layout": "IPY_MODEL_7a734d09305747e68d0d1fd38915b809"
          }
        },
        "46381340a51b4f06a545ec05e3d2592f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50411bda86e741a5b5429d2689443d21",
            "placeholder": "​",
            "style": "IPY_MODEL_e432d1c021bb4d0f8254040602b5ca91",
            "value": "Best trial: 16. Best value: 0.967432: 100%"
          }
        },
        "c164819badb448299adee6f96a26455b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cdf871277214c5d923c1f4fe8bb1d6c",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_050ee6fff3da40f4b6d14aa694cd8d83",
            "value": 50
          }
        },
        "91491491f638499cb0cbc4d7e36ac9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_561f8a89045d451da15051f9fb08aaec",
            "placeholder": "​",
            "style": "IPY_MODEL_fdcc55ba850b443e9729fa1ae3fac12a",
            "value": " 50/50 [15:57&lt;00:00, 19.14s/it]"
          }
        },
        "7a734d09305747e68d0d1fd38915b809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50411bda86e741a5b5429d2689443d21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e432d1c021bb4d0f8254040602b5ca91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cdf871277214c5d923c1f4fe8bb1d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "050ee6fff3da40f4b6d14aa694cd8d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "561f8a89045d451da15051f9fb08aaec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdcc55ba850b443e9729fa1ae3fac12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28226bd4cc064e0c8807545b5b56e65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc6fe0d40acd44caa718114b0753244d",
              "IPY_MODEL_e254438f437545ef8bffb856fe3a213d",
              "IPY_MODEL_6ac7f6de3cff4c09b55406377f92d548"
            ],
            "layout": "IPY_MODEL_05e184a9c15e43afa09314b3c8fd4488"
          }
        },
        "bc6fe0d40acd44caa718114b0753244d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bbf704d1e5e48648a41e3a4d5f79751",
            "placeholder": "​",
            "style": "IPY_MODEL_4f22d26fb7a7412db2c8453db8070825",
            "value": "Best trial: 11. Best value: 0.0319863: 100%"
          }
        },
        "e254438f437545ef8bffb856fe3a213d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebc0ba69a5984af596d087b3b19c28a5",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c00f0a6bebab482d8f2559c0e67e5fda",
            "value": 50
          }
        },
        "6ac7f6de3cff4c09b55406377f92d548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_036072bf92a947d2b3ef21a4a5dff84e",
            "placeholder": "​",
            "style": "IPY_MODEL_e3630300f43e4473987c65f1bcbcc040",
            "value": " 50/50 [00:01&lt;00:00, 25.81it/s]"
          }
        },
        "05e184a9c15e43afa09314b3c8fd4488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bbf704d1e5e48648a41e3a4d5f79751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f22d26fb7a7412db2c8453db8070825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebc0ba69a5984af596d087b3b19c28a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c00f0a6bebab482d8f2559c0e67e5fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "036072bf92a947d2b3ef21a4a5dff84e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3630300f43e4473987c65f1bcbcc040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "239fc6bd2c7f4b689e30df85dbc10a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1621be6933f46dba3bbd0b71239b53d",
              "IPY_MODEL_693c1f01256a4256ba73a2380d231c8b",
              "IPY_MODEL_36583cfadc774557a6cec76b8515d5e4"
            ],
            "layout": "IPY_MODEL_165a6213166746e4a7fd7b5d994efa60"
          }
        },
        "c1621be6933f46dba3bbd0b71239b53d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa3bf221e3ab4d4d918ab8288ffd8469",
            "placeholder": "​",
            "style": "IPY_MODEL_bd067320db154f4eaeb4dc0d7d38355a",
            "value": "Best trial: 48. Best value: 0.965036: 100%"
          }
        },
        "693c1f01256a4256ba73a2380d231c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f621170872c14126aebae6ca70b83545",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2504765652614d8da3d528fb2a8a9d60",
            "value": 50
          }
        },
        "36583cfadc774557a6cec76b8515d5e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d3f4d9272364e7ab2d5d26af4a7899f",
            "placeholder": "​",
            "style": "IPY_MODEL_be659209bef143118c7ffc7f4bfeaf2e",
            "value": " 50/50 [05:40&lt;00:00,  6.39s/it]"
          }
        },
        "165a6213166746e4a7fd7b5d994efa60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa3bf221e3ab4d4d918ab8288ffd8469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd067320db154f4eaeb4dc0d7d38355a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f621170872c14126aebae6ca70b83545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2504765652614d8da3d528fb2a8a9d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d3f4d9272364e7ab2d5d26af4a7899f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be659209bef143118c7ffc7f4bfeaf2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6041e89c2f044fb9aa0f53a6cc4a5ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_899142504e69441a884881729f63e118",
              "IPY_MODEL_626329dd68d24e3691300ca670c0b1b1",
              "IPY_MODEL_0ac023b0441b479cbb764408c182c2a0"
            ],
            "layout": "IPY_MODEL_c121bb9edbbd41848e06edab66f0f693"
          }
        },
        "899142504e69441a884881729f63e118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ab25f8c68814d38bd1c1a00ff48b386",
            "placeholder": "​",
            "style": "IPY_MODEL_b23e2e331cd2437aaac200e635874640",
            "value": "Best trial: 41. Best value: 0.965857: 100%"
          }
        },
        "626329dd68d24e3691300ca670c0b1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59afcbc8e2b34f27bd5e2d3bea6f9924",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e564509233784f5697798ba117ffdcb2",
            "value": 50
          }
        },
        "0ac023b0441b479cbb764408c182c2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2347cea7e7448fabfe99d6a2a3f7349",
            "placeholder": "​",
            "style": "IPY_MODEL_b2fd2366b4ce4e1f84435ca9f9b6e7d6",
            "value": " 50/50 [16:03&lt;00:00, 19.22s/it]"
          }
        },
        "c121bb9edbbd41848e06edab66f0f693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ab25f8c68814d38bd1c1a00ff48b386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b23e2e331cd2437aaac200e635874640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59afcbc8e2b34f27bd5e2d3bea6f9924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e564509233784f5697798ba117ffdcb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2347cea7e7448fabfe99d6a2a3f7349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2fd2366b4ce4e1f84435ca9f9b6e7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44cb2970f0cc4eb98202540520886fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd80bdc68b184b02aa0e6bc64cfc8172",
              "IPY_MODEL_17db1ee1ec9240a08657d3cda7610923",
              "IPY_MODEL_df0dc4caa8a44560a382ba7917ee2b34"
            ],
            "layout": "IPY_MODEL_541d85d39882477db6ea45cf76a77cef"
          }
        },
        "bd80bdc68b184b02aa0e6bc64cfc8172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d66cda952a614ad8aa3e7f92938b8c60",
            "placeholder": "​",
            "style": "IPY_MODEL_4d199324a80241f68d7d93649f663ff3",
            "value": "Best trial: 2. Best value: 0.0339196: 100%"
          }
        },
        "17db1ee1ec9240a08657d3cda7610923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69ac660e4590445f919e4622fde20478",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_483b2fcc0bde46628820798f207ef05d",
            "value": 50
          }
        },
        "df0dc4caa8a44560a382ba7917ee2b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af540026cd8c419882b768ed842bf3a7",
            "placeholder": "​",
            "style": "IPY_MODEL_fcdba08288ea4c87b3ae42090cd46274",
            "value": " 50/50 [00:01&lt;00:00, 29.99it/s]"
          }
        },
        "541d85d39882477db6ea45cf76a77cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d66cda952a614ad8aa3e7f92938b8c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d199324a80241f68d7d93649f663ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69ac660e4590445f919e4622fde20478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "483b2fcc0bde46628820798f207ef05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af540026cd8c419882b768ed842bf3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcdba08288ea4c87b3ae42090cd46274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fd3be0a114b46bca7b5f754609d697c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1ccc8b550a44ec88a18b4627dd451cd",
              "IPY_MODEL_62370000579a458a97d495fb7730fe06",
              "IPY_MODEL_c7ed38c754df442d9e6faa538c8fd12d"
            ],
            "layout": "IPY_MODEL_9da0389370194f898f09f61876b49a9b"
          }
        },
        "b1ccc8b550a44ec88a18b4627dd451cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fe856284778430d82d06383ea605d29",
            "placeholder": "​",
            "style": "IPY_MODEL_aa8aaa5f9f83468b855743707941a608",
            "value": "Best trial: 48. Best value: 0.964197: 100%"
          }
        },
        "62370000579a458a97d495fb7730fe06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_755c8fd404784eadb231c4e107459c6a",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a732976294c459796058549502e6265",
            "value": 50
          }
        },
        "c7ed38c754df442d9e6faa538c8fd12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bd375929cde4a6aa1e840c92d992e56",
            "placeholder": "​",
            "style": "IPY_MODEL_cbba199a33d646e582269a4ec2317597",
            "value": " 50/50 [06:46&lt;00:00,  5.07s/it]"
          }
        },
        "9da0389370194f898f09f61876b49a9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fe856284778430d82d06383ea605d29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa8aaa5f9f83468b855743707941a608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "755c8fd404784eadb231c4e107459c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a732976294c459796058549502e6265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bd375929cde4a6aa1e840c92d992e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbba199a33d646e582269a4ec2317597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc804e5993b1478e9efa28403a9c894e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ee9a219fdb24aa2b6088906b324f384",
              "IPY_MODEL_26568db2b1074ed4bff4426fd08143dd",
              "IPY_MODEL_58ca2543c6af462c810622a3b267a41f"
            ],
            "layout": "IPY_MODEL_c05e1649d14f44298b0b98747220db54"
          }
        },
        "4ee9a219fdb24aa2b6088906b324f384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c919a2b49db44bd2bc29be18a0f9e188",
            "placeholder": "​",
            "style": "IPY_MODEL_cfe013ceb1824f17b5176ec5e509e40e",
            "value": "Best trial: 21. Best value: 0.964298: 100%"
          }
        },
        "26568db2b1074ed4bff4426fd08143dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7c6a566e1574a37958959c8949d79f2",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f81951d21d843a39ed732dcbcc737aa",
            "value": 50
          }
        },
        "58ca2543c6af462c810622a3b267a41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40c2e593bd4544c8bbe10806ea592c2f",
            "placeholder": "​",
            "style": "IPY_MODEL_fdea5a997d1041b0a4732b0b8865dc1a",
            "value": " 50/50 [16:00&lt;00:00, 19.24s/it]"
          }
        },
        "c05e1649d14f44298b0b98747220db54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c919a2b49db44bd2bc29be18a0f9e188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe013ceb1824f17b5176ec5e509e40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7c6a566e1574a37958959c8949d79f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f81951d21d843a39ed732dcbcc737aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40c2e593bd4544c8bbe10806ea592c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdea5a997d1041b0a4732b0b8865dc1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "417c04caaf634982994a83128099f473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46ecb456095c45c5879234405240cdd2",
              "IPY_MODEL_e7f61c70fd4e403db98608bf3caed6eb",
              "IPY_MODEL_9085b0d9020b46518b8980d00395e1dd"
            ],
            "layout": "IPY_MODEL_63f3d84f319c415684233804a800ea58"
          }
        },
        "46ecb456095c45c5879234405240cdd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ecd7787a6a944af905bcefd119c8b88",
            "placeholder": "​",
            "style": "IPY_MODEL_ccb9a11cfab64d83bef972528ac5e228",
            "value": "Best trial: 45. Best value: 0.0346649: 100%"
          }
        },
        "e7f61c70fd4e403db98608bf3caed6eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c92fbaa87ec41f4b1b1094d84c6f7ca",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42be92c3ed2940a898e07e2030027ea1",
            "value": 50
          }
        },
        "9085b0d9020b46518b8980d00395e1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_584a42c414524d24add2576c49bb0605",
            "placeholder": "​",
            "style": "IPY_MODEL_c6c8604ad27e4280846c8086a8cff2df",
            "value": " 50/50 [00:01&lt;00:00, 29.59it/s]"
          }
        },
        "63f3d84f319c415684233804a800ea58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ecd7787a6a944af905bcefd119c8b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccb9a11cfab64d83bef972528ac5e228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c92fbaa87ec41f4b1b1094d84c6f7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42be92c3ed2940a898e07e2030027ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "584a42c414524d24add2576c49bb0605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c8604ad27e4280846c8086a8cff2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7716b75be3c34cdb8bea71f66e9c3504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f35d7ca21d4d4584af32ff2539994a08",
              "IPY_MODEL_c74e8e573e6b4dbf9ba65c6666c65bd9",
              "IPY_MODEL_40e3ea274a28476c81cfc53e8feb50f2"
            ],
            "layout": "IPY_MODEL_e468fb4aedfc4ee4a3f9bbffde35295e"
          }
        },
        "f35d7ca21d4d4584af32ff2539994a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0840086fee55462e8b31c6eb73ca3750",
            "placeholder": "​",
            "style": "IPY_MODEL_471bea78c3a34f0b9ede50568d0db46b",
            "value": "Best trial: 70. Best value: 0.903084: 100%"
          }
        },
        "c74e8e573e6b4dbf9ba65c6666c65bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce5a60ed28324f3085688aa47b0bd87f",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a592945d6574ce883f5fc354d1cc7b4",
            "value": 100
          }
        },
        "40e3ea274a28476c81cfc53e8feb50f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1af2a3e7e9364be09592aeac74f19121",
            "placeholder": "​",
            "style": "IPY_MODEL_8f770e7aea3340efa8cc789f4de70353",
            "value": " 100/100 [14:52&lt;00:00,  4.03s/it]"
          }
        },
        "e468fb4aedfc4ee4a3f9bbffde35295e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0840086fee55462e8b31c6eb73ca3750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471bea78c3a34f0b9ede50568d0db46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce5a60ed28324f3085688aa47b0bd87f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a592945d6574ce883f5fc354d1cc7b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1af2a3e7e9364be09592aeac74f19121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f770e7aea3340efa8cc789f4de70353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36c5ea9fd5ad4054971613e27773d31c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_725c302771ba4f16b95c98867a1384ea",
              "IPY_MODEL_bf53b69de8e249669715c3013dc84c9d",
              "IPY_MODEL_611b4750f5d044f7ac1ce3f18fb0a033"
            ],
            "layout": "IPY_MODEL_2dfbdc0776cd47a69a2083c2d3970b80"
          }
        },
        "725c302771ba4f16b95c98867a1384ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c342d2bd47a74cb788ea6f3cbff1118e",
            "placeholder": "​",
            "style": "IPY_MODEL_336eb8f5075f43e087aae24bfdec9a21",
            "value": "Best trial: 16. Best value: 0.901305: 100%"
          }
        },
        "bf53b69de8e249669715c3013dc84c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66582595c6814b1ab642dfa93633c45e",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6048dcfa001247d0b04ddcc9b1bb7eb3",
            "value": 100
          }
        },
        "611b4750f5d044f7ac1ce3f18fb0a033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb898e09a2c74b95a25abf29535a9fd2",
            "placeholder": "​",
            "style": "IPY_MODEL_b57bea9ab0a347e68070f0c8c0f49139",
            "value": " 100/100 [38:12&lt;00:00, 23.01s/it]"
          }
        },
        "2dfbdc0776cd47a69a2083c2d3970b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c342d2bd47a74cb788ea6f3cbff1118e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "336eb8f5075f43e087aae24bfdec9a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66582595c6814b1ab642dfa93633c45e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6048dcfa001247d0b04ddcc9b1bb7eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb898e09a2c74b95a25abf29535a9fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b57bea9ab0a347e68070f0c8c0f49139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7c9d430235f4ef593213008ab5c5ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1165da476854ee6b38afc3206c3c097",
              "IPY_MODEL_85bdae8dd4f644fa9237a42e5f2c626c",
              "IPY_MODEL_23da79a271ec4f7990d1ed5e654c72c7"
            ],
            "layout": "IPY_MODEL_f04be76e61694685aae5724cca61df39"
          }
        },
        "d1165da476854ee6b38afc3206c3c097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc8fb0c23494436a8222b7d3b0c291e0",
            "placeholder": "​",
            "style": "IPY_MODEL_2d9b5eb007b0441bb188e8d4cf8376ba",
            "value": "Best trial: 66. Best value: 0.0961911: 100%"
          }
        },
        "85bdae8dd4f644fa9237a42e5f2c626c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe22b55fbac4480397dacf107e972bf4",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82bed2a355aa42aebaa46027c338128f",
            "value": 100
          }
        },
        "23da79a271ec4f7990d1ed5e654c72c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad6baa3d828945e19b3662661b437129",
            "placeholder": "​",
            "style": "IPY_MODEL_059903f785194f55b3bf93c4ff375084",
            "value": " 100/100 [00:03&lt;00:00, 26.94it/s]"
          }
        },
        "f04be76e61694685aae5724cca61df39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc8fb0c23494436a8222b7d3b0c291e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9b5eb007b0441bb188e8d4cf8376ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe22b55fbac4480397dacf107e972bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82bed2a355aa42aebaa46027c338128f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad6baa3d828945e19b3662661b437129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "059903f785194f55b3bf93c4ff375084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwmWBN0ib8gD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff505a34-e66c-4d8a-a77f-aca6adab0867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Définir les chemins pour les fichiers source sur Google Drive et destination locale\n",
        "\n",
        "X_trein_french = '/content/drive/MyDrive/Colab Notebooks/fahim/final/X_trainfr_final.csv'\n",
        "\n",
        "# Définir les chemins locaux pour stocker les fichiers copiés\n",
        "local_path = '/content/data/'\n",
        "\n",
        "# Créer le dossier local si ce n'est pas déjà fait\n",
        "os.makedirs(local_path, exist_ok=True)\n",
        "\n",
        "# Copier les fichiers de Google Drive vers l'espace local de Colab\n",
        "\n",
        "shutil.copy(X_trein_french, local_path)\n",
        "\n",
        "# Vérifier que les fichiers ont été copiés correctement\n",
        "print(\"Fichiers copiés dans l'espace local de Colab.\")\n",
        "print(os.listdir(local_path))"
      ],
      "metadata": {
        "id": "-NlDHQdGfSAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc9349dd-73a0-4d4c-a63f-80fa2406e080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fichiers copiés dans l'espace local de Colab.\n",
            "['X_trainfr_final.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "avWq2-TImxLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8f7d05-aad7-4258-d6ac-f843845d5a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses) (2024.11.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sacremoses) (4.67.1)\n",
            "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/897.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/897.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m737.3/897.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== ENTRAINEMENT CAMEMBERT ===\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import (\n",
        "    CamembertTokenizer,\n",
        "    CamembertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    EarlyStoppingCallback,\n",
        "    set_seed,\n",
        "    TrainerCallback\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import gc\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BASE = \"/content/drive/MyDrive/Colab Notebooks/fahim/final\"\n",
        "os.makedirs(BASE + \"/models\", exist_ok=True)\n",
        "os.makedirs(\"./results_cam\", exist_ok=True)\n",
        "print(f\"Device utilisé: {device}\")\n",
        "\n",
        "# Chargement des données et labels\n",
        "df = pd.read_csv(os.path.join(BASE, \"X_trainfr_finalCollab.csv\"))\n",
        "le = joblib.load(os.path.join(BASE, 'label_encoder_final.pkl'))\n",
        "texts = df['translated_text_combined'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "with open(os.path.join(BASE, 'val_indices.json'), 'r') as f:\n",
        "    val_idx = np.array(json.load(f), dtype=int)\n",
        "train_idx = np.setdiff1d(np.arange(len(df)), val_idx)\n",
        "print(f\"Train: {len(train_idx)}, Validation: {len(val_idx)}\")\n",
        "\n",
        "# Calculer les poids de classe pour CrossEntropyLoss\n",
        "class_weights_np = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights_np, dtype=torch.float).to(device)\n",
        "\n",
        "# Dataset PyTorch personnalisé\n",
        "class TextDS(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, i):\n",
        "        item = {k: v[i] for k, v in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[i], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# Trainer pondéré CrossEntropy\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Fonction métriques détaillées\n",
        "def compute_metrics_detailed(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(axis=1)\n",
        "    f1_per_class = f1_score(labels, preds, average=None)\n",
        "    f1_macro = f1_score(labels, preds, average=\"macro\")\n",
        "    f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    class_perf = {f\"f1_class_{i}_{le.classes_[i]}\": f1 for i, f1 in enumerate(f1_per_class)}\n",
        "    return {\n",
        "        \"f1_weighted\": f1_weighted,\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"accuracy\": accuracy,\n",
        "        **class_perf\n",
        "    }\n",
        "\n",
        "# Callback affichage métriques par epoch (texte)\n",
        "class DetailedLoggingCallback(TrainerCallback):\n",
        "    def __init__(self, le_classes):\n",
        "        self.le_classes = le_classes\n",
        "        self.best_f1 = 0\n",
        "    def on_evaluate(self, args, state, control, model=None, eval_dataloader=None, **kwargs):\n",
        "        if state.epoch is not None and state.epoch == int(state.epoch):\n",
        "            current_epoch = int(state.epoch)\n",
        "            if hasattr(state, 'log_history') and state.log_history:\n",
        "                last_eval = next((log for log in reversed(state.log_history) if 'eval_f1_weighted' in log), None)\n",
        "                if last_eval:\n",
        "                    current_f1 = last_eval.get('eval_f1_weighted', 0)\n",
        "                    print(f\"\\nEPOCH {current_epoch} - RÉSULTATS DÉTAILLÉS:\")\n",
        "                    print(f\"  F1-weighted: {current_f1:.4f} {' NOUVEAU RECORD!' if current_f1 > self.best_f1 else ''}\")\n",
        "                    print(f\"  F1-macro: {last_eval.get('eval_f1_macro', 0):.4f}\")\n",
        "                    print(f\"  Accuracy: {last_eval.get('eval_accuracy', 0):.4f}\")\n",
        "                    print(f\"  Eval Loss: {last_eval.get('eval_loss', 0):.4f}\")\n",
        "                    if current_f1 > self.best_f1:\n",
        "                        self.best_f1 = current_f1\n",
        "                    weak_classes = [f\"{key.split('_')[-1]}: {value:.3f}\" for key, value in last_eval.items() if key.startswith('eval_f1_class_') and value < 0.5]\n",
        "                    if weak_classes:\n",
        "                        print(f\" Classes faibles: {', '.join(weak_classes[:3])}\")\n",
        "\n",
        "# Callback pour collecter et afficher les courbes métriques à la fin\n",
        "class PlotMetricsCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.epochs = []\n",
        "        self.train_losses = []\n",
        "        self.eval_losses = []\n",
        "        self.f1_weighteds = []\n",
        "        self.accuracies = []\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is None or 'epoch' not in logs:\n",
        "            return\n",
        "        self.epochs.append(logs['epoch'])\n",
        "        self.train_losses.append(logs.get('loss') or logs.get('train_loss'))\n",
        "        self.eval_losses.append(logs.get('eval_loss'))\n",
        "        self.f1_weighteds.append(logs.get('eval_f1_weighted'))\n",
        "        self.accuracies.append(logs.get('eval_accuracy'))\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        if not self.epochs:\n",
        "            print(\"Aucune donnée métrique collectée.\")\n",
        "            return\n",
        "        plt.figure(figsize=(14,10))\n",
        "        plt.subplot(2,2,1)\n",
        "        plt.plot(self.epochs, self.train_losses, label='Train Loss')\n",
        "        plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Train Loss'); plt.grid(True); plt.legend()\n",
        "        plt.subplot(2,2,2)\n",
        "        plt.plot(self.epochs, self.eval_losses, label='Eval Loss', color='orange')\n",
        "        plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Eval Loss'); plt.grid(True); plt.legend()\n",
        "        plt.subplot(2,2,3)\n",
        "        plt.plot(self.epochs, self.f1_weighteds, label='F1 Weighted', color='green')\n",
        "        plt.xlabel('Epoch'); plt.ylabel('F1 Weighted'); plt.title('F1 Weighted'); plt.grid(True); plt.legend()\n",
        "        plt.subplot(2,2,4)\n",
        "        plt.plot(self.epochs, self.accuracies, label='Accuracy', color='red')\n",
        "        plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy'); plt.grid(True); plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Initialisation tokenizer + datasets + splits\n",
        "cam_tok = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "full_cam = TextDS(texts, labels, cam_tok, max_length=512)\n",
        "train_cam = Subset(full_cam, train_idx)\n",
        "val_cam = Subset(full_cam, val_idx)\n",
        "\n",
        "num_labels = len(le.classes_)\n",
        "\n",
        "# Chargement modèle Camembert\n",
        "model = CamembertForSequenceClassification.from_pretrained(\n",
        "    \"camembert-base\",\n",
        "    num_labels=num_labels,\n",
        "    hidden_dropout_prob=0.3,\n",
        "    attention_probs_dropout_prob=0.3\n",
        ").to(device)\n",
        "\n",
        "# Arguments entraînement avec tes anciens paramètres\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_cam\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=96,\n",
        "    num_train_epochs=50,\n",
        "    weight_decay=0.1,\n",
        "    warmup_steps=500,\n",
        "    lr_scheduler_type=\"cosine_with_restarts\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_weighted\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    gradient_accumulation_steps=1,\n",
        "    max_grad_norm=1.0,\n",
        "    dataloader_num_workers=16,\n",
        "    dataloader_pin_memory=False,\n",
        "    save_total_limit=3,\n",
        "    fp16=True,\n",
        "    dataloader_persistent_workers=True,\n",
        "    dataloader_prefetch_factor=4,\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStoppingCallback(\n",
        "    early_stopping_patience=8,\n",
        "    early_stopping_threshold=0.0005\n",
        ")\n",
        "\n",
        "plot_metrics = PlotMetricsCallback()\n",
        "detailed_logging = DetailedLoggingCallback(le.classes_)\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_cam,\n",
        "    eval_dataset=val_cam,\n",
        "    data_collator=DataCollatorWithPadding(cam_tok),\n",
        "    compute_metrics=compute_metrics_detailed,\n",
        "    callbacks=[early_stopping, detailed_logging, plot_metrics]\n",
        ")\n",
        "\n",
        "print(\"\\n=== DÉBUT DE L'ENTRAÎNEMENT CAMEMBERT ===\")\n",
        "trainer.train()\n",
        "\n",
        "best_checkpoint = trainer.state.best_model_checkpoint\n",
        "print(f\"Meilleur checkpoint : {best_checkpoint}\")\n",
        "\n",
        "# Sauvegarde du modèle\n",
        "best_model = CamembertForSequenceClassification.from_pretrained(best_checkpoint)\n",
        "best_model.save_pretrained(os.path.join(BASE, \"camembert2_model\"))\n",
        "\n",
        "# Sauvegarde des logits complets\n",
        "print(\"\\n=== SAUVEGARDE DES LOGITS ET LABELS COMPLETS ===\")\n",
        "cam_logits = trainer.predict(full_cam).predictions\n",
        "torch.save(torch.tensor(cam_logits), os.path.join(BASE, \"camembert2_logits.pt\"))\n",
        "\n",
        "print(\"\\n=== RAPPORT DE CLASSIFICATION FINAL SUR VALIDATION ===\")\n",
        "with open(os.path.join(BASE, \"label_mapping_final.json\"), \"r\") as f:\n",
        "    label_mapping = json.load(f)\n",
        "class_names = [label_mapping[str(i)][\"label_name\"] for i in range(len(label_mapping))]\n",
        "\n",
        "predictions = trainer.predict(val_cam)\n",
        "preds = predictions.predictions.argmax(axis=1)\n",
        "labels_val = predictions.label_ids\n",
        "print(classification_report(labels_val, preds, target_names=class_names))\n",
        "\n",
        "# Nettoyage mémoire\n",
        "del trainer, model, best_model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"\\n=== ENTRAÎNEMENT CAMEMBERT TERMINÉ ===\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "61313f60e32f472dabaf4e3359f5d5bf",
            "b1a5dfeeef874dea8f13917fe5f230bc",
            "fba9e01e8aea49d8b8525f7a25cc783d",
            "8a320124ec614f22a68460e4b8ec1478",
            "a699e7e67a904945a7323be8cca911d1",
            "1e13081aede444a6be5c73f398f522cc",
            "f4e69bbd58214bc6b214591f8893da66",
            "e02d46c6f0b14d0bb5c50e8be70dbe21",
            "9d2f1ffbe41648e9887ace8247f3274b",
            "299d870982c94d24a3b059de5ce84d4d",
            "5f48b36d0b8944978a9b78c672cd092f",
            "eecd9f9ac25141a9bd0777887cb33d7f",
            "3ad3ab9ccef64c408eea809afb7aa30b",
            "3fb0fcf05c214c2f9c3776e3d3320c59",
            "d3db0e2676b94966ac5f809b7be8eb13",
            "91a4d37c575840339f4e59f9c3bdd6fd",
            "1ef7c7cfeb234f7c9e94c3c19aebec28",
            "850bdd0b4b7a444c978c5ff22da6f0e4",
            "77eb5f4f7d994b14a4b6aadb66f0b19c",
            "6f6e09fb777f4f7dbfdfe3e1be6e2047",
            "7646c179f2884009b5a937dad192cf2c",
            "7353f7b643524ce3b5b5800cd70b027e",
            "efebe00af2d74c72b6cd900422c7e0ff",
            "7afbb240534f41c5bd321156045eaacd",
            "c974d28be2d34d49a91098d6f86da04e",
            "51cd090672174645a125e59fbc19b9b6",
            "5a3aae5999854d2d8afd1e419a6309b7",
            "a80097b9f2244fb0b4d2114c5aca781b",
            "876a02eb0f1f40819095d4a7341ca7ac",
            "8e4cac2e3aca433a9ff02a411293f8ef",
            "11f0527cb37447fe8e3fa59b34d037cc",
            "3dd7c561ea4b4601a925bf346ce85876",
            "2f23f20ca48040ec8b41a35ef4edf596",
            "1cf192631e3e406b88920ddeb70fb9bc",
            "1b82512f20f243e0b9b418222565d95e",
            "3741a177f9c1441e82e45ec113a2a78e",
            "0d9cf78259ec49b3b8b3f43a591aa198",
            "6bafd113898541a194826cfde7550e6e",
            "2277dbd38b8a43eba940356aab330e97",
            "c6019bd0cf2b492bb6e2cbb897b3e737",
            "16c00adaffb34426b6cb6728d037d07b",
            "fc07d8706cac4ec7b088af5b3e49c0b9",
            "737a4fab8f634a849b72749b74397498",
            "a5811802cf2f4a20917e4eaf7a81c9f9",
            "65b22565b5c449dc8bb1a3c0afeefc29",
            "db2041ea7a034d618b75d9bec3d505ff",
            "51159bfc46c74617bb51f2f5215f8074",
            "5f1fa2c96d5a46e79ed4cf816d2a77f4",
            "20386684ac6d4fe5bcb0768ea3ebdac0",
            "317cc458abe8481b8975ff5624b9cee8",
            "e1c9194d4e0242fea8b5af3d94212731",
            "0a9bdf15113844dab6eafe897252b0f0",
            "c32819e9b1094c05bfffde7b63b4251e",
            "513d4098fdaf437cba4276ce69194307",
            "bd344cb63a7146caa95681f89f5bc7d1"
          ]
        },
        "id": "mw6rME4TT8mX",
        "outputId": "7ed0b71f-6a26-4f0d-e973-735fa543f197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device utilisé: cuda\n",
            "Train: 74447, Validation: 13138\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61313f60e32f472dabaf4e3359f5d5bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eecd9f9ac25141a9bd0777887cb33d7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efebe00af2d74c72b6cd900422c7e0ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cf192631e3e406b88920ddeb70fb9bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65b22565b5c449dc8bb1a3c0afeefc29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DÉBUT DE L'ENTRAÎNEMENT CAMEMBERT ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='58200' max='58200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [58200/58200 15:05:20, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Class 0 10</th>\n",
              "      <th>F1 Class 1 40</th>\n",
              "      <th>F1 Class 2 50</th>\n",
              "      <th>F1 Class 3 60</th>\n",
              "      <th>F1 Class 4 1140</th>\n",
              "      <th>F1 Class 5 1160</th>\n",
              "      <th>F1 Class 6 1180</th>\n",
              "      <th>F1 Class 7 1280</th>\n",
              "      <th>F1 Class 8 1281</th>\n",
              "      <th>F1 Class 9 1300</th>\n",
              "      <th>F1 Class 10 1301</th>\n",
              "      <th>F1 Class 11 1302</th>\n",
              "      <th>F1 Class 12 1320</th>\n",
              "      <th>F1 Class 13 1560</th>\n",
              "      <th>F1 Class 14 1920</th>\n",
              "      <th>F1 Class 15 1940</th>\n",
              "      <th>F1 Class 16 2060</th>\n",
              "      <th>F1 Class 17 2220</th>\n",
              "      <th>F1 Class 18 2280</th>\n",
              "      <th>F1 Class 19 2403</th>\n",
              "      <th>F1 Class 20 2462</th>\n",
              "      <th>F1 Class 21 2522</th>\n",
              "      <th>F1 Class 22 2582</th>\n",
              "      <th>F1 Class 23 2583</th>\n",
              "      <th>F1 Class 24 2585</th>\n",
              "      <th>F1 Class 25 2705</th>\n",
              "      <th>F1 Class 26 2905</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.889900</td>\n",
              "      <td>2.148369</td>\n",
              "      <td>0.488571</td>\n",
              "      <td>0.438182</td>\n",
              "      <td>0.534556</td>\n",
              "      <td>0.365782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156863</td>\n",
              "      <td>0.439791</td>\n",
              "      <td>0.482372</td>\n",
              "      <td>0.530581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.432836</td>\n",
              "      <td>0.181303</td>\n",
              "      <td>0.780544</td>\n",
              "      <td>0.549112</td>\n",
              "      <td>0.221176</td>\n",
              "      <td>0.113553</td>\n",
              "      <td>0.499074</td>\n",
              "      <td>0.703660</td>\n",
              "      <td>0.813187</td>\n",
              "      <td>0.619539</td>\n",
              "      <td>0.673392</td>\n",
              "      <td>0.643678</td>\n",
              "      <td>0.457055</td>\n",
              "      <td>0.093506</td>\n",
              "      <td>0.809171</td>\n",
              "      <td>0.211416</td>\n",
              "      <td>0.784658</td>\n",
              "      <td>0.284024</td>\n",
              "      <td>0.604959</td>\n",
              "      <td>0.379679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.846700</td>\n",
              "      <td>1.378304</td>\n",
              "      <td>0.656000</td>\n",
              "      <td>0.634030</td>\n",
              "      <td>0.678109</td>\n",
              "      <td>0.541555</td>\n",
              "      <td>0.174840</td>\n",
              "      <td>0.694524</td>\n",
              "      <td>0.827586</td>\n",
              "      <td>0.549320</td>\n",
              "      <td>0.732516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.503096</td>\n",
              "      <td>0.471910</td>\n",
              "      <td>0.835244</td>\n",
              "      <td>0.657005</td>\n",
              "      <td>0.542314</td>\n",
              "      <td>0.377976</td>\n",
              "      <td>0.654624</td>\n",
              "      <td>0.806711</td>\n",
              "      <td>0.930599</td>\n",
              "      <td>0.691943</td>\n",
              "      <td>0.813814</td>\n",
              "      <td>0.790782</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.536285</td>\n",
              "      <td>0.859752</td>\n",
              "      <td>0.491176</td>\n",
              "      <td>0.895262</td>\n",
              "      <td>0.650131</td>\n",
              "      <td>0.647929</td>\n",
              "      <td>0.875233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.296000</td>\n",
              "      <td>0.988853</td>\n",
              "      <td>0.734079</td>\n",
              "      <td>0.718858</td>\n",
              "      <td>0.743112</td>\n",
              "      <td>0.570647</td>\n",
              "      <td>0.462908</td>\n",
              "      <td>0.691391</td>\n",
              "      <td>0.870175</td>\n",
              "      <td>0.612322</td>\n",
              "      <td>0.824291</td>\n",
              "      <td>0.141643</td>\n",
              "      <td>0.461261</td>\n",
              "      <td>0.503420</td>\n",
              "      <td>0.865035</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.678191</td>\n",
              "      <td>0.662069</td>\n",
              "      <td>0.751734</td>\n",
              "      <td>0.856512</td>\n",
              "      <td>0.944356</td>\n",
              "      <td>0.726158</td>\n",
              "      <td>0.877023</td>\n",
              "      <td>0.849903</td>\n",
              "      <td>0.734017</td>\n",
              "      <td>0.632219</td>\n",
              "      <td>0.883301</td>\n",
              "      <td>0.627876</td>\n",
              "      <td>0.929928</td>\n",
              "      <td>0.740645</td>\n",
              "      <td>0.690042</td>\n",
              "      <td>0.936396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.986800</td>\n",
              "      <td>0.799121</td>\n",
              "      <td>0.771392</td>\n",
              "      <td>0.764581</td>\n",
              "      <td>0.775460</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.556430</td>\n",
              "      <td>0.737752</td>\n",
              "      <td>0.884106</td>\n",
              "      <td>0.710956</td>\n",
              "      <td>0.868794</td>\n",
              "      <td>0.577540</td>\n",
              "      <td>0.456604</td>\n",
              "      <td>0.517464</td>\n",
              "      <td>0.879647</td>\n",
              "      <td>0.935275</td>\n",
              "      <td>0.704981</td>\n",
              "      <td>0.714441</td>\n",
              "      <td>0.763840</td>\n",
              "      <td>0.870658</td>\n",
              "      <td>0.948882</td>\n",
              "      <td>0.739689</td>\n",
              "      <td>0.861586</td>\n",
              "      <td>0.879461</td>\n",
              "      <td>0.788448</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.897233</td>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.935065</td>\n",
              "      <td>0.785615</td>\n",
              "      <td>0.694362</td>\n",
              "      <td>0.965636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.812800</td>\n",
              "      <td>0.711177</td>\n",
              "      <td>0.795582</td>\n",
              "      <td>0.789813</td>\n",
              "      <td>0.797838</td>\n",
              "      <td>0.602941</td>\n",
              "      <td>0.587361</td>\n",
              "      <td>0.730506</td>\n",
              "      <td>0.911304</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.892794</td>\n",
              "      <td>0.660839</td>\n",
              "      <td>0.582299</td>\n",
              "      <td>0.568935</td>\n",
              "      <td>0.892520</td>\n",
              "      <td>0.943820</td>\n",
              "      <td>0.753623</td>\n",
              "      <td>0.741617</td>\n",
              "      <td>0.780181</td>\n",
              "      <td>0.877013</td>\n",
              "      <td>0.973770</td>\n",
              "      <td>0.743056</td>\n",
              "      <td>0.877898</td>\n",
              "      <td>0.887509</td>\n",
              "      <td>0.795549</td>\n",
              "      <td>0.742947</td>\n",
              "      <td>0.905361</td>\n",
              "      <td>0.703466</td>\n",
              "      <td>0.943220</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.739474</td>\n",
              "      <td>0.958333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.709000</td>\n",
              "      <td>0.641515</td>\n",
              "      <td>0.814218</td>\n",
              "      <td>0.808607</td>\n",
              "      <td>0.814736</td>\n",
              "      <td>0.635897</td>\n",
              "      <td>0.620779</td>\n",
              "      <td>0.762570</td>\n",
              "      <td>0.935750</td>\n",
              "      <td>0.738928</td>\n",
              "      <td>0.905923</td>\n",
              "      <td>0.697329</td>\n",
              "      <td>0.639332</td>\n",
              "      <td>0.568935</td>\n",
              "      <td>0.924438</td>\n",
              "      <td>0.965964</td>\n",
              "      <td>0.751256</td>\n",
              "      <td>0.754237</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.887556</td>\n",
              "      <td>0.980132</td>\n",
              "      <td>0.755585</td>\n",
              "      <td>0.909677</td>\n",
              "      <td>0.896412</td>\n",
              "      <td>0.817712</td>\n",
              "      <td>0.742496</td>\n",
              "      <td>0.914094</td>\n",
              "      <td>0.730323</td>\n",
              "      <td>0.947507</td>\n",
              "      <td>0.833563</td>\n",
              "      <td>0.764398</td>\n",
              "      <td>0.965517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.636500</td>\n",
              "      <td>0.596459</td>\n",
              "      <td>0.822857</td>\n",
              "      <td>0.817590</td>\n",
              "      <td>0.822956</td>\n",
              "      <td>0.640244</td>\n",
              "      <td>0.684755</td>\n",
              "      <td>0.808260</td>\n",
              "      <td>0.950331</td>\n",
              "      <td>0.735714</td>\n",
              "      <td>0.919201</td>\n",
              "      <td>0.693069</td>\n",
              "      <td>0.668666</td>\n",
              "      <td>0.567857</td>\n",
              "      <td>0.944634</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.728774</td>\n",
              "      <td>0.754912</td>\n",
              "      <td>0.781388</td>\n",
              "      <td>0.888054</td>\n",
              "      <td>0.968903</td>\n",
              "      <td>0.761039</td>\n",
              "      <td>0.884080</td>\n",
              "      <td>0.911234</td>\n",
              "      <td>0.812221</td>\n",
              "      <td>0.783784</td>\n",
              "      <td>0.916112</td>\n",
              "      <td>0.732143</td>\n",
              "      <td>0.955184</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.778351</td>\n",
              "      <td>0.979592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.584700</td>\n",
              "      <td>0.586386</td>\n",
              "      <td>0.826889</td>\n",
              "      <td>0.822801</td>\n",
              "      <td>0.828589</td>\n",
              "      <td>0.639381</td>\n",
              "      <td>0.690013</td>\n",
              "      <td>0.806405</td>\n",
              "      <td>0.936535</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.920608</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.646677</td>\n",
              "      <td>0.563574</td>\n",
              "      <td>0.944785</td>\n",
              "      <td>0.969005</td>\n",
              "      <td>0.755556</td>\n",
              "      <td>0.768763</td>\n",
              "      <td>0.800813</td>\n",
              "      <td>0.888092</td>\n",
              "      <td>0.983444</td>\n",
              "      <td>0.754821</td>\n",
              "      <td>0.910543</td>\n",
              "      <td>0.905971</td>\n",
              "      <td>0.824727</td>\n",
              "      <td>0.787682</td>\n",
              "      <td>0.922034</td>\n",
              "      <td>0.752577</td>\n",
              "      <td>0.952632</td>\n",
              "      <td>0.842250</td>\n",
              "      <td>0.791866</td>\n",
              "      <td>0.979592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.541600</td>\n",
              "      <td>0.562266</td>\n",
              "      <td>0.832940</td>\n",
              "      <td>0.827737</td>\n",
              "      <td>0.832927</td>\n",
              "      <td>0.648091</td>\n",
              "      <td>0.674446</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.960133</td>\n",
              "      <td>0.759281</td>\n",
              "      <td>0.925606</td>\n",
              "      <td>0.749621</td>\n",
              "      <td>0.675991</td>\n",
              "      <td>0.582524</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.972268</td>\n",
              "      <td>0.755772</td>\n",
              "      <td>0.774923</td>\n",
              "      <td>0.810345</td>\n",
              "      <td>0.900593</td>\n",
              "      <td>0.965854</td>\n",
              "      <td>0.781794</td>\n",
              "      <td>0.917460</td>\n",
              "      <td>0.916784</td>\n",
              "      <td>0.827035</td>\n",
              "      <td>0.798046</td>\n",
              "      <td>0.925800</td>\n",
              "      <td>0.759748</td>\n",
              "      <td>0.953443</td>\n",
              "      <td>0.852778</td>\n",
              "      <td>0.739946</td>\n",
              "      <td>0.969072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.509100</td>\n",
              "      <td>0.543638</td>\n",
              "      <td>0.839146</td>\n",
              "      <td>0.834364</td>\n",
              "      <td>0.840234</td>\n",
              "      <td>0.644342</td>\n",
              "      <td>0.728246</td>\n",
              "      <td>0.838806</td>\n",
              "      <td>0.952066</td>\n",
              "      <td>0.760429</td>\n",
              "      <td>0.924806</td>\n",
              "      <td>0.729050</td>\n",
              "      <td>0.675325</td>\n",
              "      <td>0.576389</td>\n",
              "      <td>0.944406</td>\n",
              "      <td>0.980263</td>\n",
              "      <td>0.768293</td>\n",
              "      <td>0.783058</td>\n",
              "      <td>0.824671</td>\n",
              "      <td>0.905153</td>\n",
              "      <td>0.981758</td>\n",
              "      <td>0.784969</td>\n",
              "      <td>0.859649</td>\n",
              "      <td>0.910727</td>\n",
              "      <td>0.839221</td>\n",
              "      <td>0.820261</td>\n",
              "      <td>0.925699</td>\n",
              "      <td>0.768666</td>\n",
              "      <td>0.958940</td>\n",
              "      <td>0.866035</td>\n",
              "      <td>0.788372</td>\n",
              "      <td>0.988235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.478500</td>\n",
              "      <td>0.520140</td>\n",
              "      <td>0.849450</td>\n",
              "      <td>0.846875</td>\n",
              "      <td>0.850358</td>\n",
              "      <td>0.662420</td>\n",
              "      <td>0.741026</td>\n",
              "      <td>0.852359</td>\n",
              "      <td>0.968280</td>\n",
              "      <td>0.775087</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>0.798122</td>\n",
              "      <td>0.681319</td>\n",
              "      <td>0.604269</td>\n",
              "      <td>0.951136</td>\n",
              "      <td>0.983553</td>\n",
              "      <td>0.804657</td>\n",
              "      <td>0.790787</td>\n",
              "      <td>0.837509</td>\n",
              "      <td>0.903464</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.801849</td>\n",
              "      <td>0.909938</td>\n",
              "      <td>0.918353</td>\n",
              "      <td>0.841642</td>\n",
              "      <td>0.827471</td>\n",
              "      <td>0.925828</td>\n",
              "      <td>0.780178</td>\n",
              "      <td>0.958797</td>\n",
              "      <td>0.849275</td>\n",
              "      <td>0.794749</td>\n",
              "      <td>0.989899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.447500</td>\n",
              "      <td>0.514025</td>\n",
              "      <td>0.850421</td>\n",
              "      <td>0.847706</td>\n",
              "      <td>0.851423</td>\n",
              "      <td>0.659193</td>\n",
              "      <td>0.739653</td>\n",
              "      <td>0.839470</td>\n",
              "      <td>0.966216</td>\n",
              "      <td>0.766398</td>\n",
              "      <td>0.928934</td>\n",
              "      <td>0.791176</td>\n",
              "      <td>0.683307</td>\n",
              "      <td>0.608403</td>\n",
              "      <td>0.947730</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.781441</td>\n",
              "      <td>0.795656</td>\n",
              "      <td>0.830243</td>\n",
              "      <td>0.913806</td>\n",
              "      <td>0.988314</td>\n",
              "      <td>0.811308</td>\n",
              "      <td>0.924290</td>\n",
              "      <td>0.917241</td>\n",
              "      <td>0.839852</td>\n",
              "      <td>0.829187</td>\n",
              "      <td>0.928904</td>\n",
              "      <td>0.782822</td>\n",
              "      <td>0.964613</td>\n",
              "      <td>0.876081</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.996656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.424500</td>\n",
              "      <td>0.490725</td>\n",
              "      <td>0.857927</td>\n",
              "      <td>0.856150</td>\n",
              "      <td>0.858730</td>\n",
              "      <td>0.670391</td>\n",
              "      <td>0.756158</td>\n",
              "      <td>0.865031</td>\n",
              "      <td>0.966443</td>\n",
              "      <td>0.775320</td>\n",
              "      <td>0.931298</td>\n",
              "      <td>0.823171</td>\n",
              "      <td>0.708397</td>\n",
              "      <td>0.610390</td>\n",
              "      <td>0.956051</td>\n",
              "      <td>0.986755</td>\n",
              "      <td>0.796895</td>\n",
              "      <td>0.806484</td>\n",
              "      <td>0.835549</td>\n",
              "      <td>0.915280</td>\n",
              "      <td>0.988353</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.925515</td>\n",
              "      <td>0.920723</td>\n",
              "      <td>0.843497</td>\n",
              "      <td>0.855241</td>\n",
              "      <td>0.931987</td>\n",
              "      <td>0.798498</td>\n",
              "      <td>0.964613</td>\n",
              "      <td>0.879452</td>\n",
              "      <td>0.798111</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.402900</td>\n",
              "      <td>0.490966</td>\n",
              "      <td>0.856541</td>\n",
              "      <td>0.854984</td>\n",
              "      <td>0.857436</td>\n",
              "      <td>0.673036</td>\n",
              "      <td>0.761084</td>\n",
              "      <td>0.851632</td>\n",
              "      <td>0.965517</td>\n",
              "      <td>0.779463</td>\n",
              "      <td>0.926582</td>\n",
              "      <td>0.839937</td>\n",
              "      <td>0.687550</td>\n",
              "      <td>0.618462</td>\n",
              "      <td>0.955571</td>\n",
              "      <td>0.983553</td>\n",
              "      <td>0.773723</td>\n",
              "      <td>0.804853</td>\n",
              "      <td>0.841055</td>\n",
              "      <td>0.914974</td>\n",
              "      <td>0.988391</td>\n",
              "      <td>0.820067</td>\n",
              "      <td>0.939490</td>\n",
              "      <td>0.913817</td>\n",
              "      <td>0.842566</td>\n",
              "      <td>0.847973</td>\n",
              "      <td>0.928947</td>\n",
              "      <td>0.806574</td>\n",
              "      <td>0.962426</td>\n",
              "      <td>0.882682</td>\n",
              "      <td>0.786458</td>\n",
              "      <td>0.988196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.383200</td>\n",
              "      <td>0.472884</td>\n",
              "      <td>0.859499</td>\n",
              "      <td>0.859369</td>\n",
              "      <td>0.860557</td>\n",
              "      <td>0.665904</td>\n",
              "      <td>0.758621</td>\n",
              "      <td>0.881250</td>\n",
              "      <td>0.966997</td>\n",
              "      <td>0.783505</td>\n",
              "      <td>0.931741</td>\n",
              "      <td>0.849758</td>\n",
              "      <td>0.683386</td>\n",
              "      <td>0.629080</td>\n",
              "      <td>0.944904</td>\n",
              "      <td>0.970779</td>\n",
              "      <td>0.808786</td>\n",
              "      <td>0.802116</td>\n",
              "      <td>0.843509</td>\n",
              "      <td>0.913011</td>\n",
              "      <td>0.988391</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.940989</td>\n",
              "      <td>0.920083</td>\n",
              "      <td>0.850291</td>\n",
              "      <td>0.868852</td>\n",
              "      <td>0.930876</td>\n",
              "      <td>0.806974</td>\n",
              "      <td>0.967528</td>\n",
              "      <td>0.884154</td>\n",
              "      <td>0.802339</td>\n",
              "      <td>0.998336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.368000</td>\n",
              "      <td>0.477715</td>\n",
              "      <td>0.858801</td>\n",
              "      <td>0.858160</td>\n",
              "      <td>0.859263</td>\n",
              "      <td>0.673866</td>\n",
              "      <td>0.758788</td>\n",
              "      <td>0.870624</td>\n",
              "      <td>0.972881</td>\n",
              "      <td>0.786385</td>\n",
              "      <td>0.934468</td>\n",
              "      <td>0.854400</td>\n",
              "      <td>0.682889</td>\n",
              "      <td>0.622356</td>\n",
              "      <td>0.944675</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.801175</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.919818</td>\n",
              "      <td>0.985124</td>\n",
              "      <td>0.819213</td>\n",
              "      <td>0.935024</td>\n",
              "      <td>0.922222</td>\n",
              "      <td>0.846672</td>\n",
              "      <td>0.855738</td>\n",
              "      <td>0.933868</td>\n",
              "      <td>0.799496</td>\n",
              "      <td>0.960682</td>\n",
              "      <td>0.876374</td>\n",
              "      <td>0.795673</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.348400</td>\n",
              "      <td>0.487614</td>\n",
              "      <td>0.858938</td>\n",
              "      <td>0.857064</td>\n",
              "      <td>0.859568</td>\n",
              "      <td>0.683983</td>\n",
              "      <td>0.752998</td>\n",
              "      <td>0.859813</td>\n",
              "      <td>0.974619</td>\n",
              "      <td>0.772674</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>0.824405</td>\n",
              "      <td>0.684996</td>\n",
              "      <td>0.609250</td>\n",
              "      <td>0.946355</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.775904</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.914798</td>\n",
              "      <td>0.986755</td>\n",
              "      <td>0.816514</td>\n",
              "      <td>0.929134</td>\n",
              "      <td>0.925227</td>\n",
              "      <td>0.852339</td>\n",
              "      <td>0.858995</td>\n",
              "      <td>0.935915</td>\n",
              "      <td>0.812903</td>\n",
              "      <td>0.961892</td>\n",
              "      <td>0.889189</td>\n",
              "      <td>0.786600</td>\n",
              "      <td>0.994975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.334400</td>\n",
              "      <td>0.480447</td>\n",
              "      <td>0.861659</td>\n",
              "      <td>0.859618</td>\n",
              "      <td>0.862232</td>\n",
              "      <td>0.683598</td>\n",
              "      <td>0.786755</td>\n",
              "      <td>0.879020</td>\n",
              "      <td>0.970395</td>\n",
              "      <td>0.773519</td>\n",
              "      <td>0.938500</td>\n",
              "      <td>0.802276</td>\n",
              "      <td>0.702580</td>\n",
              "      <td>0.619902</td>\n",
              "      <td>0.949176</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.817481</td>\n",
              "      <td>0.803571</td>\n",
              "      <td>0.854713</td>\n",
              "      <td>0.918507</td>\n",
              "      <td>0.985025</td>\n",
              "      <td>0.823290</td>\n",
              "      <td>0.922118</td>\n",
              "      <td>0.919698</td>\n",
              "      <td>0.848576</td>\n",
              "      <td>0.860927</td>\n",
              "      <td>0.933962</td>\n",
              "      <td>0.796651</td>\n",
              "      <td>0.966425</td>\n",
              "      <td>0.880886</td>\n",
              "      <td>0.783715</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.321100</td>\n",
              "      <td>0.481259</td>\n",
              "      <td>0.865169</td>\n",
              "      <td>0.864661</td>\n",
              "      <td>0.866266</td>\n",
              "      <td>0.690045</td>\n",
              "      <td>0.776819</td>\n",
              "      <td>0.898279</td>\n",
              "      <td>0.983389</td>\n",
              "      <td>0.779310</td>\n",
              "      <td>0.930891</td>\n",
              "      <td>0.841317</td>\n",
              "      <td>0.699387</td>\n",
              "      <td>0.647746</td>\n",
              "      <td>0.949176</td>\n",
              "      <td>0.980328</td>\n",
              "      <td>0.801489</td>\n",
              "      <td>0.810127</td>\n",
              "      <td>0.841499</td>\n",
              "      <td>0.916413</td>\n",
              "      <td>0.985025</td>\n",
              "      <td>0.822493</td>\n",
              "      <td>0.927900</td>\n",
              "      <td>0.927336</td>\n",
              "      <td>0.858177</td>\n",
              "      <td>0.879085</td>\n",
              "      <td>0.942838</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.966975</td>\n",
              "      <td>0.884298</td>\n",
              "      <td>0.798042</td>\n",
              "      <td>0.994975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.305800</td>\n",
              "      <td>0.470092</td>\n",
              "      <td>0.867953</td>\n",
              "      <td>0.867788</td>\n",
              "      <td>0.868625</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>0.797858</td>\n",
              "      <td>0.905901</td>\n",
              "      <td>0.978441</td>\n",
              "      <td>0.801453</td>\n",
              "      <td>0.935216</td>\n",
              "      <td>0.827485</td>\n",
              "      <td>0.702498</td>\n",
              "      <td>0.643791</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.803946</td>\n",
              "      <td>0.822467</td>\n",
              "      <td>0.849964</td>\n",
              "      <td>0.923896</td>\n",
              "      <td>0.986711</td>\n",
              "      <td>0.828323</td>\n",
              "      <td>0.939683</td>\n",
              "      <td>0.925086</td>\n",
              "      <td>0.855670</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.938370</td>\n",
              "      <td>0.795699</td>\n",
              "      <td>0.965744</td>\n",
              "      <td>0.876945</td>\n",
              "      <td>0.804938</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.296500</td>\n",
              "      <td>0.472246</td>\n",
              "      <td>0.871246</td>\n",
              "      <td>0.870584</td>\n",
              "      <td>0.871974</td>\n",
              "      <td>0.692144</td>\n",
              "      <td>0.792258</td>\n",
              "      <td>0.895476</td>\n",
              "      <td>0.977929</td>\n",
              "      <td>0.790152</td>\n",
              "      <td>0.936922</td>\n",
              "      <td>0.844776</td>\n",
              "      <td>0.726592</td>\n",
              "      <td>0.647651</td>\n",
              "      <td>0.956224</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.814527</td>\n",
              "      <td>0.823887</td>\n",
              "      <td>0.852857</td>\n",
              "      <td>0.923896</td>\n",
              "      <td>0.988314</td>\n",
              "      <td>0.828628</td>\n",
              "      <td>0.933544</td>\n",
              "      <td>0.925849</td>\n",
              "      <td>0.856933</td>\n",
              "      <td>0.872786</td>\n",
              "      <td>0.934394</td>\n",
              "      <td>0.830808</td>\n",
              "      <td>0.967148</td>\n",
              "      <td>0.899183</td>\n",
              "      <td>0.804455</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.280900</td>\n",
              "      <td>0.470845</td>\n",
              "      <td>0.869821</td>\n",
              "      <td>0.868291</td>\n",
              "      <td>0.870224</td>\n",
              "      <td>0.696486</td>\n",
              "      <td>0.789014</td>\n",
              "      <td>0.872894</td>\n",
              "      <td>0.977929</td>\n",
              "      <td>0.785799</td>\n",
              "      <td>0.938983</td>\n",
              "      <td>0.842730</td>\n",
              "      <td>0.718984</td>\n",
              "      <td>0.641571</td>\n",
              "      <td>0.954918</td>\n",
              "      <td>0.990066</td>\n",
              "      <td>0.799001</td>\n",
              "      <td>0.820988</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>0.925926</td>\n",
              "      <td>0.985025</td>\n",
              "      <td>0.832440</td>\n",
              "      <td>0.933754</td>\n",
              "      <td>0.924033</td>\n",
              "      <td>0.852679</td>\n",
              "      <td>0.867863</td>\n",
              "      <td>0.940388</td>\n",
              "      <td>0.829949</td>\n",
              "      <td>0.965109</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.806412</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.273900</td>\n",
              "      <td>0.462788</td>\n",
              "      <td>0.871641</td>\n",
              "      <td>0.871520</td>\n",
              "      <td>0.872659</td>\n",
              "      <td>0.689880</td>\n",
              "      <td>0.791721</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.983333</td>\n",
              "      <td>0.794811</td>\n",
              "      <td>0.937343</td>\n",
              "      <td>0.869432</td>\n",
              "      <td>0.712644</td>\n",
              "      <td>0.656000</td>\n",
              "      <td>0.954856</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.817481</td>\n",
              "      <td>0.829120</td>\n",
              "      <td>0.858741</td>\n",
              "      <td>0.920874</td>\n",
              "      <td>0.988353</td>\n",
              "      <td>0.826058</td>\n",
              "      <td>0.945687</td>\n",
              "      <td>0.925311</td>\n",
              "      <td>0.862293</td>\n",
              "      <td>0.868852</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.824845</td>\n",
              "      <td>0.966425</td>\n",
              "      <td>0.890710</td>\n",
              "      <td>0.807980</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.264600</td>\n",
              "      <td>0.463867</td>\n",
              "      <td>0.870910</td>\n",
              "      <td>0.871359</td>\n",
              "      <td>0.871974</td>\n",
              "      <td>0.682432</td>\n",
              "      <td>0.801040</td>\n",
              "      <td>0.898596</td>\n",
              "      <td>0.981575</td>\n",
              "      <td>0.789035</td>\n",
              "      <td>0.944962</td>\n",
              "      <td>0.871166</td>\n",
              "      <td>0.706935</td>\n",
              "      <td>0.667791</td>\n",
              "      <td>0.946207</td>\n",
              "      <td>0.985173</td>\n",
              "      <td>0.791209</td>\n",
              "      <td>0.824121</td>\n",
              "      <td>0.856330</td>\n",
              "      <td>0.922264</td>\n",
              "      <td>0.986667</td>\n",
              "      <td>0.834455</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.919509</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.883871</td>\n",
              "      <td>0.938206</td>\n",
              "      <td>0.818955</td>\n",
              "      <td>0.967062</td>\n",
              "      <td>0.900826</td>\n",
              "      <td>0.809976</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.256200</td>\n",
              "      <td>0.460766</td>\n",
              "      <td>0.873463</td>\n",
              "      <td>0.873761</td>\n",
              "      <td>0.874258</td>\n",
              "      <td>0.691304</td>\n",
              "      <td>0.801014</td>\n",
              "      <td>0.905063</td>\n",
              "      <td>0.981697</td>\n",
              "      <td>0.792982</td>\n",
              "      <td>0.940286</td>\n",
              "      <td>0.879875</td>\n",
              "      <td>0.726592</td>\n",
              "      <td>0.662139</td>\n",
              "      <td>0.952577</td>\n",
              "      <td>0.981938</td>\n",
              "      <td>0.809045</td>\n",
              "      <td>0.828882</td>\n",
              "      <td>0.857548</td>\n",
              "      <td>0.923780</td>\n",
              "      <td>0.986711</td>\n",
              "      <td>0.830214</td>\n",
              "      <td>0.942675</td>\n",
              "      <td>0.920873</td>\n",
              "      <td>0.854599</td>\n",
              "      <td>0.893617</td>\n",
              "      <td>0.942915</td>\n",
              "      <td>0.818071</td>\n",
              "      <td>0.968296</td>\n",
              "      <td>0.895978</td>\n",
              "      <td>0.802867</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.246700</td>\n",
              "      <td>0.466931</td>\n",
              "      <td>0.872538</td>\n",
              "      <td>0.872302</td>\n",
              "      <td>0.872812</td>\n",
              "      <td>0.683297</td>\n",
              "      <td>0.789149</td>\n",
              "      <td>0.895476</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.790533</td>\n",
              "      <td>0.942588</td>\n",
              "      <td>0.856712</td>\n",
              "      <td>0.718404</td>\n",
              "      <td>0.650869</td>\n",
              "      <td>0.945329</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.823077</td>\n",
              "      <td>0.828283</td>\n",
              "      <td>0.864301</td>\n",
              "      <td>0.926154</td>\n",
              "      <td>0.986667</td>\n",
              "      <td>0.835092</td>\n",
              "      <td>0.935024</td>\n",
              "      <td>0.923501</td>\n",
              "      <td>0.854167</td>\n",
              "      <td>0.892206</td>\n",
              "      <td>0.942838</td>\n",
              "      <td>0.832298</td>\n",
              "      <td>0.966557</td>\n",
              "      <td>0.900699</td>\n",
              "      <td>0.800496</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.240400</td>\n",
              "      <td>0.470342</td>\n",
              "      <td>0.872206</td>\n",
              "      <td>0.872840</td>\n",
              "      <td>0.873040</td>\n",
              "      <td>0.694897</td>\n",
              "      <td>0.796915</td>\n",
              "      <td>0.899687</td>\n",
              "      <td>0.983333</td>\n",
              "      <td>0.794393</td>\n",
              "      <td>0.944538</td>\n",
              "      <td>0.872894</td>\n",
              "      <td>0.706767</td>\n",
              "      <td>0.664516</td>\n",
              "      <td>0.944022</td>\n",
              "      <td>0.980328</td>\n",
              "      <td>0.816327</td>\n",
              "      <td>0.828000</td>\n",
              "      <td>0.861800</td>\n",
              "      <td>0.923547</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.832447</td>\n",
              "      <td>0.932283</td>\n",
              "      <td>0.921811</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.891089</td>\n",
              "      <td>0.939374</td>\n",
              "      <td>0.827757</td>\n",
              "      <td>0.962866</td>\n",
              "      <td>0.895105</td>\n",
              "      <td>0.804848</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.228900</td>\n",
              "      <td>0.466206</td>\n",
              "      <td>0.875006</td>\n",
              "      <td>0.875246</td>\n",
              "      <td>0.875704</td>\n",
              "      <td>0.698031</td>\n",
              "      <td>0.795944</td>\n",
              "      <td>0.897196</td>\n",
              "      <td>0.985025</td>\n",
              "      <td>0.781503</td>\n",
              "      <td>0.944351</td>\n",
              "      <td>0.868502</td>\n",
              "      <td>0.726731</td>\n",
              "      <td>0.664384</td>\n",
              "      <td>0.947658</td>\n",
              "      <td>0.986799</td>\n",
              "      <td>0.805861</td>\n",
              "      <td>0.827447</td>\n",
              "      <td>0.858161</td>\n",
              "      <td>0.930268</td>\n",
              "      <td>0.991653</td>\n",
              "      <td>0.832461</td>\n",
              "      <td>0.951768</td>\n",
              "      <td>0.929363</td>\n",
              "      <td>0.860310</td>\n",
              "      <td>0.894389</td>\n",
              "      <td>0.941884</td>\n",
              "      <td>0.838628</td>\n",
              "      <td>0.964706</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.808612</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.225000</td>\n",
              "      <td>0.465218</td>\n",
              "      <td>0.876070</td>\n",
              "      <td>0.876465</td>\n",
              "      <td>0.876465</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.811370</td>\n",
              "      <td>0.893023</td>\n",
              "      <td>0.981758</td>\n",
              "      <td>0.791715</td>\n",
              "      <td>0.947547</td>\n",
              "      <td>0.872504</td>\n",
              "      <td>0.724009</td>\n",
              "      <td>0.674342</td>\n",
              "      <td>0.947586</td>\n",
              "      <td>0.985173</td>\n",
              "      <td>0.811955</td>\n",
              "      <td>0.839232</td>\n",
              "      <td>0.855932</td>\n",
              "      <td>0.932308</td>\n",
              "      <td>0.988314</td>\n",
              "      <td>0.835762</td>\n",
              "      <td>0.950241</td>\n",
              "      <td>0.922343</td>\n",
              "      <td>0.858427</td>\n",
              "      <td>0.901830</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.821516</td>\n",
              "      <td>0.973440</td>\n",
              "      <td>0.911081</td>\n",
              "      <td>0.796992</td>\n",
              "      <td>0.994975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.217000</td>\n",
              "      <td>0.462737</td>\n",
              "      <td>0.878252</td>\n",
              "      <td>0.878328</td>\n",
              "      <td>0.878749</td>\n",
              "      <td>0.698238</td>\n",
              "      <td>0.806492</td>\n",
              "      <td>0.903021</td>\n",
              "      <td>0.986622</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.944068</td>\n",
              "      <td>0.874807</td>\n",
              "      <td>0.735094</td>\n",
              "      <td>0.659271</td>\n",
              "      <td>0.956344</td>\n",
              "      <td>0.990066</td>\n",
              "      <td>0.826144</td>\n",
              "      <td>0.823293</td>\n",
              "      <td>0.866340</td>\n",
              "      <td>0.926754</td>\n",
              "      <td>0.988353</td>\n",
              "      <td>0.832339</td>\n",
              "      <td>0.935229</td>\n",
              "      <td>0.925086</td>\n",
              "      <td>0.867980</td>\n",
              "      <td>0.906404</td>\n",
              "      <td>0.940080</td>\n",
              "      <td>0.832695</td>\n",
              "      <td>0.973404</td>\n",
              "      <td>0.914052</td>\n",
              "      <td>0.811005</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.463680</td>\n",
              "      <td>0.877448</td>\n",
              "      <td>0.877942</td>\n",
              "      <td>0.878064</td>\n",
              "      <td>0.692982</td>\n",
              "      <td>0.799492</td>\n",
              "      <td>0.911717</td>\n",
              "      <td>0.986622</td>\n",
              "      <td>0.795294</td>\n",
              "      <td>0.947547</td>\n",
              "      <td>0.877301</td>\n",
              "      <td>0.731599</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.953297</td>\n",
              "      <td>0.986799</td>\n",
              "      <td>0.818878</td>\n",
              "      <td>0.828974</td>\n",
              "      <td>0.856942</td>\n",
              "      <td>0.928296</td>\n",
              "      <td>0.986622</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.938193</td>\n",
              "      <td>0.924776</td>\n",
              "      <td>0.867347</td>\n",
              "      <td>0.908795</td>\n",
              "      <td>0.941333</td>\n",
              "      <td>0.834184</td>\n",
              "      <td>0.970899</td>\n",
              "      <td>0.916553</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.203900</td>\n",
              "      <td>0.465597</td>\n",
              "      <td>0.878122</td>\n",
              "      <td>0.878654</td>\n",
              "      <td>0.878673</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.796547</td>\n",
              "      <td>0.905901</td>\n",
              "      <td>0.983108</td>\n",
              "      <td>0.795750</td>\n",
              "      <td>0.945578</td>\n",
              "      <td>0.881720</td>\n",
              "      <td>0.736457</td>\n",
              "      <td>0.675722</td>\n",
              "      <td>0.947006</td>\n",
              "      <td>0.990066</td>\n",
              "      <td>0.830530</td>\n",
              "      <td>0.832146</td>\n",
              "      <td>0.861604</td>\n",
              "      <td>0.925926</td>\n",
              "      <td>0.988275</td>\n",
              "      <td>0.837451</td>\n",
              "      <td>0.939683</td>\n",
              "      <td>0.926054</td>\n",
              "      <td>0.865259</td>\n",
              "      <td>0.902087</td>\n",
              "      <td>0.939695</td>\n",
              "      <td>0.828105</td>\n",
              "      <td>0.971014</td>\n",
              "      <td>0.913580</td>\n",
              "      <td>0.804401</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.203500</td>\n",
              "      <td>0.475943</td>\n",
              "      <td>0.876878</td>\n",
              "      <td>0.877019</td>\n",
              "      <td>0.877455</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.801536</td>\n",
              "      <td>0.894410</td>\n",
              "      <td>0.983333</td>\n",
              "      <td>0.809069</td>\n",
              "      <td>0.947547</td>\n",
              "      <td>0.883077</td>\n",
              "      <td>0.742524</td>\n",
              "      <td>0.663248</td>\n",
              "      <td>0.946491</td>\n",
              "      <td>0.985173</td>\n",
              "      <td>0.825921</td>\n",
              "      <td>0.828974</td>\n",
              "      <td>0.858765</td>\n",
              "      <td>0.925212</td>\n",
              "      <td>0.988353</td>\n",
              "      <td>0.835509</td>\n",
              "      <td>0.938193</td>\n",
              "      <td>0.925414</td>\n",
              "      <td>0.862974</td>\n",
              "      <td>0.908197</td>\n",
              "      <td>0.941255</td>\n",
              "      <td>0.823239</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.908840</td>\n",
              "      <td>0.797101</td>\n",
              "      <td>0.994975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.198500</td>\n",
              "      <td>0.470537</td>\n",
              "      <td>0.877724</td>\n",
              "      <td>0.878429</td>\n",
              "      <td>0.878368</td>\n",
              "      <td>0.697268</td>\n",
              "      <td>0.804511</td>\n",
              "      <td>0.904459</td>\n",
              "      <td>0.986667</td>\n",
              "      <td>0.804790</td>\n",
              "      <td>0.949153</td>\n",
              "      <td>0.879020</td>\n",
              "      <td>0.734513</td>\n",
              "      <td>0.667785</td>\n",
              "      <td>0.947006</td>\n",
              "      <td>0.985173</td>\n",
              "      <td>0.823980</td>\n",
              "      <td>0.825651</td>\n",
              "      <td>0.859135</td>\n",
              "      <td>0.926979</td>\n",
              "      <td>0.988353</td>\n",
              "      <td>0.833442</td>\n",
              "      <td>0.939683</td>\n",
              "      <td>0.925926</td>\n",
              "      <td>0.864945</td>\n",
              "      <td>0.916256</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.833753</td>\n",
              "      <td>0.970297</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.798561</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.192800</td>\n",
              "      <td>0.480797</td>\n",
              "      <td>0.877626</td>\n",
              "      <td>0.877560</td>\n",
              "      <td>0.878292</td>\n",
              "      <td>0.702643</td>\n",
              "      <td>0.795511</td>\n",
              "      <td>0.903021</td>\n",
              "      <td>0.983221</td>\n",
              "      <td>0.802367</td>\n",
              "      <td>0.946399</td>\n",
              "      <td>0.876336</td>\n",
              "      <td>0.738166</td>\n",
              "      <td>0.665535</td>\n",
              "      <td>0.945253</td>\n",
              "      <td>0.990066</td>\n",
              "      <td>0.824742</td>\n",
              "      <td>0.827655</td>\n",
              "      <td>0.861626</td>\n",
              "      <td>0.927803</td>\n",
              "      <td>0.986667</td>\n",
              "      <td>0.837750</td>\n",
              "      <td>0.927900</td>\n",
              "      <td>0.927736</td>\n",
              "      <td>0.871533</td>\n",
              "      <td>0.911765</td>\n",
              "      <td>0.941255</td>\n",
              "      <td>0.826141</td>\n",
              "      <td>0.968421</td>\n",
              "      <td>0.899291</td>\n",
              "      <td>0.805320</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.191400</td>\n",
              "      <td>0.471870</td>\n",
              "      <td>0.878551</td>\n",
              "      <td>0.879384</td>\n",
              "      <td>0.878901</td>\n",
              "      <td>0.703093</td>\n",
              "      <td>0.798489</td>\n",
              "      <td>0.909667</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.806183</td>\n",
              "      <td>0.949153</td>\n",
              "      <td>0.885802</td>\n",
              "      <td>0.736451</td>\n",
              "      <td>0.675630</td>\n",
              "      <td>0.945404</td>\n",
              "      <td>0.991708</td>\n",
              "      <td>0.817610</td>\n",
              "      <td>0.831984</td>\n",
              "      <td>0.862773</td>\n",
              "      <td>0.925926</td>\n",
              "      <td>0.989967</td>\n",
              "      <td>0.827232</td>\n",
              "      <td>0.938193</td>\n",
              "      <td>0.927736</td>\n",
              "      <td>0.867153</td>\n",
              "      <td>0.917492</td>\n",
              "      <td>0.943371</td>\n",
              "      <td>0.832061</td>\n",
              "      <td>0.970938</td>\n",
              "      <td>0.906815</td>\n",
              "      <td>0.802548</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.186000</td>\n",
              "      <td>0.470480</td>\n",
              "      <td>0.879777</td>\n",
              "      <td>0.880002</td>\n",
              "      <td>0.880423</td>\n",
              "      <td>0.707889</td>\n",
              "      <td>0.797011</td>\n",
              "      <td>0.896226</td>\n",
              "      <td>0.986667</td>\n",
              "      <td>0.811976</td>\n",
              "      <td>0.949410</td>\n",
              "      <td>0.893354</td>\n",
              "      <td>0.741405</td>\n",
              "      <td>0.667780</td>\n",
              "      <td>0.956879</td>\n",
              "      <td>0.985173</td>\n",
              "      <td>0.819095</td>\n",
              "      <td>0.831301</td>\n",
              "      <td>0.866197</td>\n",
              "      <td>0.924847</td>\n",
              "      <td>0.988314</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.938193</td>\n",
              "      <td>0.929558</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.912972</td>\n",
              "      <td>0.942039</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.969737</td>\n",
              "      <td>0.908587</td>\n",
              "      <td>0.803483</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.181600</td>\n",
              "      <td>0.474542</td>\n",
              "      <td>0.879782</td>\n",
              "      <td>0.880009</td>\n",
              "      <td>0.880499</td>\n",
              "      <td>0.693157</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.899841</td>\n",
              "      <td>0.984874</td>\n",
              "      <td>0.813478</td>\n",
              "      <td>0.950211</td>\n",
              "      <td>0.891975</td>\n",
              "      <td>0.745588</td>\n",
              "      <td>0.674658</td>\n",
              "      <td>0.954078</td>\n",
              "      <td>0.986799</td>\n",
              "      <td>0.820577</td>\n",
              "      <td>0.833502</td>\n",
              "      <td>0.864789</td>\n",
              "      <td>0.926040</td>\n",
              "      <td>0.989967</td>\n",
              "      <td>0.832355</td>\n",
              "      <td>0.936709</td>\n",
              "      <td>0.926359</td>\n",
              "      <td>0.872832</td>\n",
              "      <td>0.918033</td>\n",
              "      <td>0.942116</td>\n",
              "      <td>0.829146</td>\n",
              "      <td>0.970297</td>\n",
              "      <td>0.906815</td>\n",
              "      <td>0.798544</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.180900</td>\n",
              "      <td>0.474629</td>\n",
              "      <td>0.879859</td>\n",
              "      <td>0.880350</td>\n",
              "      <td>0.880575</td>\n",
              "      <td>0.694878</td>\n",
              "      <td>0.806084</td>\n",
              "      <td>0.903328</td>\n",
              "      <td>0.983278</td>\n",
              "      <td>0.811005</td>\n",
              "      <td>0.948696</td>\n",
              "      <td>0.881098</td>\n",
              "      <td>0.748905</td>\n",
              "      <td>0.670017</td>\n",
              "      <td>0.950549</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.829457</td>\n",
              "      <td>0.834343</td>\n",
              "      <td>0.858974</td>\n",
              "      <td>0.929012</td>\n",
              "      <td>0.988314</td>\n",
              "      <td>0.834092</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.925394</td>\n",
              "      <td>0.869438</td>\n",
              "      <td>0.921311</td>\n",
              "      <td>0.940239</td>\n",
              "      <td>0.825871</td>\n",
              "      <td>0.971580</td>\n",
              "      <td>0.917355</td>\n",
              "      <td>0.796631</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.178200</td>\n",
              "      <td>0.473728</td>\n",
              "      <td>0.880634</td>\n",
              "      <td>0.881168</td>\n",
              "      <td>0.881260</td>\n",
              "      <td>0.702586</td>\n",
              "      <td>0.800512</td>\n",
              "      <td>0.899054</td>\n",
              "      <td>0.986622</td>\n",
              "      <td>0.813478</td>\n",
              "      <td>0.951736</td>\n",
              "      <td>0.885145</td>\n",
              "      <td>0.740632</td>\n",
              "      <td>0.672326</td>\n",
              "      <td>0.951270</td>\n",
              "      <td>0.986799</td>\n",
              "      <td>0.825478</td>\n",
              "      <td>0.830986</td>\n",
              "      <td>0.862691</td>\n",
              "      <td>0.929730</td>\n",
              "      <td>0.988314</td>\n",
              "      <td>0.833766</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.927934</td>\n",
              "      <td>0.868864</td>\n",
              "      <td>0.916530</td>\n",
              "      <td>0.941806</td>\n",
              "      <td>0.838628</td>\n",
              "      <td>0.972222</td>\n",
              "      <td>0.918845</td>\n",
              "      <td>0.804401</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.178600</td>\n",
              "      <td>0.472963</td>\n",
              "      <td>0.880758</td>\n",
              "      <td>0.881267</td>\n",
              "      <td>0.881337</td>\n",
              "      <td>0.701412</td>\n",
              "      <td>0.803050</td>\n",
              "      <td>0.906200</td>\n",
              "      <td>0.984874</td>\n",
              "      <td>0.815696</td>\n",
              "      <td>0.947723</td>\n",
              "      <td>0.886503</td>\n",
              "      <td>0.746356</td>\n",
              "      <td>0.668930</td>\n",
              "      <td>0.949828</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.828205</td>\n",
              "      <td>0.831169</td>\n",
              "      <td>0.863955</td>\n",
              "      <td>0.926267</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.835840</td>\n",
              "      <td>0.939683</td>\n",
              "      <td>0.928916</td>\n",
              "      <td>0.870262</td>\n",
              "      <td>0.920065</td>\n",
              "      <td>0.942359</td>\n",
              "      <td>0.836915</td>\n",
              "      <td>0.971580</td>\n",
              "      <td>0.914365</td>\n",
              "      <td>0.795620</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.176500</td>\n",
              "      <td>0.475630</td>\n",
              "      <td>0.880913</td>\n",
              "      <td>0.880953</td>\n",
              "      <td>0.881413</td>\n",
              "      <td>0.700965</td>\n",
              "      <td>0.800508</td>\n",
              "      <td>0.899054</td>\n",
              "      <td>0.983278</td>\n",
              "      <td>0.813842</td>\n",
              "      <td>0.949324</td>\n",
              "      <td>0.881098</td>\n",
              "      <td>0.748718</td>\n",
              "      <td>0.671164</td>\n",
              "      <td>0.951203</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.826255</td>\n",
              "      <td>0.834835</td>\n",
              "      <td>0.868347</td>\n",
              "      <td>0.931168</td>\n",
              "      <td>0.988314</td>\n",
              "      <td>0.840864</td>\n",
              "      <td>0.942675</td>\n",
              "      <td>0.926129</td>\n",
              "      <td>0.865979</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.943068</td>\n",
              "      <td>0.826467</td>\n",
              "      <td>0.970336</td>\n",
              "      <td>0.917127</td>\n",
              "      <td>0.798526</td>\n",
              "      <td>0.994975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.173400</td>\n",
              "      <td>0.475366</td>\n",
              "      <td>0.881227</td>\n",
              "      <td>0.881619</td>\n",
              "      <td>0.881869</td>\n",
              "      <td>0.702820</td>\n",
              "      <td>0.805000</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.983221</td>\n",
              "      <td>0.813926</td>\n",
              "      <td>0.949324</td>\n",
              "      <td>0.878419</td>\n",
              "      <td>0.744152</td>\n",
              "      <td>0.672384</td>\n",
              "      <td>0.950549</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.830573</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.867925</td>\n",
              "      <td>0.931274</td>\n",
              "      <td>0.988314</td>\n",
              "      <td>0.839426</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.927298</td>\n",
              "      <td>0.866130</td>\n",
              "      <td>0.918033</td>\n",
              "      <td>0.943068</td>\n",
              "      <td>0.834805</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.914365</td>\n",
              "      <td>0.800983</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.172900</td>\n",
              "      <td>0.475354</td>\n",
              "      <td>0.881362</td>\n",
              "      <td>0.881719</td>\n",
              "      <td>0.882022</td>\n",
              "      <td>0.699346</td>\n",
              "      <td>0.807018</td>\n",
              "      <td>0.905901</td>\n",
              "      <td>0.984874</td>\n",
              "      <td>0.811456</td>\n",
              "      <td>0.947723</td>\n",
              "      <td>0.882443</td>\n",
              "      <td>0.743947</td>\n",
              "      <td>0.674617</td>\n",
              "      <td>0.951857</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.826972</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.867740</td>\n",
              "      <td>0.929122</td>\n",
              "      <td>0.988314</td>\n",
              "      <td>0.842381</td>\n",
              "      <td>0.939683</td>\n",
              "      <td>0.927298</td>\n",
              "      <td>0.868228</td>\n",
              "      <td>0.920065</td>\n",
              "      <td>0.943144</td>\n",
              "      <td>0.837327</td>\n",
              "      <td>0.970336</td>\n",
              "      <td>0.914365</td>\n",
              "      <td>0.800490</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.173300</td>\n",
              "      <td>0.473702</td>\n",
              "      <td>0.881125</td>\n",
              "      <td>0.881669</td>\n",
              "      <td>0.881717</td>\n",
              "      <td>0.698378</td>\n",
              "      <td>0.805063</td>\n",
              "      <td>0.910256</td>\n",
              "      <td>0.988275</td>\n",
              "      <td>0.811976</td>\n",
              "      <td>0.947723</td>\n",
              "      <td>0.883792</td>\n",
              "      <td>0.743066</td>\n",
              "      <td>0.670068</td>\n",
              "      <td>0.951136</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.824584</td>\n",
              "      <td>0.835010</td>\n",
              "      <td>0.864751</td>\n",
              "      <td>0.929122</td>\n",
              "      <td>0.989967</td>\n",
              "      <td>0.838083</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.928375</td>\n",
              "      <td>0.871273</td>\n",
              "      <td>0.920325</td>\n",
              "      <td>0.943068</td>\n",
              "      <td>0.838628</td>\n",
              "      <td>0.970336</td>\n",
              "      <td>0.915629</td>\n",
              "      <td>0.796569</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.170400</td>\n",
              "      <td>0.473340</td>\n",
              "      <td>0.881950</td>\n",
              "      <td>0.882400</td>\n",
              "      <td>0.882554</td>\n",
              "      <td>0.700214</td>\n",
              "      <td>0.803030</td>\n",
              "      <td>0.911717</td>\n",
              "      <td>0.984975</td>\n",
              "      <td>0.812425</td>\n",
              "      <td>0.947723</td>\n",
              "      <td>0.890601</td>\n",
              "      <td>0.747253</td>\n",
              "      <td>0.670068</td>\n",
              "      <td>0.954078</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.829706</td>\n",
              "      <td>0.835520</td>\n",
              "      <td>0.866899</td>\n",
              "      <td>0.928406</td>\n",
              "      <td>0.989967</td>\n",
              "      <td>0.841146</td>\n",
              "      <td>0.938193</td>\n",
              "      <td>0.927934</td>\n",
              "      <td>0.868421</td>\n",
              "      <td>0.918033</td>\n",
              "      <td>0.942436</td>\n",
              "      <td>0.841169</td>\n",
              "      <td>0.970336</td>\n",
              "      <td>0.915629</td>\n",
              "      <td>0.800493</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.169500</td>\n",
              "      <td>0.475138</td>\n",
              "      <td>0.881269</td>\n",
              "      <td>0.881661</td>\n",
              "      <td>0.881946</td>\n",
              "      <td>0.697725</td>\n",
              "      <td>0.804540</td>\n",
              "      <td>0.908800</td>\n",
              "      <td>0.986622</td>\n",
              "      <td>0.811005</td>\n",
              "      <td>0.947723</td>\n",
              "      <td>0.882443</td>\n",
              "      <td>0.742524</td>\n",
              "      <td>0.668966</td>\n",
              "      <td>0.951923</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.828645</td>\n",
              "      <td>0.836694</td>\n",
              "      <td>0.867503</td>\n",
              "      <td>0.929122</td>\n",
              "      <td>0.989967</td>\n",
              "      <td>0.841146</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.927934</td>\n",
              "      <td>0.869056</td>\n",
              "      <td>0.916803</td>\n",
              "      <td>0.942359</td>\n",
              "      <td>0.840506</td>\n",
              "      <td>0.970336</td>\n",
              "      <td>0.914365</td>\n",
              "      <td>0.798535</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.170800</td>\n",
              "      <td>0.475105</td>\n",
              "      <td>0.881433</td>\n",
              "      <td>0.881895</td>\n",
              "      <td>0.882098</td>\n",
              "      <td>0.699892</td>\n",
              "      <td>0.806533</td>\n",
              "      <td>0.908800</td>\n",
              "      <td>0.986622</td>\n",
              "      <td>0.811976</td>\n",
              "      <td>0.947723</td>\n",
              "      <td>0.882443</td>\n",
              "      <td>0.744526</td>\n",
              "      <td>0.672384</td>\n",
              "      <td>0.951923</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.827145</td>\n",
              "      <td>0.835851</td>\n",
              "      <td>0.866713</td>\n",
              "      <td>0.929122</td>\n",
              "      <td>0.989967</td>\n",
              "      <td>0.840939</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.927934</td>\n",
              "      <td>0.868228</td>\n",
              "      <td>0.916803</td>\n",
              "      <td>0.941806</td>\n",
              "      <td>0.840506</td>\n",
              "      <td>0.970336</td>\n",
              "      <td>0.914365</td>\n",
              "      <td>0.799020</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.475401</td>\n",
              "      <td>0.881502</td>\n",
              "      <td>0.881953</td>\n",
              "      <td>0.882174</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.806533</td>\n",
              "      <td>0.908800</td>\n",
              "      <td>0.986622</td>\n",
              "      <td>0.811976</td>\n",
              "      <td>0.948523</td>\n",
              "      <td>0.882443</td>\n",
              "      <td>0.744526</td>\n",
              "      <td>0.672384</td>\n",
              "      <td>0.951270</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.827145</td>\n",
              "      <td>0.835851</td>\n",
              "      <td>0.866713</td>\n",
              "      <td>0.929122</td>\n",
              "      <td>0.989967</td>\n",
              "      <td>0.841146</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.927934</td>\n",
              "      <td>0.868228</td>\n",
              "      <td>0.916803</td>\n",
              "      <td>0.942436</td>\n",
              "      <td>0.839037</td>\n",
              "      <td>0.970336</td>\n",
              "      <td>0.914365</td>\n",
              "      <td>0.800977</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.168300</td>\n",
              "      <td>0.475428</td>\n",
              "      <td>0.881502</td>\n",
              "      <td>0.881953</td>\n",
              "      <td>0.882174</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.806533</td>\n",
              "      <td>0.908800</td>\n",
              "      <td>0.986622</td>\n",
              "      <td>0.811976</td>\n",
              "      <td>0.948523</td>\n",
              "      <td>0.882443</td>\n",
              "      <td>0.744526</td>\n",
              "      <td>0.672384</td>\n",
              "      <td>0.951270</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.827145</td>\n",
              "      <td>0.835851</td>\n",
              "      <td>0.866713</td>\n",
              "      <td>0.929122</td>\n",
              "      <td>0.989967</td>\n",
              "      <td>0.841146</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.927934</td>\n",
              "      <td>0.868228</td>\n",
              "      <td>0.916803</td>\n",
              "      <td>0.942436</td>\n",
              "      <td>0.839037</td>\n",
              "      <td>0.970336</td>\n",
              "      <td>0.914365</td>\n",
              "      <td>0.800977</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH 1 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.4886  NOUVEAU RECORD!\n",
            "  F1-macro: 0.4382\n",
            "  Accuracy: 0.5346\n",
            "  Eval Loss: 2.1484\n",
            " Classes faibles: 10: 0.366, 40: 0.000, 50: 0.157\n",
            "\n",
            "EPOCH 2 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.6560  NOUVEAU RECORD!\n",
            "  F1-macro: 0.6340\n",
            "  Accuracy: 0.6781\n",
            "  Eval Loss: 1.3783\n",
            " Classes faibles: 40: 0.175, 1180: 0.000, 1281: 0.472\n",
            "\n",
            "EPOCH 3 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.7341  NOUVEAU RECORD!\n",
            "  F1-macro: 0.7189\n",
            "  Accuracy: 0.7431\n",
            "  Eval Loss: 0.9889\n",
            " Classes faibles: 40: 0.463, 1180: 0.142, 1280: 0.461\n",
            "\n",
            "EPOCH 4 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.7714  NOUVEAU RECORD!\n",
            "  F1-macro: 0.7646\n",
            "  Accuracy: 0.7755\n",
            "  Eval Loss: 0.7991\n",
            " Classes faibles: 1280: 0.457\n",
            "\n",
            "EPOCH 5 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.7956  NOUVEAU RECORD!\n",
            "  F1-macro: 0.7898\n",
            "  Accuracy: 0.7978\n",
            "  Eval Loss: 0.7112\n",
            "\n",
            "EPOCH 6 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8142  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8086\n",
            "  Accuracy: 0.8147\n",
            "  Eval Loss: 0.6415\n",
            "\n",
            "EPOCH 7 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8229  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8176\n",
            "  Accuracy: 0.8230\n",
            "  Eval Loss: 0.5965\n",
            "\n",
            "EPOCH 8 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8269  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8228\n",
            "  Accuracy: 0.8286\n",
            "  Eval Loss: 0.5864\n",
            "\n",
            "EPOCH 9 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8329  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8277\n",
            "  Accuracy: 0.8329\n",
            "  Eval Loss: 0.5623\n",
            "\n",
            "EPOCH 10 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8391  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8344\n",
            "  Accuracy: 0.8402\n",
            "  Eval Loss: 0.5436\n",
            "\n",
            "EPOCH 11 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8495  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8469\n",
            "  Accuracy: 0.8504\n",
            "  Eval Loss: 0.5201\n",
            "\n",
            "EPOCH 12 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8504  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8477\n",
            "  Accuracy: 0.8514\n",
            "  Eval Loss: 0.5140\n",
            "\n",
            "EPOCH 13 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8579  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8562\n",
            "  Accuracy: 0.8587\n",
            "  Eval Loss: 0.4907\n",
            "\n",
            "EPOCH 14 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8565 \n",
            "  F1-macro: 0.8550\n",
            "  Accuracy: 0.8574\n",
            "  Eval Loss: 0.4910\n",
            "\n",
            "EPOCH 15 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8595  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8594\n",
            "  Accuracy: 0.8606\n",
            "  Eval Loss: 0.4729\n",
            "\n",
            "EPOCH 16 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8588 \n",
            "  F1-macro: 0.8582\n",
            "  Accuracy: 0.8593\n",
            "  Eval Loss: 0.4777\n",
            "\n",
            "EPOCH 17 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8589 \n",
            "  F1-macro: 0.8571\n",
            "  Accuracy: 0.8596\n",
            "  Eval Loss: 0.4876\n",
            "\n",
            "EPOCH 18 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8617  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8596\n",
            "  Accuracy: 0.8622\n",
            "  Eval Loss: 0.4804\n",
            "\n",
            "EPOCH 19 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8652  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8647\n",
            "  Accuracy: 0.8663\n",
            "  Eval Loss: 0.4813\n",
            "\n",
            "EPOCH 20 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8680  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8678\n",
            "  Accuracy: 0.8686\n",
            "  Eval Loss: 0.4701\n",
            "\n",
            "EPOCH 21 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8712  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8706\n",
            "  Accuracy: 0.8720\n",
            "  Eval Loss: 0.4722\n",
            "\n",
            "EPOCH 22 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8698 \n",
            "  F1-macro: 0.8683\n",
            "  Accuracy: 0.8702\n",
            "  Eval Loss: 0.4708\n",
            "\n",
            "EPOCH 23 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8716  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8715\n",
            "  Accuracy: 0.8727\n",
            "  Eval Loss: 0.4628\n",
            "\n",
            "EPOCH 24 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8709 \n",
            "  F1-macro: 0.8714\n",
            "  Accuracy: 0.8720\n",
            "  Eval Loss: 0.4639\n",
            "\n",
            "EPOCH 25 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8735  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8738\n",
            "  Accuracy: 0.8743\n",
            "  Eval Loss: 0.4608\n",
            "\n",
            "EPOCH 26 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8725 \n",
            "  F1-macro: 0.8723\n",
            "  Accuracy: 0.8728\n",
            "  Eval Loss: 0.4669\n",
            "\n",
            "EPOCH 27 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8722 \n",
            "  F1-macro: 0.8728\n",
            "  Accuracy: 0.8730\n",
            "  Eval Loss: 0.4703\n",
            "\n",
            "EPOCH 28 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8750  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8752\n",
            "  Accuracy: 0.8757\n",
            "  Eval Loss: 0.4662\n",
            "\n",
            "EPOCH 29 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8761  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8765\n",
            "  Accuracy: 0.8765\n",
            "  Eval Loss: 0.4652\n",
            "\n",
            "EPOCH 30 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8783  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8783\n",
            "  Accuracy: 0.8787\n",
            "  Eval Loss: 0.4627\n",
            "\n",
            "EPOCH 31 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8774 \n",
            "  F1-macro: 0.8779\n",
            "  Accuracy: 0.8781\n",
            "  Eval Loss: 0.4637\n",
            "\n",
            "EPOCH 32 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8781 \n",
            "  F1-macro: 0.8787\n",
            "  Accuracy: 0.8787\n",
            "  Eval Loss: 0.4656\n",
            "\n",
            "EPOCH 33 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8769 \n",
            "  F1-macro: 0.8770\n",
            "  Accuracy: 0.8775\n",
            "  Eval Loss: 0.4759\n",
            "\n",
            "EPOCH 34 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8777 \n",
            "  F1-macro: 0.8784\n",
            "  Accuracy: 0.8784\n",
            "  Eval Loss: 0.4705\n",
            "\n",
            "EPOCH 35 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8776 \n",
            "  F1-macro: 0.8776\n",
            "  Accuracy: 0.8783\n",
            "  Eval Loss: 0.4808\n",
            "\n",
            "EPOCH 36 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8786  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8794\n",
            "  Accuracy: 0.8789\n",
            "  Eval Loss: 0.4719\n",
            "\n",
            "EPOCH 37 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8798  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8800\n",
            "  Accuracy: 0.8804\n",
            "  Eval Loss: 0.4705\n",
            "\n",
            "EPOCH 38 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8798  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8800\n",
            "  Accuracy: 0.8805\n",
            "  Eval Loss: 0.4745\n",
            "\n",
            "EPOCH 39 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8799  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8804\n",
            "  Accuracy: 0.8806\n",
            "  Eval Loss: 0.4746\n",
            "\n",
            "EPOCH 40 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8806  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8812\n",
            "  Accuracy: 0.8813\n",
            "  Eval Loss: 0.4737\n",
            "\n",
            "EPOCH 41 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8808  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8813\n",
            "  Accuracy: 0.8813\n",
            "  Eval Loss: 0.4730\n",
            "\n",
            "EPOCH 42 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8809  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8810\n",
            "  Accuracy: 0.8814\n",
            "  Eval Loss: 0.4756\n",
            "\n",
            "EPOCH 43 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8812  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8816\n",
            "  Accuracy: 0.8819\n",
            "  Eval Loss: 0.4754\n",
            "\n",
            "EPOCH 44 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8814  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8817\n",
            "  Accuracy: 0.8820\n",
            "  Eval Loss: 0.4754\n",
            "\n",
            "EPOCH 45 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8811 \n",
            "  F1-macro: 0.8817\n",
            "  Accuracy: 0.8817\n",
            "  Eval Loss: 0.4737\n",
            "\n",
            "EPOCH 46 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8819  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8824\n",
            "  Accuracy: 0.8826\n",
            "  Eval Loss: 0.4733\n",
            "\n",
            "EPOCH 47 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8813 \n",
            "  F1-macro: 0.8817\n",
            "  Accuracy: 0.8819\n",
            "  Eval Loss: 0.4751\n",
            "\n",
            "EPOCH 48 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8814 \n",
            "  F1-macro: 0.8819\n",
            "  Accuracy: 0.8821\n",
            "  Eval Loss: 0.4751\n",
            "\n",
            "EPOCH 49 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8815 \n",
            "  F1-macro: 0.8820\n",
            "  Accuracy: 0.8822\n",
            "  Eval Loss: 0.4754\n",
            "\n",
            "EPOCH 50 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8815 \n",
            "  F1-macro: 0.8820\n",
            "  Accuracy: 0.8822\n",
            "  Eval Loss: 0.4754\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meilleur checkpoint : ./results_cam/checkpoint-53544\n",
            "\n",
            "=== SAUVEGARDE DES LOGITS ET LABELS COMPLETS ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== RAPPORT DE CLASSIFICATION FINAL SUR VALIDATION ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "DataLoader worker (pid 170959) is killed by signal: Killed. ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b754db3be386>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_cam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0mlabels_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4250\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4251\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4252\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4253\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4357\u001b[0m         \u001b[0;31m# Main evaluation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4358\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4359\u001b[0m             \u001b[0;31m# Update the observed num examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m             \u001b[0mobserved_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m         self.record = torch.ops.profiler._record_function_enter_new(\n\u001b[0m\u001b[1;32m    753\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 170959) is killed by signal: Killed. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== FLAUBERT ====\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import (\n",
        "    FlaubertTokenizer,\n",
        "    FlaubertForSequenceClassification,\n",
        "    FlaubertConfig,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    EarlyStoppingCallback,\n",
        "    set_seed,\n",
        "    TrainerCallback\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import gc\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "set_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BASE = \"/content/drive/MyDrive/Colab Notebooks/fahim/final\"\n",
        "os.makedirs(BASE + \"/models\", exist_ok=True)\n",
        "os.makedirs(\"./results_fla\", exist_ok=True)\n",
        "print(f\"Device utilisé: {device}\")\n",
        "\n",
        "# Chargement des données et labels\n",
        "df = pd.read_csv(os.path.join(BASE, \"X_trainfr_finalCollab.csv\"))\n",
        "le = joblib.load(os.path.join(BASE, 'label_encoder_final.pkl'))\n",
        "texts = df['translated_text_combined'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "with open(os.path.join(BASE, 'val_indices.json'), 'r') as f:\n",
        "    val_idx = np.array(json.load(f), dtype=int)\n",
        "train_idx = np.setdiff1d(np.arange(len(df)), val_idx)\n",
        "print(f\"Train: {len(train_idx)}, Validation: {len(val_idx)}\")\n",
        "\n",
        "# Calculer les poids de classe pour CrossEntropyLoss\n",
        "class_weights_np = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(labels),\n",
        "    y=labels\n",
        ")\n",
        "class_weights = torch.tensor(class_weights_np, dtype=torch.float).to(device)\n",
        "\n",
        "# Dataset PyTorch personnalisé\n",
        "class TextDS(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
        "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, i):\n",
        "        item = {k: v[i] for k, v in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[i], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# Trainer pondéré CrossEntropy\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get('logits')\n",
        "        loss_fct = CrossEntropyLoss(weight=class_weights)\n",
        "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Fonction métriques détaillées\n",
        "def compute_metrics_detailed(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(axis=1)\n",
        "    f1_per_class = f1_score(labels, preds, average=None)\n",
        "    f1_macro = f1_score(labels, preds, average=\"macro\")\n",
        "    f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    class_perf = {f\"f1_class_{i}_{le.classes_[i]}\": f1 for i, f1 in enumerate(f1_per_class)}\n",
        "    return {\n",
        "        \"f1_weighted\": f1_weighted,\n",
        "        \"f1_macro\": f1_macro,\n",
        "        \"accuracy\": accuracy,\n",
        "        **class_perf\n",
        "    }\n",
        "\n",
        "# Callback affichage métriques par epoch (texte)\n",
        "class DetailedLoggingCallback(TrainerCallback):\n",
        "    def __init__(self, le_classes):\n",
        "        self.le_classes = le_classes\n",
        "        self.best_f1 = 0\n",
        "    def on_evaluate(self, args, state, control, model=None, eval_dataloader=None, **kwargs):\n",
        "        if state.epoch is not None and state.epoch == int(state.epoch):\n",
        "            current_epoch = int(state.epoch)\n",
        "            if hasattr(state, 'log_history') and state.log_history:\n",
        "                last_eval = next((log for log in reversed(state.log_history) if 'eval_f1_weighted' in log), None)\n",
        "                if last_eval:\n",
        "                    current_f1 = last_eval.get('eval_f1_weighted', 0)\n",
        "                    print(f\"\\nEPOCH {current_epoch} - RÉSULTATS DÉTAILLÉS:\")\n",
        "                    print(f\"  F1-weighted: {current_f1:.4f} {' NOUVEAU RECORD!' if current_f1 > self.best_f1 else ''}\")\n",
        "                    print(f\"  F1-macro: {last_eval.get('eval_f1_macro', 0):.4f}\")\n",
        "                    print(f\"  Accuracy: {last_eval.get('eval_accuracy', 0):.4f}\")\n",
        "                    print(f\"  Eval Loss: {last_eval.get('eval_loss', 0):.4f}\")\n",
        "                    if current_f1 > self.best_f1:\n",
        "                        self.best_f1 = current_f1\n",
        "                    weak_classes = [f\"{key.split('_')[-1]}: {value:.3f}\" for key, value in last_eval.items() if key.startswith('eval_f1_class_') and value < 0.5]\n",
        "                    if weak_classes:\n",
        "                        print(f\" Classes faibles: {', '.join(weak_classes[:3])}\")\n",
        "\n",
        "# Callback pour vider la RAM CPU à la fin de chaque epoch\n",
        "class RAMCleanupCallback(TrainerCallback):\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# Initialisation tokenizer + datasets + splits\n",
        "fla_tok = FlaubertTokenizer.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
        "full_fla = TextDS(texts, labels, fla_tok, max_length=512)\n",
        "train_fla = Subset(full_fla, train_idx)\n",
        "val_fla = Subset(full_fla, val_idx)\n",
        "\n",
        "num_labels = len(le.classes_)\n",
        "\n",
        "# Configuration du modèle avec dropout personnalisé\n",
        "config = FlaubertConfig.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
        "config.num_labels = num_labels\n",
        "config.dropout = 0.3\n",
        "config.attention_dropout = 0.3\n",
        "\n",
        "# Chargement modèle FlauBERT avec configuration personnalisée\n",
        "model = FlaubertForSequenceClassification.from_pretrained(\n",
        "    \"flaubert/flaubert_base_cased\",\n",
        "    config=config\n",
        ").to(device)\n",
        "\n",
        "# Arguments entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results_fla\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=48,\n",
        "    per_device_eval_batch_size=96,\n",
        "    num_train_epochs=50,\n",
        "    weight_decay=0.1,\n",
        "    warmup_steps=500,\n",
        "    lr_scheduler_type=\"cosine_with_restarts\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_weighted\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\",\n",
        "    gradient_accumulation_steps=1,\n",
        "    max_grad_norm=1.0,\n",
        "    dataloader_num_workers=16,\n",
        "    dataloader_pin_memory=False,\n",
        "    save_total_limit=3,\n",
        "    fp16=True,\n",
        "    dataloader_persistent_workers=True,\n",
        "    dataloader_prefetch_factor=4,\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStoppingCallback(\n",
        "    early_stopping_patience=8,\n",
        "    early_stopping_threshold=0.0005\n",
        ")\n",
        "\n",
        "detailed_logging = DetailedLoggingCallback(le.classes_)\n",
        "ram_cleanup = RAMCleanupCallback()\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_fla,\n",
        "    eval_dataset=val_fla,\n",
        "    data_collator=DataCollatorWithPadding(fla_tok),\n",
        "    compute_metrics=compute_metrics_detailed,\n",
        "    callbacks=[early_stopping, detailed_logging, ram_cleanup]\n",
        ")\n",
        "\n",
        "print(\"\\n=== DÉBUT DE L'ENTRAÎNEMENT FLAUBERT ===\")\n",
        "trainer.train()\n",
        "\n",
        "best_checkpoint = trainer.state.best_model_checkpoint\n",
        "print(f\"Meilleur checkpoint : {best_checkpoint}\")\n",
        "\n",
        "# Sauvegarde du modèle\n",
        "best_model = FlaubertForSequenceClassification.from_pretrained(best_checkpoint)\n",
        "best_model.save_pretrained(os.path.join(BASE, \"flaubert2_model\"))\n",
        "\n",
        "# Sauvegarde des logits complets\n",
        "print(\"\\n=== SAUVEGARDE DES LOGITS ET LABELS COMPLETS ===\")\n",
        "fla_logits = trainer.predict(full_fla).predictions\n",
        "torch.save(torch.tensor(fla_logits), os.path.join(BASE, \"flaubert2_logits.pt\"))\n",
        "\n",
        "print(\"\\n=== RAPPORT DE CLASSIFICATION FINAL SUR VALIDATION ===\")\n",
        "with open(os.path.join(BASE, \"label_mapping_final.json\"), \"r\") as f:\n",
        "    label_mapping = json.load(f)\n",
        "class_names = [label_mapping[str(i)][\"label_name\"] for i in range(len(label_mapping))]\n",
        "\n",
        "predictions = trainer.predict(val_fla)\n",
        "preds = predictions.predictions.argmax(axis=1)\n",
        "labels_val = predictions.label_ids\n",
        "print(classification_report(labels_val, preds, target_names=class_names))\n",
        "\n",
        "# Nettoyage mémoire final\n",
        "del trainer, model, best_model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"\\n=== ENTRAÎNEMENT FLAUBERT TERMINÉ ===\")"
      ],
      "metadata": {
        "id": "jQqdxc4NF2Xk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8641fd56d8874a8a8ac103413663571a",
            "c7f2f916ef7140d386ffd3c405fa91ab",
            "631a576369e342d386bb545cb2d91162",
            "a19870d611754e8e870727bac8761454",
            "5c8ce7813a6e46e6be10e9a3c53fb0ea",
            "11a09ee3e47842ee9a72f07d24217abf",
            "b18f54cd43f142c09bfc3411955ff504",
            "4151fc8fd5ae494fafe2c324c9b5e7f3",
            "be20494f54ec46c897a4a951e45d6c8e",
            "ee29f4ca614b4635825c10403422041e",
            "f4390a9799de46b28467ac809949eeb6",
            "c4728596336842dd8a44995f92224886",
            "47f2cd21d10b455eb3b1103004d799d6",
            "52e17bae70a14a838492b6f0ae7d712a",
            "6398eb464fa74b488684fad0fed265b4",
            "de4573e8306548a78be2d3b670675dab",
            "b4ca18c38fa6482ea258cadaa157237b",
            "dc0816b0179d4a64a8d3d3e18d06caa0",
            "56c974b738034c50b495ab931f3eef95",
            "e9916e3187d3488590fdf5c06fe52d6c",
            "9f071a366ed743c39c90f19494d0f409",
            "0c85fd10258a4844a9a4521d3bf43885",
            "88d442047c574385be53cc08078927e6",
            "b8d1bc4706fe422d9f465b2eca3ed5d4",
            "1e467404879b4db89e8363bf4f7e43a4",
            "4d3d4dbbe6ee4d2985a068884d1c8ae8",
            "bfacb6f470c54cfcbc74c5c1b53897a6",
            "1daec2a6a19f43ffb1b6a428f53d97e4",
            "6d85810f013640d9a7404929820d6694",
            "9e8e560e491f4917b844798cca108eb1",
            "12e1e3fba1ac44e5965f6af7255c7286",
            "8295ba0db6c84f5b957ad6beaf9d7040",
            "efca43122d034434856fb35f36963d73",
            "2642806dcd5f441d928bcd6c1014053f",
            "52ec42cb1bfc47da9d49da5fa380c3e6",
            "8ea60278b9cb4fef834ccab908c93700",
            "9b0e64b8c82a46c88a4f1c91f0f93062",
            "bb1153306e9b4fb9b795437b32da5642",
            "d2a397cfaa8d477db62b8f0872a4cdf9",
            "a2fae01286a84d83a24ccb59989c7142",
            "a8da7be480e648dd8aa3a084e0394188",
            "c960b4d5b3974468b8b1d3b3bc373b5f",
            "63922b565d0d4ed28ca44a7a165b10d3",
            "37ab7c45c1f14e35b7f79963d10ce395",
            "9ac096e74dd34a6396b716c171ef2dc3",
            "d7a23612be20438884846a91aa726a99",
            "d8381bbcefe446f2a88e59f3ac6eddc3",
            "81888e73ca7d4e93ba80dce3e04824ce",
            "9d8baf4217944d3e9c4e3dbe74bcdcb7",
            "30f018bee4b14ac393a6560e438f3d7e",
            "095ef07abcbd42939d1472cd4fdb8834",
            "c933cc217688481b81a9ba27f0a53327",
            "72535b242ae24d4894a66edfa6197c2d",
            "f2a7ddb88d1c4b93b2c952a244af1188",
            "3651e0b457b6419e97275160a1f62734"
          ]
        },
        "outputId": "c0f4b0f7-3c19-4a8e-e125-e7faaf085302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device utilisé: cuda\n",
            "Train: 74447, Validation: 13138\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8641fd56d8874a8a8ac103413663571a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.56M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4728596336842dd8a44995f92224886"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/896k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88d442047c574385be53cc08078927e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2642806dcd5f441d928bcd6c1014053f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/553M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ac096e74dd34a6396b716c171ef2dc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of FlaubertForSequenceClassification were not initialized from the model checkpoint at flaubert/flaubert_base_cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== DÉBUT DE L'ENTRAÎNEMENT FLAUBERT ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='52734' max='77550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [52734/77550 4:18:15 < 2:01:32, 3.40 it/s, Epoch 34/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Class 0 10</th>\n",
              "      <th>F1 Class 1 40</th>\n",
              "      <th>F1 Class 2 50</th>\n",
              "      <th>F1 Class 3 60</th>\n",
              "      <th>F1 Class 4 1140</th>\n",
              "      <th>F1 Class 5 1160</th>\n",
              "      <th>F1 Class 6 1180</th>\n",
              "      <th>F1 Class 7 1280</th>\n",
              "      <th>F1 Class 8 1281</th>\n",
              "      <th>F1 Class 9 1300</th>\n",
              "      <th>F1 Class 10 1301</th>\n",
              "      <th>F1 Class 11 1302</th>\n",
              "      <th>F1 Class 12 1320</th>\n",
              "      <th>F1 Class 13 1560</th>\n",
              "      <th>F1 Class 14 1920</th>\n",
              "      <th>F1 Class 15 1940</th>\n",
              "      <th>F1 Class 16 2060</th>\n",
              "      <th>F1 Class 17 2220</th>\n",
              "      <th>F1 Class 18 2280</th>\n",
              "      <th>F1 Class 19 2403</th>\n",
              "      <th>F1 Class 20 2462</th>\n",
              "      <th>F1 Class 21 2522</th>\n",
              "      <th>F1 Class 22 2582</th>\n",
              "      <th>F1 Class 23 2583</th>\n",
              "      <th>F1 Class 24 2585</th>\n",
              "      <th>F1 Class 25 2705</th>\n",
              "      <th>F1 Class 26 2905</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.087200</td>\n",
              "      <td>1.167331</td>\n",
              "      <td>0.657454</td>\n",
              "      <td>0.640417</td>\n",
              "      <td>0.663039</td>\n",
              "      <td>0.453052</td>\n",
              "      <td>0.313576</td>\n",
              "      <td>0.608280</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.458599</td>\n",
              "      <td>0.686540</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.485938</td>\n",
              "      <td>0.373288</td>\n",
              "      <td>0.791128</td>\n",
              "      <td>0.849758</td>\n",
              "      <td>0.575269</td>\n",
              "      <td>0.577083</td>\n",
              "      <td>0.682759</td>\n",
              "      <td>0.834109</td>\n",
              "      <td>0.813031</td>\n",
              "      <td>0.678806</td>\n",
              "      <td>0.828885</td>\n",
              "      <td>0.782486</td>\n",
              "      <td>0.562368</td>\n",
              "      <td>0.511771</td>\n",
              "      <td>0.770470</td>\n",
              "      <td>0.591978</td>\n",
              "      <td>0.892529</td>\n",
              "      <td>0.648402</td>\n",
              "      <td>0.687879</td>\n",
              "      <td>0.907436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.143000</td>\n",
              "      <td>0.856855</td>\n",
              "      <td>0.736850</td>\n",
              "      <td>0.730987</td>\n",
              "      <td>0.737631</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.573727</td>\n",
              "      <td>0.696756</td>\n",
              "      <td>0.875458</td>\n",
              "      <td>0.636656</td>\n",
              "      <td>0.783969</td>\n",
              "      <td>0.525698</td>\n",
              "      <td>0.498078</td>\n",
              "      <td>0.482955</td>\n",
              "      <td>0.836907</td>\n",
              "      <td>0.858896</td>\n",
              "      <td>0.660352</td>\n",
              "      <td>0.654832</td>\n",
              "      <td>0.731114</td>\n",
              "      <td>0.842825</td>\n",
              "      <td>0.909953</td>\n",
              "      <td>0.711765</td>\n",
              "      <td>0.828313</td>\n",
              "      <td>0.838057</td>\n",
              "      <td>0.714185</td>\n",
              "      <td>0.690967</td>\n",
              "      <td>0.842333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.914021</td>\n",
              "      <td>0.736413</td>\n",
              "      <td>0.729763</td>\n",
              "      <td>0.983498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.935300</td>\n",
              "      <td>0.797169</td>\n",
              "      <td>0.757504</td>\n",
              "      <td>0.749515</td>\n",
              "      <td>0.759020</td>\n",
              "      <td>0.563207</td>\n",
              "      <td>0.585209</td>\n",
              "      <td>0.723056</td>\n",
              "      <td>0.879339</td>\n",
              "      <td>0.677146</td>\n",
              "      <td>0.845121</td>\n",
              "      <td>0.554622</td>\n",
              "      <td>0.457143</td>\n",
              "      <td>0.488457</td>\n",
              "      <td>0.890541</td>\n",
              "      <td>0.902913</td>\n",
              "      <td>0.696023</td>\n",
              "      <td>0.696731</td>\n",
              "      <td>0.752089</td>\n",
              "      <td>0.858006</td>\n",
              "      <td>0.884558</td>\n",
              "      <td>0.742779</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>0.862826</td>\n",
              "      <td>0.747024</td>\n",
              "      <td>0.701518</td>\n",
              "      <td>0.855337</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.779330</td>\n",
              "      <td>0.753623</td>\n",
              "      <td>0.983553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.812600</td>\n",
              "      <td>0.711242</td>\n",
              "      <td>0.782596</td>\n",
              "      <td>0.776534</td>\n",
              "      <td>0.785508</td>\n",
              "      <td>0.492958</td>\n",
              "      <td>0.622556</td>\n",
              "      <td>0.769001</td>\n",
              "      <td>0.866460</td>\n",
              "      <td>0.712999</td>\n",
              "      <td>0.885965</td>\n",
              "      <td>0.667660</td>\n",
              "      <td>0.573259</td>\n",
              "      <td>0.510152</td>\n",
              "      <td>0.916782</td>\n",
              "      <td>0.940594</td>\n",
              "      <td>0.712435</td>\n",
              "      <td>0.704319</td>\n",
              "      <td>0.770053</td>\n",
              "      <td>0.855457</td>\n",
              "      <td>0.927445</td>\n",
              "      <td>0.752161</td>\n",
              "      <td>0.853659</td>\n",
              "      <td>0.858316</td>\n",
              "      <td>0.767218</td>\n",
              "      <td>0.742947</td>\n",
              "      <td>0.889333</td>\n",
              "      <td>0.697248</td>\n",
              "      <td>0.939096</td>\n",
              "      <td>0.808989</td>\n",
              "      <td>0.742553</td>\n",
              "      <td>0.986799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.724900</td>\n",
              "      <td>0.612681</td>\n",
              "      <td>0.816245</td>\n",
              "      <td>0.811588</td>\n",
              "      <td>0.815954</td>\n",
              "      <td>0.625892</td>\n",
              "      <td>0.694340</td>\n",
              "      <td>0.786885</td>\n",
              "      <td>0.924875</td>\n",
              "      <td>0.728774</td>\n",
              "      <td>0.909565</td>\n",
              "      <td>0.735245</td>\n",
              "      <td>0.655450</td>\n",
              "      <td>0.564315</td>\n",
              "      <td>0.936828</td>\n",
              "      <td>0.941558</td>\n",
              "      <td>0.729252</td>\n",
              "      <td>0.721533</td>\n",
              "      <td>0.787709</td>\n",
              "      <td>0.879349</td>\n",
              "      <td>0.963934</td>\n",
              "      <td>0.779362</td>\n",
              "      <td>0.866864</td>\n",
              "      <td>0.873239</td>\n",
              "      <td>0.806886</td>\n",
              "      <td>0.788274</td>\n",
              "      <td>0.901159</td>\n",
              "      <td>0.742574</td>\n",
              "      <td>0.951751</td>\n",
              "      <td>0.845506</td>\n",
              "      <td>0.775068</td>\n",
              "      <td>0.996678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.648100</td>\n",
              "      <td>0.611358</td>\n",
              "      <td>0.816603</td>\n",
              "      <td>0.810598</td>\n",
              "      <td>0.817095</td>\n",
              "      <td>0.598558</td>\n",
              "      <td>0.684783</td>\n",
              "      <td>0.792453</td>\n",
              "      <td>0.896445</td>\n",
              "      <td>0.724390</td>\n",
              "      <td>0.905172</td>\n",
              "      <td>0.651048</td>\n",
              "      <td>0.656855</td>\n",
              "      <td>0.563953</td>\n",
              "      <td>0.935844</td>\n",
              "      <td>0.963455</td>\n",
              "      <td>0.748031</td>\n",
              "      <td>0.713436</td>\n",
              "      <td>0.803069</td>\n",
              "      <td>0.882789</td>\n",
              "      <td>0.968801</td>\n",
              "      <td>0.794693</td>\n",
              "      <td>0.893683</td>\n",
              "      <td>0.868863</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.767402</td>\n",
              "      <td>0.910221</td>\n",
              "      <td>0.775457</td>\n",
              "      <td>0.954335</td>\n",
              "      <td>0.861745</td>\n",
              "      <td>0.775648</td>\n",
              "      <td>0.995008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.593800</td>\n",
              "      <td>0.566907</td>\n",
              "      <td>0.829064</td>\n",
              "      <td>0.823980</td>\n",
              "      <td>0.830111</td>\n",
              "      <td>0.582500</td>\n",
              "      <td>0.696296</td>\n",
              "      <td>0.779412</td>\n",
              "      <td>0.943522</td>\n",
              "      <td>0.744131</td>\n",
              "      <td>0.916183</td>\n",
              "      <td>0.738416</td>\n",
              "      <td>0.689604</td>\n",
              "      <td>0.585516</td>\n",
              "      <td>0.956815</td>\n",
              "      <td>0.964286</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.752665</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.891566</td>\n",
              "      <td>0.965630</td>\n",
              "      <td>0.801614</td>\n",
              "      <td>0.905132</td>\n",
              "      <td>0.893886</td>\n",
              "      <td>0.801200</td>\n",
              "      <td>0.791319</td>\n",
              "      <td>0.910458</td>\n",
              "      <td>0.761457</td>\n",
              "      <td>0.955482</td>\n",
              "      <td>0.866485</td>\n",
              "      <td>0.763429</td>\n",
              "      <td>0.998336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.546600</td>\n",
              "      <td>0.533491</td>\n",
              "      <td>0.833151</td>\n",
              "      <td>0.830519</td>\n",
              "      <td>0.835059</td>\n",
              "      <td>0.604478</td>\n",
              "      <td>0.673966</td>\n",
              "      <td>0.822581</td>\n",
              "      <td>0.952055</td>\n",
              "      <td>0.762255</td>\n",
              "      <td>0.921484</td>\n",
              "      <td>0.733871</td>\n",
              "      <td>0.660535</td>\n",
              "      <td>0.561622</td>\n",
              "      <td>0.955466</td>\n",
              "      <td>0.980198</td>\n",
              "      <td>0.782034</td>\n",
              "      <td>0.768603</td>\n",
              "      <td>0.813084</td>\n",
              "      <td>0.884286</td>\n",
              "      <td>0.975207</td>\n",
              "      <td>0.776435</td>\n",
              "      <td>0.937198</td>\n",
              "      <td>0.889336</td>\n",
              "      <td>0.815752</td>\n",
              "      <td>0.822222</td>\n",
              "      <td>0.919289</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.964380</td>\n",
              "      <td>0.887671</td>\n",
              "      <td>0.795767</td>\n",
              "      <td>0.995008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.506400</td>\n",
              "      <td>0.521671</td>\n",
              "      <td>0.845415</td>\n",
              "      <td>0.842039</td>\n",
              "      <td>0.844801</td>\n",
              "      <td>0.644211</td>\n",
              "      <td>0.700665</td>\n",
              "      <td>0.825600</td>\n",
              "      <td>0.964824</td>\n",
              "      <td>0.763285</td>\n",
              "      <td>0.923213</td>\n",
              "      <td>0.753463</td>\n",
              "      <td>0.674230</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.956873</td>\n",
              "      <td>0.977049</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.813853</td>\n",
              "      <td>0.830189</td>\n",
              "      <td>0.907727</td>\n",
              "      <td>0.968903</td>\n",
              "      <td>0.800272</td>\n",
              "      <td>0.946515</td>\n",
              "      <td>0.897305</td>\n",
              "      <td>0.830056</td>\n",
              "      <td>0.832536</td>\n",
              "      <td>0.926630</td>\n",
              "      <td>0.801527</td>\n",
              "      <td>0.966158</td>\n",
              "      <td>0.895978</td>\n",
              "      <td>0.795062</td>\n",
              "      <td>0.991708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.470800</td>\n",
              "      <td>0.487557</td>\n",
              "      <td>0.849994</td>\n",
              "      <td>0.847840</td>\n",
              "      <td>0.851119</td>\n",
              "      <td>0.610086</td>\n",
              "      <td>0.729223</td>\n",
              "      <td>0.878444</td>\n",
              "      <td>0.958678</td>\n",
              "      <td>0.763158</td>\n",
              "      <td>0.936207</td>\n",
              "      <td>0.747989</td>\n",
              "      <td>0.684334</td>\n",
              "      <td>0.597938</td>\n",
              "      <td>0.961460</td>\n",
              "      <td>0.972268</td>\n",
              "      <td>0.795244</td>\n",
              "      <td>0.784708</td>\n",
              "      <td>0.841897</td>\n",
              "      <td>0.911742</td>\n",
              "      <td>0.973597</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.946688</td>\n",
              "      <td>0.902557</td>\n",
              "      <td>0.821530</td>\n",
              "      <td>0.867314</td>\n",
              "      <td>0.922656</td>\n",
              "      <td>0.810345</td>\n",
              "      <td>0.965744</td>\n",
              "      <td>0.892517</td>\n",
              "      <td>0.803063</td>\n",
              "      <td>0.998331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.437900</td>\n",
              "      <td>0.475222</td>\n",
              "      <td>0.857224</td>\n",
              "      <td>0.854845</td>\n",
              "      <td>0.857208</td>\n",
              "      <td>0.660173</td>\n",
              "      <td>0.729825</td>\n",
              "      <td>0.860317</td>\n",
              "      <td>0.947712</td>\n",
              "      <td>0.774942</td>\n",
              "      <td>0.931125</td>\n",
              "      <td>0.819970</td>\n",
              "      <td>0.682258</td>\n",
              "      <td>0.614951</td>\n",
              "      <td>0.960705</td>\n",
              "      <td>0.986711</td>\n",
              "      <td>0.811908</td>\n",
              "      <td>0.799601</td>\n",
              "      <td>0.852210</td>\n",
              "      <td>0.914199</td>\n",
              "      <td>0.980132</td>\n",
              "      <td>0.822626</td>\n",
              "      <td>0.911353</td>\n",
              "      <td>0.915862</td>\n",
              "      <td>0.839192</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.932881</td>\n",
              "      <td>0.805419</td>\n",
              "      <td>0.967657</td>\n",
              "      <td>0.894952</td>\n",
              "      <td>0.800931</td>\n",
              "      <td>0.998331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.408300</td>\n",
              "      <td>0.482340</td>\n",
              "      <td>0.856040</td>\n",
              "      <td>0.855086</td>\n",
              "      <td>0.857208</td>\n",
              "      <td>0.646298</td>\n",
              "      <td>0.762295</td>\n",
              "      <td>0.873065</td>\n",
              "      <td>0.972696</td>\n",
              "      <td>0.766110</td>\n",
              "      <td>0.940486</td>\n",
              "      <td>0.815249</td>\n",
              "      <td>0.683955</td>\n",
              "      <td>0.629730</td>\n",
              "      <td>0.959569</td>\n",
              "      <td>0.973856</td>\n",
              "      <td>0.794451</td>\n",
              "      <td>0.797342</td>\n",
              "      <td>0.837022</td>\n",
              "      <td>0.914329</td>\n",
              "      <td>0.978441</td>\n",
              "      <td>0.813678</td>\n",
              "      <td>0.949757</td>\n",
              "      <td>0.908595</td>\n",
              "      <td>0.833938</td>\n",
              "      <td>0.850082</td>\n",
              "      <td>0.930574</td>\n",
              "      <td>0.779741</td>\n",
              "      <td>0.966601</td>\n",
              "      <td>0.898630</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.998331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.382700</td>\n",
              "      <td>0.465262</td>\n",
              "      <td>0.865194</td>\n",
              "      <td>0.862964</td>\n",
              "      <td>0.865352</td>\n",
              "      <td>0.662831</td>\n",
              "      <td>0.767263</td>\n",
              "      <td>0.887417</td>\n",
              "      <td>0.968174</td>\n",
              "      <td>0.781775</td>\n",
              "      <td>0.944056</td>\n",
              "      <td>0.812680</td>\n",
              "      <td>0.721109</td>\n",
              "      <td>0.630098</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.958466</td>\n",
              "      <td>0.811908</td>\n",
              "      <td>0.804233</td>\n",
              "      <td>0.856160</td>\n",
              "      <td>0.920489</td>\n",
              "      <td>0.983444</td>\n",
              "      <td>0.832425</td>\n",
              "      <td>0.957516</td>\n",
              "      <td>0.919444</td>\n",
              "      <td>0.844250</td>\n",
              "      <td>0.867200</td>\n",
              "      <td>0.933694</td>\n",
              "      <td>0.802902</td>\n",
              "      <td>0.965789</td>\n",
              "      <td>0.893387</td>\n",
              "      <td>0.812013</td>\n",
              "      <td>0.998331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.362100</td>\n",
              "      <td>0.447314</td>\n",
              "      <td>0.868445</td>\n",
              "      <td>0.866952</td>\n",
              "      <td>0.868625</td>\n",
              "      <td>0.670954</td>\n",
              "      <td>0.761194</td>\n",
              "      <td>0.868750</td>\n",
              "      <td>0.960526</td>\n",
              "      <td>0.789976</td>\n",
              "      <td>0.947009</td>\n",
              "      <td>0.822823</td>\n",
              "      <td>0.710900</td>\n",
              "      <td>0.629681</td>\n",
              "      <td>0.964406</td>\n",
              "      <td>0.988430</td>\n",
              "      <td>0.815115</td>\n",
              "      <td>0.806517</td>\n",
              "      <td>0.859230</td>\n",
              "      <td>0.925532</td>\n",
              "      <td>0.981818</td>\n",
              "      <td>0.834031</td>\n",
              "      <td>0.967532</td>\n",
              "      <td>0.921088</td>\n",
              "      <td>0.840149</td>\n",
              "      <td>0.882662</td>\n",
              "      <td>0.934492</td>\n",
              "      <td>0.823834</td>\n",
              "      <td>0.974086</td>\n",
              "      <td>0.905660</td>\n",
              "      <td>0.822967</td>\n",
              "      <td>0.998331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.339300</td>\n",
              "      <td>0.463128</td>\n",
              "      <td>0.867447</td>\n",
              "      <td>0.865937</td>\n",
              "      <td>0.868321</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.883943</td>\n",
              "      <td>0.967105</td>\n",
              "      <td>0.798133</td>\n",
              "      <td>0.945993</td>\n",
              "      <td>0.855385</td>\n",
              "      <td>0.736264</td>\n",
              "      <td>0.660633</td>\n",
              "      <td>0.965841</td>\n",
              "      <td>0.991708</td>\n",
              "      <td>0.834225</td>\n",
              "      <td>0.796238</td>\n",
              "      <td>0.860963</td>\n",
              "      <td>0.917119</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.830051</td>\n",
              "      <td>0.957792</td>\n",
              "      <td>0.914952</td>\n",
              "      <td>0.841727</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.936828</td>\n",
              "      <td>0.804651</td>\n",
              "      <td>0.970938</td>\n",
              "      <td>0.879581</td>\n",
              "      <td>0.803132</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.319300</td>\n",
              "      <td>0.456442</td>\n",
              "      <td>0.868659</td>\n",
              "      <td>0.866726</td>\n",
              "      <td>0.869006</td>\n",
              "      <td>0.678652</td>\n",
              "      <td>0.753939</td>\n",
              "      <td>0.880368</td>\n",
              "      <td>0.983165</td>\n",
              "      <td>0.785805</td>\n",
              "      <td>0.949094</td>\n",
              "      <td>0.803371</td>\n",
              "      <td>0.723946</td>\n",
              "      <td>0.641940</td>\n",
              "      <td>0.967224</td>\n",
              "      <td>0.991736</td>\n",
              "      <td>0.821053</td>\n",
              "      <td>0.801268</td>\n",
              "      <td>0.851578</td>\n",
              "      <td>0.925532</td>\n",
              "      <td>0.980198</td>\n",
              "      <td>0.831282</td>\n",
              "      <td>0.940252</td>\n",
              "      <td>0.925620</td>\n",
              "      <td>0.850405</td>\n",
              "      <td>0.899145</td>\n",
              "      <td>0.940379</td>\n",
              "      <td>0.816229</td>\n",
              "      <td>0.967869</td>\n",
              "      <td>0.890095</td>\n",
              "      <td>0.803132</td>\n",
              "      <td>0.998331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.302100</td>\n",
              "      <td>0.466348</td>\n",
              "      <td>0.869862</td>\n",
              "      <td>0.867846</td>\n",
              "      <td>0.870376</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.756691</td>\n",
              "      <td>0.867925</td>\n",
              "      <td>0.981636</td>\n",
              "      <td>0.789779</td>\n",
              "      <td>0.945830</td>\n",
              "      <td>0.805594</td>\n",
              "      <td>0.717042</td>\n",
              "      <td>0.667665</td>\n",
              "      <td>0.968835</td>\n",
              "      <td>0.990033</td>\n",
              "      <td>0.820645</td>\n",
              "      <td>0.788501</td>\n",
              "      <td>0.866347</td>\n",
              "      <td>0.921792</td>\n",
              "      <td>0.980066</td>\n",
              "      <td>0.834464</td>\n",
              "      <td>0.952077</td>\n",
              "      <td>0.927736</td>\n",
              "      <td>0.850713</td>\n",
              "      <td>0.887372</td>\n",
              "      <td>0.943499</td>\n",
              "      <td>0.835279</td>\n",
              "      <td>0.974291</td>\n",
              "      <td>0.896921</td>\n",
              "      <td>0.796117</td>\n",
              "      <td>0.998331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.285900</td>\n",
              "      <td>0.473538</td>\n",
              "      <td>0.870529</td>\n",
              "      <td>0.869450</td>\n",
              "      <td>0.870376</td>\n",
              "      <td>0.663784</td>\n",
              "      <td>0.783398</td>\n",
              "      <td>0.888199</td>\n",
              "      <td>0.979933</td>\n",
              "      <td>0.773510</td>\n",
              "      <td>0.952951</td>\n",
              "      <td>0.797799</td>\n",
              "      <td>0.723618</td>\n",
              "      <td>0.680597</td>\n",
              "      <td>0.964722</td>\n",
              "      <td>0.991708</td>\n",
              "      <td>0.825806</td>\n",
              "      <td>0.804481</td>\n",
              "      <td>0.852901</td>\n",
              "      <td>0.930375</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.843357</td>\n",
              "      <td>0.962602</td>\n",
              "      <td>0.920999</td>\n",
              "      <td>0.844512</td>\n",
              "      <td>0.878378</td>\n",
              "      <td>0.937759</td>\n",
              "      <td>0.817308</td>\n",
              "      <td>0.967869</td>\n",
              "      <td>0.906815</td>\n",
              "      <td>0.796690</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.267900</td>\n",
              "      <td>0.460058</td>\n",
              "      <td>0.874004</td>\n",
              "      <td>0.874175</td>\n",
              "      <td>0.874638</td>\n",
              "      <td>0.676923</td>\n",
              "      <td>0.787097</td>\n",
              "      <td>0.888535</td>\n",
              "      <td>0.979798</td>\n",
              "      <td>0.795092</td>\n",
              "      <td>0.950904</td>\n",
              "      <td>0.847059</td>\n",
              "      <td>0.728682</td>\n",
              "      <td>0.675883</td>\n",
              "      <td>0.964213</td>\n",
              "      <td>0.995008</td>\n",
              "      <td>0.830968</td>\n",
              "      <td>0.798799</td>\n",
              "      <td>0.845461</td>\n",
              "      <td>0.923308</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.840220</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.922652</td>\n",
              "      <td>0.854015</td>\n",
              "      <td>0.903437</td>\n",
              "      <td>0.945159</td>\n",
              "      <td>0.826994</td>\n",
              "      <td>0.966645</td>\n",
              "      <td>0.911565</td>\n",
              "      <td>0.802721</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.256700</td>\n",
              "      <td>0.455362</td>\n",
              "      <td>0.879763</td>\n",
              "      <td>0.879510</td>\n",
              "      <td>0.880347</td>\n",
              "      <td>0.688636</td>\n",
              "      <td>0.798398</td>\n",
              "      <td>0.890966</td>\n",
              "      <td>0.985025</td>\n",
              "      <td>0.802424</td>\n",
              "      <td>0.954428</td>\n",
              "      <td>0.859675</td>\n",
              "      <td>0.740230</td>\n",
              "      <td>0.678519</td>\n",
              "      <td>0.964674</td>\n",
              "      <td>0.985173</td>\n",
              "      <td>0.818068</td>\n",
              "      <td>0.820821</td>\n",
              "      <td>0.865191</td>\n",
              "      <td>0.928953</td>\n",
              "      <td>0.986711</td>\n",
              "      <td>0.845833</td>\n",
              "      <td>0.970588</td>\n",
              "      <td>0.928375</td>\n",
              "      <td>0.861152</td>\n",
              "      <td>0.911864</td>\n",
              "      <td>0.948287</td>\n",
              "      <td>0.839444</td>\n",
              "      <td>0.962289</td>\n",
              "      <td>0.895317</td>\n",
              "      <td>0.815730</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.242400</td>\n",
              "      <td>0.467292</td>\n",
              "      <td>0.880649</td>\n",
              "      <td>0.880400</td>\n",
              "      <td>0.881032</td>\n",
              "      <td>0.690021</td>\n",
              "      <td>0.778061</td>\n",
              "      <td>0.905600</td>\n",
              "      <td>0.980132</td>\n",
              "      <td>0.795995</td>\n",
              "      <td>0.953191</td>\n",
              "      <td>0.835735</td>\n",
              "      <td>0.749621</td>\n",
              "      <td>0.690625</td>\n",
              "      <td>0.967003</td>\n",
              "      <td>0.993333</td>\n",
              "      <td>0.843792</td>\n",
              "      <td>0.822449</td>\n",
              "      <td>0.859649</td>\n",
              "      <td>0.928074</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.844000</td>\n",
              "      <td>0.962723</td>\n",
              "      <td>0.929307</td>\n",
              "      <td>0.855863</td>\n",
              "      <td>0.917219</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.832911</td>\n",
              "      <td>0.971014</td>\n",
              "      <td>0.909333</td>\n",
              "      <td>0.822695</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.228300</td>\n",
              "      <td>0.449820</td>\n",
              "      <td>0.881958</td>\n",
              "      <td>0.881928</td>\n",
              "      <td>0.882174</td>\n",
              "      <td>0.686316</td>\n",
              "      <td>0.789407</td>\n",
              "      <td>0.900474</td>\n",
              "      <td>0.984874</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.950847</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.752137</td>\n",
              "      <td>0.681548</td>\n",
              "      <td>0.973843</td>\n",
              "      <td>0.988391</td>\n",
              "      <td>0.828309</td>\n",
              "      <td>0.813977</td>\n",
              "      <td>0.859935</td>\n",
              "      <td>0.931087</td>\n",
              "      <td>0.988353</td>\n",
              "      <td>0.838889</td>\n",
              "      <td>0.961039</td>\n",
              "      <td>0.926184</td>\n",
              "      <td>0.861314</td>\n",
              "      <td>0.915825</td>\n",
              "      <td>0.946801</td>\n",
              "      <td>0.850900</td>\n",
              "      <td>0.973650</td>\n",
              "      <td>0.901252</td>\n",
              "      <td>0.821853</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.218200</td>\n",
              "      <td>0.451365</td>\n",
              "      <td>0.880792</td>\n",
              "      <td>0.881572</td>\n",
              "      <td>0.881184</td>\n",
              "      <td>0.686760</td>\n",
              "      <td>0.807339</td>\n",
              "      <td>0.889590</td>\n",
              "      <td>0.984823</td>\n",
              "      <td>0.813642</td>\n",
              "      <td>0.951899</td>\n",
              "      <td>0.870624</td>\n",
              "      <td>0.742236</td>\n",
              "      <td>0.705357</td>\n",
              "      <td>0.970310</td>\n",
              "      <td>0.996656</td>\n",
              "      <td>0.839142</td>\n",
              "      <td>0.792415</td>\n",
              "      <td>0.858268</td>\n",
              "      <td>0.932722</td>\n",
              "      <td>0.986711</td>\n",
              "      <td>0.846479</td>\n",
              "      <td>0.975288</td>\n",
              "      <td>0.924746</td>\n",
              "      <td>0.855647</td>\n",
              "      <td>0.914754</td>\n",
              "      <td>0.943729</td>\n",
              "      <td>0.814545</td>\n",
              "      <td>0.972185</td>\n",
              "      <td>0.914518</td>\n",
              "      <td>0.813714</td>\n",
              "      <td>0.998336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.204000</td>\n",
              "      <td>0.474871</td>\n",
              "      <td>0.881214</td>\n",
              "      <td>0.882043</td>\n",
              "      <td>0.881717</td>\n",
              "      <td>0.696677</td>\n",
              "      <td>0.791403</td>\n",
              "      <td>0.892405</td>\n",
              "      <td>0.984925</td>\n",
              "      <td>0.814724</td>\n",
              "      <td>0.953925</td>\n",
              "      <td>0.899225</td>\n",
              "      <td>0.742205</td>\n",
              "      <td>0.704615</td>\n",
              "      <td>0.969450</td>\n",
              "      <td>0.994992</td>\n",
              "      <td>0.834875</td>\n",
              "      <td>0.794795</td>\n",
              "      <td>0.868185</td>\n",
              "      <td>0.930798</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.848443</td>\n",
              "      <td>0.958065</td>\n",
              "      <td>0.927062</td>\n",
              "      <td>0.847843</td>\n",
              "      <td>0.915541</td>\n",
              "      <td>0.942895</td>\n",
              "      <td>0.819905</td>\n",
              "      <td>0.968504</td>\n",
              "      <td>0.915119</td>\n",
              "      <td>0.813520</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.197600</td>\n",
              "      <td>0.476977</td>\n",
              "      <td>0.881385</td>\n",
              "      <td>0.881579</td>\n",
              "      <td>0.882022</td>\n",
              "      <td>0.697624</td>\n",
              "      <td>0.798419</td>\n",
              "      <td>0.902516</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.799483</td>\n",
              "      <td>0.957338</td>\n",
              "      <td>0.840876</td>\n",
              "      <td>0.741960</td>\n",
              "      <td>0.700935</td>\n",
              "      <td>0.969210</td>\n",
              "      <td>0.990066</td>\n",
              "      <td>0.849132</td>\n",
              "      <td>0.789157</td>\n",
              "      <td>0.866303</td>\n",
              "      <td>0.930128</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.845778</td>\n",
              "      <td>0.970779</td>\n",
              "      <td>0.922350</td>\n",
              "      <td>0.852875</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.951417</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.975513</td>\n",
              "      <td>0.923899</td>\n",
              "      <td>0.819444</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.190500</td>\n",
              "      <td>0.465027</td>\n",
              "      <td>0.884530</td>\n",
              "      <td>0.884408</td>\n",
              "      <td>0.884990</td>\n",
              "      <td>0.690423</td>\n",
              "      <td>0.798956</td>\n",
              "      <td>0.898279</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.818640</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.755327</td>\n",
              "      <td>0.700906</td>\n",
              "      <td>0.970966</td>\n",
              "      <td>0.990033</td>\n",
              "      <td>0.834211</td>\n",
              "      <td>0.816116</td>\n",
              "      <td>0.870259</td>\n",
              "      <td>0.935907</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.851389</td>\n",
              "      <td>0.964286</td>\n",
              "      <td>0.933698</td>\n",
              "      <td>0.853513</td>\n",
              "      <td>0.919275</td>\n",
              "      <td>0.944258</td>\n",
              "      <td>0.841191</td>\n",
              "      <td>0.971692</td>\n",
              "      <td>0.912568</td>\n",
              "      <td>0.810268</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.178700</td>\n",
              "      <td>0.509061</td>\n",
              "      <td>0.880175</td>\n",
              "      <td>0.880051</td>\n",
              "      <td>0.880575</td>\n",
              "      <td>0.687285</td>\n",
              "      <td>0.807895</td>\n",
              "      <td>0.906793</td>\n",
              "      <td>0.981636</td>\n",
              "      <td>0.800502</td>\n",
              "      <td>0.959044</td>\n",
              "      <td>0.849195</td>\n",
              "      <td>0.747664</td>\n",
              "      <td>0.690625</td>\n",
              "      <td>0.955449</td>\n",
              "      <td>0.991736</td>\n",
              "      <td>0.840159</td>\n",
              "      <td>0.803589</td>\n",
              "      <td>0.867486</td>\n",
              "      <td>0.934057</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.846206</td>\n",
              "      <td>0.952229</td>\n",
              "      <td>0.931959</td>\n",
              "      <td>0.855849</td>\n",
              "      <td>0.917342</td>\n",
              "      <td>0.945381</td>\n",
              "      <td>0.831683</td>\n",
              "      <td>0.967827</td>\n",
              "      <td>0.901639</td>\n",
              "      <td>0.803063</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.171500</td>\n",
              "      <td>0.492225</td>\n",
              "      <td>0.882161</td>\n",
              "      <td>0.883160</td>\n",
              "      <td>0.882707</td>\n",
              "      <td>0.664360</td>\n",
              "      <td>0.810952</td>\n",
              "      <td>0.907643</td>\n",
              "      <td>0.983278</td>\n",
              "      <td>0.802532</td>\n",
              "      <td>0.955123</td>\n",
              "      <td>0.859675</td>\n",
              "      <td>0.756996</td>\n",
              "      <td>0.713396</td>\n",
              "      <td>0.968835</td>\n",
              "      <td>0.996656</td>\n",
              "      <td>0.846354</td>\n",
              "      <td>0.793530</td>\n",
              "      <td>0.860945</td>\n",
              "      <td>0.928025</td>\n",
              "      <td>0.986711</td>\n",
              "      <td>0.835270</td>\n",
              "      <td>0.969005</td>\n",
              "      <td>0.929321</td>\n",
              "      <td>0.861943</td>\n",
              "      <td>0.935750</td>\n",
              "      <td>0.947791</td>\n",
              "      <td>0.836111</td>\n",
              "      <td>0.972149</td>\n",
              "      <td>0.912517</td>\n",
              "      <td>0.810458</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.163500</td>\n",
              "      <td>0.491379</td>\n",
              "      <td>0.882724</td>\n",
              "      <td>0.883968</td>\n",
              "      <td>0.883011</td>\n",
              "      <td>0.684665</td>\n",
              "      <td>0.792974</td>\n",
              "      <td>0.897959</td>\n",
              "      <td>0.981697</td>\n",
              "      <td>0.824121</td>\n",
              "      <td>0.959726</td>\n",
              "      <td>0.883792</td>\n",
              "      <td>0.750760</td>\n",
              "      <td>0.712963</td>\n",
              "      <td>0.968222</td>\n",
              "      <td>0.996656</td>\n",
              "      <td>0.837388</td>\n",
              "      <td>0.803554</td>\n",
              "      <td>0.853454</td>\n",
              "      <td>0.926267</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.836889</td>\n",
              "      <td>0.981818</td>\n",
              "      <td>0.928423</td>\n",
              "      <td>0.863636</td>\n",
              "      <td>0.925620</td>\n",
              "      <td>0.946801</td>\n",
              "      <td>0.830892</td>\n",
              "      <td>0.974734</td>\n",
              "      <td>0.908356</td>\n",
              "      <td>0.810685</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.152900</td>\n",
              "      <td>0.506339</td>\n",
              "      <td>0.884070</td>\n",
              "      <td>0.884616</td>\n",
              "      <td>0.884457</td>\n",
              "      <td>0.679528</td>\n",
              "      <td>0.817824</td>\n",
              "      <td>0.905901</td>\n",
              "      <td>0.983278</td>\n",
              "      <td>0.805933</td>\n",
              "      <td>0.961506</td>\n",
              "      <td>0.869173</td>\n",
              "      <td>0.757121</td>\n",
              "      <td>0.695518</td>\n",
              "      <td>0.971237</td>\n",
              "      <td>0.991681</td>\n",
              "      <td>0.847091</td>\n",
              "      <td>0.810101</td>\n",
              "      <td>0.861478</td>\n",
              "      <td>0.930769</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.841033</td>\n",
              "      <td>0.969005</td>\n",
              "      <td>0.931677</td>\n",
              "      <td>0.861631</td>\n",
              "      <td>0.923333</td>\n",
              "      <td>0.944223</td>\n",
              "      <td>0.852713</td>\n",
              "      <td>0.972185</td>\n",
              "      <td>0.905660</td>\n",
              "      <td>0.809955</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.149400</td>\n",
              "      <td>0.512334</td>\n",
              "      <td>0.883101</td>\n",
              "      <td>0.883263</td>\n",
              "      <td>0.883848</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.820181</td>\n",
              "      <td>0.907937</td>\n",
              "      <td>0.984925</td>\n",
              "      <td>0.808458</td>\n",
              "      <td>0.956743</td>\n",
              "      <td>0.867362</td>\n",
              "      <td>0.754967</td>\n",
              "      <td>0.693164</td>\n",
              "      <td>0.973118</td>\n",
              "      <td>0.993333</td>\n",
              "      <td>0.848322</td>\n",
              "      <td>0.807851</td>\n",
              "      <td>0.869742</td>\n",
              "      <td>0.936460</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.839506</td>\n",
              "      <td>0.953748</td>\n",
              "      <td>0.931755</td>\n",
              "      <td>0.862658</td>\n",
              "      <td>0.929160</td>\n",
              "      <td>0.942039</td>\n",
              "      <td>0.841169</td>\n",
              "      <td>0.972296</td>\n",
              "      <td>0.908847</td>\n",
              "      <td>0.792617</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.141100</td>\n",
              "      <td>0.515928</td>\n",
              "      <td>0.884519</td>\n",
              "      <td>0.885546</td>\n",
              "      <td>0.884686</td>\n",
              "      <td>0.692880</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.911147</td>\n",
              "      <td>0.984925</td>\n",
              "      <td>0.799476</td>\n",
              "      <td>0.963855</td>\n",
              "      <td>0.896124</td>\n",
              "      <td>0.758123</td>\n",
              "      <td>0.707547</td>\n",
              "      <td>0.966033</td>\n",
              "      <td>0.993333</td>\n",
              "      <td>0.854054</td>\n",
              "      <td>0.806946</td>\n",
              "      <td>0.859776</td>\n",
              "      <td>0.929062</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.841237</td>\n",
              "      <td>0.967427</td>\n",
              "      <td>0.934347</td>\n",
              "      <td>0.859281</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.949062</td>\n",
              "      <td>0.846348</td>\n",
              "      <td>0.970336</td>\n",
              "      <td>0.906667</td>\n",
              "      <td>0.811927</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.136800</td>\n",
              "      <td>0.526854</td>\n",
              "      <td>0.882032</td>\n",
              "      <td>0.882370</td>\n",
              "      <td>0.882631</td>\n",
              "      <td>0.672686</td>\n",
              "      <td>0.816901</td>\n",
              "      <td>0.902208</td>\n",
              "      <td>0.981636</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.960818</td>\n",
              "      <td>0.863976</td>\n",
              "      <td>0.747504</td>\n",
              "      <td>0.692913</td>\n",
              "      <td>0.961905</td>\n",
              "      <td>0.988391</td>\n",
              "      <td>0.837517</td>\n",
              "      <td>0.806517</td>\n",
              "      <td>0.862978</td>\n",
              "      <td>0.928296</td>\n",
              "      <td>0.985075</td>\n",
              "      <td>0.853574</td>\n",
              "      <td>0.961415</td>\n",
              "      <td>0.929558</td>\n",
              "      <td>0.863870</td>\n",
              "      <td>0.934211</td>\n",
              "      <td>0.944000</td>\n",
              "      <td>0.843312</td>\n",
              "      <td>0.969816</td>\n",
              "      <td>0.915068</td>\n",
              "      <td>0.809143</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.131900</td>\n",
              "      <td>0.532373</td>\n",
              "      <td>0.881767</td>\n",
              "      <td>0.882399</td>\n",
              "      <td>0.882098</td>\n",
              "      <td>0.669673</td>\n",
              "      <td>0.800496</td>\n",
              "      <td>0.900958</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.816176</td>\n",
              "      <td>0.960549</td>\n",
              "      <td>0.879154</td>\n",
              "      <td>0.752226</td>\n",
              "      <td>0.696970</td>\n",
              "      <td>0.959782</td>\n",
              "      <td>0.993333</td>\n",
              "      <td>0.840108</td>\n",
              "      <td>0.796020</td>\n",
              "      <td>0.868579</td>\n",
              "      <td>0.929339</td>\n",
              "      <td>0.981818</td>\n",
              "      <td>0.843258</td>\n",
              "      <td>0.965854</td>\n",
              "      <td>0.932872</td>\n",
              "      <td>0.855856</td>\n",
              "      <td>0.931780</td>\n",
              "      <td>0.944704</td>\n",
              "      <td>0.846547</td>\n",
              "      <td>0.972259</td>\n",
              "      <td>0.909582</td>\n",
              "      <td>0.796875</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH 1 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.6575  NOUVEAU RECORD!\n",
            "  F1-macro: 0.6404\n",
            "  Accuracy: 0.6630\n",
            "  Eval Loss: 1.1673\n",
            " Classes faibles: 10: 0.453, 40: 0.314, 1140: 0.459\n",
            "\n",
            "EPOCH 2 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.7369  NOUVEAU RECORD!\n",
            "  F1-macro: 0.7310\n",
            "  Accuracy: 0.7376\n",
            "  Eval Loss: 0.8569\n",
            " Classes faibles: 1280: 0.498, 1281: 0.483\n",
            "\n",
            "EPOCH 3 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.7575  NOUVEAU RECORD!\n",
            "  F1-macro: 0.7495\n",
            "  Accuracy: 0.7590\n",
            "  Eval Loss: 0.7972\n",
            " Classes faibles: 1280: 0.457, 1281: 0.488\n",
            "\n",
            "EPOCH 4 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.7826  NOUVEAU RECORD!\n",
            "  F1-macro: 0.7765\n",
            "  Accuracy: 0.7855\n",
            "  Eval Loss: 0.7112\n",
            " Classes faibles: 10: 0.493\n",
            "\n",
            "EPOCH 5 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8162  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8116\n",
            "  Accuracy: 0.8160\n",
            "  Eval Loss: 0.6127\n",
            "\n",
            "EPOCH 6 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8166  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8106\n",
            "  Accuracy: 0.8171\n",
            "  Eval Loss: 0.6114\n",
            "\n",
            "EPOCH 7 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8291  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8240\n",
            "  Accuracy: 0.8301\n",
            "  Eval Loss: 0.5669\n",
            "\n",
            "EPOCH 8 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8332  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8305\n",
            "  Accuracy: 0.8351\n",
            "  Eval Loss: 0.5335\n",
            "\n",
            "EPOCH 9 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8454  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8420\n",
            "  Accuracy: 0.8448\n",
            "  Eval Loss: 0.5217\n",
            "\n",
            "EPOCH 10 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8500  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8478\n",
            "  Accuracy: 0.8511\n",
            "  Eval Loss: 0.4876\n",
            "\n",
            "EPOCH 11 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8572  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8548\n",
            "  Accuracy: 0.8572\n",
            "  Eval Loss: 0.4752\n",
            "\n",
            "EPOCH 12 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8560 \n",
            "  F1-macro: 0.8551\n",
            "  Accuracy: 0.8572\n",
            "  Eval Loss: 0.4823\n",
            "\n",
            "EPOCH 13 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8652  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8630\n",
            "  Accuracy: 0.8654\n",
            "  Eval Loss: 0.4653\n",
            "\n",
            "EPOCH 14 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8684  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8670\n",
            "  Accuracy: 0.8686\n",
            "  Eval Loss: 0.4473\n",
            "\n",
            "EPOCH 15 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8674 \n",
            "  F1-macro: 0.8659\n",
            "  Accuracy: 0.8683\n",
            "  Eval Loss: 0.4631\n",
            "\n",
            "EPOCH 16 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8687  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8667\n",
            "  Accuracy: 0.8690\n",
            "  Eval Loss: 0.4564\n",
            "\n",
            "EPOCH 17 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8699  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8678\n",
            "  Accuracy: 0.8704\n",
            "  Eval Loss: 0.4663\n",
            "\n",
            "EPOCH 18 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8705  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8694\n",
            "  Accuracy: 0.8704\n",
            "  Eval Loss: 0.4735\n",
            "\n",
            "EPOCH 19 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8740  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8742\n",
            "  Accuracy: 0.8746\n",
            "  Eval Loss: 0.4601\n",
            "\n",
            "EPOCH 20 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8798  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8795\n",
            "  Accuracy: 0.8803\n",
            "  Eval Loss: 0.4554\n",
            "\n",
            "EPOCH 21 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8806  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8804\n",
            "  Accuracy: 0.8810\n",
            "  Eval Loss: 0.4673\n",
            "\n",
            "EPOCH 22 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8820  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8819\n",
            "  Accuracy: 0.8822\n",
            "  Eval Loss: 0.4498\n",
            "\n",
            "EPOCH 23 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8808 \n",
            "  F1-macro: 0.8816\n",
            "  Accuracy: 0.8812\n",
            "  Eval Loss: 0.4514\n",
            "\n",
            "EPOCH 24 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8812 \n",
            "  F1-macro: 0.8820\n",
            "  Accuracy: 0.8817\n",
            "  Eval Loss: 0.4749\n",
            "\n",
            "EPOCH 25 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8814 \n",
            "  F1-macro: 0.8816\n",
            "  Accuracy: 0.8820\n",
            "  Eval Loss: 0.4770\n",
            "\n",
            "EPOCH 26 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8845  NOUVEAU RECORD!\n",
            "  F1-macro: 0.8844\n",
            "  Accuracy: 0.8850\n",
            "  Eval Loss: 0.4650\n",
            "\n",
            "EPOCH 27 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8802 \n",
            "  F1-macro: 0.8801\n",
            "  Accuracy: 0.8806\n",
            "  Eval Loss: 0.5091\n",
            "\n",
            "EPOCH 28 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8822 \n",
            "  F1-macro: 0.8832\n",
            "  Accuracy: 0.8827\n",
            "  Eval Loss: 0.4922\n",
            "\n",
            "EPOCH 29 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8827 \n",
            "  F1-macro: 0.8840\n",
            "  Accuracy: 0.8830\n",
            "  Eval Loss: 0.4914\n",
            "\n",
            "EPOCH 30 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8841 \n",
            "  F1-macro: 0.8846\n",
            "  Accuracy: 0.8845\n",
            "  Eval Loss: 0.5063\n",
            "\n",
            "EPOCH 31 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8831 \n",
            "  F1-macro: 0.8833\n",
            "  Accuracy: 0.8838\n",
            "  Eval Loss: 0.5123\n",
            "\n",
            "EPOCH 32 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8845 \n",
            "  F1-macro: 0.8855\n",
            "  Accuracy: 0.8847\n",
            "  Eval Loss: 0.5159\n",
            "\n",
            "EPOCH 33 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8820 \n",
            "  F1-macro: 0.8824\n",
            "  Accuracy: 0.8826\n",
            "  Eval Loss: 0.5269\n",
            "\n",
            "EPOCH 34 - RÉSULTATS DÉTAILLÉS:\n",
            "  F1-weighted: 0.8818 \n",
            "  F1-macro: 0.8824\n",
            "  Accuracy: 0.8821\n",
            "  Eval Loss: 0.5324\n",
            "Meilleur checkpoint : ./results_fla/checkpoint-40326\n",
            "\n",
            "=== SAUVEGARDE DES LOGITS ET LABELS COMPLETS ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== RAPPORT DE CLASSIFICATION FINAL SUR VALIDATION ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              precision    recall  f1-score   support\n",
            "\n",
            "                      Livres       0.72      0.66      0.69       467\n",
            "                  Jeux Vidéo       0.78      0.81      0.80       376\n",
            "     Accessoires jeux vidéos       0.85      0.96      0.90       300\n",
            "       Jeux vidéo & Consoles       0.98      0.98      0.98       300\n",
            "                   Figurines       0.83      0.81      0.82       401\n",
            "              Cartes de jeux       0.97      0.95      0.96       593\n",
            "Jeux de rôle et de figurines       0.80      0.96      0.87       300\n",
            "             Jouets & Enfant       0.82      0.70      0.76       731\n",
            "             Jeux de société       0.66      0.75      0.70       311\n",
            "   Véhicules RC & miniatures       0.98      0.96      0.97       750\n",
            "            Chaussettes bébé       0.99      0.99      0.99       300\n",
            "            Sports & Loisirs       0.82      0.85      0.83       374\n",
            "                Puériculture       0.82      0.81      0.82       486\n",
            "                      Maison       0.87      0.87      0.87       750\n",
            "             Linge de maison       0.93      0.94      0.94       646\n",
            "              Petit déjeuner       0.98      0.99      0.99       300\n",
            "                  Décoration       0.89      0.82      0.85       749\n",
            "                  Animalerie       0.94      0.99      0.96       300\n",
            "                       Revue       0.91      0.96      0.93       714\n",
            "        Lots Livres & Revues       0.92      0.80      0.85       716\n",
            "        Lots consoles & jeux       0.91      0.93      0.92       300\n",
            "       Fournitures Papeterie       0.95      0.94      0.94       748\n",
            "          Mobilier de jardin       0.81      0.87      0.84       388\n",
            "    Équipement piscine & spa       0.96      0.98      0.97       750\n",
            "         Outillage de jardin       0.93      0.89      0.91       374\n",
            "                      eBooks       0.75      0.88      0.81       414\n",
            "      Jeux en téléchargement       1.00      1.00      1.00       300\n",
            "\n",
            "                    accuracy                           0.88     13138\n",
            "                   macro avg       0.88      0.89      0.88     13138\n",
            "                weighted avg       0.89      0.88      0.88     13138\n",
            "\n",
            "\n",
            "=== ENTRAÎNEMENT FLAUBERT TERMINÉ ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# La on a la partie interpretation"
      ],
      "metadata": {
        "id": "ovCkXq5UH5U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install captum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gxRREgWQ5dm9",
        "outputId": "db139d70-605c-4198-b320-24b023dd8c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting captum\n",
            "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from captum) (3.10.0)\n",
            "Collecting numpy<2.0 (from captum)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from captum) (24.2)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from captum) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from captum) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10->captum)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10->captum)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10->captum)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10->captum)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10->captum)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10->captum)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10->captum)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10->captum)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10->captum)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.10->captum)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->captum) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n",
            "Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, captum\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed captum-0.8.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "0fd80f05890e4c628b7a8a6eafd286b6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l \"/content/drive/MyDrive/Colab Notebooks/fahim/final/camembert2_model\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVL3AVJ_7he6",
        "outputId": "48216ca9-ef93-4b1e-f087-3f74460d9f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 432224\n",
            "-rw------- 1 root root      1861 Jun  1 23:07 config.json\n",
            "-rw------- 1 root root 442595004 Jun  2 14:13 pytorch_model.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers safetensors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2CIW4S070eS",
        "outputId": "dc976909-cabb-40dd-90be-01a7d8b7e94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFlm7H_CDz88",
        "outputId": "48c2ed84-6b99-4c9e-9a77-ecdbfe84f309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFAr-Bs2DvzL",
        "outputId": "293613cf-4f76-46f7-af25-43adfc73510e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "#  Monter Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#  Chemins\n",
        "drive_base_path = \"/content/drive/MyDrive/Colab Notebooks/fahim/final\"\n",
        "local_base_path = \"/content/modeles_importes\"\n",
        "os.makedirs(local_base_path, exist_ok=True)\n",
        "\n",
        "#  1. Modèles à copier (images + textuels)\n",
        "model_folders = {\n",
        "    \"camembert2_model\": [\"config.json\", \"model.safetensors\"],\n",
        "    \"flaubert2_model\": [\"config.json\", \"model.safetensors\"],\n",
        "}\n",
        "\n",
        "# 📥Copie des modèles\n",
        "for folder, files in model_folders.items():\n",
        "    src_dir = os.path.join(drive_base_path, folder)\n",
        "    is_text_model = \"camembert\" in folder or \"flaubert\" in folder\n",
        "    dst_subfolder = os.path.join(local_base_path, os.path.basename(folder)) if is_text_model else local_base_path\n",
        "    os.makedirs(dst_subfolder, exist_ok=True)\n",
        "\n",
        "    for filename in files:\n",
        "        src_file = os.path.join(src_dir, filename)\n",
        "        dst_file = os.path.join(dst_subfolder, filename)\n",
        "        if os.path.exists(src_file):\n",
        "            shutil.copy(src_file, dst_file)\n",
        "            print(f\"✅ Copié : {filename} → {dst_file}\")\n",
        "        else:\n",
        "            print(f\"❌ Introuvable : {src_file}\")\n",
        "\n",
        "#  2. Logits à copier (texte  + labels)\n",
        "logits_files = [\n",
        "    \"camembert2_logits.pt\",\n",
        "    \"flaubert2_logits.pt\",\n",
        "    \"true_labels_final.pt\",\n",
        "    'booster_texte_logits.pt'\n",
        "]\n",
        "\n",
        "logits_drive_path = drive_base_path\n",
        "\n",
        "for filename in logits_files:\n",
        "    src_file = os.path.join(logits_drive_path, filename)\n",
        "    dst_file = os.path.join(local_base_path, filename)\n",
        "    if os.path.exists(src_file):\n",
        "        shutil.copy(src_file, dst_file)\n",
        "        print(f\"✅ Logits copié : {filename}\")\n",
        "    else:\n",
        "        print(f\"❌ Logits manquant : {src_file}\")\n",
        "# 3. Copier le fichier de mapping labels\n",
        "mapping_filename = \"label_mapping_final.json\"\n",
        "mapping_src = os.path.join(drive_base_path, mapping_filename)\n",
        "mapping_dst = os.path.join(local_base_path, mapping_filename)\n",
        "\n",
        "if os.path.exists(mapping_src):\n",
        "    shutil.copy(mapping_src, mapping_dst)\n",
        "    print(f\"✅ Mapping copié : {mapping_filename}\")\n",
        "else:\n",
        "    print(f\"❌ Mapping manquant : {mapping_src}\")\n",
        "# 4. Copier le fichier label encoder\n",
        "label_encoder_filename = \"label_encoder_final.pkl\"\n",
        "label_encoder_src = os.path.join(drive_base_path, label_encoder_filename)\n",
        "label_encoder_dst = os.path.join(local_base_path, label_encoder_filename)\n",
        "\n",
        "if os.path.exists(label_encoder_src):\n",
        "    shutil.copy(label_encoder_src, label_encoder_dst)\n",
        "    print(f\"✅ Label Encoder copié : {label_encoder_filename}\")\n",
        "else:\n",
        "    print(f\"❌ Label Encoder manquant : {label_encoder_src}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vE9If2XDsCb",
        "outputId": "80594307-3b52-431d-899b-e11288ab204d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Copié : config.json → /content/modeles_importes/camembert2_model/config.json\n",
            "✅ Copié : model.safetensors → /content/modeles_importes/camembert2_model/model.safetensors\n",
            "✅ Copié : config.json → /content/modeles_importes/flaubert2_model/config.json\n",
            "✅ Copié : model.safetensors → /content/modeles_importes/flaubert2_model/model.safetensors\n",
            "✅ Logits copié : camembert2_logits.pt\n",
            "✅ Logits copié : flaubert2_logits.pt\n",
            "✅ Logits copié : true_labels_final.pt\n",
            "✅ Logits copié : booster_texte_logits.pt\n",
            "✅ Mapping copié : label_mapping_final.json\n",
            "✅ Label Encoder copié : label_encoder_final.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.metrics import f1_score\n",
        "import json\n",
        "\n",
        "# Chemins et config\n",
        "PATH_LOGITS = \"/content/modeles_importes\"\n",
        "LABELS_PATH = os.path.join(PATH_LOGITS, \"true_labels_final.pt\")\n",
        "VAL_INDICES_PATH = \"/content/drive/MyDrive/Colab Notebooks/fahim/final/val_indices.json\"\n",
        "\n",
        "# Modèles texte ciblés\n",
        "text_model_names = [\n",
        "    \"camembert2\", \"flaubert2\"\n",
        "]\n",
        "\n",
        "# Chargement logits\n",
        "all_logits = {name: torch.load(os.path.join(PATH_LOGITS, f\"{name}_logits.pt\")).cpu().numpy() for name in text_model_names}\n",
        "labels = torch.load(LABELS_PATH).numpy()\n",
        "with open(VAL_INDICES_PATH, \"r\") as f:\n",
        "    val_idx = np.array(json.load(f), dtype=int)\n",
        "y_val = labels[val_idx]\n",
        "\n",
        "def weighted_softmax(logits_list, weights):\n",
        "    \"\"\"Calcule la moyenne pondérée des logits softmaxés.\"\"\"\n",
        "    softmaxed = [np.exp(logits)/np.exp(logits).sum(axis=1, keepdims=True) for logits in logits_list]\n",
        "    weighted = sum(w * s for w, s in zip(weights, softmaxed))\n",
        "    return weighted\n",
        "\n",
        "def grid_weights(n):\n",
        "    \"\"\"Génère toutes les combinaisons de poids sommant à 1 avec pas de 0.1.\"\"\"\n",
        "    steps = np.arange(0.0, 1.1, 0.1)  # de 0.0 à 1.0 inclus\n",
        "    grids = [x for x in itertools.product(steps, repeat=n) if abs(sum(x) - 1) < 1e-5]\n",
        "    return grids\n",
        "\n",
        "results = []\n",
        "# Ici on teste la combinaison camembert2 + flaubert2 uniquement\n",
        "for model_combo in [(\"camembert2\", \"flaubert2\")]:\n",
        "    logits_list = [all_logits[name][val_idx] for name in model_combo]\n",
        "    best_f1, best_weights = 0, None\n",
        "    for weights in grid_weights(len(model_combo)):\n",
        "        y_pred = np.argmax(weighted_softmax(logits_list, weights), axis=1)\n",
        "        f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_weights = weights\n",
        "    results.append({\n",
        "        \"models\": model_combo,\n",
        "        \"f1_weighted\": best_f1,\n",
        "        \"weights\": best_weights\n",
        "    })\n",
        "    print(f\"[{'+'.join(model_combo)}]  F1_weighted={best_f1:.5f}  Weights={best_weights}\")\n",
        "\n",
        "# Affichage du résultat\n",
        "results = sorted(results, key=lambda x: x[\"f1_weighted\"], reverse=True)\n",
        "print(\"\\n==== Résultat Meilleure Combinaison TEXTE ====\")\n",
        "for res in results:\n",
        "    print(f\"{'+'.join(res['models']):20s} | F1={res['f1_weighted']:.5f} | Weights={res['weights']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v0pVXYUQH76",
        "outputId": "f8575754-7251-43f1-d80e-85061a5941b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[camembert2+flaubert2]  F1_weighted=0.89551  Weights=(np.float64(0.5), np.float64(0.5))\n",
            "\n",
            "==== Résultat Meilleure Combinaison TEXTE ====\n",
            "camembert2+flaubert2 | F1=0.89551 | Weights=(np.float64(0.5), np.float64(0.5))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Poids optimaux obtenus pour texte\n",
        "weights_text = np.array([0.5, 0.5])\n",
        "\n",
        "# Charge logits de camembert2 et flaubert2, full dataset (train + val + test)\n",
        "logits_text_list = [\n",
        "    torch.load(\"/content/modeles_importes/camembert2_logits.pt\").cpu().numpy(),\n",
        "    torch.load(\"/content/modeles_importes/flaubert2_logits.pt\").cpu().numpy()\n",
        "]\n",
        "\n",
        "# Fusion pondérée\n",
        "stacked_text = np.stack(logits_text_list, axis=0)  # (2, N, nb_classes)\n",
        "weighted_logits_text = np.tensordot(weights_text, stacked_text, axes=([0], [0]))  # (N, nb_classes)\n",
        "\n",
        "# Appliquer softmax (probabilités)\n",
        "weighted_probs_text = torch.softmax(torch.tensor(weighted_logits_text), dim=1).numpy()\n",
        "\n",
        "# Sauvegarder les logits fusionnés texte\n",
        "torch.save(torch.tensor(weighted_probs_text), \"/content/drive/MyDrive/Colab Notebooks/fahim/final/booster_texte_logits.pt\")\n",
        "print(\"Booster logits texte pondérés générés sur tout le dataset !\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMMgpCdaRKkR",
        "outputId": "6d026216-5b01-43b1-9fe1-99104fb00347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Booster logits texte pondérés générés sur tout le dataset !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import f1_score\n",
        "import optuna\n",
        "from itertools import combinations\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/Colab Notebooks/fahim/final\"\n",
        "PATH_LOGITS = \"/content/modeles_importes\"\n",
        "VAL_INDICES_PATH = os.path.join(BASE, \"val_indices.json\")\n",
        "LABELS_PATH = os.path.join(PATH_LOGITS, \"true_labels_final.pt\")\n",
        "\n",
        "fixed_models = [\"booster_texte_logits.pt\"]\n",
        "\n",
        "optional_models = [\n",
        "    \"camembert2_logits.pt\",\n",
        "    \"flaubert2_logits.pt\",\n",
        "]\n",
        "\n",
        "with open(VAL_INDICES_PATH, \"r\") as f:\n",
        "    val_idx = np.array(json.load(f))\n",
        "labels_full = torch.load(LABELS_PATH).numpy()\n",
        "y_val = labels_full[val_idx]\n",
        "\n",
        "def load_logits(filenames):\n",
        "    logits_list = []\n",
        "    for fname in filenames:\n",
        "        logits = torch.load(os.path.join(PATH_LOGITS, fname)).cpu().numpy()\n",
        "        # Appliquer softmax uniquement si nécessaire\n",
        "        if logits.ndim == 2 and (np.abs(np.sum(logits, axis=1) - 1) > 1e-4).any():\n",
        "            logits = softmax(logits, axis=1)\n",
        "        logits_val = logits[val_idx]\n",
        "        logits_list.append(logits_val)\n",
        "    return logits_list\n",
        "\n",
        "def weighted_fusion(logits_list, weights):\n",
        "    stacked = np.stack(logits_list, axis=0)  # (n_models, n_samples, n_classes)\n",
        "    weighted = np.tensordot(weights, stacked, axes=(0, 0))  # (n_samples, n_classes)\n",
        "    return weighted\n",
        "\n",
        "def make_objective(logits_list, y_true):\n",
        "    n_models = len(logits_list)\n",
        "    def objective(trial):\n",
        "        weights = []\n",
        "        for i in range(n_models):\n",
        "            w = trial.suggest_float(f\"w_{i}\", 0.0, 1.0)\n",
        "            weights.append(w)\n",
        "        s = sum(weights)\n",
        "        if s < 1e-6:\n",
        "            return 1.0  # éviter division par zéro\n",
        "        weights = [w / s for w in weights]\n",
        "        fused_logits = weighted_fusion(logits_list, weights)\n",
        "        preds = np.argmax(fused_logits, axis=1)\n",
        "        f1 = f1_score(y_true, preds, average=\"weighted\")\n",
        "        print(f\"Trial {trial.number}: F1={f1:.4f}\")\n",
        "        return 1 - f1\n",
        "    return objective\n",
        "\n",
        "best_score = 0\n",
        "best_combo = None\n",
        "best_weights = None\n",
        "\n",
        "for r in range(len(optional_models) + 1):\n",
        "    for combo in combinations(optional_models, r):\n",
        "        models_to_use = fixed_models + list(combo)\n",
        "        print(f\"\\nTest combo: {models_to_use}\")\n",
        "        logits_list = load_logits(models_to_use)\n",
        "        objective = make_objective(logits_list, y_val)\n",
        "        study = optuna.create_study(direction=\"minimize\")\n",
        "        study.optimize(objective, n_trials=200, n_jobs=3)  # plus rapide pour test\n",
        "        current_f1 = 1 - study.best_value\n",
        "        print(f\"Combo {models_to_use} - Best F1: {current_f1:.4f}\")\n",
        "        if current_f1 > best_score:\n",
        "            best_score = current_f1\n",
        "            best_combo = models_to_use\n",
        "            n_models = len(logits_list)\n",
        "            best_weights = np.zeros(n_models)\n",
        "            for i in range(n_models):\n",
        "                best_weights[i] = study.best_params[f\"w_{i}\"]\n",
        "\n",
        "print(\"\\n--- Résultat final ---\")\n",
        "print(f\"Meilleure combinaison : {best_combo}\")\n",
        "print(f\"Meilleur F1-weighted : {best_score:.4f}\")\n",
        "print(f\"Poids optimaux : {best_weights}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2kmb9V1Dg-0",
        "outputId": "dd517a2e-a477-4b54-e7a4-e3b09cc76fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:20,392] A new study created in memory with name: no-name-c25dc4ae-cbfc-46ea-9237-83123149ecb2\n",
            "[I 2025-06-16 10:30:20,407] Trial 1 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7601672082935111}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,420] Trial 0 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5682915983677689}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,426] Trial 3 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4743612343366346}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,441] Trial 2 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.342876753793083}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,474] Trial 4 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4347468992170753}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,476] Trial 5 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.2669930255189966}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,482] Trial 6 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8048787538698526}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,516] Trial 8 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.38973181988846084}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,521] Trial 7 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6750941207917688}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,538] Trial 10 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5657384038573527}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,544] Trial 9 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9863580450808211}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,568] Trial 11 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.952173297010452}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,572] Trial 12 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9798515330913052}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test combo: ['booster_texte_logits.pt']\n",
            "Trial 1: F1=0.8975\n",
            "Trial 0: F1=0.8975\n",
            "Trial 3: F1=0.8975\n",
            "Trial 2: F1=0.8975\n",
            "Trial 4: F1=0.8975\n",
            "Trial 5: F1=0.8975\n",
            "Trial 6: F1=0.8975\n",
            "Trial 8: F1=0.8975\n",
            "Trial 7: F1=0.8975\n",
            "Trial 10: F1=0.8975\n",
            "Trial 9: F1=0.8975\n",
            "Trial 11: F1=0.8975\n",
            "Trial 12: F1=0.8975\n",
            "Trial 13: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:20,578] Trial 13 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.03683294370466372}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,601] Trial 14 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7082313318666165}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,636] Trial 16 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7937621269598397}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,656] Trial 17 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.799608851642196}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,677] Trial 15 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7081086238332357}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,702] Trial 18 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.60408351249396}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,753] Trial 19 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5644145402505951}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,755] Trial 20 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6220593789506963}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,782] Trial 21 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.2076225585813214}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 14: F1=0.8975\n",
            "Trial 16: F1=0.8975\n",
            "Trial 17: F1=0.8975\n",
            "Trial 15: F1=0.8975\n",
            "Trial 18: F1=0.8975\n",
            "Trial 19: F1=0.8975\n",
            "Trial 20: F1=0.8975\n",
            "Trial 21: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:20,807] Trial 22 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.3000421100983812}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,811] Trial 23 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.283205608200838}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,849] Trial 24 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.35431161210164086}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,865] Trial 26 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.128771727439278}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,865] Trial 25 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.3847741850518865}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,908] Trial 28 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4998779351945857}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,918] Trial 29 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.525324974027062}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,924] Trial 27 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9082605325387229}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,953] Trial 30 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4570581392560129}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:20,985] Trial 32 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4563782465061157}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,002] Trial 31 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8683726471044935}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 22: F1=0.8975\n",
            "Trial 23: F1=0.8975\n",
            "Trial 24: F1=0.8975\n",
            "Trial 25: F1=0.8975\n",
            "Trial 26: F1=0.8975\n",
            "Trial 28: F1=0.8975\n",
            "Trial 29: F1=0.8975\n",
            "Trial 27: F1=0.8975\n",
            "Trial 30: F1=0.8975\n",
            "Trial 32: F1=0.8975\n",
            "Trial 31: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:21,029] Trial 34 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.19052979767970457}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,036] Trial 33 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.45400792843302246}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,057] Trial 35 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.19896757732994297}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,090] Trial 38 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6606726261950171}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,100] Trial 36 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6329421565502945}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,100] Trial 37 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.34411970458838326}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,146] Trial 41 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7332922677164098}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,152] Trial 40 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7519055166425662}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,179] Trial 39 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7232375247966842}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,186] Trial 42 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4315787768472405}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,220] Trial 45 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.531097001201804}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 34: F1=0.8975\n",
            "Trial 33: F1=0.8975\n",
            "Trial 35: F1=0.8975\n",
            "Trial 38: F1=0.8975\n",
            "Trial 36: F1=0.8975\n",
            "Trial 37: F1=0.8975\n",
            "Trial 41: F1=0.8975\n",
            "Trial 40: F1=0.8975\n",
            "Trial 39: F1=0.8975\n",
            "Trial 42: F1=0.8975\n",
            "Trial 45: F1=0.8975\n",
            "Trial 43: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:21,242] Trial 43 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4218934539058582}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,250] Trial 44 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5089672052178515}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,276] Trial 46 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4924171275206726}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,289] Trial 48 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5666361442287567}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,290] Trial 47 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.324083723394005}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,319] Trial 51 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.25322819333366675}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,329] Trial 49 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.39019515222399304}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,350] Trial 50 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.23746781390260405}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,357] Trial 52 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.032430129840392286}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,388] Trial 53 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.09866994181947975}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,430] Trial 54 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.08434418291702483}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,436] Trial 56 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.3792680428527448}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,440] Trial 55 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.39536116213639305}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 44: F1=0.8975\n",
            "Trial 46: F1=0.8975\n",
            "Trial 48: F1=0.8975\n",
            "Trial 47: F1=0.8975\n",
            "Trial 51: F1=0.8975\n",
            "Trial 49: F1=0.8975\n",
            "Trial 50: F1=0.8975\n",
            "Trial 52: F1=0.8975\n",
            "Trial 53: F1=0.8975\n",
            "Trial 54: F1=0.8975\n",
            "Trial 56: F1=0.8975\n",
            "Trial 55: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:21,489] Trial 58 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.2988941932570584}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,494] Trial 57 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5772081089963543}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,499] Trial 59 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.29743266746993363}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,526] Trial 60 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8616888204869299}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,548] Trial 61 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6845627046647633}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,574] Trial 64 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7959652285806605}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,559] Trial 62 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8166475747234497}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,555] Trial 63 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8424594269945036}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,610] Trial 65 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9114386094000273}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,614] Trial 66 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.47916946727788395}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,632] Trial 67 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7591816753294316}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,645] Trial 68 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.1611301326236393}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,674] Trial 70 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.34394871118469006}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,679] Trial 69 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.34262123044586296}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 58: F1=0.8975\n",
            "Trial 57: F1=0.8975\n",
            "Trial 59: F1=0.8975\n",
            "Trial 60: F1=0.8975\n",
            "Trial 61: F1=0.8975\n",
            "Trial 63: F1=0.8975\n",
            "Trial 62: F1=0.8975\n",
            "Trial 64: F1=0.8975\n",
            "Trial 65: F1=0.8975\n",
            "Trial 66: F1=0.8975\n",
            "Trial 67: F1=0.8975\n",
            "Trial 68: F1=0.8975\n",
            "Trial 70: F1=0.8975\n",
            "Trial 69: F1=0.8975\n",
            "Trial 71: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:21,685] Trial 71 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9387071685722215}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,746] Trial 72 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6569293903308803}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,749] Trial 73 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6475137575094243}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,779] Trial 74 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6472973083945879}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,789] Trial 75 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5890328066675652}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,790] Trial 76 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6095326844991082}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,824] Trial 79 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5353369212775753}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,830] Trial 78 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.687985998142506}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,800] Trial 77 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5868898099719266}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,864] Trial 81 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7655434313470999}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,873] Trial 80 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7566406954194466}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,889] Trial 82 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9997686278941393}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,914] Trial 83 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.25916860871771685}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,920] Trial 85 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4185228743205209}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,927] Trial 84 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.43338181193401965}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 73: F1=0.8975Trial 72: F1=0.8975\n",
            "\n",
            "Trial 74: F1=0.8975\n",
            "Trial 75: F1=0.8975\n",
            "Trial 76: F1=0.8975\n",
            "Trial 77: F1=0.8975\n",
            "Trial 79: F1=0.8975\n",
            "Trial 78: F1=0.8975\n",
            "Trial 81: F1=0.8975\n",
            "Trial 80: F1=0.8975\n",
            "Trial 82: F1=0.8975\n",
            "Trial 83: F1=0.8975\n",
            "Trial 85: F1=0.8975\n",
            "Trial 84: F1=0.8975\n",
            "Trial 87: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:21,955] Trial 87 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.46827419061974646}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,972] Trial 88 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.3681332952448738}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:21,975] Trial 86 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4698697382309426}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,013] Trial 91 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5476241904330038}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,018] Trial 89 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4090187603269009}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,027] Trial 90 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5450523588514133}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,054] Trial 92 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.3230219856201325}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,099] Trial 93 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.51093965417918}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,092] Trial 94 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8201053229744619}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,130] Trial 95 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7137176813750055}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,132] Trial 96 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6915705717764481}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,141] Trial 97 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6990119526261273}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,177] Trial 100 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4493039977690737}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 88: F1=0.8975\n",
            "Trial 86: F1=0.8975\n",
            "Trial 91: F1=0.8975\n",
            "Trial 89: F1=0.8975\n",
            "Trial 90: F1=0.8975\n",
            "Trial 92: F1=0.8975\n",
            "Trial 94: F1=0.8975\n",
            "Trial 93: F1=0.8975\n",
            "Trial 95: F1=0.8975\n",
            "Trial 96: F1=0.8975\n",
            "Trial 97: F1=0.8975\n",
            "Trial 100: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:22,190] Trial 99 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8883331428018848}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,210] Trial 98 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4411220299145401}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,229] Trial 101 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.2759481003160574}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,234] Trial 102 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9609275280802145}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,257] Trial 103 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.49944011470967214}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,263] Trial 104 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6262865044291338}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,269] Trial 105 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6211140190569154}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,307] Trial 106 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7366468528481026}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,312] Trial 108 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.3193804892035498}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,322] Trial 107 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.36882795190273077}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,348] Trial 110 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5194668387789261}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,353] Trial 111 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.783739078880156}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,377] Trial 112 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9291476352890504}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 99: F1=0.8975\n",
            "Trial 98: F1=0.8975\n",
            "Trial 101: F1=0.8975\n",
            "Trial 102: F1=0.8975\n",
            "Trial 103: F1=0.8975\n",
            "Trial 104: F1=0.8975\n",
            "Trial 105: F1=0.8975\n",
            "Trial 106: F1=0.8975\n",
            "Trial 108: F1=0.8975\n",
            "Trial 107: F1=0.8975\n",
            "Trial 110: F1=0.8975\n",
            "Trial 111: F1=0.8975\n",
            "Trial 112: F1=0.8975\n",
            "Trial 109: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:22,385] Trial 109 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.3615604758120596}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,413] Trial 113 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9783917562186367}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,420] Trial 115 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9678288014026106}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,443] Trial 116 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.22459040556230148}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,436] Trial 114 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9709906484693069}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,484] Trial 117 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.3951825412289297}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,491] Trial 119 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.3994531082625762}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,511] Trial 118 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4020921161852673}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,533] Trial 120 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9973355584933714}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,537] Trial 121 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.861276161063752}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,550] Trial 122 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8558230460648919}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,572] Trial 123 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9053637638717844}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,581] Trial 124 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9138782872521414}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 113: F1=0.8975\n",
            "Trial 115: F1=0.8975\n",
            "Trial 114: F1=0.8975\n",
            "Trial 116: F1=0.8975\n",
            "Trial 117: F1=0.8975\n",
            "Trial 119: F1=0.8975\n",
            "Trial 118: F1=0.8975\n",
            "Trial 120: F1=0.8975\n",
            "Trial 121: F1=0.8975\n",
            "Trial 122: F1=0.8975\n",
            "Trial 123: F1=0.8975\n",
            "Trial 124: F1=0.8975\n",
            "Trial 125: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:22,597] Trial 125 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9415969247476057}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,620] Trial 126 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9447675369280284}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,634] Trial 127 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.564299863066919}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,652] Trial 128 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7878061158221433}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,658] Trial 130 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4934495581246957}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,665] Trial 129 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8282091208508584}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,710] Trial 132 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.04902851516639818}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,712] Trial 131 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.07188521591998093}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,718] Trial 133 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.027610020069371216}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,757] Trial 134 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6698005764707083}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,758] Trial 135 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.672717356793621}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,763] Trial 136 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.1455858368112446}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,794] Trial 138 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5977451335242939}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,804] Trial 137 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.11215245312581085}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 126: F1=0.8975\n",
            "Trial 127: F1=0.8975\n",
            "Trial 128: F1=0.8975\n",
            "Trial 130: F1=0.8975\n",
            "Trial 129: F1=0.8975\n",
            "Trial 132: F1=0.8975\n",
            "Trial 131: F1=0.8975\n",
            "Trial 133: F1=0.8975\n",
            "Trial 134: F1=0.8975\n",
            "Trial 135: F1=0.8975\n",
            "Trial 136: F1=0.8975\n",
            "Trial 138: F1=0.8975\n",
            "Trial 137: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:22,828] Trial 139 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8844555359231842}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,841] Trial 141 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.43611330231108975}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,832] Trial 140 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4655682320860784}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,872] Trial 143 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7724899366202651}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,856] Trial 142 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7352562865571994}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,908] Trial 144 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9881795884350119}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,921] Trial 145 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.1701620434578373}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,939] Trial 146 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.18856498673299113}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,960] Trial 148 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7060424826752696}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,971] Trial 149 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7179327197581346}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,986] Trial 147 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8069888529761864}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:22,992] Trial 150 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.42097238671521053}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,000] Trial 151 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5624633280724393}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,026] Trial 153 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6434355815759808}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 139: F1=0.8975\n",
            "Trial 140: F1=0.8975\n",
            "Trial 141: F1=0.8975\n",
            "Trial 142: F1=0.8975\n",
            "Trial 143: F1=0.8975\n",
            "Trial 144: F1=0.8975\n",
            "Trial 145: F1=0.8975\n",
            "Trial 146: F1=0.8975\n",
            "Trial 148: F1=0.8975\n",
            "Trial 149: F1=0.8975\n",
            "Trial 147: F1=0.8975\n",
            "Trial 150: F1=0.8975\n",
            "Trial 151: F1=0.8975\n",
            "Trial 153: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:23,045] Trial 154 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.48297621610265373}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,073] Trial 152 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7483561704110117}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,080] Trial 155 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7491111494447589}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,105] Trial 156 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7423568045461608}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,117] Trial 157 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6842351952030914}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,136] Trial 159 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9620723906991121}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,146] Trial 160 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9550606367800514}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,160] Trial 158 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9543178355893019}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,192] Trial 162 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7726607028041828}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,197] Trial 161 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.002529211031311339}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,207] Trial 163 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.002881311421159355}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,216] Trial 164 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8020647304459844}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 154: F1=0.8975\n",
            "Trial 152: F1=0.8975\n",
            "Trial 155: F1=0.8975\n",
            "Trial 156: F1=0.8975\n",
            "Trial 157: F1=0.8975\n",
            "Trial 159: F1=0.8975\n",
            "Trial 160: F1=0.8975\n",
            "Trial 158: F1=0.8975\n",
            "Trial 162: F1=0.8975\n",
            "Trial 161: F1=0.8975\n",
            "Trial 163: F1=0.8975\n",
            "Trial 164: F1=0.8975\n",
            "Trial 165: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:23,233] Trial 165 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8352619149059506}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,280] Trial 167 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.34309227408245674}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,282] Trial 168 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7158139295597395}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,284] Trial 166 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7209183548526437}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,302] Trial 169 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.4476797515895962}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,343] Trial 170 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5132884349357905}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,349] Trial 171 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5266498660923487}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,365] Trial 172 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5272962859050391}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,380] Trial 174 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.793277137678211}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,410] Trial 175 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.38334640376451934}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,414] Trial 176 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.27745877675097713}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,418] Trial 173 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.784974038255884}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,456] Trial 177 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.611749490536823}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 166: F1=0.8975Trial 167: F1=0.8975\n",
            "Trial 168: F1=0.8975\n",
            "\n",
            "Trial 169: F1=0.8975\n",
            "Trial 170: F1=0.8975\n",
            "Trial 171: F1=0.8975\n",
            "Trial 172: F1=0.8975\n",
            "Trial 174: F1=0.8975\n",
            "Trial 175: F1=0.8975\n",
            "Trial 176: F1=0.8975\n",
            "Trial 173: F1=0.8975\n",
            "Trial 177: F1=0.8975\n",
            "Trial 179: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:23,465] Trial 179 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6211559323728413}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,475] Trial 178 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8141304411058025}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,503] Trial 181 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9266487359966574}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,509] Trial 180 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7715102188854991}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,535] Trial 182 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7640361191792283}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,557] Trial 185 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.594731075416577}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,560] Trial 184 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.3085426405347083}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,562] Trial 183 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5855694622953991}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,596] Trial 187 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.640499767900608}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,600] Trial 188 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6597828256463024}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,613] Trial 186 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5451652811494311}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,643] Trial 189 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5684187230008639}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,658] Trial 190 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8417269812884527}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,665] Trial 191 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9812477998817581}. Best is trial 1 with value: 0.10251100722160944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 178: F1=0.8975\n",
            "Trial 181: F1=0.8975\n",
            "Trial 180: F1=0.8975\n",
            "Trial 182: F1=0.8975\n",
            "Trial 185: F1=0.8975\n",
            "Trial 184: F1=0.8975\n",
            "Trial 183: F1=0.8975\n",
            "Trial 187: F1=0.8975\n",
            "Trial 188: F1=0.8975\n",
            "Trial 186: F1=0.8975\n",
            "Trial 189: F1=0.8975\n",
            "Trial 190: F1=0.8975\n",
            "Trial 191: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:23,707] Trial 192 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.6887401894401383}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,708] Trial 193 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5565015553542577}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,731] Trial 194 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.5520875653399553}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,746] Trial 196 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.36273165063805196}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,750] Trial 195 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.48462812716938586}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,778] Trial 197 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.9957223136999336}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,788] Trial 199 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.891829331627813}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,797] Trial 198 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.24845138271498962}. Best is trial 1 with value: 0.10251100722160944.\n",
            "[I 2025-06-16 10:30:23,849] A new study created in memory with name: no-name-d955c860-37cf-42ec-9cae-84ec8315d93b\n",
            "[I 2025-06-16 10:30:23,862] Trial 0 finished with value: 0.11711754752648551 and parameters: {'w_0': 0.08648771357147844, 'w_1': 0.9030404431957626}. Best is trial 0 with value: 0.11711754752648551.\n",
            "[I 2025-06-16 10:30:23,880] Trial 2 finished with value: 0.10815514263665138 and parameters: {'w_0': 0.20368193066369322, 'w_1': 0.18712625015730566}. Best is trial 2 with value: 0.10815514263665138.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 193: F1=0.8975Trial 192: F1=0.8975\n",
            "\n",
            "Trial 194: F1=0.8975\n",
            "Trial 196: F1=0.8975\n",
            "Trial 195: F1=0.8975\n",
            "Trial 197: F1=0.8975\n",
            "Trial 199: F1=0.8975\n",
            "Trial 198: F1=0.8975\n",
            "Combo ['booster_texte_logits.pt'] - Best F1: 0.8975\n",
            "\n",
            "Test combo: ['booster_texte_logits.pt', 'camembert2_logits.pt']\n",
            "Trial 0: F1=0.8829\n",
            "Trial 2: F1=0.8918\n",
            "Trial 1: F1=0.8942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:23,883] Trial 1 finished with value: 0.10584667397209668 and parameters: {'w_0': 0.9044348285194288, 'w_1': 0.5972804977665251}. Best is trial 1 with value: 0.10584667397209668.\n",
            "[I 2025-06-16 10:30:23,908] Trial 5 finished with value: 0.1164425158243827 and parameters: {'w_0': 0.1797584445876067, 'w_1': 0.8315453638931797}. Best is trial 1 with value: 0.10584667397209668.\n",
            "[I 2025-06-16 10:30:23,929] Trial 6 finished with value: 0.11080932670394905 and parameters: {'w_0': 0.33604205042148794, 'w_1': 0.4298404620287284}. Best is trial 4 with value: 0.1044654867758289.\n",
            "[I 2025-06-16 10:30:23,920] Trial 3 finished with value: 0.1044654867758289 and parameters: {'w_0': 0.3355711677096642, 'w_1': 0.15297239443017197}. Best is trial 4 with value: 0.1044654867758289.\n",
            "[I 2025-06-16 10:30:23,916] Trial 4 finished with value: 0.1044654867758289 and parameters: {'w_0': 0.8064560371036629, 'w_1': 0.37044345868060347}. Best is trial 4 with value: 0.1044654867758289.\n",
            "[I 2025-06-16 10:30:23,940] Trial 7 finished with value: 0.10929318189174075 and parameters: {'w_0': 0.8748954550836963, 'w_1': 0.8869597642131603}. Best is trial 4 with value: 0.1044654867758289.\n",
            "[I 2025-06-16 10:30:23,951] Trial 9 finished with value: 0.11227244201570952 and parameters: {'w_0': 0.5243013797523448, 'w_1': 0.8812328413032102}. Best is trial 4 with value: 0.1044654867758289.\n",
            "[I 2025-06-16 10:30:23,958] Trial 8 finished with value: 0.10584607703695681 and parameters: {'w_0': 0.9318974951013553, 'w_1': 0.6289015986450176}. Best is trial 4 with value: 0.1044654867758289.\n",
            "[I 2025-06-16 10:30:24,008] Trial 11 finished with value: 0.10348453753430731 and parameters: {'w_0': 0.5741738818505745, 'w_1': 0.13029485778162164}. Best is trial 11 with value: 0.10348453753430731.\n",
            "[I 2025-06-16 10:30:24,019] Trial 12 finished with value: 0.10245695215813089 and parameters: {'w_0': 0.5335911346048554, 'w_1': 0.07597298897513055}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,012] Trial 10 finished with value: 0.10242953994584603 and parameters: {'w_0': 0.5782223995789453, 'w_1': 0.011395197400456775}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,068] Trial 13 finished with value: 0.1027285068904733 and parameters: {'w_0': 0.6848095805062855, 'w_1': 0.03480516659516497}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,074] Trial 14 finished with value: 0.10422496832224326 and parameters: {'w_0': 0.6890439434621234, 'w_1': 0.2901514029576231}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,100] Trial 15 finished with value: 0.10258669323075753 and parameters: {'w_0': 0.7030949871403215, 'w_1': 0.051110305731486685}. Best is trial 10 with value: 0.10242953994584603.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5: F1=0.8836\n",
            "Trial 4: F1=0.8955\n",
            "Trial 3: F1=0.8955\n",
            "Trial 6: F1=0.8892\n",
            "Trial 7: F1=0.8907\n",
            "Trial 9: F1=0.8877\n",
            "Trial 8: F1=0.8942\n",
            "Trial 11: F1=0.8965\n",
            "Trial 10: F1=0.8976\n",
            "Trial 12: F1=0.8975\n",
            "Trial 13: F1=0.8973\n",
            "Trial 14: F1=0.8958\n",
            "Trial 15: F1=0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:24,129] Trial 17 finished with value: 0.10266365372672981 and parameters: {'w_0': 0.4105088201459538, 'w_1': 0.019633917302653674}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,135] Trial 16 finished with value: 0.10258423944504347 and parameters: {'w_0': 0.39687357988989386, 'w_1': 0.027291868247861742}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,141] Trial 18 finished with value: 0.10585042490192687 and parameters: {'w_0': 0.41282286804022905, 'w_1': 0.26596611258435365}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,193] Trial 19 finished with value: 0.10914441351021864 and parameters: {'w_0': 0.555063932675526, 'w_1': 0.5578996495673497}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,224] Trial 20 finished with value: 0.10860869579260057 and parameters: {'w_0': 0.5775883410126418, 'w_1': 0.5512714337974527}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,230] Trial 21 finished with value: 0.10455109019110742 and parameters: {'w_0': 0.5921757559212452, 'w_1': 0.2546182382691079}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,250] Trial 22 finished with value: 0.11025514425774074 and parameters: {'w_0': 0.6306991170974939, 'w_1': 0.7241763134449869}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,283] Trial 23 finished with value: 0.10357228092243465 and parameters: {'w_0': 0.4397524556726128, 'w_1': 0.10206692456504055}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,298] Trial 24 finished with value: 0.10395181221883143 and parameters: {'w_0': 0.4073082307640078, 'w_1': 0.11220920309573004}. Best is trial 10 with value: 0.10242953994584603.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 17: F1=0.8973\n",
            "Trial 16: F1=0.8974\n",
            "Trial 18: F1=0.8941\n",
            "Trial 19: F1=0.8909\n",
            "Trial 20: F1=0.8914\n",
            "Trial 21: F1=0.8954\n",
            "Trial 22: F1=0.8897\n",
            "Trial 23: F1=0.8964\n",
            "Trial 24: F1=0.8960\n",
            "Trial 25: F1=0.8968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:24,328] Trial 25 finished with value: 0.10317624245084167 and parameters: {'w_0': 0.43013735888034715, 'w_1': 0.0872427408678713}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,353] Trial 27 finished with value: 0.10600254203702586 and parameters: {'w_0': 0.27218697433850925, 'w_1': 0.19992107082457777}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,366] Trial 28 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.2910260544911089, 'w_1': 0.0012720449721934993}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,368] Trial 26 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.2975868839260571, 'w_1': 0.0002681818056609296}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,419] Trial 29 finished with value: 0.10447565478239673 and parameters: {'w_0': 0.794460211724311, 'w_1': 0.35633877615577814}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,429] Trial 30 finished with value: 0.11803871854749703 and parameters: {'w_0': 0.01636542513228234, 'w_1': 0.983940210995737}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,445] Trial 31 finished with value: 0.11673119862686598 and parameters: {'w_0': 0.055059707527545076, 'w_1': 0.37976305887717987}. Best is trial 10 with value: 0.10242953994584603.\n",
            "[I 2025-06-16 10:30:24,474] Trial 32 finished with value: 0.10238268749332746 and parameters: {'w_0': 0.12263368882638417, 'w_1': 0.01728000462854789}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,491] Trial 34 finished with value: 0.10243587412965482 and parameters: {'w_0': 0.2193312575500352, 'w_1': 0.002373294446570416}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,497] Trial 33 finished with value: 0.10257947441649828 and parameters: {'w_0': 0.14650015206243594, 'w_1': 0.008513660981371012}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 27: F1=0.8940\n",
            "Trial 28: F1=0.8975\n",
            "Trial 26: F1=0.8975\n",
            "Trial 29: F1=0.8955\n",
            "Trial 30: F1=0.8820\n",
            "Trial 31: F1=0.8833\n",
            "Trial 32: F1=0.8976\n",
            "Trial 34: F1=0.8976\n",
            "Trial 33: F1=0.8974\n",
            "Trial 37: F1=0.8880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:24,553] Trial 37 finished with value: 0.11203522328229631 and parameters: {'w_0': 0.12527976499756943, 'w_1': 0.20059527098975027}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,557] Trial 35 finished with value: 0.11280820825600946 and parameters: {'w_0': 0.1051412517145354, 'w_1': 0.18760978609534978}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,561] Trial 36 finished with value: 0.10416401201457426 and parameters: {'w_0': 0.4815116289725128, 'w_1': 0.19342742381657246}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,611] Trial 39 finished with value: 0.10416385240077564 and parameters: {'w_0': 0.22962124601439357, 'w_1': 0.0919466454968586}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,625] Trial 38 finished with value: 0.10394486264931391 and parameters: {'w_0': 0.22378239839376882, 'w_1': 0.07484842171333798}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,631] Trial 40 finished with value: 0.10416702138035605 and parameters: {'w_0': 0.21721508618938815, 'w_1': 0.08071778166380811}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,683] Trial 41 finished with value: 0.10447565478239673 and parameters: {'w_0': 0.330664870819281, 'w_1': 0.14824138132897824}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,693] Trial 43 finished with value: 0.10455109019110742 and parameters: {'w_0': 0.3499417508821767, 'w_1': 0.15037398702041954}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,717] Trial 42 finished with value: 0.1043893116725354 and parameters: {'w_0': 0.3178051144900294, 'w_1': 0.14372997495011894}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,753] Trial 44 finished with value: 0.10242953994584603 and parameters: {'w_0': 0.17081240922102212, 'w_1': 0.003231229128278487}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 35: F1=0.8872\n",
            "Trial 36: F1=0.8958\n",
            "Trial 39: F1=0.8958\n",
            "Trial 38: F1=0.8961\n",
            "Trial 40: F1=0.8958\n",
            "Trial 41: F1=0.8955\n",
            "Trial 43: F1=0.8954\n",
            "Trial 42: F1=0.8956\n",
            "Trial 44: F1=0.8976\n",
            "Trial 45: F1=0.8974\n",
            "Trial 46: F1=0.8961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:24,755] Trial 45 finished with value: 0.10258970233082831 and parameters: {'w_0': 0.494837514044143, 'w_1': 0.04763156176251916}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,757] Trial 46 finished with value: 0.10394317450567514 and parameters: {'w_0': 0.1665273489868151, 'w_1': 0.05645085965417871}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,817] Trial 49 finished with value: 0.10371946982201075 and parameters: {'w_0': 0.9881796444517178, 'w_1': 0.23741494889026102}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,817] Trial 48 finished with value: 0.11672768916482623 and parameters: {'w_0': 0.039867082734216325, 'w_1': 0.2342917829556604}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,820] Trial 47 finished with value: 0.11673261953454672 and parameters: {'w_0': 0.05203806061577987, 'w_1': 0.31247633020001697}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,871] Trial 50 finished with value: 0.10600254203702586 and parameters: {'w_0': 0.6471345443603757, 'w_1': 0.47548350803310435}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,879] Trial 52 finished with value: 0.10273757333994604 and parameters: {'w_0': 0.6403187267739272, 'w_1': 0.04996448691148144}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,891] Trial 51 finished with value: 0.10931135274895054 and parameters: {'w_0': 0.7487340584670908, 'w_1': 0.7698062848459363}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,930] Trial 53 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.2667417420959903, 'w_1': 0.0012427431255069774}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,943] Trial 54 finished with value: 0.10258239201009034 and parameters: {'w_0': 0.25100371766246415, 'w_1': 0.010422713437316374}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,978] Trial 57 finished with value: 0.10539788338446487 and parameters: {'w_0': 0.18963781645182248, 'w_1': 0.10351848687056496}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,991] Trial 55 finished with value: 0.10243587412965482 and parameters: {'w_0': 0.25493310389488666, 'w_1': 0.0031773860188020336}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:24,992] Trial 56 finished with value: 0.10599241216661204 and parameters: {'w_0': 0.1768856027300566, 'w_1': 0.1229941766846096}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 48: F1=0.8833Trial 49: F1=0.8963\n",
            "\n",
            "Trial 47: F1=0.8833\n",
            "Trial 50: F1=0.8940\n",
            "Trial 52: F1=0.8973\n",
            "Trial 51: F1=0.8907\n",
            "Trial 53: F1=0.8975\n",
            "Trial 54: F1=0.8974\n",
            "Trial 57: F1=0.8946\n",
            "Trial 55: F1=0.8976\n",
            "Trial 56: F1=0.8940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:25,054] Trial 58 finished with value: 0.10274622514637355 and parameters: {'w_0': 0.5388083205272917, 'w_1': 0.04486885490493016}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,068] Trial 59 finished with value: 0.10267149544689447 and parameters: {'w_0': 0.5319155726330513, 'w_1': 0.053946118412915106}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,070] Trial 60 finished with value: 0.10238268749332746 and parameters: {'w_0': 0.5287790616618288, 'w_1': 0.06976668163734824}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,107] Trial 61 finished with value: 0.11656706584328314 and parameters: {'w_0': 0.08213638242996532, 'w_1': 0.6379894525464944}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,116] Trial 62 finished with value: 0.10317446135299735 and parameters: {'w_0': 0.3705132150974057, 'w_1': 0.07866213572627152}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,134] Trial 63 finished with value: 0.10285940562438078 and parameters: {'w_0': 0.47471480673437927, 'w_1': 0.0768036936759239}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,173] Trial 64 finished with value: 0.10317624245084167 and parameters: {'w_0': 0.5915555697803264, 'w_1': 0.11776492798783667}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,182] Trial 65 finished with value: 0.10257599767749515 and parameters: {'w_0': 0.588464876808112, 'w_1': 0.03272520884533305}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,208] Trial 66 finished with value: 0.1030900193509885 and parameters: {'w_0': 0.6181664583598917, 'w_1': 0.11714469402895186}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 58: F1=0.8973\n",
            "Trial 59: F1=0.8973\n",
            "Trial 60: F1=0.8976\n",
            "Trial 61: F1=0.8834\n",
            "Trial 62: F1=0.8968\n",
            "Trial 63: F1=0.8971\n",
            "Trial 64: F1=0.8968\n",
            "Trial 65: F1=0.8974\n",
            "Trial 66: F1=0.8969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:25,250] Trial 67 finished with value: 0.10992445254838679 and parameters: {'w_0': 0.14089739543726487, 'w_1': 0.1530228339583447}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,264] Trial 68 finished with value: 0.10273757333994604 and parameters: {'w_0': 0.4582762838661977, 'w_1': 0.03550504063784354}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,268] Trial 69 finished with value: 0.10273757333994604 and parameters: {'w_0': 0.4549742411617028, 'w_1': 0.03585571540037617}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,313] Trial 70 finished with value: 0.1027285068904733 and parameters: {'w_0': 0.4544641494011938, 'w_1': 0.02284266789848475}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,334] Trial 71 finished with value: 0.1120444632541655 and parameters: {'w_0': 0.0991025366984787, 'w_1': 0.16392993569866404}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,353] Trial 72 finished with value: 0.10599241216661204 and parameters: {'w_0': 0.10197918933330903, 'w_1': 0.07093829060604602}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,378] Trial 73 finished with value: 0.10257599767749515 and parameters: {'w_0': 0.10587746249554278, 'w_1': 0.005855544437917994}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,393] Trial 75 finished with value: 0.1025110620813171 and parameters: {'w_0': 0.2976195400579881, 'w_1': 0.010443711257420373}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,396] Trial 74 finished with value: 0.10388015718660715 and parameters: {'w_0': 0.28257606757849413, 'w_1': 0.0709650820382787}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,435] Trial 77 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.3691748793247764, 'w_1': 0.0013776037834654661}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 67: F1=0.8901\n",
            "Trial 68: F1=0.8973\n",
            "Trial 69: F1=0.8973\n",
            "Trial 70: F1=0.8973\n",
            "Trial 71: F1=0.8880\n",
            "Trial 72: F1=0.8940\n",
            "Trial 73: F1=0.8974\n",
            "Trial 75: F1=0.8975\n",
            "Trial 74: F1=0.8961\n",
            "Trial 77: F1=0.8975\n",
            "Trial 78: F1=0.8961\n",
            "Trial 76: F1=0.8969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:25,460] Trial 78 finished with value: 0.10388218633677249 and parameters: {'w_0': 0.3853912831646671, 'w_1': 0.10108261049858637}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,466] Trial 76 finished with value: 0.1030881756607479 and parameters: {'w_0': 0.511295892864354, 'w_1': 0.09485125785713185}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,535] Trial 81 finished with value: 0.10599378883741806 and parameters: {'w_0': 0.24446927565484136, 'w_1': 0.17154188175176613}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,536] Trial 79 finished with value: 0.10371946982201075 and parameters: {'w_0': 0.2399099979415093, 'w_1': 0.05761046577159143}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,536] Trial 80 finished with value: 0.10386735411658432 and parameters: {'w_0': 0.20288499628378054, 'w_1': 0.05624305078801761}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,598] Trial 83 finished with value: 0.10250980962198597 and parameters: {'w_0': 0.26909357194251216, 'w_1': 0.003941049138530883}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,605] Trial 82 finished with value: 0.10301680883266084 and parameters: {'w_0': 0.1463797646076478, 'w_1': 0.025993381851903176}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,603] Trial 84 finished with value: 0.10259439397176395 and parameters: {'w_0': 0.25542696859345876, 'w_1': 0.02210297348232642}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,657] Trial 85 finished with value: 0.10340594834954897 and parameters: {'w_0': 0.5571401707455378, 'w_1': 0.12341698629653852}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,671] Trial 86 finished with value: 0.10364717534326362 and parameters: {'w_0': 0.5593674070803735, 'w_1': 0.1315366430731949}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,667] Trial 87 finished with value: 0.10380375660949748 and parameters: {'w_0': 0.5690088627177727, 'w_1': 0.13802942298957493}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,710] Trial 88 finished with value: 0.10257599767749515 and parameters: {'w_0': 0.6639251375255741, 'w_1': 0.03531368929197018}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 80: F1=0.8961Trial 81: F1=0.8940\n",
            "Trial 79: F1=0.8963\n",
            "\n",
            "Trial 83: F1=0.8975\n",
            "Trial 84: F1=0.8974\n",
            "Trial 82: F1=0.8970\n",
            "Trial 85: F1=0.8966\n",
            "Trial 87: F1=0.8962\n",
            "Trial 86: F1=0.8964\n",
            "Trial 88: F1=0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:25,745] Trial 89 finished with value: 0.10317932899386728 and parameters: {'w_0': 0.20735802422191557, 'w_1': 0.039756874215679396}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,767] Trial 90 finished with value: 0.10379915957219454 and parameters: {'w_0': 0.31258771182855927, 'w_1': 0.08874243302311612}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,773] Trial 91 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.20681524578628271, 'w_1': 0.0009137459595563893}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,820] Trial 92 finished with value: 0.10243587412965482 and parameters: {'w_0': 0.16456699050647577, 'w_1': 0.0012470499800128518}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,822] Trial 93 finished with value: 0.10402769324456362 and parameters: {'w_0': 0.16946779604913062, 'w_1': 0.06123133552839711}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,831] Trial 94 finished with value: 0.10364717534326362 and parameters: {'w_0': 0.2729290661880507, 'w_1': 0.06378401019031654}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,881] Trial 95 finished with value: 0.11628859502083899 and parameters: {'w_0': 0.005310643557073669, 'w_1': 0.023801974090894646}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,893] Trial 96 finished with value: 0.10395124419323853 and parameters: {'w_0': 0.06544692702330474, 'w_1': 0.022967871031145295}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,898] Trial 97 finished with value: 0.11665855874306386 and parameters: {'w_0': 0.07896490100042222, 'w_1': 0.4254911862418207}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 89: F1=0.8968\n",
            "Trial 90: F1=0.8962\n",
            "Trial 91: F1=0.8975\n",
            "Trial 92: F1=0.8976\n",
            "Trial 93: F1=0.8960\n",
            "Trial 94: F1=0.8964\n",
            "Trial 95: F1=0.8837\n",
            "Trial 96: F1=0.8960\n",
            "Trial 97: F1=0.8833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:25,965] Trial 98 finished with value: 0.10269416932495168 and parameters: {'w_0': 0.6111317391697648, 'w_1': 0.09032052365855003}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,969] Trial 99 finished with value: 0.10584779103296871 and parameters: {'w_0': 0.12404515704971945, 'w_1': 0.0846463694295955}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:25,971] Trial 100 finished with value: 0.10285940562438078 and parameters: {'w_0': 0.6148185263537709, 'w_1': 0.09745122377441168}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,028] Trial 103 finished with value: 0.10258239201009034 and parameters: {'w_0': 0.18888712222668375, 'w_1': 0.0075403778894900155}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,032] Trial 101 finished with value: 0.11673119862686598 and parameters: {'w_0': 0.13467556190037844, 'w_1': 0.9255390523062972}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,034] Trial 102 finished with value: 0.10258239201009034 and parameters: {'w_0': 0.18930593513176397, 'w_1': 0.008336141735400631}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,089] Trial 105 finished with value: 0.10394376412254103 and parameters: {'w_0': 0.1670992551030961, 'w_1': 0.05639411108645044}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,090] Trial 104 finished with value: 0.1039599423645533 and parameters: {'w_0': 0.16673079220043804, 'w_1': 0.04320164333435846}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,135] Trial 107 finished with value: 0.10243587412965482 and parameters: {'w_0': 0.33700571739272484, 'w_1': 0.002973267120008807}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,136] Trial 106 finished with value: 0.10403207980991991 and parameters: {'w_0': 0.158298896182851, 'w_1': 0.04327099190035174}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 99: F1=0.8942Trial 98: F1=0.8973\n",
            "\n",
            "Trial 100: F1=0.8971\n",
            "Trial 103: F1=0.8974\n",
            "Trial 101: F1=0.8833\n",
            "Trial 102: F1=0.8974\n",
            "Trial 105: F1=0.8961\n",
            "Trial 104: F1=0.8960\n",
            "Trial 107: F1=0.8976\n",
            "Trial 106: F1=0.8960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:26,183] Trial 110 finished with value: 0.10266260255748627 and parameters: {'w_0': 0.2925556715533247, 'w_1': 0.023462524148855232}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,183] Trial 109 finished with value: 0.10259389646386363 and parameters: {'w_0': 0.29202283202616847, 'w_1': 0.030121060181845793}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,208] Trial 108 finished with value: 0.10238268749332746 and parameters: {'w_0': 0.26207944452275933, 'w_1': 0.03386945200481456}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,212] Trial 111 finished with value: 0.10301201893768974 and parameters: {'w_0': 0.42358212391559324, 'w_1': 0.07448429844600851}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,273] Trial 114 finished with value: 0.10242953994584603 and parameters: {'w_0': 0.23282883705712432, 'w_1': 0.004363448825389071}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,277] Trial 112 finished with value: 0.10379111778819805 and parameters: {'w_0': 0.22874835542946106, 'w_1': 0.06997565103967827}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,304] Trial 113 finished with value: 0.10379915957219454 and parameters: {'w_0': 0.22901119515823806, 'w_1': 0.06419887671435388}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,338] Trial 116 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.31979881149669903, 'w_1': 0.0011423286080008781}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,347] Trial 117 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.5386095770299352, 'w_1': 0.0022450619797104283}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,375] Trial 115 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.26431806626833765, 'w_1': 0.000978875303702456}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 109: F1=0.8974Trial 110: F1=0.8973\n",
            "\n",
            "Trial 108: F1=0.8976\n",
            "Trial 111: F1=0.8970\n",
            "Trial 114: F1=0.8976\n",
            "Trial 112: F1=0.8962\n",
            "Trial 113: F1=0.8962\n",
            "Trial 116: F1=0.8975\n",
            "Trial 117: F1=0.8975\n",
            "Trial 115: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:26,415] Trial 119 finished with value: 0.11316781276704324 and parameters: {'w_0': 0.34624304237361825, 'w_1': 0.6602993880971733}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,419] Trial 118 finished with value: 0.11316781276704324 and parameters: {'w_0': 0.3478122876294952, 'w_1': 0.6693746759922113}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,419] Trial 120 finished with value: 0.11295375883644443 and parameters: {'w_0': 0.3544478616848322, 'w_1': 0.6690601470045716}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,466] Trial 121 finished with value: 0.10258970233082831 and parameters: {'w_0': 0.48090872019363956, 'w_1': 0.0460083980230501}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,493] Trial 123 finished with value: 0.10273757333994604 and parameters: {'w_0': 0.5132604473108863, 'w_1': 0.03982052984894912}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,514] Trial 124 finished with value: 0.10267149544689447 and parameters: {'w_0': 0.24744555730489431, 'w_1': 0.025075067316132994}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,544] Trial 125 finished with value: 0.10259061697519933 and parameters: {'w_0': 0.2476495313344073, 'w_1': 0.022776054930443528}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,548] Trial 122 finished with value: 0.10266712253027055 and parameters: {'w_0': 0.5199342806033953, 'w_1': 0.03873337797246672}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,575] Trial 126 finished with value: 0.10532167604279619 and parameters: {'w_0': 0.21021675823699426, 'w_1': 0.10652419770660293}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 118: F1=0.8868Trial 119: F1=0.8868\n",
            "\n",
            "Trial 120: F1=0.8870\n",
            "Trial 121: F1=0.8974\n",
            "Trial 123: F1=0.8973\n",
            "Trial 124: F1=0.8973\n",
            "Trial 125: F1=0.8974\n",
            "Trial 122: F1=0.8973\n",
            "Trial 126: F1=0.8947\n",
            "Trial 127: F1=0.8954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:26,593] Trial 127 finished with value: 0.1046205729854518 and parameters: {'w_0': 0.21634843271388038, 'w_1': 0.10064911464231979}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,622] Trial 128 finished with value: 0.1054006191512068 and parameters: {'w_0': 0.21006154354935425, 'w_1': 0.11135348056736499}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,633] Trial 129 finished with value: 0.10340594834954897 and parameters: {'w_0': 0.27267967327571657, 'w_1': 0.060483403286626075}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,668] Trial 130 finished with value: 0.10508401166608972 and parameters: {'w_0': 0.11824451796168445, 'w_1': 0.05758160487250323}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,693] Trial 131 finished with value: 0.10293719248806188 and parameters: {'w_0': 0.31338977082012154, 'w_1': 0.051952034216713454}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,694] Trial 132 finished with value: 0.10257599767749515 and parameters: {'w_0': 0.30416604316293505, 'w_1': 0.015950289847081044}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,742] Trial 133 finished with value: 0.10257599767749515 and parameters: {'w_0': 0.30564423693913984, 'w_1': 0.01659443738540832}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,745] Trial 134 finished with value: 0.11387140820238362 and parameters: {'w_0': 0.2729842594541426, 'w_1': 0.5638038414266178}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,768] Trial 135 finished with value: 0.10266145038726127 and parameters: {'w_0': 0.27334088539277335, 'w_1': 0.018134727541784405}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 128: F1=0.8946\n",
            "Trial 129: F1=0.8966\n",
            "Trial 130: F1=0.8949\n",
            "Trial 131: F1=0.8971\n",
            "Trial 132: F1=0.8974\n",
            "Trial 133: F1=0.8974\n",
            "Trial 134: F1=0.8861\n",
            "Trial 135: F1=0.8973\n",
            "Trial 137: F1=0.8875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:26,805] Trial 137 finished with value: 0.11250507092844098 and parameters: {'w_0': 0.19081476803325262, 'w_1': 0.330628240203213}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,819] Trial 136 finished with value: 0.10250980962198597 and parameters: {'w_0': 0.18835204819830817, 'w_1': 0.0026516963829420065}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,843] Trial 138 finished with value: 0.1041513462201542 and parameters: {'w_0': 0.19306361182672643, 'w_1': 0.08037316983360411}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,878] Trial 141 finished with value: 0.103095943661898 and parameters: {'w_0': 0.15350609479806043, 'w_1': 0.03301756044842896}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,881] Trial 140 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.14885206328089826, 'w_1': 0.00019281575103481316}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,916] Trial 139 finished with value: 0.10394486264931391 and parameters: {'w_0': 0.23030703511235964, 'w_1': 0.07718679343718649}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,951] Trial 143 finished with value: 0.102700711581726 and parameters: {'w_0': 0.2348802532878834, 'w_1': 0.03695216215099924}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,952] Trial 142 finished with value: 0.10285940562438078 and parameters: {'w_0': 0.23394410767854967, 'w_1': 0.037447751300916945}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:26,990] Trial 144 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.2530839488134058, 'w_1': 0.0008541017356821451}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,000] Trial 145 finished with value: 0.10243587412965482 and parameters: {'w_0': 0.3291893494559761, 'w_1': 0.003539186999391329}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 136: F1=0.8975\n",
            "Trial 138: F1=0.8958\n",
            "Trial 141: F1=0.8969\n",
            "Trial 140: F1=0.8975\n",
            "Trial 139: F1=0.8961\n",
            "Trial 143: F1=0.8973\n",
            "Trial 142: F1=0.8971\n",
            "Trial 144: F1=0.8975\n",
            "Trial 145: F1=0.8976\n",
            "Trial 146: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:27,009] Trial 146 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.8454299279745215, 'w_1': 0.0004354581378914063}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,063] Trial 148 finished with value: 0.11393890069617396 and parameters: {'w_0': 0.38256334481698495, 'w_1': 0.8250854034454473}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,063] Trial 147 finished with value: 0.1025110620813171 and parameters: {'w_0': 0.592502221365929, 'w_1': 0.021566262045557276}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,092] Trial 149 finished with value: 0.10258669323075753 and parameters: {'w_0': 0.3246067969437681, 'w_1': 0.022916480786455078}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,102] Trial 150 finished with value: 0.10285940562438078 and parameters: {'w_0': 0.3210715164368458, 'w_1': 0.0521427754805541}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,132] Trial 151 finished with value: 0.10371322729347732 and parameters: {'w_0': 0.1805965664251716, 'w_1': 0.056489955523639925}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,157] Trial 152 finished with value: 0.10245695215813089 and parameters: {'w_0': 0.1756269087192611, 'w_1': 0.024958270726079715}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,178] Trial 153 finished with value: 0.10259439397176395 and parameters: {'w_0': 0.2608519094543827, 'w_1': 0.022816573790130728}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,222] Trial 156 finished with value: 0.10395124419323853 and parameters: {'w_0': 0.1225124863201286, 'w_1': 0.04405892065601528}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,227] Trial 155 finished with value: 0.10394486264931391 and parameters: {'w_0': 0.12447014171575989, 'w_1': 0.04117104186645892}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,229] Trial 154 finished with value: 0.10285940562438078 and parameters: {'w_0': 0.12766948566292166, 'w_1': 0.02055792061020697}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 147: F1=0.8975Trial 148: F1=0.8861\n",
            "\n",
            "Trial 149: F1=0.8974\n",
            "Trial 150: F1=0.8971\n",
            "Trial 151: F1=0.8963\n",
            "Trial 152: F1=0.8975\n",
            "Trial 153: F1=0.8974\n",
            "Trial 156: F1=0.8960\n",
            "Trial 155: F1=0.8961\n",
            "Trial 154: F1=0.8971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:27,284] Trial 157 finished with value: 0.10269416932495168 and parameters: {'w_0': 0.4890583483771758, 'w_1': 0.0744379247934776}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,299] Trial 159 finished with value: 0.10447565478239673 and parameters: {'w_0': 0.17207431412061452, 'w_1': 0.07471302794271698}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,335] Trial 158 finished with value: 0.10416362771612697 and parameters: {'w_0': 0.1679332661392687, 'w_1': 0.06690413419573986}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,367] Trial 161 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.2840210119855602, 'w_1': 4.994941994459698e-05}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,388] Trial 160 finished with value: 0.10242953994584603 and parameters: {'w_0': 0.5355033679589549, 'w_1': 0.014060471860549366}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,414] Trial 162 finished with value: 0.10266712253027055 and parameters: {'w_0': 0.2176107775980272, 'w_1': 0.016692450668353745}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,438] Trial 163 finished with value: 0.10258679594199716 and parameters: {'w_0': 0.2118149275124366, 'w_1': 0.020870722465143772}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,464] Trial 164 finished with value: 0.10258239201009034 and parameters: {'w_0': 0.5297758834238145, 'w_1': 0.021119045654398}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 157: F1=0.8973\n",
            "Trial 159: F1=0.8955\n",
            "Trial 158: F1=0.8958\n",
            "Trial 161: F1=0.8975\n",
            "Trial 160: F1=0.8976\n",
            "Trial 162: F1=0.8973\n",
            "Trial 163: F1=0.8974\n",
            "Trial 164: F1=0.8974\n",
            "Trial 165: F1=0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:27,470] Trial 165 finished with value: 0.10257599767749515 and parameters: {'w_0': 0.5460358586519893, 'w_1': 0.030105439871090364}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,519] Trial 167 finished with value: 0.10274622514637355 and parameters: {'w_0': 0.574727013442609, 'w_1': 0.047913684291445366}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,533] Trial 166 finished with value: 0.10258669323075753 and parameters: {'w_0': 0.5626947905717786, 'w_1': 0.04092321888663533}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,533] Trial 168 finished with value: 0.10364717534326362 and parameters: {'w_0': 0.19181265249522533, 'w_1': 0.04527757283987603}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,579] Trial 170 finished with value: 0.10800354120466138 and parameters: {'w_0': 0.5151909387126343, 'w_1': 0.46655909613234514}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,594] Trial 169 finished with value: 0.10243587412965482 and parameters: {'w_0': 0.5096330201365759, 'w_1': 0.0036135956964638755}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,603] Trial 171 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.4642894966536436, 'w_1': 0.002323412182113021}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,655] Trial 173 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.4915311512089691, 'w_1': 0.0015298531789479206}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,666] Trial 172 finished with value: 0.10251066016173793 and parameters: {'w_0': 0.49372437301537897, 'w_1': 0.0014988706332089408}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,688] Trial 174 finished with value: 0.10243587412965482 and parameters: {'w_0': 0.494659406592401, 'w_1': 0.004220847236641178}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 166: F1=0.8974Trial 167: F1=0.8973\n",
            "Trial 168: F1=0.8964\n",
            "\n",
            "Trial 170: F1=0.8920\n",
            "Trial 169: F1=0.8976\n",
            "Trial 171: F1=0.8975\n",
            "Trial 173: F1=0.8975\n",
            "Trial 172: F1=0.8975\n",
            "Trial 174: F1=0.8976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:27,720] Trial 175 finished with value: 0.10257599767749515 and parameters: {'w_0': 0.5490320774757477, 'w_1': 0.029375205557919504}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,756] Trial 176 finished with value: 0.10257599767749515 and parameters: {'w_0': 0.5325637397523315, 'w_1': 0.02867221160507355}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,767] Trial 178 finished with value: 0.10254104180163381 and parameters: {'w_0': 0.40382122023441097, 'w_1': 0.058598321531942485}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,783] Trial 177 finished with value: 0.10266365372672981 and parameters: {'w_0': 0.5292864256109037, 'w_1': 0.02407064839940865}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,826] Trial 181 finished with value: 0.10251545588480093 and parameters: {'w_0': 0.5068411235567297, 'w_1': 0.06005941912878338}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,832] Trial 180 finished with value: 0.1026243730801587 and parameters: {'w_0': 0.5956068728844625, 'w_1': 0.093049586489241}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,844] Trial 179 finished with value: 0.10317446135299735 and parameters: {'w_0': 0.43342936989120506, 'w_1': 0.09178524653395416}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,886] Trial 183 finished with value: 0.10243587412965482 and parameters: {'w_0': 0.2882986636666633, 'w_1': 0.0019366962983028105}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,909] Trial 182 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.28992540071807305, 'w_1': 0.0003202807666464998}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 175: F1=0.8974\n",
            "Trial 176: F1=0.8974\n",
            "Trial 178: F1=0.8975\n",
            "Trial 177: F1=0.8973\n",
            "Trial 181: F1=0.8975\n",
            "Trial 180: F1=0.8974\n",
            "Trial 179: F1=0.8968\n",
            "Trial 183: F1=0.8976\n",
            "Trial 182: F1=0.8975\n",
            "Trial 184: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:27,919] Trial 184 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.7303170018094822, 'w_1': 0.0003842975789518752}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,959] Trial 185 finished with value: 0.10257599767749515 and parameters: {'w_0': 0.28992106689170455, 'w_1': 0.015504261517314558}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,959] Trial 186 finished with value: 0.10408073119449979 and parameters: {'w_0': 0.0946266433943116, 'w_1': 0.039199351005037665}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:27,996] Trial 187 finished with value: 0.10257739326105264 and parameters: {'w_0': 0.3373405971408281, 'w_1': 0.021191013858192623}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,015] Trial 188 finished with value: 0.10269416932495168 and parameters: {'w_0': 0.2435849638858953, 'w_1': 0.03781585220405329}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,068] Trial 190 finished with value: 0.10401185671907409 and parameters: {'w_0': 0.15706740545120887, 'w_1': 0.05998704504270705}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,072] Trial 189 finished with value: 0.10308198274418778 and parameters: {'w_0': 0.2494128910487128, 'w_1': 0.043520891462677076}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,076] Trial 191 finished with value: 0.10395124419323853 and parameters: {'w_0': 0.15412984460841253, 'w_1': 0.053954616744441214}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,141] Trial 194 finished with value: 0.10259065475102502 and parameters: {'w_0': 0.2668190709889553, 'w_1': 0.0178565311209364}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,147] Trial 192 finished with value: 0.10251100722160944 and parameters: {'w_0': 0.26515186615653724, 'w_1': 0.00022848155446783015}. Best is trial 32 with value: 0.10238268749332746.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 186: F1=0.8959Trial 185: F1=0.8974\n",
            "\n",
            "Trial 187: F1=0.8974\n",
            "Trial 188: F1=0.8973\n",
            "Trial 190: F1=0.8960\n",
            "Trial 189: F1=0.8969\n",
            "Trial 191: F1=0.8960\n",
            "Trial 194: F1=0.8974\n",
            "Trial 192: F1=0.8975\n",
            "Trial 193: F1=0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:28,150] Trial 193 finished with value: 0.10257947441649828 and parameters: {'w_0': 0.2711024839656225, 'w_1': 0.015533661895602454}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,221] Trial 197 finished with value: 0.10269416932495168 and parameters: {'w_0': 0.19270996911458033, 'w_1': 0.029878840327399046}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,223] Trial 196 finished with value: 0.10265244114036454 and parameters: {'w_0': 0.5786692121492868, 'w_1': 0.029788466549342044}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,223] Trial 195 finished with value: 0.10250451721673659 and parameters: {'w_0': 0.5726638491178816, 'w_1': 0.03202667166597888}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,274] Trial 199 finished with value: 0.10243002199579432 and parameters: {'w_0': 0.6355209896710192, 'w_1': 0.0178997389976196}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,279] Trial 198 finished with value: 0.10252536778897114 and parameters: {'w_0': 0.5535098525275013, 'w_1': 0.0688481234665796}. Best is trial 32 with value: 0.10238268749332746.\n",
            "[I 2025-06-16 10:30:28,341] A new study created in memory with name: no-name-ec5c2492-009c-40da-8211-ce0e83952c15\n",
            "[I 2025-06-16 10:30:28,355] Trial 0 finished with value: 0.11434169827099327 and parameters: {'w_0': 0.042990259713928, 'w_1': 0.5993107766544721}. Best is trial 0 with value: 0.11434169827099327.\n",
            "[I 2025-06-16 10:30:28,370] Trial 1 finished with value: 0.10240083753348117 and parameters: {'w_0': 0.6262677823851092, 'w_1': 0.2561296235353998}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,388] Trial 2 finished with value: 0.10903402618839086 and parameters: {'w_0': 0.18675318578301692, 'w_1': 0.33920241722779687}. Best is trial 1 with value: 0.10240083753348117.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 195: F1=0.8975Trial 197: F1=0.8973\n",
            "Trial 196: F1=0.8973\n",
            "\n",
            "Trial 199: F1=0.8976\n",
            "Trial 198: F1=0.8975\n",
            "Combo ['booster_texte_logits.pt', 'camembert2_logits.pt'] - Best F1: 0.8976\n",
            "\n",
            "Test combo: ['booster_texte_logits.pt', 'flaubert2_logits.pt']\n",
            "Trial 0: F1=0.8857\n",
            "Trial 1: F1=0.8976\n",
            "Trial 2: F1=0.8910\n",
            "Trial 4: F1=0.8935\n",
            "Trial 3: F1=0.8900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:28,403] Trial 4 finished with value: 0.10649579485009919 and parameters: {'w_0': 0.9051094596702068, 'w_1': 0.9581750536151739}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,409] Trial 3 finished with value: 0.10996037573114992 and parameters: {'w_0': 0.48851857199229476, 'w_1': 0.9909694602325405}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,429] Trial 5 finished with value: 0.10926612538134683 and parameters: {'w_0': 0.21708042050746867, 'w_1': 0.4121433438142268}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,440] Trial 6 finished with value: 0.10500132391367356 and parameters: {'w_0': 0.31586452761530015, 'w_1': 0.2039655851680463}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,452] Trial 8 finished with value: 0.10672563113299671 and parameters: {'w_0': 0.9287755244410163, 'w_1': 0.9249206854309214}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,474] Trial 10 finished with value: 0.10241447941198467 and parameters: {'w_0': 0.8908254706249866, 'w_1': 0.11128228955011366}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,482] Trial 7 finished with value: 0.10823777470597351 and parameters: {'w_0': 0.272905757984481, 'w_1': 0.38260009397011796}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,497] Trial 9 finished with value: 0.10540476910139329 and parameters: {'w_0': 0.7611301713045066, 'w_1': 0.6448558442437553}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,530] Trial 11 finished with value: 0.10565663223380717 and parameters: {'w_0': 0.6851881340313525, 'w_1': 0.6457469794386334}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,556] Trial 12 finished with value: 0.10259312268031129 and parameters: {'w_0': 0.6387045676653371, 'w_1': 0.021892574042192497}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,561] Trial 13 finished with value: 0.10249445237537891 and parameters: {'w_0': 0.6452513821797065, 'w_1': 0.03505492755911299}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,572] Trial 14 finished with value: 0.1025811233820989 and parameters: {'w_0': 0.6341285653463629, 'w_1': 0.024961225021206207}. Best is trial 1 with value: 0.10240083753348117.\n",
            "[I 2025-06-16 10:30:28,585] Trial 15 finished with value: 0.10247458163355794 and parameters: {'w_0': 0.49451305710624016, 'w_1': 0.1993982525828382}. Best is trial 1 with value: 0.10240083753348117.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5: F1=0.8907\n",
            "Trial 6: F1=0.8950\n",
            "Trial 8: F1=0.8933\n",
            "Trial 10: F1=0.8976\n",
            "Trial 7: F1=0.8918\n",
            "Trial 9: F1=0.8946\n",
            "Trial 11: F1=0.8943\n",
            "Trial 12: F1=0.8974\n",
            "Trial 13: F1=0.8975\n",
            "Trial 14: F1=0.8974\n",
            "Trial 15: F1=0.8975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:28,642] Trial 16 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.8167298478021215, 'w_1': 0.20649639065952452}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,647] Trial 17 finished with value: 0.10192566886364784 and parameters: {'w_0': 0.8433549347340606, 'w_1': 0.18692439538011998}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,676] Trial 18 finished with value: 0.10192566886364784 and parameters: {'w_0': 0.8418194528657215, 'w_1': 0.18442961241686406}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,689] Trial 19 finished with value: 0.10484602340234894 and parameters: {'w_0': 0.8026114220857619, 'w_1': 0.5000454746708451}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,723] Trial 21 finished with value: 0.10408981323435262 and parameters: {'w_0': 0.9776475217425366, 'w_1': 0.4949393391166489}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,724] Trial 20 finished with value: 0.10528628027848574 and parameters: {'w_0': 0.7984361358382495, 'w_1': 0.5452422441364351}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,759] Trial 22 finished with value: 0.10186510516943037 and parameters: {'w_0': 0.990823693230428, 'w_1': 0.29019770049521565}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,771] Trial 23 finished with value: 0.10215515775313211 and parameters: {'w_0': 0.8318513088956373, 'w_1': 0.27911100796037447}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,778] Trial 24 finished with value: 0.10243725295930706 and parameters: {'w_0': 0.8283117295224999, 'w_1': 0.13016776485472442}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,799] Trial 25 finished with value: 0.10178285929008701 and parameters: {'w_0': 0.9932714353410508, 'w_1': 0.29632907268327047}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,839] Trial 26 finished with value: 0.10186130275236482 and parameters: {'w_0': 0.9990864679465502, 'w_1': 0.3105087757660216}. Best is trial 16 with value: 0.10177248593513244.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 16: F1=0.8982\n",
            "Trial 17: F1=0.8981\n",
            "Trial 18: F1=0.8981\n",
            "Trial 19: F1=0.8952\n",
            "Trial 21: F1=0.8959\n",
            "Trial 20: F1=0.8947\n",
            "Trial 22: F1=0.8981\n",
            "Trial 23: F1=0.8978\n",
            "Trial 24: F1=0.8976\n",
            "Trial 25: F1=0.8982\n",
            "Trial 26: F1=0.8981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:28,862] Trial 29 finished with value: 0.10548402800229484 and parameters: {'w_0': 0.9949300746621794, 'w_1': 0.7793091944379389}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,869] Trial 27 finished with value: 0.10186130275236482 and parameters: {'w_0': 0.9702989456530621, 'w_1': 0.30247755097540324}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,900] Trial 28 finished with value: 0.10200345235439734 and parameters: {'w_0': 0.9994492514242042, 'w_1': 0.3269364099064883}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,931] Trial 31 finished with value: 0.11509094153492161 and parameters: {'w_0': 0.004830985314896119, 'w_1': 0.42445867509274443}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,932] Trial 30 finished with value: 0.10453985123965415 and parameters: {'w_0': 0.7309558364884785, 'w_1': 0.42295946932262896}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,960] Trial 32 finished with value: 0.10453985123965415 and parameters: {'w_0': 0.7429383874279086, 'w_1': 0.42625530869674727}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,981] Trial 33 finished with value: 0.10212097973502232 and parameters: {'w_0': 0.9239970463682746, 'w_1': 0.11052376125560812}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:28,991] Trial 34 finished with value: 0.10226397358521866 and parameters: {'w_0': 0.9145810124243026, 'w_1': 0.10083756947645073}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:29,006] Trial 35 finished with value: 0.10241447941198467 and parameters: {'w_0': 0.9227322305003561, 'w_1': 0.11503784185919586}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:29,042] Trial 36 finished with value: 0.10301647544327419 and parameters: {'w_0': 0.5446919556343608, 'w_1': 0.253242934122972}. Best is trial 16 with value: 0.10177248593513244.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 29: F1=0.8945\n",
            "Trial 27: F1=0.8981\n",
            "Trial 28: F1=0.8980\n",
            "Trial 31: F1=0.8849\n",
            "Trial 30: F1=0.8955\n",
            "Trial 32: F1=0.8955\n",
            "Trial 33: F1=0.8979\n",
            "Trial 34: F1=0.8977\n",
            "Trial 35: F1=0.8976\n",
            "Trial 36: F1=0.8970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:29,064] Trial 37 finished with value: 0.10477392916189243 and parameters: {'w_0': 0.5656438046644199, 'w_1': 0.34827350335963064}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:29,099] Trial 39 finished with value: 0.10557039232322951 and parameters: {'w_0': 0.37927518141161587, 'w_1': 0.34653685079957264}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:29,106] Trial 38 finished with value: 0.10543071231075074 and parameters: {'w_0': 0.4326514838972795, 'w_1': 0.3562680299744555}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:29,115] Trial 40 finished with value: 0.10417800796714305 and parameters: {'w_0': 0.432608700313598, 'w_1': 0.2254685519496743}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:29,171] Trial 42 finished with value: 0.10178732901439658 and parameters: {'w_0': 0.9710579098605066, 'w_1': 0.29161709625929705}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:29,195] Trial 43 finished with value: 0.10178732901439658 and parameters: {'w_0': 0.9536437965083705, 'w_1': 0.29016204932004147}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:29,200] Trial 41 finished with value: 0.10177504095985745 and parameters: {'w_0': 0.9595150085738646, 'w_1': 0.25640736924430296}. Best is trial 16 with value: 0.10177248593513244.\n",
            "[I 2025-06-16 10:30:29,244] Trial 44 finished with value: 0.10215639358442119 and parameters: {'w_0': 0.8755987115451456, 'w_1': 0.2907906314187846}. Best is trial 16 with value: 0.10177248593513244.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 37: F1=0.8952\n",
            "Trial 39: F1=0.8944\n",
            "Trial 38: F1=0.8946\n",
            "Trial 40: F1=0.8958\n",
            "Trial 42: F1=0.8982\n",
            "Trial 43: F1=0.8982\n",
            "Trial 41: F1=0.8982\n",
            "Trial 44: F1=0.8978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:29,271] Trial 46 finished with value: 0.10162432709486313 and parameters: {'w_0': 0.8834828751178178, 'w_1': 0.2318294777276655}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,274] Trial 45 finished with value: 0.11003242415004755 and parameters: {'w_0': 0.11982529806352704, 'w_1': 0.2511708118825196}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,304] Trial 47 finished with value: 0.10178285929008701 and parameters: {'w_0': 0.8830961862935546, 'w_1': 0.26008618933032424}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,330] Trial 49 finished with value: 0.10213001370066022 and parameters: {'w_0': 0.8815941144996228, 'w_1': 0.15254443714497407}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,351] Trial 50 finished with value: 0.10206095201860532 and parameters: {'w_0': 0.8784234788024323, 'w_1': 0.1571930275653396}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,353] Trial 48 finished with value: 0.10235880815386367 and parameters: {'w_0': 0.8902476145985615, 'w_1': 0.14819935969418524}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,384] Trial 51 finished with value: 0.1022594657962479 and parameters: {'w_0': 0.708745208863651, 'w_1': 0.06153732122520894}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,417] Trial 53 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.9436577656178621, 'w_1': 0.2407698051660587}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,419] Trial 52 finished with value: 0.10171555961300671 and parameters: {'w_0': 0.6966824622151261, 'w_1': 0.19616988820546838}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,452] Trial 54 finished with value: 0.10199715141268761 and parameters: {'w_0': 0.9462366021828331, 'w_1': 0.22913387495305865}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 46: F1=0.8984\n",
            "Trial 45: F1=0.8900\n",
            "Trial 47: F1=0.8982\n",
            "Trial 49: F1=0.8979\n",
            "Trial 50: F1=0.8979\n",
            "Trial 48: F1=0.8976\n",
            "Trial 51: F1=0.8977\n",
            "Trial 53: F1=0.8982\n",
            "Trial 52: F1=0.8983\n",
            "Trial 54: F1=0.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:29,488] Trial 56 finished with value: 0.10207624832641848 and parameters: {'w_0': 0.6793020824258253, 'w_1': 0.22354306399455806}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,494] Trial 55 finished with value: 0.10171172114712801 and parameters: {'w_0': 0.782994145332974, 'w_1': 0.2176955797965302}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,551] Trial 58 finished with value: 0.10191598059503637 and parameters: {'w_0': 0.7626256735539597, 'w_1': 0.1851451871864317}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,567] Trial 59 finished with value: 0.10226385356325673 and parameters: {'w_0': 0.781576801765083, 'w_1': 0.07473115281662601}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,559] Trial 57 finished with value: 0.10377891289936747 and parameters: {'w_0': 0.7799006283729539, 'w_1': 0.38432271760412906}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,622] Trial 61 finished with value: 0.1019211728321936 and parameters: {'w_0': 0.820419247074662, 'w_1': 0.17734638719747448}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,635] Trial 62 finished with value: 0.10266849814238255 and parameters: {'w_0': 0.593862894966104, 'w_1': 0.004490030132734912}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,663] Trial 60 finished with value: 0.10226517356808396 and parameters: {'w_0': 0.8108651532842475, 'w_1': 0.053829534005011115}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 56: F1=0.8979\n",
            "Trial 55: F1=0.8983\n",
            "Trial 58: F1=0.8981\n",
            "Trial 57: F1=0.8962\n",
            "Trial 59: F1=0.8977\n",
            "Trial 61: F1=0.8981\n",
            "Trial 62: F1=0.8973\n",
            "Trial 60: F1=0.8977\n",
            "Trial 63: F1=0.8983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:29,682] Trial 63 finished with value: 0.10169616355544575 and parameters: {'w_0': 0.8529762558601905, 'w_1': 0.21265044218493984}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,706] Trial 64 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.8597311480979593, 'w_1': 0.222100233104599}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,729] Trial 65 finished with value: 0.1020017132468819 and parameters: {'w_0': 0.9423799836733026, 'w_1': 0.22126351736085467}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,754] Trial 66 finished with value: 0.10169743330357461 and parameters: {'w_0': 0.8590346603626199, 'w_1': 0.21506190975069053}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,759] Trial 67 finished with value: 0.10199715141268761 and parameters: {'w_0': 0.8611357568276782, 'w_1': 0.20840566218146017}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,767] Trial 68 finished with value: 0.10665275850028899 and parameters: {'w_0': 0.8512144108215776, 'w_1': 0.8677568949222119}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,825] Trial 69 finished with value: 0.10212097973502232 and parameters: {'w_0': 0.669697357391686, 'w_1': 0.07939202215533078}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,810] Trial 70 finished with value: 0.1020017132468819 and parameters: {'w_0': 0.7213300090459207, 'w_1': 0.16693064321764642}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,848] Trial 71 finished with value: 0.105207797902376 and parameters: {'w_0': 0.6717549139096337, 'w_1': 0.4742758095514785}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,896] Trial 72 finished with value: 0.10221009877840037 and parameters: {'w_0': 0.7565892710896527, 'w_1': 0.13166035151280409}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 65: F1=0.8980Trial 64: F1=0.8982\n",
            "\n",
            "Trial 66: F1=0.8983\n",
            "Trial 67: F1=0.8980\n",
            "Trial 68: F1=0.8933\n",
            "Trial 70: F1=0.8980\n",
            "Trial 69: F1=0.8979\n",
            "Trial 71: F1=0.8948\n",
            "Trial 72: F1=0.8978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:29,918] Trial 74 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.7606474047926453, 'w_1': 0.19757579539248163}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,919] Trial 73 finished with value: 0.10162432709486313 and parameters: {'w_0': 0.7911654209410527, 'w_1': 0.2091996376218499}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,961] Trial 75 finished with value: 0.10240083753348117 and parameters: {'w_0': 0.794646194292385, 'w_1': 0.3232355577224268}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,979] Trial 77 finished with value: 0.10240083753348117 and parameters: {'w_0': 0.7905702774900987, 'w_1': 0.3233675360828626}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:29,994] Trial 76 finished with value: 0.10331672944597647 and parameters: {'w_0': 0.7952932624849505, 'w_1': 0.37892510253753464}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,037] Trial 78 finished with value: 0.10243341174359799 and parameters: {'w_0': 0.9108398797603109, 'w_1': 0.1331681834358524}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,042] Trial 79 finished with value: 0.10178732901439658 and parameters: {'w_0': 0.837713050954189, 'w_1': 0.2536411868498866}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,057] Trial 80 finished with value: 0.10186510516943037 and parameters: {'w_0': 0.9079476518467334, 'w_1': 0.2661022343906705}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,099] Trial 82 finished with value: 0.1020056872024887 and parameters: {'w_0': 0.8540455783143976, 'w_1': 0.1964995629778622}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 73: F1=0.8984Trial 74: F1=0.8982\n",
            "\n",
            "Trial 75: F1=0.8976\n",
            "Trial 77: F1=0.8976\n",
            "Trial 76: F1=0.8967\n",
            "Trial 78: F1=0.8976\n",
            "Trial 79: F1=0.8982\n",
            "Trial 80: F1=0.8981\n",
            "Trial 82: F1=0.8980\n",
            "Trial 81: F1=0.8945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:30,108] Trial 81 finished with value: 0.10548397095324513 and parameters: {'w_0': 0.7025674886224831, 'w_1': 0.6128266318191492}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,142] Trial 83 finished with value: 0.10542783589578608 and parameters: {'w_0': 0.8624574305953524, 'w_1': 0.63225921523981}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,168] Trial 84 finished with value: 0.10179182643862195 and parameters: {'w_0': 0.8314344920304347, 'w_1': 0.23515792693735832}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,175] Trial 85 finished with value: 0.10178344964693797 and parameters: {'w_0': 0.8244138622005049, 'w_1': 0.23585484410183238}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,207] Trial 86 finished with value: 0.10178344964693797 and parameters: {'w_0': 0.8199489932750837, 'w_1': 0.23350008208789053}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,230] Trial 89 finished with value: 0.10198727637363558 and parameters: {'w_0': 0.8963348025382311, 'w_1': 0.16882850787138878}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,252] Trial 88 finished with value: 0.10211806279021751 and parameters: {'w_0': 0.9003502174237005, 'w_1': 0.10452244111418521}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,261] Trial 87 finished with value: 0.10206095201860532 and parameters: {'w_0': 0.9276029281372833, 'w_1': 0.1702312036228793}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,313] Trial 90 finished with value: 0.10230099543871896 and parameters: {'w_0': 0.7462763318883571, 'w_1': 0.2736142526771164}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,327] Trial 91 finished with value: 0.10230098489711448 and parameters: {'w_0': 0.7385885488068591, 'w_1': 0.2768927933297654}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 83: F1=0.8946\n",
            "Trial 84: F1=0.8982\n",
            "Trial 85: F1=0.8982\n",
            "Trial 86: F1=0.8982\n",
            "Trial 89: F1=0.8980\n",
            "Trial 88: F1=0.8979\n",
            "Trial 87: F1=0.8979\n",
            "Trial 90: F1=0.8977\n",
            "Trial 91: F1=0.8977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:30,338] Trial 92 finished with value: 0.10223894165570813 and parameters: {'w_0': 0.7272775749917977, 'w_1': 0.27941992204126925}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,381] Trial 93 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.7761066021632944, 'w_1': 0.20044034356615106}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,390] Trial 94 finished with value: 0.10169751838374363 and parameters: {'w_0': 0.7759835534750243, 'w_1': 0.20676366182794512}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,414] Trial 95 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.774823547057436, 'w_1': 0.19800664057910333}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,427] Trial 96 finished with value: 0.1023628449940458 and parameters: {'w_0': 0.8656503889855768, 'w_1': 0.1415129113541279}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,441] Trial 97 finished with value: 0.10228352493711756 and parameters: {'w_0': 0.8652716997534762, 'w_1': 0.14638968841647657}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,505] Trial 98 finished with value: 0.1065622946257142 and parameters: {'w_0': 0.291403426267855, 'w_1': 0.3030412601718742}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,516] Trial 99 finished with value: 0.10162432709486313 and parameters: {'w_0': 0.8070576476860081, 'w_1': 0.21358030686994758}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 92: F1=0.8978\n",
            "Trial 93: F1=0.8982\n",
            "Trial 94: F1=0.8983\n",
            "Trial 95: F1=0.8982\n",
            "Trial 96: F1=0.8976\n",
            "Trial 97: F1=0.8977\n",
            "Trial 98: F1=0.8934\n",
            "Trial 99: F1=0.8984\n",
            "Trial 100: F1=0.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:30,519] Trial 100 finished with value: 0.10200345235439734 and parameters: {'w_0': 0.942476634542986, 'w_1': 0.3083628373951864}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,582] Trial 101 finished with value: 0.1057903863593368 and parameters: {'w_0': 0.8040055051058266, 'w_1': 0.7249003204118238}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,587] Trial 102 finished with value: 0.10170183811915279 and parameters: {'w_0': 0.8161807143373015, 'w_1': 0.21713751335498938}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,595] Trial 103 finished with value: 0.10162432709486313 and parameters: {'w_0': 0.8150924990133409, 'w_1': 0.2161033798244281}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,630] Trial 104 finished with value: 0.10222756426581547 and parameters: {'w_0': 0.6098501595554857, 'w_1': 0.21442917206171935}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,673] Trial 107 finished with value: 0.10234988298078884 and parameters: {'w_0': 0.8437363724668362, 'w_1': 0.11824132512806533}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,676] Trial 106 finished with value: 0.10169743330357461 and parameters: {'w_0': 0.69847937299921, 'w_1': 0.17554299952759936}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,680] Trial 105 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.8413283405167509, 'w_1': 0.21308464813352496}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,723] Trial 109 finished with value: 0.10234988298078884 and parameters: {'w_0': 0.6573537688850326, 'w_1': 0.09400213969920418}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,758] Trial 111 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.691519708619325, 'w_1': 0.17863654902145915}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,771] Trial 108 finished with value: 0.1020017132468819 and parameters: {'w_0': 0.7665115594404026, 'w_1': 0.17828513070224794}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 101: F1=0.8942\n",
            "Trial 102: F1=0.8983\n",
            "Trial 103: F1=0.8984\n",
            "Trial 104: F1=0.8978\n",
            "Trial 107: F1=0.8977\n",
            "Trial 106: F1=0.8983\n",
            "Trial 105: F1=0.8982\n",
            "Trial 109: F1=0.8977\n",
            "Trial 111: F1=0.8982\n",
            "Trial 110: F1=0.8977\n",
            "Trial 108: F1=0.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:30,767] Trial 110 finished with value: 0.10233937235761714 and parameters: {'w_0': 0.7017588492914886, 'w_1': 0.08576831688232535}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,828] Trial 112 finished with value: 0.1018355542997722 and parameters: {'w_0': 0.7957182183946753, 'w_1': 0.15684051810394817}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,839] Trial 114 finished with value: 0.10186130275236482 and parameters: {'w_0': 0.796275459419983, 'w_1': 0.24587093751678427}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,861] Trial 116 finished with value: 0.10162432709486313 and parameters: {'w_0': 0.7274310493303731, 'w_1': 0.1904532315366027}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,881] Trial 115 finished with value: 0.10178732901439658 and parameters: {'w_0': 0.8161692697251915, 'w_1': 0.24660847707678024}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,883] Trial 113 finished with value: 0.1018355542997722 and parameters: {'w_0': 0.8018151542724656, 'w_1': 0.1577702685036848}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,939] Trial 117 finished with value: 0.10178294443533797 and parameters: {'w_0': 0.7214960257239245, 'w_1': 0.1969746917027437}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,944] Trial 118 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.7285629837011951, 'w_1': 0.18839750580944942}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:30,949] Trial 119 finished with value: 0.1018355542997722 and parameters: {'w_0': 0.6267109768597949, 'w_1': 0.12171834175227182}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,019] Trial 121 finished with value: 0.10233653406567611 and parameters: {'w_0': 0.5148152654030639, 'w_1': 0.046496426663585166}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,028] Trial 120 finished with value: 0.11219206632097856 and parameters: {'w_0': 0.22183663730257874, 'w_1': 0.9999632153671054}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 112: F1=0.8982\n",
            "Trial 114: F1=0.8981\n",
            "Trial 116: F1=0.8984\n",
            "Trial 115: F1=0.8982\n",
            "Trial 113: F1=0.8982\n",
            "Trial 117: F1=0.8982\n",
            "Trial 118: F1=0.8982\n",
            "Trial 119: F1=0.8982\n",
            "Trial 121: F1=0.8977\n",
            "Trial 120: F1=0.8878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:31,044] Trial 122 finished with value: 0.10222327549845522 and parameters: {'w_0': 0.7569957374153715, 'w_1': 0.26426494215333496}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,093] Trial 123 finished with value: 0.10163833064684868 and parameters: {'w_0': 0.7615261899306636, 'w_1': 0.21350158704627462}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,116] Trial 126 finished with value: 0.10215515775313211 and parameters: {'w_0': 0.6421080433627876, 'w_1': 0.21523302941140607}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,118] Trial 124 finished with value: 0.10215515775313211 and parameters: {'w_0': 0.6507321573042826, 'w_1': 0.21985456663465586}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,121] Trial 125 finished with value: 0.10178344964693797 and parameters: {'w_0': 0.7490449961549932, 'w_1': 0.21391004303531097}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,180] Trial 127 finished with value: 0.1016921630666856 and parameters: {'w_0': 0.7050268053361798, 'w_1': 0.17326323073595798}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,181] Trial 128 finished with value: 0.10169743330357461 and parameters: {'w_0': 0.7036903202631453, 'w_1': 0.17751927642315377}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,188] Trial 129 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.7097444639974053, 'w_1': 0.1802690944412679}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,234] Trial 130 finished with value: 0.10191748656084909 and parameters: {'w_0': 0.6851609977591379, 'w_1': 0.1417473118235728}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 122: F1=0.8978\n",
            "Trial 123: F1=0.8984\n",
            "Trial 126: F1=0.8978\n",
            "Trial 124: F1=0.8978\n",
            "Trial 125: F1=0.8982\n",
            "Trial 127: F1=0.8983\n",
            "Trial 128: F1=0.8983\n",
            "Trial 129: F1=0.8982\n",
            "Trial 130: F1=0.8981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:31,265] Trial 131 finished with value: 0.10198727637363558 and parameters: {'w_0': 0.7391912217165252, 'w_1': 0.13672119177955983}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,265] Trial 132 finished with value: 0.10191748656084909 and parameters: {'w_0': 0.736499825890568, 'w_1': 0.15034236567767217}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,279] Trial 133 finished with value: 0.10208091263001529 and parameters: {'w_0': 0.7385103098989287, 'w_1': 0.2436994704449035}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,324] Trial 134 finished with value: 0.1019211728321936 and parameters: {'w_0': 0.7758292306483853, 'w_1': 0.1677622061032892}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,359] Trial 135 finished with value: 0.10199242138698417 and parameters: {'w_0': 0.7832058656978385, 'w_1': 0.16477637125733807}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,382] Trial 136 finished with value: 0.1020056872024887 and parameters: {'w_0': 0.7687512121879249, 'w_1': 0.17295757013657548}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,391] Trial 137 finished with value: 0.10178344964693797 and parameters: {'w_0': 0.8101943595158394, 'w_1': 0.23136159471058557}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,433] Trial 138 finished with value: 0.10200707397768194 and parameters: {'w_0': 0.8200676331515718, 'w_1': 0.26265421256925037}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,454] Trial 139 finished with value: 0.10170802400774237 and parameters: {'w_0': 0.8281768208095497, 'w_1': 0.2380495253358468}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 132: F1=0.8981Trial 131: F1=0.8980\n",
            "\n",
            "Trial 133: F1=0.8979\n",
            "Trial 134: F1=0.8981\n",
            "Trial 135: F1=0.8980\n",
            "Trial 136: F1=0.8980\n",
            "Trial 137: F1=0.8982\n",
            "Trial 138: F1=0.8980\n",
            "Trial 139: F1=0.8983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:31,464] Trial 140 finished with value: 0.10186130275236482 and parameters: {'w_0': 0.8304970425097596, 'w_1': 0.2598235725662361}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,494] Trial 142 finished with value: 0.10192566886364784 and parameters: {'w_0': 0.871043042422722, 'w_1': 0.19325197118431894}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,504] Trial 141 finished with value: 0.10178732901439658 and parameters: {'w_0': 0.6710161146944594, 'w_1': 0.2009005623447585}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,531] Trial 143 finished with value: 0.10207670596579876 and parameters: {'w_0': 0.8441874698343383, 'w_1': 0.20092978694290162}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,577] Trial 145 finished with value: 0.10215515775313211 and parameters: {'w_0': 0.84448857519462, 'w_1': 0.2831299792564391}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,582] Trial 144 finished with value: 0.10162432709486313 and parameters: {'w_0': 0.8885916793383313, 'w_1': 0.2331294095622863}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,596] Trial 146 finished with value: 0.10499987168953528 and parameters: {'w_0': 0.8861941177925848, 'w_1': 0.566502633738965}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,631] Trial 147 finished with value: 0.10162432709486313 and parameters: {'w_0': 0.8832223483438166, 'w_1': 0.2331382041066183}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,645] Trial 148 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.8929289429704897, 'w_1': 0.2295403923941567}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 140: F1=0.8981\n",
            "Trial 142: F1=0.8981\n",
            "Trial 141: F1=0.8982\n",
            "Trial 143: F1=0.8979\n",
            "Trial 145: F1=0.8978\n",
            "Trial 144: F1=0.8984\n",
            "Trial 146: F1=0.8950\n",
            "Trial 147: F1=0.8984\n",
            "Trial 148: F1=0.8982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:31,688] Trial 149 finished with value: 0.10162432709486313 and parameters: {'w_0': 0.8962128807102188, 'w_1': 0.23528051725423}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,711] Trial 150 finished with value: 0.1018355542997722 and parameters: {'w_0': 0.9191333704194734, 'w_1': 0.18025851997812437}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,727] Trial 151 finished with value: 0.10249609894721845 and parameters: {'w_0': 0.9209444379966536, 'w_1': 0.11813925298602634}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,754] Trial 152 finished with value: 0.10249609894721845 and parameters: {'w_0': 0.9203307046025434, 'w_1': 0.11889085820523186}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,788] Trial 153 finished with value: 0.1020017132468819 and parameters: {'w_0': 0.8771258582756917, 'w_1': 0.20624894580330783}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,828] Trial 156 finished with value: 0.10162432709486313 and parameters: {'w_0': 0.8965600164249088, 'w_1': 0.2342790412672586}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,829] Trial 155 finished with value: 0.10199715141268761 and parameters: {'w_0': 0.8819835338640987, 'w_1': 0.21231405436604553}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,831] Trial 154 finished with value: 0.10171555961300671 and parameters: {'w_0': 0.8820438020571056, 'w_1': 0.24869472119799368}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 149: F1=0.8984\n",
            "Trial 150: F1=0.8982\n",
            "Trial 151: F1=0.8975\n",
            "Trial 152: F1=0.8975\n",
            "Trial 153: F1=0.8980\n",
            "Trial 156: F1=0.8984\n",
            "Trial 155: F1=0.8980\n",
            "Trial 154: F1=0.8983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:31,900] Trial 157 finished with value: 0.10178732901439658 and parameters: {'w_0': 0.9604991881789808, 'w_1': 0.29000629631535285}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,920] Trial 158 finished with value: 0.10200457319390088 and parameters: {'w_0': 0.9033457310526618, 'w_1': 0.2941991133175774}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,937] Trial 159 finished with value: 0.10177504095985745 and parameters: {'w_0': 0.9728271379642833, 'w_1': 0.260161405864072}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,978] Trial 160 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.9043566360925201, 'w_1': 0.23480137177450514}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:31,979] Trial 161 finished with value: 0.10186130275236482 and parameters: {'w_0': 0.8575657473393445, 'w_1': 0.26784211264786795}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,013] Trial 162 finished with value: 0.10163833064684868 and parameters: {'w_0': 0.8574364809088203, 'w_1': 0.2403642800769806}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,023] Trial 164 finished with value: 0.10191304893107667 and parameters: {'w_0': 0.9363371270674867, 'w_1': 0.18140372208925665}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,059] Trial 163 finished with value: 0.1019211728321936 and parameters: {'w_0': 0.852980306118333, 'w_1': 0.18310433961824787}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,086] Trial 166 finished with value: 0.10178294443533797 and parameters: {'w_0': 0.8505190080103457, 'w_1': 0.23251983125474054}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 157: F1=0.8982\n",
            "Trial 158: F1=0.8980\n",
            "Trial 159: F1=0.8982\n",
            "Trial 160: F1=0.8982\n",
            "Trial 161: F1=0.8981\n",
            "Trial 162: F1=0.8984\n",
            "Trial 164: F1=0.8981\n",
            "Trial 163: F1=0.8981\n",
            "Trial 166: F1=0.8982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:32,128] Trial 165 finished with value: 0.10200707397768194 and parameters: {'w_0': 0.7076952082944175, 'w_1': 0.22645162703496155}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,160] Trial 168 finished with value: 0.10417800796714305 and parameters: {'w_0': 0.8720492487695573, 'w_1': 0.46126407883040094}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,167] Trial 167 finished with value: 0.10301647544327419 and parameters: {'w_0': 0.7131899395076302, 'w_1': 0.3323953384726852}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,219] Trial 170 finished with value: 0.1016921630666856 and parameters: {'w_0': 0.8026513170228446, 'w_1': 0.1956550024414663}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,223] Trial 169 finished with value: 0.10221009877840037 and parameters: {'w_0': 0.8709374922782296, 'w_1': 0.1522626730172239}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,228] Trial 171 finished with value: 0.1018355542997722 and parameters: {'w_0': 0.8001761659783435, 'w_1': 0.15557084858319464}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,298] Trial 174 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.7639838930946883, 'w_1': 0.19846787082023287}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,302] Trial 173 finished with value: 0.10178294443533797 and parameters: {'w_0': 0.7533335131875706, 'w_1': 0.20679629495239965}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,314] Trial 172 finished with value: 0.10177248593513244 and parameters: {'w_0': 0.7540942722845815, 'w_1': 0.19576243522184758}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 165: F1=0.8980\n",
            "Trial 168: F1=0.8958\n",
            "Trial 167: F1=0.8970\n",
            "Trial 170: F1=0.8983\n",
            "Trial 169: F1=0.8978\n",
            "Trial 171: F1=0.8982\n",
            "Trial 174: F1=0.8982\n",
            "Trial 173: F1=0.8982\n",
            "Trial 172: F1=0.8982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:32,398] Trial 176 finished with value: 0.10178732901439658 and parameters: {'w_0': 0.8276802538859094, 'w_1': 0.2533035128907203}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,405] Trial 175 finished with value: 0.10536791402831969 and parameters: {'w_0': 0.38074328711312233, 'w_1': 0.25498507117685787}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,432] Trial 177 finished with value: 0.10533530991465678 and parameters: {'w_0': 0.832021699656512, 'w_1': 0.6917073139205311}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,484] Trial 178 finished with value: 0.11364038371625906 and parameters: {'w_0': 0.08560475972702442, 'w_1': 0.6840075205531253}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,490] Trial 179 finished with value: 0.10178344964693797 and parameters: {'w_0': 0.7851543485859386, 'w_1': 0.22358929483693774}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,498] Trial 180 finished with value: 0.10171172114712801 and parameters: {'w_0': 0.7895377262585264, 'w_1': 0.21980937574656878}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,540] Trial 181 finished with value: 0.10199242138698417 and parameters: {'w_0': 0.8126506708519914, 'w_1': 0.17203364016936537}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,587] Trial 182 finished with value: 0.10199242138698417 and parameters: {'w_0': 0.8152248441525272, 'w_1': 0.1722081816832745}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 176: F1=0.8982\n",
            "Trial 175: F1=0.8946\n",
            "Trial 177: F1=0.8947\n",
            "Trial 178: F1=0.8864\n",
            "Trial 179: F1=0.8982\n",
            "Trial 180: F1=0.8983\n",
            "Trial 181: F1=0.8980\n",
            "Trial 182: F1=0.8980\n",
            "Trial 183: F1=0.8980\n",
            "Trial 184: F1=0.8983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:32,591] Trial 183 finished with value: 0.10199242138698417 and parameters: {'w_0': 0.8132151116061901, 'w_1': 0.17002443582166415}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,597] Trial 184 finished with value: 0.10169751838374363 and parameters: {'w_0': 0.8964193792892842, 'w_1': 0.23865890951273688}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,652] Trial 186 finished with value: 0.10162432709486313 and parameters: {'w_0': 0.8988790995230864, 'w_1': 0.23844073065975513}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,674] Trial 187 finished with value: 0.10178294443533797 and parameters: {'w_0': 0.8969904046379792, 'w_1': 0.2448061804026167}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,679] Trial 185 finished with value: 0.10177504095985745 and parameters: {'w_0': 0.8989820278753315, 'w_1': 0.2418677630713122}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,734] Trial 188 finished with value: 0.10192488386769649 and parameters: {'w_0': 0.8419770791558137, 'w_1': 0.2746721039728535}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,760] Trial 189 finished with value: 0.10191748656084909 and parameters: {'w_0': 0.9384138795496918, 'w_1': 0.19104342028213117}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,795] Trial 190 finished with value: 0.10200707397768194 and parameters: {'w_0': 0.8605171001947103, 'w_1': 0.2730867677222527}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,831] Trial 191 finished with value: 0.1016921630666856 and parameters: {'w_0': 0.866563904753205, 'w_1': 0.21142037978852263}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 186: F1=0.8984\n",
            "Trial 187: F1=0.8982\n",
            "Trial 185: F1=0.8982\n",
            "Trial 188: F1=0.8981\n",
            "Trial 189: F1=0.8981\n",
            "Trial 190: F1=0.8980\n",
            "Trial 191: F1=0.8983\n",
            "Trial 192: F1=0.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:32,854] Trial 192 finished with value: 0.1020017132468819 and parameters: {'w_0': 0.8655386216399117, 'w_1': 0.20193585251989327}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,881] Trial 193 finished with value: 0.1020056872024887 and parameters: {'w_0': 0.911863365376408, 'w_1': 0.20979906624048755}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,922] Trial 194 finished with value: 0.1020017132468819 and parameters: {'w_0': 0.9139065913947738, 'w_1': 0.21127040497183883}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,970] Trial 196 finished with value: 0.10178294443533797 and parameters: {'w_0': 0.8444803252111064, 'w_1': 0.23199146488692615}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:32,986] Trial 195 finished with value: 0.10191598059503637 and parameters: {'w_0': 0.9164886662691779, 'w_1': 0.22249863705774311}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:33,014] Trial 197 finished with value: 0.10177504095985745 and parameters: {'w_0': 0.8430261482854394, 'w_1': 0.22509782644305842}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:33,060] Trial 199 finished with value: 0.10178294443533797 and parameters: {'w_0': 0.695392923655991, 'w_1': 0.18918248666599283}. Best is trial 46 with value: 0.10162432709486313.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 193: F1=0.8980\n",
            "Trial 194: F1=0.8980\n",
            "Trial 196: F1=0.8982\n",
            "Trial 195: F1=0.8981\n",
            "Trial 197: F1=0.8982\n",
            "Trial 199: F1=0.8982\n",
            "Trial 198: F1=0.8937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:33,067] Trial 198 finished with value: 0.10628001099309659 and parameters: {'w_0': 0.8823671384647268, 'w_1': 0.8608489664541564}. Best is trial 46 with value: 0.10162432709486313.\n",
            "[I 2025-06-16 10:30:33,174] A new study created in memory with name: no-name-7180a2f4-13a9-4c5e-8d35-d149299a0c42\n",
            "[I 2025-06-16 10:30:33,191] Trial 1 finished with value: 0.11031448634260932 and parameters: {'w_0': 0.07947724246558141, 'w_1': 0.1549378809431876, 'w_2': 0.751161424092223}. Best is trial 1 with value: 0.11031448634260932.\n",
            "[I 2025-06-16 10:30:33,228] Trial 0 finished with value: 0.10359368176747075 and parameters: {'w_0': 0.5041804458239965, 'w_1': 0.931201974171916, 'w_2': 0.9769461211361453}. Best is trial 0 with value: 0.10359368176747075.\n",
            "[I 2025-06-16 10:30:33,251] Trial 4 finished with value: 0.10496091424477016 and parameters: {'w_0': 0.23658052562629728, 'w_1': 0.7278939541468286, 'w_2': 0.8949108281212427}. Best is trial 0 with value: 0.10359368176747075.\n",
            "[I 2025-06-16 10:30:33,257] Trial 2 finished with value: 0.10186740954563545 and parameters: {'w_0': 0.9175098251380639, 'w_1': 0.06973168867396251, 'w_2': 0.3502853321319084}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,269] Trial 3 finished with value: 0.10754312595849225 and parameters: {'w_0': 0.32116390475804424, 'w_1': 0.6180978266739686, 'w_2': 0.28152965350431824}. Best is trial 2 with value: 0.10186740954563545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combo ['booster_texte_logits.pt', 'flaubert2_logits.pt'] - Best F1: 0.8984\n",
            "\n",
            "Test combo: ['booster_texte_logits.pt', 'camembert2_logits.pt', 'flaubert2_logits.pt']\n",
            "Trial 1: F1=0.8897\n",
            "Trial 0: F1=0.8964\n",
            "Trial 4: F1=0.8950\n",
            "Trial 2: F1=0.8981\n",
            "Trial 3: F1=0.8925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:33,279] Trial 6 finished with value: 0.10526624745486668 and parameters: {'w_0': 0.6291202165873566, 'w_1': 0.6977389342913954, 'w_2': 0.28034324759094686}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,289] Trial 8 finished with value: 0.10439345617893714 and parameters: {'w_0': 0.12374535571898326, 'w_1': 0.7744516478762162, 'w_2': 0.7347321409616567}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,298] Trial 5 finished with value: 0.10480941583959758 and parameters: {'w_0': 0.5682060202125612, 'w_1': 0.5821878682046983, 'w_2': 0.9701845042729317}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,313] Trial 7 finished with value: 0.10310410036874518 and parameters: {'w_0': 0.2566953955382959, 'w_1': 0.38628417033350415, 'w_2': 0.4505049391792121}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,327] Trial 11 finished with value: 0.10686879111649616 and parameters: {'w_0': 0.9058943015427497, 'w_1': 0.9381237736742087, 'w_2': 0.18024950896319525}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,334] Trial 9 finished with value: 0.10306789652952653 and parameters: {'w_0': 0.8779872278114265, 'w_1': 0.45811480865625576, 'w_2': 0.6548546611418165}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,341] Trial 10 finished with value: 0.10476801939869829 and parameters: {'w_0': 0.38932003614247557, 'w_1': 0.3102605662432828, 'w_2': 0.09226511212568345}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,407] Trial 12 finished with value: 0.1028672702087593 and parameters: {'w_0': 0.8654844545156053, 'w_1': 0.11900321977660244, 'w_2': 0.5222056023191832}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,429] Trial 13 finished with value: 0.10440014042498302 and parameters: {'w_0': 0.9891918518414825, 'w_1': 0.026518560845779318, 'w_2': 0.5452180765535828}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,436] Trial 14 finished with value: 0.10432628716895975 and parameters: {'w_0': 0.9951110409355072, 'w_1': 0.0041272621704433465, 'w_2': 0.5424426873714356}. Best is trial 2 with value: 0.10186740954563545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 6: F1=0.8947\n",
            "Trial 8: F1=0.8956\n",
            "Trial 5: F1=0.8952\n",
            "Trial 7: F1=0.8969\n",
            "Trial 11: F1=0.8931\n",
            "Trial 9: F1=0.8969\n",
            "Trial 10: F1=0.8952\n",
            "Trial 12: F1=0.8971\n",
            "Trial 13: F1=0.8956\n",
            "Trial 14: F1=0.8957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:33,489] Trial 16 finished with value: 0.1025443738703844 and parameters: {'w_0': 0.7498418305121842, 'w_1': 0.21868486321585162, 'w_2': 0.40390539435356354}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,497] Trial 15 finished with value: 0.10500132391367356 and parameters: {'w_0': 0.743037486486722, 'w_1': 0.0013154606562436055, 'w_2': 0.4821446577978277}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,546] Trial 17 finished with value: 0.10254203249194915 and parameters: {'w_0': 0.729777241451887, 'w_1': 0.2026098853951699, 'w_2': 0.39219898309184265}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,573] Trial 18 finished with value: 0.10267699948792941 and parameters: {'w_0': 0.7239358451853588, 'w_1': 0.23935869637358398, 'w_2': 0.3590785008697588}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,608] Trial 19 finished with value: 0.10268521136347697 and parameters: {'w_0': 0.7107141607165115, 'w_1': 0.26933307047714516, 'w_2': 0.3788534791663862}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,653] Trial 21 finished with value: 0.10407656424633094 and parameters: {'w_0': 0.6971153024155679, 'w_1': 0.31958751323753404, 'w_2': 0.030108595460745513}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,670] Trial 20 finished with value: 0.10418707816840733 and parameters: {'w_0': 0.7606653140245585, 'w_1': 0.29186066108599346, 'w_2': 0.0330728538670797}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,674] Trial 22 finished with value: 0.1041896731575006 and parameters: {'w_0': 0.81704882919188, 'w_1': 0.37257129830303526, 'w_2': 0.07880116057468445}. Best is trial 2 with value: 0.10186740954563545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 16: F1=0.8975\n",
            "Trial 15: F1=0.8950\n",
            "Trial 17: F1=0.8975\n",
            "Trial 18: F1=0.8973\n",
            "Trial 19: F1=0.8973\n",
            "Trial 21: F1=0.8959\n",
            "Trial 20: F1=0.8958\n",
            "Trial 22: F1=0.8958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:33,775] Trial 24 finished with value: 0.10234532902219429 and parameters: {'w_0': 0.6286470319688354, 'w_1': 0.1534172639759406, 'w_2': 0.21087407123087382}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,776] Trial 23 finished with value: 0.10275265678785328 and parameters: {'w_0': 0.444145781722257, 'w_1': 0.15570768006788627, 'w_2': 0.23404460999343102}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,826] Trial 25 finished with value: 0.10258202295524399 and parameters: {'w_0': 0.6083245484021553, 'w_1': 0.1572754885727342, 'w_2': 0.1935089089389339}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,854] Trial 27 finished with value: 0.10234569726032416 and parameters: {'w_0': 0.6211091512863757, 'w_1': 0.09891326296294498, 'w_2': 0.1673624361779955}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,906] Trial 26 finished with value: 0.10268217204547447 and parameters: {'w_0': 0.6265552256275501, 'w_1': 0.15997972737471133, 'w_2': 0.15724278728531482}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,946] Trial 28 finished with value: 0.1030115045968889 and parameters: {'w_0': 0.5402027827033675, 'w_1': 0.07645867576512089, 'w_2': 0.3007229865241722}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:33,959] Trial 29 finished with value: 0.10235080808597186 and parameters: {'w_0': 0.5433365996078463, 'w_1': 0.0868562486622218, 'w_2': 0.13964129700701827}. Best is trial 2 with value: 0.10186740954563545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 24: F1=0.8977\n",
            "Trial 23: F1=0.8972\n",
            "Trial 25: F1=0.8974\n",
            "Trial 27: F1=0.8977\n",
            "Trial 26: F1=0.8973\n",
            "Trial 28: F1=0.8970\n",
            "Trial 29: F1=0.8976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:34,004] Trial 30 finished with value: 0.10308352425553202 and parameters: {'w_0': 0.5394196240448524, 'w_1': 0.0795410678194335, 'w_2': 0.30549804521600604}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,037] Trial 31 finished with value: 0.1022779561643894 and parameters: {'w_0': 0.4374020627967278, 'w_1': 0.08757247707489217, 'w_2': 0.13798842674118417}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,069] Trial 32 finished with value: 0.10467578059573457 and parameters: {'w_0': 0.4567410196007238, 'w_1': 0.47414177881940534, 'w_2': 0.32297757565757257}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,102] Trial 33 finished with value: 0.10251325279501666 and parameters: {'w_0': 0.45274094925974306, 'w_1': 0.08228808651857906, 'w_2': 0.10283980924101971}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,128] Trial 34 finished with value: 0.10218596668718849 and parameters: {'w_0': 0.46795603603807423, 'w_1': 0.0650023197471129, 'w_2': 0.2241010792268415}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,172] Trial 35 finished with value: 0.1022681735560711 and parameters: {'w_0': 0.4583044805920822, 'w_1': 0.07220213327158642, 'w_2': 0.22764917988929997}. Best is trial 2 with value: 0.10186740954563545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30: F1=0.8969\n",
            "Trial 31: F1=0.8977\n",
            "Trial 32: F1=0.8953\n",
            "Trial 33: F1=0.8975\n",
            "Trial 34: F1=0.8978\n",
            "Trial 35: F1=0.8977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:34,214] Trial 37 finished with value: 0.10277181122244095 and parameters: {'w_0': 0.35389723805685047, 'w_1': 0.18722162165300074, 'w_2': 0.23189776672001233}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,214] Trial 36 finished with value: 0.11071140781338151 and parameters: {'w_0': 0.3824461045371663, 'w_1': 0.8442208900222916, 'w_2': 0.24305725030771058}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,238] Trial 38 finished with value: 0.10416878708048094 and parameters: {'w_0': 0.3485935986402725, 'w_1': 0.029536245404660905, 'w_2': 0.21129932218073047}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,302] Trial 40 finished with value: 0.10503334156859734 and parameters: {'w_0': 0.2691560805345313, 'w_1': 0.41282553761032115, 'w_2': 0.6374724289357373}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,309] Trial 41 finished with value: 0.10863490545742238 and parameters: {'w_0': 0.19163877378583982, 'w_1': 0.5838350652779323, 'w_2': 0.2820809116281217}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,361] Trial 39 finished with value: 0.1081688627439551 and parameters: {'w_0': 0.2566292563757919, 'w_1': 0.03707516623983971, 'w_2': 0.4428254488395842}. Best is trial 2 with value: 0.10186740954563545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 37: F1=0.8972\n",
            "Trial 36: F1=0.8893\n",
            "Trial 38: F1=0.8958\n",
            "Trial 40: F1=0.8950\n",
            "Trial 41: F1=0.8914\n",
            "Trial 39: F1=0.8918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:34,421] Trial 42 finished with value: 0.10631859533472265 and parameters: {'w_0': 0.3021065209364935, 'w_1': 0.12241056728024152, 'w_2': 0.43291528678418534}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,430] Trial 43 finished with value: 0.10274660513342859 and parameters: {'w_0': 0.49718131021841455, 'w_1': 0.12255943642403215, 'w_2': 0.10788918242211454}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,481] Trial 44 finished with value: 0.10266979134079002 and parameters: {'w_0': 0.4937279960687659, 'w_1': 0.1274951772952489, 'w_2': 0.10103694756883672}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,503] Trial 45 finished with value: 0.10410650988045855 and parameters: {'w_0': 0.503543400189591, 'w_1': 0.2409659699375545, 'w_2': 0.12935188193386282}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,525] Trial 46 finished with value: 0.10694063154237787 and parameters: {'w_0': 0.41942607149142785, 'w_1': 0.24415775613631177, 'w_2': 0.8616877966737361}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,571] Trial 49 finished with value: 0.10195193626313237 and parameters: {'w_0': 0.9414749523796263, 'w_1': 0.04359338799977967, 'w_2': 0.33092715070699324}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,578] Trial 47 finished with value: 0.10394902673322015 and parameters: {'w_0': 0.41034761563556116, 'w_1': 0.049485463617981826, 'w_2': 0.25877014416064725}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,598] Trial 48 finished with value: 0.1070295924833069 and parameters: {'w_0': 0.40611112420318696, 'w_1': 0.6641596527030244, 'w_2': 0.25848084442643054}. Best is trial 2 with value: 0.10186740954563545.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 42: F1=0.8937\n",
            "Trial 43: F1=0.8973\n",
            "Trial 44: F1=0.8973\n",
            "Trial 45: F1=0.8959\n",
            "Trial 46: F1=0.8931\n",
            "Trial 49: F1=0.8980\n",
            "Trial 47: F1=0.8961\n",
            "Trial 48: F1=0.8930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:34,665] Trial 50 finished with value: 0.11248092962511225 and parameters: {'w_0': 0.00015843975307494595, 'w_1': 0.6566687690785451, 'w_2': 0.32531037004885266}. Best is trial 2 with value: 0.10186740954563545.\n",
            "[I 2025-06-16 10:30:34,689] Trial 52 finished with value: 0.10186230078553604 and parameters: {'w_0': 0.9395476358406052, 'w_1': 0.05851658615366319, 'w_2': 0.35635521094995914}. Best is trial 52 with value: 0.10186230078553604.\n",
            "[I 2025-06-16 10:30:34,692] Trial 51 finished with value: 0.11510400195358994 and parameters: {'w_0': 0.0030868205209887423, 'w_1': 0.0034853537975284704, 'w_2': 0.34337849026200834}. Best is trial 52 with value: 0.10186230078553604.\n",
            "[I 2025-06-16 10:30:34,742] Trial 53 finished with value: 0.1017196649140667 and parameters: {'w_0': 0.9703689049722536, 'w_1': 0.05875403369825283, 'w_2': 0.3440636195021457}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:34,787] Trial 54 finished with value: 0.1027816359344863 and parameters: {'w_0': 0.966004038802301, 'w_1': 0.05364873137680644, 'w_2': 0.49236523496271195}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:34,792] Trial 55 finished with value: 0.10285861713804212 and parameters: {'w_0': 0.9324879879475678, 'w_1': 0.04756888458838296, 'w_2': 0.4747950560458718}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:34,833] Trial 56 finished with value: 0.10340626046114176 and parameters: {'w_0': 0.9444664255471518, 'w_1': 0.05074119601056189, 'w_2': 0.509276123200354}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 50: F1=0.8875\n",
            "Trial 52: F1=0.8981\n",
            "Trial 51: F1=0.8849\n",
            "Trial 53: F1=0.8983\n",
            "Trial 54: F1=0.8972\n",
            "Trial 55: F1=0.8971\n",
            "Trial 56: F1=0.8966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:34,887] Trial 57 finished with value: 0.10239939454066993 and parameters: {'w_0': 0.8239729740922521, 'w_1': 0.18617501216583168, 'w_2': 0.4199736915761039}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:34,894] Trial 58 finished with value: 0.10394952874572083 and parameters: {'w_0': 0.8608509620891257, 'w_1': 0.5308510431905525, 'w_2': 0.3547939723586643}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:34,928] Trial 59 finished with value: 0.10294264979761436 and parameters: {'w_0': 0.8456103642357735, 'w_1': 0.18339720983894459, 'w_2': 0.5833435716511586}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:34,959] Trial 60 finished with value: 0.10555925816678469 and parameters: {'w_0': 0.8811781865417085, 'w_1': 0.985651621306426, 'w_2': 0.35879717957891877}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:34,981] Trial 62 finished with value: 0.10292739906941717 and parameters: {'w_0': 0.9010780697270024, 'w_1': 0.34191473613115364, 'w_2': 0.37790607981056346}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:34,991] Trial 61 finished with value: 0.10528628027848574 and parameters: {'w_0': 0.9030651552621164, 'w_1': 0.002914252250040772, 'w_2': 0.6216153834268701}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,036] Trial 63 finished with value: 0.10240045143869758 and parameters: {'w_0': 0.9168498831462067, 'w_1': 0.0019675699863111185, 'w_2': 0.387672403857035}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 57: F1=0.8976\n",
            "Trial 58: F1=0.8961\n",
            "Trial 59: F1=0.8971\n",
            "Trial 60: F1=0.8944\n",
            "Trial 62: F1=0.8971\n",
            "Trial 61: F1=0.8947\n",
            "Trial 63: F1=0.8976\n",
            "Trial 65: F1=0.8979\n",
            "Trial 64: F1=0.8974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:35,065] Trial 65 finished with value: 0.10212478740594477 and parameters: {'w_0': 0.9760754206594675, 'w_1': 0.1073355308682839, 'w_2': 0.2812038840541031}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,070] Trial 64 finished with value: 0.10264934301102902 and parameters: {'w_0': 0.9947605494527947, 'w_1': 0.10880044602340454, 'w_2': 0.06320036115907429}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,147] Trial 67 finished with value: 0.10221294176061657 and parameters: {'w_0': 0.7830753080393671, 'w_1': 0.1401057422339303, 'w_2': 0.2852878751519309}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,155] Trial 66 finished with value: 0.1023643501242959 and parameters: {'w_0': 0.9664023370580479, 'w_1': 0.13355217016524945, 'w_2': 0.292851451806127}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,207] Trial 68 finished with value: 0.1022878475996376 and parameters: {'w_0': 0.7785098583663526, 'w_1': 0.14049364138627748, 'w_2': 0.2883211045945138}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,260] Trial 70 finished with value: 0.10267607447184035 and parameters: {'w_0': 0.9660169753102914, 'w_1': 0.21525997354659582, 'w_2': 0.19060788457084799}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,279] Trial 69 finished with value: 0.10229688881492038 and parameters: {'w_0': 0.7915734693779186, 'w_1': 0.14378025863069482, 'w_2': 0.31596527281075604}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,324] Trial 71 finished with value: 0.10252016450326107 and parameters: {'w_0': 0.6783013519540788, 'w_1': 0.2212551466619242, 'w_2': 0.3287955043402776}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,344] Trial 73 finished with value: 0.1021492748813786 and parameters: {'w_0': 0.6661870945837769, 'w_1': 0.08028992157669698, 'w_2': 0.20826683518016262}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 67: F1=0.8978\n",
            "Trial 66: F1=0.8976\n",
            "Trial 68: F1=0.8977\n",
            "Trial 70: F1=0.8973\n",
            "Trial 69: F1=0.8977\n",
            "Trial 71: F1=0.8975\n",
            "Trial 73: F1=0.8979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:35,366] Trial 72 finished with value: 0.10520479744416078 and parameters: {'w_0': 0.8098524397748472, 'w_1': 0.7710649499278204, 'w_2': 0.411495051357869}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,442] Trial 74 finished with value: 0.10222653159666972 and parameters: {'w_0': 0.8337262638892909, 'w_1': 0.07519301072760261, 'w_2': 0.26689505925276197}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,445] Trial 75 finished with value: 0.10223540334369752 and parameters: {'w_0': 0.6644744412516265, 'w_1': 0.09963259304670094, 'w_2': 0.2626074699435071}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,475] Trial 76 finished with value: 0.10218773554213978 and parameters: {'w_0': 0.9467418125816904, 'w_1': 0.09545029409831023, 'w_2': 0.26103468679119746}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,517] Trial 78 finished with value: 0.10190897141752697 and parameters: {'w_0': 0.8797414054177938, 'w_1': 0.03344398290094651, 'w_2': 0.2052451300397256}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,524] Trial 77 finished with value: 0.10190897141752697 and parameters: {'w_0': 0.8855502934638919, 'w_1': 0.032270984037617155, 'w_2': 0.2066201530530804}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 72: F1=0.8948\n",
            "Trial 74: F1=0.8978\n",
            "Trial 75: F1=0.8978\n",
            "Trial 76: F1=0.8978\n",
            "Trial 78: F1=0.8981\n",
            "Trial 77: F1=0.8981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:35,588] Trial 79 finished with value: 0.10190897141752697 and parameters: {'w_0': 0.9443808799684111, 'w_1': 0.027571211384054318, 'w_2': 0.21300213609794516}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,602] Trial 80 finished with value: 0.10212804543857046 and parameters: {'w_0': 0.8822865618141127, 'w_1': 0.022745550124865795, 'w_2': 0.17078976514204985}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,609] Trial 81 finished with value: 0.10220171092927832 and parameters: {'w_0': 0.9267938209750759, 'w_1': 0.012878331292359275, 'w_2': 0.17163637943136992}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,656] Trial 82 finished with value: 0.10278722071005353 and parameters: {'w_0': 0.9983378988046636, 'w_1': 0.028756317307193448, 'w_2': 0.46104843977645654}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,687] Trial 84 finished with value: 0.10213017034047245 and parameters: {'w_0': 0.8830005340494144, 'w_1': 0.030532401243189983, 'w_2': 0.18424188361500635}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,727] Trial 83 finished with value: 0.10234220364306001 and parameters: {'w_0': 0.8921987345037843, 'w_1': 0.03416424474532751, 'w_2': 0.16266514514808023}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,755] Trial 85 finished with value: 0.10234398008940948 and parameters: {'w_0': 0.8861132137190685, 'w_1': 0.030402216995552494, 'w_2': 0.14508874113581494}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,765] Trial 86 finished with value: 0.1021067228556628 and parameters: {'w_0': 0.8521776265531237, 'w_1': 0.05361944843912893, 'w_2': 0.15404660146447502}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 79: F1=0.8981\n",
            "Trial 80: F1=0.8979\n",
            "Trial 81: F1=0.8978\n",
            "Trial 82: F1=0.8972\n",
            "Trial 84: F1=0.8979\n",
            "Trial 83: F1=0.8977\n",
            "Trial 85: F1=0.8977\n",
            "Trial 86: F1=0.8979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:35,841] Trial 87 finished with value: 0.1024282085934155 and parameters: {'w_0': 0.8563693161871003, 'w_1': 0.06265553956408007, 'w_2': 0.06733429815847514}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,882] Trial 89 finished with value: 0.10227097498135074 and parameters: {'w_0': 0.8518560900676143, 'w_1': 0.17056756094054923, 'w_2': 0.24286392535257212}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,890] Trial 88 finished with value: 0.10190990508930642 and parameters: {'w_0': 0.9636707985223962, 'w_1': 0.06237462438498641, 'w_2': 0.2416566883414407}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,945] Trial 90 finished with value: 0.10227758594385084 and parameters: {'w_0': 0.9709866831177363, 'w_1': 0.11789138541134059, 'w_2': 0.23626866782838787}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,971] Trial 92 finished with value: 0.10235265071537025 and parameters: {'w_0': 0.9352699288470061, 'w_1': 0.06352153856507606, 'w_2': 0.2083345099786044}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:35,963] Trial 91 finished with value: 0.10265244114036454 and parameters: {'w_0': 0.9481846902475447, 'w_1': 0.05681817679773003, 'w_2': 0.007777380571181963}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 87: F1=0.8976\n",
            "Trial 89: F1=0.8977\n",
            "Trial 88: F1=0.8981\n",
            "Trial 90: F1=0.8977\n",
            "Trial 91: F1=0.8973\n",
            "Trial 92: F1=0.8976\n",
            "Trial 95: F1=0.8981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:36,040] Trial 95 finished with value: 0.1018535911183236 and parameters: {'w_0': 0.9763318232149861, 'w_1': 0.09897323159273828, 'w_2': 0.34285604477610443}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,073] Trial 93 finished with value: 0.10227134149128236 and parameters: {'w_0': 0.9243494234378189, 'w_1': 0.10294211249223452, 'w_2': 0.20921072864509035}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,088] Trial 94 finished with value: 0.10201022664729276 and parameters: {'w_0': 0.915596955960604, 'w_1': 0.10494336699752653, 'w_2': 0.34197602993101445}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,126] Trial 97 finished with value: 0.1018523128118819 and parameters: {'w_0': 0.9493556144903351, 'w_1': 0.047460610285858316, 'w_2': 0.3475099010409601}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,161] Trial 98 finished with value: 0.10269452623473918 and parameters: {'w_0': 0.9053868879877378, 'w_1': 0.16387333395561549, 'w_2': 0.37190924030851386}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,165] Trial 96 finished with value: 0.10230147811050305 and parameters: {'w_0': 0.9139302462744733, 'w_1': 0.09896741350969895, 'w_2': 0.3093180971302885}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,227] Trial 99 finished with value: 0.10236718727337113 and parameters: {'w_0': 0.9996839199504525, 'w_1': 0.01688805394166245, 'w_2': 0.38098257713181843}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,254] Trial 100 finished with value: 0.10286336212132341 and parameters: {'w_0': 0.9517223707758415, 'w_1': 0.02171733325677476, 'w_2': 0.437553267510693}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 93: F1=0.8977\n",
            "Trial 94: F1=0.8980\n",
            "Trial 97: F1=0.8981\n",
            "Trial 98: F1=0.8973\n",
            "Trial 96: F1=0.8977\n",
            "Trial 99: F1=0.8976\n",
            "Trial 100: F1=0.8971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:36,289] Trial 101 finished with value: 0.10225085521987531 and parameters: {'w_0': 0.9527282217838479, 'w_1': 0.081003649279785, 'w_2': 0.41217372871128566}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,321] Trial 102 finished with value: 0.10232028191473308 and parameters: {'w_0': 0.9549208052344658, 'w_1': 0.0761130547426927, 'w_2': 0.409035161692371}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,347] Trial 103 finished with value: 0.1020124742922488 and parameters: {'w_0': 0.982176743048067, 'w_1': 0.08022776220644821, 'w_2': 0.3367034069075144}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,390] Trial 104 finished with value: 0.10186967730021013 and parameters: {'w_0': 0.9799701654461623, 'w_1': 0.04615807131212934, 'w_2': 0.3490272424108412}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,426] Trial 105 finished with value: 0.1018613491134368 and parameters: {'w_0': 0.9733770496671414, 'w_1': 0.04183533014631846, 'w_2': 0.34259003383277}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,458] Trial 106 finished with value: 0.10184987803268553 and parameters: {'w_0': 0.9228854402875076, 'w_1': 0.04836403658272549, 'w_2': 0.34677708406873414}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,482] Trial 107 finished with value: 0.10230467427330503 and parameters: {'w_0': 0.9797901165055463, 'w_1': 0.001057086312707442, 'w_2': 0.3635915383568122}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 101: F1=0.8977\n",
            "Trial 102: F1=0.8977\n",
            "Trial 103: F1=0.8980\n",
            "Trial 104: F1=0.8981\n",
            "Trial 105: F1=0.8981\n",
            "Trial 106: F1=0.8982\n",
            "Trial 107: F1=0.8977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:36,522] Trial 108 finished with value: 0.1018523128118819 and parameters: {'w_0': 0.9837346791149005, 'w_1': 0.043432699848216724, 'w_2': 0.35278457532832525}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,542] Trial 109 finished with value: 0.10187236436469216 and parameters: {'w_0': 0.874054138516893, 'w_1': 0.04226854363524949, 'w_2': 0.3037352057297825}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,552] Trial 110 finished with value: 0.10276962094109421 and parameters: {'w_0': 0.9282831697090342, 'w_1': 0.04543162875863774, 'w_2': 0.3916709775002444}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,599] Trial 111 finished with value: 0.10276285424437248 and parameters: {'w_0': 0.868530780900003, 'w_1': 0.12243876657045429, 'w_2': 0.45814666829874306}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,634] Trial 113 finished with value: 0.10230147811050305 and parameters: {'w_0': 0.982209955695022, 'w_1': 0.12048280504003425, 'w_2': 0.3502572955616791}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,645] Trial 112 finished with value: 0.10228661397908123 and parameters: {'w_0': 0.9879364836499208, 'w_1': 0.12595816355824263, 'w_2': 0.30555924960217207}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,674] Trial 114 finished with value: 0.1018652778537299 and parameters: {'w_0': 0.985115794173289, 'w_1': 0.04435947627934454, 'w_2': 0.31677087441195834}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 108: F1=0.8981\n",
            "Trial 109: F1=0.8981\n",
            "Trial 110: F1=0.8972\n",
            "Trial 111: F1=0.8972\n",
            "Trial 113: F1=0.8977\n",
            "Trial 112: F1=0.8977\n",
            "Trial 114: F1=0.8981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:36,744] Trial 115 finished with value: 0.1018523128118819 and parameters: {'w_0': 0.8935504347151226, 'w_1': 0.04185881546976508, 'w_2': 0.32584857383402355}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,756] Trial 116 finished with value: 0.10187635853150001 and parameters: {'w_0': 0.9020520504241557, 'w_1': 0.046167866202458566, 'w_2': 0.31867698060197996}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,765] Trial 117 finished with value: 0.10187635853150001 and parameters: {'w_0': 0.9160571544070868, 'w_1': 0.045548059599491465, 'w_2': 0.32021965323209495}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,835] Trial 118 finished with value: 0.10210485350398124 and parameters: {'w_0': 0.9320657405625783, 'w_1': 0.08700031302815218, 'w_2': 0.39480875122018827}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,837] Trial 119 finished with value: 0.10292088418530787 and parameters: {'w_0': 0.968363904354541, 'w_1': 0.4172680097173913, 'w_2': 0.36114843452588813}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,879] Trial 120 finished with value: 0.10230099543871896 and parameters: {'w_0': 0.9996551548937307, 'w_1': 0.00017222606719645428, 'w_2': 0.3653956922659276}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,924] Trial 122 finished with value: 0.1026390878990785 and parameters: {'w_0': 0.9998469612057557, 'w_1': 0.0023565962989414713, 'w_2': 0.4286635289773366}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,926] Trial 121 finished with value: 0.10178285929008701 and parameters: {'w_0': 0.9961661733932562, 'w_1': 0.005077442700864958, 'w_2': 0.3023846677154943}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 115: F1=0.8981\n",
            "Trial 116: F1=0.8981\n",
            "Trial 117: F1=0.8981\n",
            "Trial 118: F1=0.8979\n",
            "Trial 119: F1=0.8971\n",
            "Trial 120: F1=0.8977\n",
            "Trial 122: F1=0.8974\n",
            "Trial 121: F1=0.8982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:36,963] Trial 123 finished with value: 0.10186740954563545 and parameters: {'w_0': 0.9104692326567883, 'w_1': 0.05715170796833023, 'w_2': 0.3328303222510808}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:36,991] Trial 124 finished with value: 0.10185701166141559 and parameters: {'w_0': 0.9625086663876693, 'w_1': 0.0684901532321769, 'w_2': 0.3037628043325279}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,026] Trial 126 finished with value: 0.1018650905048244 and parameters: {'w_0': 0.9643155290881944, 'w_1': 0.06626476313485698, 'w_2': 0.3424786359483864}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,030] Trial 125 finished with value: 0.10222526184854075 and parameters: {'w_0': 0.967201091312046, 'w_1': 0.06956418987752654, 'w_2': 0.29000023424377375}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,046] Trial 127 finished with value: 0.10215528304187904 and parameters: {'w_0': 0.9532674787889246, 'w_1': 0.06471570802376746, 'w_2': 0.2839098353327983}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,098] Trial 128 finished with value: 0.10224293263813045 and parameters: {'w_0': 0.9324963335208735, 'w_1': 0.14562586481382847, 'w_2': 0.3841904657543949}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,137] Trial 130 finished with value: 0.10523894932134326 and parameters: {'w_0': 0.9266069080315283, 'w_1': 0.14597121407576336, 'w_2': 0.7909897622553533}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 123: F1=0.8981\n",
            "Trial 124: F1=0.8981\n",
            "Trial 126: F1=0.8981\n",
            "Trial 125: F1=0.8978\n",
            "Trial 127: F1=0.8978\n",
            "Trial 128: F1=0.8978\n",
            "Trial 130: F1=0.8948\n",
            "Trial 129: F1=0.8942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:37,155] Trial 129 finished with value: 0.10577223855145068 and parameters: {'w_0': 0.9337379774709257, 'w_1': 0.08815193133122094, 'w_2': 0.954593973117562}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,197] Trial 131 finished with value: 0.10197663011177671 and parameters: {'w_0': 0.952534480547114, 'w_1': 0.09301358652408409, 'w_2': 0.27078454833059235}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,214] Trial 132 finished with value: 0.10215160005746426 and parameters: {'w_0': 0.9607158458916645, 'w_1': 0.014765531132588793, 'w_2': 0.3357311700102578}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,227] Trial 133 finished with value: 0.1121687269159678 and parameters: {'w_0': 0.17738115143793332, 'w_1': 0.8539597608087722, 'w_2': 0.32925211270482674}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,279] Trial 134 finished with value: 0.10186740954563545 and parameters: {'w_0': 0.9068754290535327, 'w_1': 0.06327102378868332, 'w_2': 0.34121525721915325}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,302] Trial 136 finished with value: 0.10185471104719013 and parameters: {'w_0': 0.9070191052162146, 'w_1': 0.07037507725613815, 'w_2': 0.30197385522462317}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,337] Trial 135 finished with value: 0.10208997215387905 and parameters: {'w_0': 0.9008732426059313, 'w_1': 0.06449450002341733, 'w_2': 0.3069221473825112}. Best is trial 53 with value: 0.1017196649140667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 131: F1=0.8980\n",
            "Trial 132: F1=0.8978\n",
            "Trial 133: F1=0.8878\n",
            "Trial 134: F1=0.8981\n",
            "Trial 136: F1=0.8981\n",
            "Trial 135: F1=0.8979\n",
            "Trial 138: F1=0.8983\n",
            "Trial 137: F1=0.8984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:37,390] Trial 138 finished with value: 0.10172223752994558 and parameters: {'w_0': 0.9798412399543803, 'w_1': 0.0250815555734364, 'w_2': 0.3043838402767445}. Best is trial 53 with value: 0.1017196649140667.\n",
            "[I 2025-06-16 10:30:37,394] Trial 137 finished with value: 0.10156011592079184 and parameters: {'w_0': 0.9779327592303688, 'w_1': 0.02240673525900959, 'w_2': 0.2990432494502124}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,407] Trial 139 finished with value: 0.10363313133050556 and parameters: {'w_0': 0.9746471200473806, 'w_1': 0.5343129058773526, 'w_2': 0.36597587677478877}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,470] Trial 141 finished with value: 0.10170603723605698 and parameters: {'w_0': 0.9465229545389744, 'w_1': 0.021508484578875296, 'w_2': 0.25690133568860296}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,488] Trial 140 finished with value: 0.10247217765088978 and parameters: {'w_0': 0.5967670551136517, 'w_1': 0.020632294572297982, 'w_2': 0.2642115118365846}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,530] Trial 142 finished with value: 0.10170603723605698 and parameters: {'w_0': 0.9556536727026562, 'w_1': 0.021229121781332613, 'w_2': 0.2601118439668285}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,544] Trial 143 finished with value: 0.10180274046856941 and parameters: {'w_0': 0.9432572734561633, 'w_1': 0.022043920565731803, 'w_2': 0.29381921644018133}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,592] Trial 144 finished with value: 0.10187815462304728 and parameters: {'w_0': 0.951778289624313, 'w_1': 0.01895889669501328, 'w_2': 0.29210582444532623}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,603] Trial 145 finished with value: 0.1020082616791691 and parameters: {'w_0': 0.937631589165697, 'w_1': 0.02120865615993473, 'w_2': 0.24798597163651295}. Best is trial 137 with value: 0.10156011592079184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 139: F1=0.8964\n",
            "Trial 141: F1=0.8983\n",
            "Trial 140: F1=0.8975\n",
            "Trial 142: F1=0.8983\n",
            "Trial 143: F1=0.8982\n",
            "Trial 144: F1=0.8981\n",
            "Trial 145: F1=0.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:37,644] Trial 146 finished with value: 0.10170603723605698 and parameters: {'w_0': 0.943430897203357, 'w_1': 0.021952762284478556, 'w_2': 0.25519230427993217}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,694] Trial 148 finished with value: 0.1017809837498902 and parameters: {'w_0': 0.9802377889119032, 'w_1': 0.033692949089007315, 'w_2': 0.28803195278289684}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,709] Trial 147 finished with value: 0.1020082616791691 and parameters: {'w_0': 0.9819266934417307, 'w_1': 0.025785466271563157, 'w_2': 0.2620692864203181}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,728] Trial 149 finished with value: 0.10163833064684868 and parameters: {'w_0': 0.996285162667376, 'w_1': 0.0003747936254030731, 'w_2': 0.27875009115844024}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,768] Trial 150 finished with value: 0.10177705599936704 and parameters: {'w_0': 0.9965700639306344, 'w_1': 0.016583327655259626, 'w_2': 0.27242288401786185}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,778] Trial 151 finished with value: 0.10171172114712801 and parameters: {'w_0': 0.9963923200254234, 'w_1': 0.003676509475993177, 'w_2': 0.28054552516606585}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,811] Trial 152 finished with value: 0.1020056872024887 and parameters: {'w_0': 0.9926273946901331, 'w_1': 0.001230075074306944, 'w_2': 0.22959634502649787}. Best is trial 137 with value: 0.10156011592079184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 146: F1=0.8983\n",
            "Trial 148: F1=0.8982\n",
            "Trial 147: F1=0.8980\n",
            "Trial 149: F1=0.8984\n",
            "Trial 150: F1=0.8982\n",
            "Trial 151: F1=0.8983\n",
            "Trial 152: F1=0.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:37,878] Trial 153 finished with value: 0.1020056872024887 and parameters: {'w_0': 0.9954657497702997, 'w_1': 0.004732669764567668, 'w_2': 0.23123933649196282}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,880] Trial 154 finished with value: 0.1020056872024887 and parameters: {'w_0': 0.9992501026544527, 'w_1': 0.0013982998621761555, 'w_2': 0.23256893740248014}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,887] Trial 155 finished with value: 0.1016288509540142 and parameters: {'w_0': 0.9979099509727041, 'w_1': 0.016077794504626895, 'w_2': 0.27949090837704493}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,939] Trial 156 finished with value: 0.10170449428168071 and parameters: {'w_0': 0.9542901726651812, 'w_1': 0.024055911218182666, 'w_2': 0.2770339764866181}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:37,988] Trial 158 finished with value: 0.10170207926581254 and parameters: {'w_0': 0.9522025210356598, 'w_1': 0.021575919922619577, 'w_2': 0.27728335138505833}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,010] Trial 157 finished with value: 0.10170207926581254 and parameters: {'w_0': 0.9430028213204957, 'w_1': 0.023851135099763915, 'w_2': 0.277524236507195}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,021] Trial 159 finished with value: 0.10170207926581254 and parameters: {'w_0': 0.9396096567803387, 'w_1': 0.02220870692712571, 'w_2': 0.2748520042566753}. Best is trial 137 with value: 0.10156011592079184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 153: F1=0.8980\n",
            "Trial 154: F1=0.8980\n",
            "Trial 155: F1=0.8984\n",
            "Trial 156: F1=0.8983\n",
            "Trial 158: F1=0.8983\n",
            "Trial 157: F1=0.8983\n",
            "Trial 159: F1=0.8983\n",
            "Trial 160: F1=0.8982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:38,076] Trial 160 finished with value: 0.1017809837498902 and parameters: {'w_0': 0.9455473058715939, 'w_1': 0.028343502545652162, 'w_2': 0.27604656562788554}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,115] Trial 161 finished with value: 0.1017809837498902 and parameters: {'w_0': 0.9648479122982605, 'w_1': 0.020928007442121855, 'w_2': 0.272450854525403}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,119] Trial 162 finished with value: 0.1017809837498902 and parameters: {'w_0': 0.9678705702813618, 'w_1': 0.02191595443088013, 'w_2': 0.27522310218899027}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,143] Trial 163 finished with value: 0.10170636197830374 and parameters: {'w_0': 0.9673980930330955, 'w_1': 0.019611858936906482, 'w_2': 0.2785144471272834}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,192] Trial 164 finished with value: 0.10178585884079605 and parameters: {'w_0': 0.9451858367323458, 'w_1': 0.02626730480511276, 'w_2': 0.25632174166905214}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,222] Trial 165 finished with value: 0.10200599738203386 and parameters: {'w_0': 0.9446110413637069, 'w_1': 0.029614820709194252, 'w_2': 0.25205161322002057}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,257] Trial 166 finished with value: 0.10200599738203386 and parameters: {'w_0': 0.9401927875183803, 'w_1': 0.03129683346696947, 'w_2': 0.24808735632386647}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,275] Trial 167 finished with value: 0.10178285929008701 and parameters: {'w_0': 0.9258748559416787, 'w_1': 0.0005978986751187312, 'w_2': 0.2773128532148829}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,310] Trial 168 finished with value: 0.10178732901439658 and parameters: {'w_0': 0.9210240735887323, 'w_1': 0.0005782628243790784, 'w_2': 0.276846938038572}. Best is trial 137 with value: 0.10156011592079184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 161: F1=0.8982\n",
            "Trial 162: F1=0.8982\n",
            "Trial 163: F1=0.8983\n",
            "Trial 164: F1=0.8982\n",
            "Trial 165: F1=0.8980\n",
            "Trial 166: F1=0.8980\n",
            "Trial 167: F1=0.8982\n",
            "Trial 168: F1=0.8982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:38,360] Trial 169 finished with value: 0.1018355542997722 and parameters: {'w_0': 0.9999721953315129, 'w_1': 0.01492373135348142, 'w_2': 0.21778538859293095}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,392] Trial 170 finished with value: 0.1019831902836591 and parameters: {'w_0': 0.9767368373372306, 'w_1': 0.03936570672245715, 'w_2': 0.22094383564795927}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,422] Trial 171 finished with value: 0.10242759558844894 and parameters: {'w_0': 0.9689990374116871, 'w_1': 0.03859572553710537, 'w_2': 0.19481394921076}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,469] Trial 173 finished with value: 0.1017809837498902 and parameters: {'w_0': 0.9643537615438015, 'w_1': 0.02115622240207652, 'w_2': 0.2725468220773266}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,481] Trial 172 finished with value: 0.10242759558844894 and parameters: {'w_0': 0.9750086976929986, 'w_1': 0.040199480643718616, 'w_2': 0.1971024526196149}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,490] Trial 174 finished with value: 0.1017809837498902 and parameters: {'w_0': 0.9614695436528204, 'w_1': 0.028167013496256384, 'w_2': 0.27380002615876153}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,551] Trial 175 finished with value: 0.10200599738203386 and parameters: {'w_0': 0.9594793272088147, 'w_1': 0.020292431931588417, 'w_2': 0.24402210173558375}. Best is trial 137 with value: 0.10156011592079184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 169: F1=0.8982\n",
            "Trial 170: F1=0.8980\n",
            "Trial 171: F1=0.8976\n",
            "Trial 173: F1=0.8982\n",
            "Trial 172: F1=0.8976\n",
            "Trial 174: F1=0.8982\n",
            "Trial 175: F1=0.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:38,586] Trial 176 finished with value: 0.1020082616791691 and parameters: {'w_0': 0.9803418752498918, 'w_1': 0.01809306527629747, 'w_2': 0.2464538209995595}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,589] Trial 177 finished with value: 0.10190897141752697 and parameters: {'w_0': 0.9553319827942086, 'w_1': 0.05456753528352713, 'w_2': 0.24108664436520028}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,636] Trial 178 finished with value: 0.10199070196859317 and parameters: {'w_0': 0.9815831452376901, 'w_1': 0.05536283237147502, 'w_2': 0.25374986422767976}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,662] Trial 179 finished with value: 0.10222653159666972 and parameters: {'w_0': 0.9275722951653302, 'w_1': 0.07678796087230862, 'w_2': 0.2891855261289984}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,685] Trial 180 finished with value: 0.10215528304187904 and parameters: {'w_0': 0.9301164112184757, 'w_1': 0.07462676010288127, 'w_2': 0.2928766044075854}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,716] Trial 181 finished with value: 0.1022238320179214 and parameters: {'w_0': 0.9306511547856413, 'w_1': 0.08165318902593688, 'w_2': 0.2900527186003476}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,741] Trial 182 finished with value: 0.11250354569649357 and parameters: {'w_0': 0.05595732825990485, 'w_1': 0.0013628885275882331, 'w_2': 0.28947257182136904}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,780] Trial 183 finished with value: 0.10170603723605698 and parameters: {'w_0': 0.9986232931957925, 'w_1': 0.0179913169614998, 'w_2': 0.2690755021670388}. Best is trial 137 with value: 0.10156011592079184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 176: F1=0.8980\n",
            "Trial 177: F1=0.8981\n",
            "Trial 178: F1=0.8980\n",
            "Trial 179: F1=0.8978\n",
            "Trial 180: F1=0.8978\n",
            "Trial 181: F1=0.8978\n",
            "Trial 182: F1=0.8875\n",
            "Trial 183: F1=0.8983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:38,838] Trial 185 finished with value: 0.1017809837498902 and parameters: {'w_0': 0.9575699861111631, 'w_1': 0.023985345614468044, 'w_2': 0.26820264453380943}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,848] Trial 184 finished with value: 0.10170603723605698 and parameters: {'w_0': 0.9982294168195692, 'w_1': 0.02052661743493931, 'w_2': 0.2671350078577239}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,866] Trial 186 finished with value: 0.10200599738203386 and parameters: {'w_0': 0.9849029337200239, 'w_1': 0.03722414717970246, 'w_2': 0.269879220622077}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,923] Trial 189 finished with value: 0.10178355822657059 and parameters: {'w_0': 0.9993739472453046, 'w_1': 0.04826691492933188, 'w_2': 0.3129495876406665}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,930] Trial 187 finished with value: 0.10170605322141935 and parameters: {'w_0': 0.9861711979204932, 'w_1': 0.042577073967022615, 'w_2': 0.31075487502154336}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:38,937] Trial 188 finished with value: 0.10178457978265087 and parameters: {'w_0': 0.9992164929082904, 'w_1': 0.04863527334571338, 'w_2': 0.31639921969318735}. Best is trial 137 with value: 0.10156011592079184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 184: F1=0.8983Trial 185: F1=0.8982\n",
            "\n",
            "Trial 186: F1=0.8980\n",
            "Trial 189: F1=0.8982\n",
            "Trial 187: F1=0.8983\n",
            "Trial 188: F1=0.8982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:39,017] Trial 191 finished with value: 0.1020056872024887 and parameters: {'w_0': 0.9998947192782175, 'w_1': 0.0013077664373832149, 'w_2': 0.22790256166449757}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:39,019] Trial 190 finished with value: 0.1020056872024887 and parameters: {'w_0': 0.979938538284928, 'w_1': 0.004464780001527533, 'w_2': 0.22874306755332957}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:39,028] Trial 192 finished with value: 0.1020056872024887 and parameters: {'w_0': 0.979137592659864, 'w_1': 0.00011570323319262665, 'w_2': 0.22443517131076363}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:39,108] Trial 193 finished with value: 0.10214556842570488 and parameters: {'w_0': 0.9486156754059101, 'w_1': 0.05678604162934224, 'w_2': 0.2593172868260267}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:39,113] Trial 195 finished with value: 0.10200599738203386 and parameters: {'w_0': 0.9503288106064254, 'w_1': 0.03171357937864619, 'w_2': 0.25772998783228485}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:39,125] Trial 194 finished with value: 0.10268017833110987 and parameters: {'w_0': 0.9495948981178246, 'w_1': 0.27690890597148343, 'w_2': 0.26234823300628535}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:39,207] Trial 196 finished with value: 0.10171306730311713 and parameters: {'w_0': 0.980542715483684, 'w_1': 0.03694526704752307, 'w_2': 0.31586400621468413}. Best is trial 137 with value: 0.10156011592079184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 191: F1=0.8980\n",
            "Trial 190: F1=0.8980\n",
            "Trial 192: F1=0.8980\n",
            "Trial 193: F1=0.8979\n",
            "Trial 195: F1=0.8980\n",
            "Trial 194: F1=0.8973\n",
            "Trial 196: F1=0.8983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:30:39,228] Trial 197 finished with value: 0.10178357579753305 and parameters: {'w_0': 0.9769650780257729, 'w_1': 0.03857987787165388, 'w_2': 0.3049999872164223}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:39,230] Trial 198 finished with value: 0.10171623185199741 and parameters: {'w_0': 0.9789188951847866, 'w_1': 0.03261378740291425, 'w_2': 0.3070127939985095}. Best is trial 137 with value: 0.10156011592079184.\n",
            "[I 2025-06-16 10:30:39,248] Trial 199 finished with value: 0.10178355822657059 and parameters: {'w_0': 0.9777910861075664, 'w_1': 0.05945339563568133, 'w_2': 0.31474741751696717}. Best is trial 137 with value: 0.10156011592079184.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 197: F1=0.8982\n",
            "Trial 198: F1=0.8983\n",
            "Trial 199: F1=0.8982\n",
            "Combo ['booster_texte_logits.pt', 'camembert2_logits.pt', 'flaubert2_logits.pt'] - Best F1: 0.8984\n",
            "\n",
            "--- Résultat final ---\n",
            "Meilleure combinaison : ['booster_texte_logits.pt', 'camembert2_logits.pt', 'flaubert2_logits.pt']\n",
            "Meilleur F1-weighted : 0.8984\n",
            "Poids optimaux : [0.97793276 0.02240674 0.29904325]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import lightgbm as lgb\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from itertools import combinations\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import optuna\n",
        "\n",
        "# --- Config chemins ---\n",
        "BASE = \"/content/drive/MyDrive/Colab Notebooks/fahim/final\"\n",
        "PATH_LOGITS = \"/content/modeles_importes\"\n",
        "VAL_INDICES_PATH = os.path.join(BASE, \"val_indices.json\")\n",
        "LABEL_MAPPING_PATH = os.path.join(BASE, \"label_mapping_final.json\")\n",
        "LABELS_PATH = os.path.join(PATH_LOGITS, \"true_labels_final.pt\")\n",
        "\n",
        "# --- Meilleure combinaison modèles ---\n",
        "best_models = [\n",
        "    \"booster_texte_logits.pt\",\n",
        "    \"camembert2_logits.pt\",\n",
        "    \"flaubert2_logits.pt\",\n",
        "]\n",
        "\n",
        "# --- Poids fixes des modèles dans la fusion ---\n",
        "fixed_weights = np.array([0.97793276, 0.02240674, 0.29904325])\n",
        "\n",
        "# --- Chargement labels et indices ---\n",
        "with open(VAL_INDICES_PATH, \"r\") as f:\n",
        "    val_idx = np.array(json.load(f))\n",
        "with open(LABEL_MAPPING_PATH, \"r\") as f:\n",
        "    label_mapping = json.load(f)\n",
        "class_names = [label_mapping[str(i)][\"label_name\"] for i in range(len(label_mapping))]\n",
        "\n",
        "labels_full = torch.load(LABELS_PATH).numpy()\n",
        "n_samples = labels_full.shape[0]\n",
        "all_indices = np.arange(n_samples)\n",
        "train_idx = np.setdiff1d(all_indices, val_idx)\n",
        "\n",
        "y_train = labels_full[train_idx]\n",
        "y_val = labels_full[val_idx]\n",
        "\n",
        "# --- Charger logits ---\n",
        "def load_logits(fnames, indices):\n",
        "    logits_list = []\n",
        "    for fname in fnames:\n",
        "        logits = torch.load(os.path.join(PATH_LOGITS, fname)).cpu().numpy()\n",
        "        if logits.ndim == 2 and (np.abs(np.sum(logits, axis=1) - 1) > 1e-4).any():\n",
        "            logits = softmax(logits, axis=1)\n",
        "        logits = logits[indices]\n",
        "        logits_list.append(logits)\n",
        "    return logits_list\n",
        "\n",
        "logits_train_list = load_logits(best_models, train_idx)\n",
        "logits_val_list = load_logits(best_models, val_idx)\n",
        "\n",
        "# --- Fusion pondérée ---\n",
        "def weighted_fusion(logits_list, weights):\n",
        "    stacked = np.stack(logits_list, axis=0)\n",
        "    weighted = np.tensordot(weights, stacked, axes=(0, 0))\n",
        "    return weighted\n",
        "\n",
        "# --- Entraînement LightGBM ---\n",
        "def train_lgb(X_train, y_train, X_val, y_val):\n",
        "    model = lgb.LGBMClassifier(\n",
        "        objective=\"multiclass\",\n",
        "        num_class=len(class_names),\n",
        "        metric=\"multi_logloss\",\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=31,\n",
        "        max_depth=7,\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "    )\n",
        "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
        "    preds_proba = model.predict_proba(X_val)\n",
        "    f1 = f1_score(y_val, np.argmax(preds_proba, axis=1), average='weighted')\n",
        "    return model, preds_proba, f1\n",
        "\n",
        "# --- Méta-MLP ---\n",
        "class MetaMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=512, n_classes=len(class_names)):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, n_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def train_mlp(X_train, y_train, X_val, y_val, epochs=20, batch_size=256, lr=1e-3, weight_decay=1e-5):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = MetaMLP(X_train.shape[1], hidden_dim=512).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "    val_ds = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
        "\n",
        "    best_f1 = 0\n",
        "    best_state = None\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                logits = model(xb)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                all_preds.append(preds.cpu().numpy())\n",
        "                all_targets.append(yb.cpu().numpy())\n",
        "        all_preds = np.concatenate(all_preds)\n",
        "        all_targets = np.concatenate(all_targets)\n",
        "        f1 = f1_score(all_targets, all_preds, average='weighted')\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_state = model.state_dict()\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_probs = model(torch.tensor(X_val, dtype=torch.float32).to(device)).cpu().numpy()\n",
        "    return model, val_probs, best_f1\n",
        "\n",
        "# --- Entraînement Régression Logistique ---\n",
        "def train_logreg(X_train, y_train, X_val, y_val):\n",
        "    model = LogisticRegression(\n",
        "        penalty='l2',\n",
        "        C=1.0,\n",
        "        solver='lbfgs',\n",
        "        max_iter=500,\n",
        "        multi_class='multinomial',\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    preds_proba = model.predict_proba(X_val)\n",
        "    f1 = f1_score(y_val, np.argmax(preds_proba, axis=1), average='weighted')\n",
        "    return model, preds_proba, f1\n",
        "\n",
        "# --- Fusion pondérée des probabilités ---\n",
        "def fusion_probs(weights, *probas):\n",
        "    fusion = np.zeros_like(probas[0])\n",
        "    for w, p in zip(weights, probas):\n",
        "        fusion += w * p\n",
        "    return fusion\n",
        "\n",
        "# --- Fonction objectif Optuna ---\n",
        "def objective(trial, probas_list, y_true):\n",
        "    n_weights = len(probas_list)\n",
        "    weights = []\n",
        "    for i in range(n_weights):\n",
        "        weights.append(trial.suggest_float(f'w{i}', 0.0, 1.0))\n",
        "    weights = np.array(weights)\n",
        "    if weights.sum() == 0:\n",
        "        return 1.0\n",
        "    weights /= weights.sum()\n",
        "    fusion = fusion_probs(weights, *probas_list)\n",
        "    preds = np.argmax(fusion, axis=1)\n",
        "    return 1 - f1_score(y_true, preds, average='weighted')\n",
        "\n",
        "# --- Validation croisée stratifiée sur train uniquement ---\n",
        "def cross_val_train_metas(logits_train_list, y_train, fixed_weights, classifiers, n_splits=5, n_trials_optuna=50):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    cv_scores = {combo: [] for r in range(1, 4) for combo in combinations(classifiers.keys(), r)}\n",
        "\n",
        "    for fold_idx, (train_fold_idx, val_fold_idx) in enumerate(skf.split(np.zeros(len(y_train)), y_train)):\n",
        "        print(f\"\\n=== Fold {fold_idx+1}/{n_splits} ===\")\n",
        "\n",
        "        # Préparer les données du fold\n",
        "        X_train_fold = weighted_fusion([logits[train_fold_idx] for logits in logits_train_list], fixed_weights)\n",
        "        y_train_fold = y_train[train_fold_idx]\n",
        "\n",
        "        X_val_fold = weighted_fusion([logits[val_fold_idx] for logits in logits_train_list], fixed_weights)\n",
        "        y_val_fold = y_train[val_fold_idx]\n",
        "\n",
        "        for r in range(1, 4):\n",
        "            for combo in combinations(classifiers.keys(), r):\n",
        "                print(f\"\\n--- Training combination {combo} ---\")\n",
        "\n",
        "                probas_list = []\n",
        "                for clf_name in combo:\n",
        "                    model, val_proba, f1 = classifiers[clf_name](X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "                    print(f\"F1-weighted {clf_name} (fold {fold_idx+1}): {f1:.4f}\")\n",
        "                    probas_list.append(val_proba)\n",
        "\n",
        "                # Optimisation des poids avec Optuna\n",
        "                study = optuna.create_study(direction=\"minimize\")\n",
        "                study.optimize(lambda trial: objective(trial, probas_list, y_val_fold), n_trials=n_trials_optuna, show_progress_bar=False)\n",
        "\n",
        "                best_weights = []\n",
        "                for i in range(len(probas_list)):\n",
        "                    best_weights.append(study.best_params[f'w{i}'])\n",
        "                best_weights = np.array(best_weights)\n",
        "                best_weights /= best_weights.sum()\n",
        "\n",
        "                fusion = fusion_probs(best_weights, *probas_list)\n",
        "                preds = np.argmax(fusion, axis=1)\n",
        "                f1 = f1_score(y_val_fold, preds, average='weighted')\n",
        "                print(f\"Best weighted fusion F1 (fold {fold_idx+1}): {f1:.4f}\")\n",
        "\n",
        "                cv_scores[combo].append(f1)\n",
        "\n",
        "    # Calcul moyenne et std des scores CV\n",
        "    mean_std_scores = {}\n",
        "    for combo, scores in cv_scores.items():\n",
        "        mean_std_scores[combo] = (np.mean(scores), np.std(scores))\n",
        "        print(f\"\\n=== Combo {combo} CV mean F1: {np.mean(scores):.4f} ± {np.std(scores):.4f} ===\")\n",
        "\n",
        "    return mean_std_scores\n",
        "\n",
        "# --- Entraînement final sur tout train_idx ---\n",
        "def train_final_and_eval(logits_train_list, y_train, logits_val_list, y_val, fixed_weights, classifiers, best_combo, n_trials_optuna=200):\n",
        "    # Fusion train et val\n",
        "    X_train = weighted_fusion(logits_train_list, fixed_weights)\n",
        "    X_val = weighted_fusion(logits_val_list, fixed_weights)\n",
        "\n",
        "    probas_list = []\n",
        "    for clf_name in best_combo:\n",
        "        model, val_proba, f1 = classifiers[clf_name](X_train, y_train, X_val, y_val)\n",
        "        print(f\"Final train F1 {clf_name}: {f1:.4f}\")\n",
        "        probas_list.append(val_proba)\n",
        "\n",
        "    # Optimisation finale des poids\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective(trial, probas_list, y_val), n_trials=n_trials_optuna, show_progress_bar=True)\n",
        "\n",
        "    best_weights = []\n",
        "    for i in range(len(probas_list)):\n",
        "        best_weights.append(study.best_params[f'w{i}'])\n",
        "    best_weights = np.array(best_weights)\n",
        "    best_weights /= best_weights.sum()\n",
        "\n",
        "    fusion = fusion_probs(best_weights, *probas_list)\n",
        "    preds = np.argmax(fusion, axis=1)\n",
        "    f1 = f1_score(y_val, preds, average='weighted')\n",
        "\n",
        "    print(\"\\n=== Résultats finaux ===\")\n",
        "    print(f\"Combinaison utilisée : {best_combo}\")\n",
        "    print(f\"F1-weighted final : {f1:.4f}\")\n",
        "    print(classification_report(y_val, preds, target_names=class_names, digits=4))\n",
        "\n",
        "    return best_weights, f1\n",
        "\n",
        "# --- Dictionnaire des classifieurs ---\n",
        "classifiers = {\n",
        "    \"lgbm\": train_lgb,\n",
        "    \"mlp\": train_mlp,\n",
        "    \"logreg\": train_logreg\n",
        "}\n",
        "\n",
        "# --- 1) Validation croisée sur train_idx ---\n",
        "cv_results = cross_val_train_metas(logits_train_list, y_train, fixed_weights, classifiers, n_splits=5, n_trials_optuna=100)\n",
        "\n",
        "# --- Trouver la meilleure combinaison selon CV ---\n",
        "best_combo = max(cv_results.items(), key=lambda x: x[1][0])[0]\n",
        "print(f\"\\n=== Meilleure combinaison selon CV: {best_combo} ===\")\n",
        "\n",
        "# --- 2) Entraînement final sur tout train_idx et évaluation sur val_idx ---\n",
        "best_weights, final_f1 = train_final_and_eval(logits_train_list, y_train, logits_val_list, y_val, fixed_weights, classifiers, best_combo, n_trials_optuna=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e455079d782c499ca98f78a9b89ccafa",
            "25981d34bcd943028702bb7bb8e717a1",
            "9052d53cba8a4f79a52808dd0c9cd7d4",
            "2babc4ae64934b8888c58872478999a1",
            "92e6d97ecdd641d9a94345703b3f052a",
            "426ecf9bcd624d018a8f90df0e033c00",
            "b9fda17193df4b86a5d758dcdd5a4be5",
            "744857648ce0462e82d692bfe6a8cd4e",
            "7dde4582ab7842b498e6b771dde02dee",
            "c5b4eee927e24e309f2493eafb6f77df",
            "256db103db2547e5aa4fbd9d65fde207"
          ]
        },
        "id": "7NHyVVgSHKu8",
        "outputId": "8abc6838-bf1d-494e-f3ec-f904c07c452d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1/5 ===\n",
            "\n",
            "--- Training combination ('lgbm',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003397 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59557, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335990\n",
            "[LightGBM] [Info] Start training from score -3.552782\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.490298\n",
            "[LightGBM] [Info] Start training from score -3.098136\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.889684\n",
            "[LightGBM] [Info] Start training from score -3.745474\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.559841\n",
            "[LightGBM] [Info] Start training from score -3.296660\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.013298\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.864630\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.912287\n",
            "[LightGBM] [Info] Start training from score -2.909510\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.865219\n",
            "[LightGBM] [Info] Start training from score -3.521052\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.558072\n",
            "[LightGBM] [Info] Start training from score -3.457259\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:34:39,131] A new study created in memory with name: no-name-2adc0b5c-f855-4178-82c3-e7bc34bb8490\n",
            "[I 2025-06-16 10:34:39,138] Trial 0 finished with value: 0.03524474018859325 and parameters: {'w0': 0.8957681954876603}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,143] Trial 1 finished with value: 0.03524474018859325 and parameters: {'w0': 0.19213341113336402}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,148] Trial 2 finished with value: 0.03524474018859325 and parameters: {'w0': 0.058384250569769036}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,154] Trial 3 finished with value: 0.03524474018859325 and parameters: {'w0': 0.2037186256775808}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,159] Trial 4 finished with value: 0.03524474018859325 and parameters: {'w0': 0.45851229894624723}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,164] Trial 5 finished with value: 0.03524474018859325 and parameters: {'w0': 0.3234470682615631}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,169] Trial 6 finished with value: 0.03524474018859325 and parameters: {'w0': 0.300122490698549}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,174] Trial 7 finished with value: 0.03524474018859325 and parameters: {'w0': 0.7202216519364625}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,179] Trial 8 finished with value: 0.03524474018859325 and parameters: {'w0': 0.6463185358480377}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,184] Trial 9 finished with value: 0.03524474018859325 and parameters: {'w0': 0.8759509338890095}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,193] Trial 10 finished with value: 0.03524474018859325 and parameters: {'w0': 0.9967507098437138}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,203] Trial 11 finished with value: 0.03524474018859325 and parameters: {'w0': 0.5474241298796159}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,212] Trial 12 finished with value: 0.03524474018859325 and parameters: {'w0': 0.014122387151615734}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,221] Trial 13 finished with value: 0.03524474018859325 and parameters: {'w0': 0.8627191310773736}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,230] Trial 14 finished with value: 0.03524474018859325 and parameters: {'w0': 0.4532381731163042}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,239] Trial 15 finished with value: 0.03524474018859325 and parameters: {'w0': 0.1331997478489642}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,249] Trial 16 finished with value: 0.03524474018859325 and parameters: {'w0': 0.30871938191294945}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,257] Trial 17 finished with value: 0.03524474018859325 and parameters: {'w0': 0.7227056040276851}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,266] Trial 18 finished with value: 0.03524474018859325 and parameters: {'w0': 0.5547956344954987}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,275] Trial 19 finished with value: 0.03524474018859325 and parameters: {'w0': 0.9544528212912181}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,285] Trial 20 finished with value: 0.03524474018859325 and parameters: {'w0': 0.3873503850444774}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,293] Trial 21 finished with value: 0.03524474018859325 and parameters: {'w0': 0.010984293366495423}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,302] Trial 22 finished with value: 0.03524474018859325 and parameters: {'w0': 0.13583415581579456}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,312] Trial 23 finished with value: 0.03524474018859325 and parameters: {'w0': 0.18532667138712988}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,322] Trial 24 finished with value: 0.03524474018859325 and parameters: {'w0': 0.06905751925864256}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,331] Trial 25 finished with value: 0.03524474018859325 and parameters: {'w0': 0.2414029169814574}. Best is trial 0 with value: 0.03524474018859325.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 1): 0.9648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:34:39,340] Trial 26 finished with value: 0.03524474018859325 and parameters: {'w0': 0.07389755674675126}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,349] Trial 27 finished with value: 0.03524474018859325 and parameters: {'w0': 0.651102986342905}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,359] Trial 28 finished with value: 0.03524474018859325 and parameters: {'w0': 0.3878588162986467}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,368] Trial 29 finished with value: 0.03524474018859325 and parameters: {'w0': 0.1833479183681985}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,377] Trial 30 finished with value: 0.03524474018859325 and parameters: {'w0': 0.2302376835970465}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,386] Trial 31 finished with value: 0.03524474018859325 and parameters: {'w0': 0.09824753039835565}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,395] Trial 32 finished with value: 0.03524474018859325 and parameters: {'w0': 0.24721433448529428}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,404] Trial 33 finished with value: 0.03524474018859325 and parameters: {'w0': 0.372946981427691}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,414] Trial 34 finished with value: 0.03524474018859325 and parameters: {'w0': 0.17269021645910104}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,423] Trial 35 finished with value: 0.03524474018859325 and parameters: {'w0': 0.4423963827870048}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,432] Trial 36 finished with value: 0.03524474018859325 and parameters: {'w0': 0.28937080989193614}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,442] Trial 37 finished with value: 0.03524474018859325 and parameters: {'w0': 0.7956110163533207}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,451] Trial 38 finished with value: 0.03524474018859325 and parameters: {'w0': 0.004414138837410375}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,460] Trial 39 finished with value: 0.03524474018859325 and parameters: {'w0': 0.508009980745511}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,469] Trial 40 finished with value: 0.03524474018859325 and parameters: {'w0': 0.6356803767161749}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,478] Trial 41 finished with value: 0.03524474018859325 and parameters: {'w0': 0.6009478233534442}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,488] Trial 42 finished with value: 0.03524474018859325 and parameters: {'w0': 0.33393351378605646}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,497] Trial 43 finished with value: 0.03524474018859325 and parameters: {'w0': 0.05817788007989399}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,506] Trial 44 finished with value: 0.03524474018859325 and parameters: {'w0': 0.7390775853467118}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,515] Trial 45 finished with value: 0.03524474018859325 and parameters: {'w0': 0.129322155209518}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,526] Trial 46 finished with value: 0.03524474018859325 and parameters: {'w0': 0.8593986785832255}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,536] Trial 47 finished with value: 0.03524474018859325 and parameters: {'w0': 0.44330717655748275}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,546] Trial 48 finished with value: 0.03524474018859325 and parameters: {'w0': 0.26782340534411075}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,555] Trial 49 finished with value: 0.03524474018859325 and parameters: {'w0': 0.9805906029087587}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,564] Trial 50 finished with value: 0.03524474018859325 and parameters: {'w0': 0.206465266582988}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,574] Trial 51 finished with value: 0.03524474018859325 and parameters: {'w0': 0.33028777540021775}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,583] Trial 52 finished with value: 0.03524474018859325 and parameters: {'w0': 0.49009305063712405}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,592] Trial 53 finished with value: 0.03524474018859325 and parameters: {'w0': 0.14593529639224856}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,602] Trial 54 finished with value: 0.03524474018859325 and parameters: {'w0': 0.33962744427126224}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,611] Trial 55 finished with value: 0.03524474018859325 and parameters: {'w0': 0.3982061713382176}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,620] Trial 56 finished with value: 0.03524474018859325 and parameters: {'w0': 0.5485327556902917}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,630] Trial 57 finished with value: 0.03524474018859325 and parameters: {'w0': 0.04806143189444101}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,640] Trial 58 finished with value: 0.03524474018859325 and parameters: {'w0': 0.10902886887342075}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,650] Trial 59 finished with value: 0.03524474018859325 and parameters: {'w0': 0.2688687542251368}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,659] Trial 60 finished with value: 0.03524474018859325 and parameters: {'w0': 0.22599319834327836}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,669] Trial 61 finished with value: 0.03524474018859325 and parameters: {'w0': 0.30073674616248985}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,678] Trial 62 finished with value: 0.03524474018859325 and parameters: {'w0': 0.41084466308266593}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,688] Trial 63 finished with value: 0.03524474018859325 and parameters: {'w0': 0.15741959574195047}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,698] Trial 64 finished with value: 0.03524474018859325 and parameters: {'w0': 0.20314736099916986}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,707] Trial 65 finished with value: 0.03524474018859325 and parameters: {'w0': 0.3649358628860473}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,717] Trial 66 finished with value: 0.03524474018859325 and parameters: {'w0': 0.9132145815622845}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,727] Trial 67 finished with value: 0.03524474018859325 and parameters: {'w0': 0.497178514625766}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,737] Trial 68 finished with value: 0.03524474018859325 and parameters: {'w0': 0.27232743458804415}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,747] Trial 69 finished with value: 0.03524474018859325 and parameters: {'w0': 0.09059935908747196}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,757] Trial 70 finished with value: 0.03524474018859325 and parameters: {'w0': 0.042100620888246953}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,767] Trial 71 finished with value: 0.03524474018859325 and parameters: {'w0': 0.7783976253732389}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,777] Trial 72 finished with value: 0.03524474018859325 and parameters: {'w0': 0.7184382366775918}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,786] Trial 73 finished with value: 0.03524474018859325 and parameters: {'w0': 0.829806810380346}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,797] Trial 74 finished with value: 0.03524474018859325 and parameters: {'w0': 0.9248237988399869}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,807] Trial 75 finished with value: 0.03524474018859325 and parameters: {'w0': 0.6777332597712412}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,817] Trial 76 finished with value: 0.03524474018859325 and parameters: {'w0': 0.579432557043076}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,827] Trial 77 finished with value: 0.03524474018859325 and parameters: {'w0': 0.46983997903768204}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,837] Trial 78 finished with value: 0.03524474018859325 and parameters: {'w0': 0.4243636137338115}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,847] Trial 79 finished with value: 0.03524474018859325 and parameters: {'w0': 0.35259550742574}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,858] Trial 80 finished with value: 0.03524474018859325 and parameters: {'w0': 0.31376485985094743}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,868] Trial 81 finished with value: 0.03524474018859325 and parameters: {'w0': 0.6810922380872142}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,878] Trial 82 finished with value: 0.03524474018859325 and parameters: {'w0': 0.6305937907026897}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,888] Trial 83 finished with value: 0.03524474018859325 and parameters: {'w0': 0.5221819054937311}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,897] Trial 84 finished with value: 0.03524474018859325 and parameters: {'w0': 0.8089496595887717}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,907] Trial 85 finished with value: 0.03524474018859325 and parameters: {'w0': 0.24652820516632645}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,917] Trial 86 finished with value: 0.03524474018859325 and parameters: {'w0': 0.7598972351233232}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,927] Trial 87 finished with value: 0.03524474018859325 and parameters: {'w0': 0.5851162898021625}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,937] Trial 88 finished with value: 0.03524474018859325 and parameters: {'w0': 0.19488495766072855}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,948] Trial 89 finished with value: 0.03524474018859325 and parameters: {'w0': 0.8894205462617226}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,957] Trial 90 finished with value: 0.03524474018859325 and parameters: {'w0': 0.2190204014073726}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,967] Trial 91 finished with value: 0.03524474018859325 and parameters: {'w0': 0.9750825098477731}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,977] Trial 92 finished with value: 0.03524474018859325 and parameters: {'w0': 0.8325599675986979}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,987] Trial 93 finished with value: 0.03524474018859325 and parameters: {'w0': 0.862272342599931}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:39,997] Trial 94 finished with value: 0.03524474018859325 and parameters: {'w0': 0.943292341031707}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:40,006] Trial 95 finished with value: 0.03524474018859325 and parameters: {'w0': 0.12119548747208708}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:40,016] Trial 96 finished with value: 0.03524474018859325 and parameters: {'w0': 0.894703908036215}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:40,027] Trial 97 finished with value: 0.03524474018859325 and parameters: {'w0': 0.6992531963623048}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:40,036] Trial 98 finished with value: 0.03524474018859325 and parameters: {'w0': 0.17491529639248832}. Best is trial 0 with value: 0.03524474018859325.\n",
            "[I 2025-06-16 10:34:40,045] Trial 99 finished with value: 0.03524474018859325 and parameters: {'w0': 0.08419389226932109}. Best is trial 0 with value: 0.03524474018859325.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 1): 0.9648\n",
            "\n",
            "--- Training combination ('mlp',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:35:03,254] A new study created in memory with name: no-name-fb0988b8-dac8-4762-9d1c-28b8cdff8a5f\n",
            "[I 2025-06-16 10:35:03,261] Trial 0 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3313642197278096}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,266] Trial 1 finished with value: 0.033491320568750704 and parameters: {'w0': 0.0855115978767077}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,271] Trial 2 finished with value: 0.033491320568750704 and parameters: {'w0': 0.09855925754384798}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,277] Trial 3 finished with value: 0.033491320568750704 and parameters: {'w0': 0.7545490211424231}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,282] Trial 4 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2746213200823292}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,287] Trial 5 finished with value: 0.033491320568750704 and parameters: {'w0': 0.6749040481738766}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,292] Trial 6 finished with value: 0.033491320568750704 and parameters: {'w0': 0.37111917937738625}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,297] Trial 7 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3066273967403762}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,303] Trial 8 finished with value: 0.033491320568750704 and parameters: {'w0': 0.5059335638871387}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,309] Trial 9 finished with value: 0.033491320568750704 and parameters: {'w0': 0.11785358572848903}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,318] Trial 10 finished with value: 0.033491320568750704 and parameters: {'w0': 0.994028726576226}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,326] Trial 11 finished with value: 0.033491320568750704 and parameters: {'w0': 0.02729161914133356}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,335] Trial 12 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2353494669329821}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,343] Trial 13 finished with value: 0.033491320568750704 and parameters: {'w0': 0.48161690597611917}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,352] Trial 14 finished with value: 0.033491320568750704 and parameters: {'w0': 0.1644764487797954}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,361] Trial 15 finished with value: 0.033491320568750704 and parameters: {'w0': 0.018779027240113044}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,369] Trial 16 finished with value: 0.033491320568750704 and parameters: {'w0': 0.43468054524952526}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,377] Trial 17 finished with value: 0.033491320568750704 and parameters: {'w0': 0.6462754278923138}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,386] Trial 18 finished with value: 0.033491320568750704 and parameters: {'w0': 0.19079446947719794}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,396] Trial 19 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3482922424486766}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,406] Trial 20 finished with value: 0.033491320568750704 and parameters: {'w0': 0.5594719776406285}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,415] Trial 21 finished with value: 0.033491320568750704 and parameters: {'w0': 0.10528727942718885}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,424] Trial 22 finished with value: 0.033491320568750704 and parameters: {'w0': 0.09997029669646193}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,433] Trial 23 finished with value: 0.033491320568750704 and parameters: {'w0': 0.002819676070666244}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,442] Trial 24 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2249026573263031}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,451] Trial 25 finished with value: 0.033491320568750704 and parameters: {'w0': 0.36544390227350054}. Best is trial 0 with value: 0.033491320568750704.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted mlp (fold 1): 0.9672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:35:03,461] Trial 26 finished with value: 0.033491320568750704 and parameters: {'w0': 0.1446685477585814}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,470] Trial 27 finished with value: 0.033491320568750704 and parameters: {'w0': 0.05857574289889799}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,480] Trial 28 finished with value: 0.033491320568750704 and parameters: {'w0': 0.27679141183636113}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,488] Trial 29 finished with value: 0.033491320568750704 and parameters: {'w0': 0.8987865220334091}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,497] Trial 30 finished with value: 0.033491320568750704 and parameters: {'w0': 0.4044640430631859}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,506] Trial 31 finished with value: 0.033491320568750704 and parameters: {'w0': 0.7383211868443118}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,515] Trial 32 finished with value: 0.033491320568750704 and parameters: {'w0': 0.7974169018513156}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,525] Trial 33 finished with value: 0.033491320568750704 and parameters: {'w0': 0.8519325947974363}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,534] Trial 34 finished with value: 0.033491320568750704 and parameters: {'w0': 0.6260432371996129}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,543] Trial 35 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2930417686113536}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,553] Trial 36 finished with value: 0.033491320568750704 and parameters: {'w0': 0.5334487864765323}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,562] Trial 37 finished with value: 0.033491320568750704 and parameters: {'w0': 0.08397699140609324}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,571] Trial 38 finished with value: 0.033491320568750704 and parameters: {'w0': 0.1949031634658352}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,580] Trial 39 finished with value: 0.033491320568750704 and parameters: {'w0': 0.7152393326446672}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,590] Trial 40 finished with value: 0.033491320568750704 and parameters: {'w0': 0.958490197342099}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,599] Trial 41 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2551996181634654}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,609] Trial 42 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3295654500032559}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,618] Trial 43 finished with value: 0.033491320568750704 and parameters: {'w0': 0.4600957527099153}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,627] Trial 44 finished with value: 0.033491320568750704 and parameters: {'w0': 0.15652874883903345}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,636] Trial 45 finished with value: 0.033491320568750704 and parameters: {'w0': 0.5794746360920257}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,646] Trial 46 finished with value: 0.033491320568750704 and parameters: {'w0': 0.05119010480299413}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,655] Trial 47 finished with value: 0.033491320568750704 and parameters: {'w0': 0.40831423061738387}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,664] Trial 48 finished with value: 0.033491320568750704 and parameters: {'w0': 0.19610261331444667}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,674] Trial 49 finished with value: 0.033491320568750704 and parameters: {'w0': 0.13510344393924195}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,683] Trial 50 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3097604158968885}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,693] Trial 51 finished with value: 0.033491320568750704 and parameters: {'w0': 0.6701114795933059}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,702] Trial 52 finished with value: 0.033491320568750704 and parameters: {'w0': 0.7310737407644988}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,712] Trial 53 finished with value: 0.033491320568750704 and parameters: {'w0': 0.808097073196042}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,722] Trial 54 finished with value: 0.033491320568750704 and parameters: {'w0': 0.504009601434462}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,731] Trial 55 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2244097581773209}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,741] Trial 56 finished with value: 0.033491320568750704 and parameters: {'w0': 0.7838272269332186}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,751] Trial 57 finished with value: 0.033491320568750704 and parameters: {'w0': 0.6216925390181255}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,760] Trial 58 finished with value: 0.033491320568750704 and parameters: {'w0': 0.04067574517799963}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,770] Trial 59 finished with value: 0.033491320568750704 and parameters: {'w0': 0.6937658108997263}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,780] Trial 60 finished with value: 0.033491320568750704 and parameters: {'w0': 0.11326795647675611}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,790] Trial 61 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3728700784744398}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,800] Trial 62 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2622740610320563}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,810] Trial 63 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3437561917069519}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,819] Trial 64 finished with value: 0.033491320568750704 and parameters: {'w0': 0.4699731773141257}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,829] Trial 65 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3936700037946617}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,839] Trial 66 finished with value: 0.033491320568750704 and parameters: {'w0': 0.43376279442378973}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,849] Trial 67 finished with value: 0.033491320568750704 and parameters: {'w0': 0.7645282746662456}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,859] Trial 68 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3097133815017977}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,869] Trial 69 finished with value: 0.033491320568750704 and parameters: {'w0': 0.8579102433120822}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,878] Trial 70 finished with value: 0.033491320568750704 and parameters: {'w0': 0.08543652179006057}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,888] Trial 71 finished with value: 0.033491320568750704 and parameters: {'w0': 6.492599659124743e-05}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,897] Trial 72 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2054583224375588}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,907] Trial 73 finished with value: 0.033491320568750704 and parameters: {'w0': 0.1707405786261505}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,917] Trial 74 finished with value: 0.033491320568750704 and parameters: {'w0': 0.23246460755660187}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,927] Trial 75 finished with value: 0.033491320568750704 and parameters: {'w0': 0.5346277429342938}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,937] Trial 76 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2841877738943255}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,946] Trial 77 finished with value: 0.033491320568750704 and parameters: {'w0': 0.5813255523829528}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,956] Trial 78 finished with value: 0.033491320568750704 and parameters: {'w0': 0.37387672237064}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,966] Trial 79 finished with value: 0.033491320568750704 and parameters: {'w0': 0.4256065171232504}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,975] Trial 80 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3153375546787822}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,986] Trial 81 finished with value: 0.033491320568750704 and parameters: {'w0': 0.4997267446427707}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:03,996] Trial 82 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3457455813043921}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,005] Trial 83 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2643858463655924}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,015] Trial 84 finished with value: 0.033491320568750704 and parameters: {'w0': 0.12927859111925932}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,024] Trial 85 finished with value: 0.033491320568750704 and parameters: {'w0': 0.1775380579941798}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,034] Trial 86 finished with value: 0.033491320568750704 and parameters: {'w0': 0.6562643161563406}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,044] Trial 87 finished with value: 0.033491320568750704 and parameters: {'w0': 0.08349826009815602}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,054] Trial 88 finished with value: 0.033491320568750704 and parameters: {'w0': 0.6130689921086716}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,064] Trial 89 finished with value: 0.033491320568750704 and parameters: {'w0': 0.29426998443731456}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,073] Trial 90 finished with value: 0.033491320568750704 and parameters: {'w0': 0.4528790696008596}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,083] Trial 91 finished with value: 0.033491320568750704 and parameters: {'w0': 0.06086843894172343}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,092] Trial 92 finished with value: 0.033491320568750704 and parameters: {'w0': 0.21273954449081353}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,102] Trial 93 finished with value: 0.033491320568750704 and parameters: {'w0': 0.022016754594799}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,111] Trial 94 finished with value: 0.033491320568750704 and parameters: {'w0': 0.2413145336165814}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,121] Trial 95 finished with value: 0.033491320568750704 and parameters: {'w0': 0.8225768453722868}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,131] Trial 96 finished with value: 0.033491320568750704 and parameters: {'w0': 0.7442281215757126}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,140] Trial 97 finished with value: 0.033491320568750704 and parameters: {'w0': 0.3936318438996232}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,150] Trial 98 finished with value: 0.033491320568750704 and parameters: {'w0': 0.11250506071556525}. Best is trial 0 with value: 0.033491320568750704.\n",
            "[I 2025-06-16 10:35:04,160] Trial 99 finished with value: 0.033491320568750704 and parameters: {'w0': 0.14683604284854473}. Best is trial 0 with value: 0.033491320568750704.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 1): 0.9665\n",
            "\n",
            "--- Training combination ('logreg',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:35:07,136] A new study created in memory with name: no-name-996d3a1c-6414-4dc5-9355-4be8e569ae61\n",
            "[I 2025-06-16 10:35:07,144] Trial 0 finished with value: 0.03462483170810149 and parameters: {'w0': 0.35255079713643633}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,151] Trial 1 finished with value: 0.03462483170810149 and parameters: {'w0': 0.993504876371399}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,158] Trial 2 finished with value: 0.03462483170810149 and parameters: {'w0': 0.34535688935222497}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,165] Trial 3 finished with value: 0.03462483170810149 and parameters: {'w0': 0.029981186561451656}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,172] Trial 4 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8107065871005209}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,179] Trial 5 finished with value: 0.03462483170810149 and parameters: {'w0': 0.47687497028008186}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,186] Trial 6 finished with value: 0.03462483170810149 and parameters: {'w0': 0.7802958261158977}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,193] Trial 7 finished with value: 0.03462483170810149 and parameters: {'w0': 0.08785926628626795}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,200] Trial 8 finished with value: 0.03462483170810149 and parameters: {'w0': 0.787126556178091}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,207] Trial 9 finished with value: 0.03462483170810149 and parameters: {'w0': 0.15317108157202608}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,220] Trial 10 finished with value: 0.03462483170810149 and parameters: {'w0': 0.39629095751423843}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,232] Trial 11 finished with value: 0.03462483170810149 and parameters: {'w0': 0.9385306122491905}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,245] Trial 12 finished with value: 0.03462483170810149 and parameters: {'w0': 0.6328300394216745}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,255] Trial 13 finished with value: 0.03462483170810149 and parameters: {'w0': 0.25913821218427735}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,264] Trial 14 finished with value: 0.03462483170810149 and parameters: {'w0': 0.5798676010696444}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,274] Trial 15 finished with value: 0.03462483170810149 and parameters: {'w0': 0.9871146925924817}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,283] Trial 16 finished with value: 0.03462483170810149 and parameters: {'w0': 0.2133191115358798}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,293] Trial 17 finished with value: 0.03462483170810149 and parameters: {'w0': 0.6327188600177424}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,302] Trial 18 finished with value: 0.03462483170810149 and parameters: {'w0': 0.48708042241071825}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,312] Trial 19 finished with value: 0.03462483170810149 and parameters: {'w0': 0.3439962164245699}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,322] Trial 20 finished with value: 0.03462483170810149 and parameters: {'w0': 0.9012087426442903}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,332] Trial 21 finished with value: 0.03462483170810149 and parameters: {'w0': 0.3828792284865001}. Best is trial 0 with value: 0.03462483170810149.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 1): 0.9654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:35:07,341] Trial 22 finished with value: 0.03462483170810149 and parameters: {'w0': 0.2935717271373818}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,351] Trial 23 finished with value: 0.03462483170810149 and parameters: {'w0': 0.5538840995274554}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,361] Trial 24 finished with value: 0.03462483170810149 and parameters: {'w0': 0.168121632375963}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,371] Trial 25 finished with value: 0.03462483170810149 and parameters: {'w0': 0.42495484733330324}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,380] Trial 26 finished with value: 0.03462483170810149 and parameters: {'w0': 0.30591609502170136}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,390] Trial 27 finished with value: 0.03462483170810149 and parameters: {'w0': 0.6677944274267157}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,400] Trial 28 finished with value: 0.03462483170810149 and parameters: {'w0': 0.44579411949065356}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,409] Trial 29 finished with value: 0.03462483170810149 and parameters: {'w0': 0.07151639834347218}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,419] Trial 30 finished with value: 0.03462483170810149 and parameters: {'w0': 0.7123079215772039}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,429] Trial 31 finished with value: 0.03462483170810149 and parameters: {'w0': 0.21960836373416892}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,439] Trial 32 finished with value: 0.03462483170810149 and parameters: {'w0': 0.015156897923407908}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,449] Trial 33 finished with value: 0.03462483170810149 and parameters: {'w0': 0.5353863145962726}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,458] Trial 34 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8501774876679892}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,468] Trial 35 finished with value: 0.03462483170810149 and parameters: {'w0': 0.10634445890087207}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,478] Trial 36 finished with value: 0.03462483170810149 and parameters: {'w0': 0.022319016765803}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,488] Trial 37 finished with value: 0.03462483170810149 and parameters: {'w0': 0.7350552832952828}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,497] Trial 38 finished with value: 0.03462483170810149 and parameters: {'w0': 0.18962058802312223}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,506] Trial 39 finished with value: 0.03462483170810149 and parameters: {'w0': 0.30570537038998935}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,516] Trial 40 finished with value: 0.03462483170810149 and parameters: {'w0': 0.13393023210921218}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,526] Trial 41 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8315729199720836}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,536] Trial 42 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8743065937092822}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,546] Trial 43 finished with value: 0.03462483170810149 and parameters: {'w0': 0.9662556083215238}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,555] Trial 44 finished with value: 0.03462483170810149 and parameters: {'w0': 0.7618875714039491}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,566] Trial 45 finished with value: 0.03462483170810149 and parameters: {'w0': 0.9182146330160672}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,576] Trial 46 finished with value: 0.03462483170810149 and parameters: {'w0': 0.36090541394230774}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,586] Trial 47 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8007406231087577}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,596] Trial 48 finished with value: 0.03462483170810149 and parameters: {'w0': 0.2505274176824762}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,606] Trial 49 finished with value: 0.03462483170810149 and parameters: {'w0': 0.505558711417265}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,616] Trial 50 finished with value: 0.03462483170810149 and parameters: {'w0': 0.6339646311418276}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,626] Trial 51 finished with value: 0.03462483170810149 and parameters: {'w0': 0.4590939872055799}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,636] Trial 52 finished with value: 0.03462483170810149 and parameters: {'w0': 0.5827466964736712}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,646] Trial 53 finished with value: 0.03462483170810149 and parameters: {'w0': 0.42237546581727586}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,656] Trial 54 finished with value: 0.03462483170810149 and parameters: {'w0': 0.33596946991007015}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,666] Trial 55 finished with value: 0.03462483170810149 and parameters: {'w0': 0.9517112312607515}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,676] Trial 56 finished with value: 0.03462483170810149 and parameters: {'w0': 0.3765402688954523}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,686] Trial 57 finished with value: 0.03462483170810149 and parameters: {'w0': 0.9909140228228303}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,695] Trial 58 finished with value: 0.03462483170810149 and parameters: {'w0': 0.4791894588567196}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,705] Trial 59 finished with value: 0.03462483170810149 and parameters: {'w0': 0.5867270458532772}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,716] Trial 60 finished with value: 0.03462483170810149 and parameters: {'w0': 0.24436089764101557}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,726] Trial 61 finished with value: 0.03462483170810149 and parameters: {'w0': 0.7132822464125604}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,736] Trial 62 finished with value: 0.03462483170810149 and parameters: {'w0': 0.6652603397772258}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,746] Trial 63 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8080922744612479}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,756] Trial 64 finished with value: 0.03462483170810149 and parameters: {'w0': 0.5362864411613136}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,765] Trial 65 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8757158123873169}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,775] Trial 66 finished with value: 0.03462483170810149 and parameters: {'w0': 0.4293809363410327}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,785] Trial 67 finished with value: 0.03462483170810149 and parameters: {'w0': 0.773914841847489}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,795] Trial 68 finished with value: 0.03462483170810149 and parameters: {'w0': 0.06174924843685186}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,804] Trial 69 finished with value: 0.03462483170810149 and parameters: {'w0': 0.9171234010205638}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,814] Trial 70 finished with value: 0.03462483170810149 and parameters: {'w0': 0.2835639691313442}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,823] Trial 71 finished with value: 0.03462483170810149 and parameters: {'w0': 0.0483852999671304}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,834] Trial 72 finished with value: 0.03462483170810149 and parameters: {'w0': 0.09460586360958943}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,844] Trial 73 finished with value: 0.03462483170810149 and parameters: {'w0': 0.14983450194190157}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,853] Trial 74 finished with value: 0.03462483170810149 and parameters: {'w0': 0.402639875664751}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,863] Trial 75 finished with value: 0.03462483170810149 and parameters: {'w0': 0.5007812898238053}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,874] Trial 76 finished with value: 0.03462483170810149 and parameters: {'w0': 0.20907355459207888}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,884] Trial 77 finished with value: 0.03462483170810149 and parameters: {'w0': 0.32990919090109416}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,894] Trial 78 finished with value: 0.03462483170810149 and parameters: {'w0': 0.11754834400457284}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,904] Trial 79 finished with value: 0.03462483170810149 and parameters: {'w0': 0.675567456039381}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,914] Trial 80 finished with value: 0.03462483170810149 and parameters: {'w0': 0.17522605325959734}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,924] Trial 81 finished with value: 0.03462483170810149 and parameters: {'w0': 0.03057395350429677}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,934] Trial 82 finished with value: 0.03462483170810149 and parameters: {'w0': 0.7758888364413319}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,944] Trial 83 finished with value: 0.03462483170810149 and parameters: {'w0': 0.004281541818140999}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,955] Trial 84 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8400534592978369}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,965] Trial 85 finished with value: 0.03462483170810149 and parameters: {'w0': 0.6179206648463791}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,975] Trial 86 finished with value: 0.03462483170810149 and parameters: {'w0': 0.732765646137329}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,985] Trial 87 finished with value: 0.03462483170810149 and parameters: {'w0': 0.08769292449341448}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:07,995] Trial 88 finished with value: 0.03462483170810149 and parameters: {'w0': 0.7940193019402594}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,004] Trial 89 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8880088857567994}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,016] Trial 90 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8563470907058701}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,025] Trial 91 finished with value: 0.03462483170810149 and parameters: {'w0': 0.1512807231265498}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,036] Trial 92 finished with value: 0.03462483170810149 and parameters: {'w0': 0.9646057514396525}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,046] Trial 93 finished with value: 0.03462483170810149 and parameters: {'w0': 0.04083005193693251}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,056] Trial 94 finished with value: 0.03462483170810149 and parameters: {'w0': 0.07458555789122234}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,065] Trial 95 finished with value: 0.03462483170810149 and parameters: {'w0': 0.12685277007411705}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,075] Trial 96 finished with value: 0.03462483170810149 and parameters: {'w0': 0.274109948307797}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,085] Trial 97 finished with value: 0.03462483170810149 and parameters: {'w0': 0.5251141462006448}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,095] Trial 98 finished with value: 0.03462483170810149 and parameters: {'w0': 0.46743702682760463}. Best is trial 0 with value: 0.03462483170810149.\n",
            "[I 2025-06-16 10:35:08,105] Trial 99 finished with value: 0.03462483170810149 and parameters: {'w0': 0.8203834763489367}. Best is trial 0 with value: 0.03462483170810149.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 1): 0.9654\n",
            "\n",
            "--- Training combination ('lgbm', 'mlp') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003454 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59557, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335990\n",
            "[LightGBM] [Info] Start training from score -3.552782\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.490298\n",
            "[LightGBM] [Info] Start training from score -3.098136\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.889684\n",
            "[LightGBM] [Info] Start training from score -3.745474\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.559841\n",
            "[LightGBM] [Info] Start training from score -3.296660\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.013298\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.864630\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.912287\n",
            "[LightGBM] [Info] Start training from score -2.909510\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.865219\n",
            "[LightGBM] [Info] Start training from score -3.521052\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.558072\n",
            "[LightGBM] [Info] Start training from score -3.457259\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 1): 0.9648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:35:32,876] A new study created in memory with name: no-name-25a75aa9-84b9-4c03-9196-54d53a7c526b\n",
            "[I 2025-06-16 10:35:32,883] Trial 0 finished with value: 0.033638649120905306 and parameters: {'w0': 0.5328312588451766, 'w1': 0.17719168015418185}. Best is trial 0 with value: 0.033638649120905306.\n",
            "[I 2025-06-16 10:35:32,889] Trial 1 finished with value: 0.033167824084819886 and parameters: {'w0': 0.42187058693979906, 'w1': 0.8291470876553095}. Best is trial 1 with value: 0.033167824084819886.\n",
            "[I 2025-06-16 10:35:32,895] Trial 2 finished with value: 0.033299915594961704 and parameters: {'w0': 0.3534338019848995, 'w1': 0.9033980938808216}. Best is trial 1 with value: 0.033167824084819886.\n",
            "[I 2025-06-16 10:35:32,900] Trial 3 finished with value: 0.03310781112097261 and parameters: {'w0': 0.07436571096220523, 'w1': 0.483061040982549}. Best is trial 3 with value: 0.03310781112097261.\n",
            "[I 2025-06-16 10:35:32,906] Trial 4 finished with value: 0.03296904952044155 and parameters: {'w0': 0.17428473127600075, 'w1': 0.814379509240689}. Best is trial 4 with value: 0.03296904952044155.\n",
            "[I 2025-06-16 10:35:32,911] Trial 5 finished with value: 0.03296709290441624 and parameters: {'w0': 0.6412965357754464, 'w1': 0.8097259832363451}. Best is trial 5 with value: 0.03296709290441624.\n",
            "[I 2025-06-16 10:35:32,917] Trial 6 finished with value: 0.033303340474174936 and parameters: {'w0': 0.13054002855520375, 'w1': 0.45134855060442547}. Best is trial 5 with value: 0.03296709290441624.\n",
            "[I 2025-06-16 10:35:32,923] Trial 7 finished with value: 0.03423287108101902 and parameters: {'w0': 0.5974423625555441, 'w1': 0.08040841407451405}. Best is trial 5 with value: 0.03296709290441624.\n",
            "[I 2025-06-16 10:35:32,929] Trial 8 finished with value: 0.03296709290441624 and parameters: {'w0': 0.3685928031399913, 'w1': 0.4731117204849564}. Best is trial 5 with value: 0.03296709290441624.\n",
            "[I 2025-06-16 10:35:32,934] Trial 9 finished with value: 0.03310918305841737 and parameters: {'w0': 0.12789983247561243, 'w1': 0.6563594425012311}. Best is trial 5 with value: 0.03296709290441624.\n",
            "[I 2025-06-16 10:35:32,947] Trial 10 finished with value: 0.03336759332666539 and parameters: {'w0': 0.8885950418195485, 'w1': 0.7107396209602272}. Best is trial 5 with value: 0.03296709290441624.\n",
            "[I 2025-06-16 10:35:32,961] Trial 11 finished with value: 0.0329637924203634 and parameters: {'w0': 0.7504655272166181, 'w1': 0.3362357030147831}. Best is trial 11 with value: 0.0329637924203634.\n",
            "[I 2025-06-16 10:35:32,974] Trial 12 finished with value: 0.033638649120905306 and parameters: {'w0': 0.7752177742047203, 'w1': 0.25708076663144647}. Best is trial 11 with value: 0.0329637924203634.\n",
            "[I 2025-06-16 10:35:32,987] Trial 13 finished with value: 0.032963213226715915 and parameters: {'w0': 0.7299832945781051, 'w1': 0.33441264399385173}. Best is trial 13 with value: 0.032963213226715915.\n",
            "[I 2025-06-16 10:35:33,000] Trial 14 finished with value: 0.033908206186507805 and parameters: {'w0': 0.9556627183977231, 'w1': 0.2993064277924956}. Best is trial 13 with value: 0.032963213226715915.\n",
            "[I 2025-06-16 10:35:33,013] Trial 15 finished with value: 0.03309954264358905 and parameters: {'w0': 0.7315271494308286, 'w1': 0.3531248979327284}. Best is trial 13 with value: 0.032963213226715915.\n",
            "[I 2025-06-16 10:35:33,026] Trial 16 finished with value: 0.0349026855413499 and parameters: {'w0': 0.79320434902408, 'w1': 0.02047325984678461}. Best is trial 13 with value: 0.032963213226715915.\n",
            "[I 2025-06-16 10:35:33,039] Trial 17 finished with value: 0.033303343325557955 and parameters: {'w0': 0.9899758903249971, 'w1': 0.6039606048687617}. Best is trial 13 with value: 0.032963213226715915.\n",
            "[I 2025-06-16 10:35:33,052] Trial 18 finished with value: 0.03397396717908918 and parameters: {'w0': 0.6736968286582558, 'w1': 0.1956416168488278}. Best is trial 13 with value: 0.032963213226715915.\n",
            "[I 2025-06-16 10:35:33,065] Trial 19 finished with value: 0.03296662434008424 and parameters: {'w0': 0.8383486840833775, 'w1': 0.3665251419992796}. Best is trial 13 with value: 0.032963213226715915.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted mlp (fold 1): 0.9672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:35:33,079] Trial 20 finished with value: 0.03296872467423795 and parameters: {'w0': 0.5328102803458263, 'w1': 0.5987421465650126}. Best is trial 13 with value: 0.032963213226715915.\n",
            "[I 2025-06-16 10:35:33,093] Trial 21 finished with value: 0.0329637924203634 and parameters: {'w0': 0.8391071606514483, 'w1': 0.37309575596457567}. Best is trial 13 with value: 0.032963213226715915.\n",
            "[I 2025-06-16 10:35:33,106] Trial 22 finished with value: 0.03289851725830362 and parameters: {'w0': 0.9031583807198802, 'w1': 0.3891337227428616}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,120] Trial 23 finished with value: 0.034244711368281444 and parameters: {'w0': 0.9163170908197886, 'w1': 0.17073851040443355}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,134] Trial 24 finished with value: 0.03336608664525853 and parameters: {'w0': 0.6771607266734361, 'w1': 0.5559250040841838}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,147] Trial 25 finished with value: 0.0331675180872848 and parameters: {'w0': 0.7343255634310395, 'w1': 0.4211644038068638}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,160] Trial 26 finished with value: 0.033638649120905306 and parameters: {'w0': 0.8882277137628102, 'w1': 0.2972634246361337}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,173] Trial 27 finished with value: 0.03323688293555971 and parameters: {'w0': 0.827342245893361, 'w1': 0.533422818334228}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,187] Trial 28 finished with value: 0.03310077214681395 and parameters: {'w0': 0.4598113204432009, 'w1': 0.2559359333046652}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,201] Trial 29 finished with value: 0.03396996897975013 and parameters: {'w0': 0.5807696898501491, 'w1': 0.151480732180684}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,214] Trial 30 finished with value: 0.0331675180872848 and parameters: {'w0': 0.7292850414615608, 'w1': 0.40889722622957614}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,227] Trial 31 finished with value: 0.03323934207366919 and parameters: {'w0': 0.8562987273926539, 'w1': 0.3470639524839513}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,241] Trial 32 finished with value: 0.03396627041026845 and parameters: {'w0': 0.9503155354476129, 'w1': 0.228768832462594}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,254] Trial 33 finished with value: 0.03310553712561448 and parameters: {'w0': 0.7765518141746802, 'w1': 0.3986313044622314}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,268] Trial 34 finished with value: 0.03309954264358905 and parameters: {'w0': 0.6197714870764787, 'w1': 0.2995588528711466}. Best is trial 22 with value: 0.03289851725830362.\n",
            "[I 2025-06-16 10:35:33,281] Trial 35 finished with value: 0.03289713599483912 and parameters: {'w0': 0.2665232190858894, 'w1': 0.11995658755527772}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,295] Trial 36 finished with value: 0.03289713599483912 and parameters: {'w0': 0.30224121521193215, 'w1': 0.13779270944545902}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,309] Trial 37 finished with value: 0.03289851725830362 and parameters: {'w0': 0.24898054663783786, 'w1': 0.10762525254620431}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,323] Trial 38 finished with value: 0.03337050685216425 and parameters: {'w0': 0.2822502555000921, 'w1': 0.10641450605423891}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,337] Trial 39 finished with value: 0.03431114311285921 and parameters: {'w0': 0.23988569746425534, 'w1': 0.042061893368408654}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,350] Trial 40 finished with value: 0.03337050685216425 and parameters: {'w0': 0.32956050414881816, 'w1': 0.1187969963510602}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,364] Trial 41 finished with value: 0.033303092691912894 and parameters: {'w0': 0.027868642543474847, 'w1': 0.057861837771643276}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,379] Trial 42 finished with value: 0.03303694529212464 and parameters: {'w0': 0.2051553054510982, 'w1': 0.9903920757262802}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,393] Trial 43 finished with value: 0.03497111585896673 and parameters: {'w0': 0.4238160554253948, 'w1': 0.00556524316819168}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,407] Trial 44 finished with value: 0.03289713599483912 and parameters: {'w0': 0.29751350546357375, 'w1': 0.13382482671748666}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,422] Trial 45 finished with value: 0.03289851725830362 and parameters: {'w0': 0.30875923151158424, 'w1': 0.13031358029060838}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,436] Trial 46 finished with value: 0.03424381483603789 and parameters: {'w0': 0.3835474926120242, 'w1': 0.08156839668239424}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,450] Trial 47 finished with value: 0.03296709290441624 and parameters: {'w0': 0.15425216660738306, 'w1': 0.2023292598348541}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,464] Trial 48 finished with value: 0.03304093559852794 and parameters: {'w0': 0.09329668166006266, 'w1': 0.7381221717323736}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,478] Trial 49 finished with value: 0.03370383709395253 and parameters: {'w0': 0.25707059544882455, 'w1': 0.08352829979179424}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,493] Trial 50 finished with value: 0.03349938176189404 and parameters: {'w0': 0.18880708271921431, 'w1': 0.1680876493026984}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,507] Trial 51 finished with value: 0.03297188373755877 and parameters: {'w0': 0.31597679792082334, 'w1': 0.13110937156464975}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,522] Trial 52 finished with value: 0.032963213226715915 and parameters: {'w0': 0.29259230335387193, 'w1': 0.13373001635706014}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,536] Trial 53 finished with value: 0.033303343325557955 and parameters: {'w0': 0.36960979222556334, 'w1': 0.231416470836191}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,550] Trial 54 finished with value: 0.03397396717908918 and parameters: {'w0': 0.22795559679664137, 'w1': 0.06560404972039752}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,564] Trial 55 finished with value: 0.03484626268952151 and parameters: {'w0': 0.47036388211149305, 'w1': 0.03215901278507692}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,579] Trial 56 finished with value: 0.033103728243526365 and parameters: {'w0': 0.39222720829760827, 'w1': 0.19518595817147377}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,593] Trial 57 finished with value: 0.033299915594961704 and parameters: {'w0': 0.10707808300377314, 'w1': 0.2678143199691315}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,607] Trial 58 finished with value: 0.03317148974376294 and parameters: {'w0': 0.2781636285393173, 'w1': 0.1108091964496083}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,621] Trial 59 finished with value: 0.033169016226216486 and parameters: {'w0': 0.3343407265943846, 'w1': 0.22546723712332029}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,636] Trial 60 finished with value: 0.034902690816468684 and parameters: {'w0': 0.03716294238270912, 'w1': 0.0015645649404376905}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,650] Trial 61 finished with value: 0.0331016464278876 and parameters: {'w0': 0.4165285092743281, 'w1': 0.4407803891846859}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,665] Trial 62 finished with value: 0.033171551859847326 and parameters: {'w0': 0.15115899208014066, 'w1': 0.16535383575165308}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,680] Trial 63 finished with value: 0.03303247062268844 and parameters: {'w0': 0.21289027143331998, 'w1': 0.3050997775186629}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,694] Trial 64 finished with value: 0.03316483288281957 and parameters: {'w0': 0.31043611572390184, 'w1': 0.5175310259081469}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,709] Trial 65 finished with value: 0.03337050685216425 and parameters: {'w0': 0.24903421661293337, 'w1': 0.09171107198733616}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,724] Trial 66 finished with value: 0.03310154808266019 and parameters: {'w0': 0.3505439073796772, 'w1': 0.4825304850429683}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,739] Trial 67 finished with value: 0.03383565088706897 and parameters: {'w0': 0.5531987359018606, 'w1': 0.14842701392228938}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,755] Trial 68 finished with value: 0.033638649120905306 and parameters: {'w0': 0.9881620565794549, 'w1': 0.32680948228475515}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,770] Trial 69 finished with value: 0.03383565088706897 and parameters: {'w0': 0.6768295718970075, 'w1': 0.18439504856483407}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,784] Trial 70 finished with value: 0.03336759332666539 and parameters: {'w0': 0.4991660857088164, 'w1': 0.39093288458489833}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,799] Trial 71 finished with value: 0.03316558517423307 and parameters: {'w0': 0.1861351364030062, 'w1': 0.14049907051914923}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,814] Trial 72 finished with value: 0.033432977192369595 and parameters: {'w0': 0.29827076573182215, 'w1': 0.2724294561510071}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,828] Trial 73 finished with value: 0.03336759332666539 and parameters: {'w0': 0.2775686917267604, 'w1': 0.21720442578247648}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,843] Trial 74 finished with value: 0.03437662655723839 and parameters: {'w0': 0.26398547891048046, 'w1': 0.04239367046851181}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,859] Trial 75 finished with value: 0.03337050685216425 and parameters: {'w0': 0.34244532167675573, 'w1': 0.1226161768617618}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,874] Trial 76 finished with value: 0.03323451604928074 and parameters: {'w0': 0.4089818424088019, 'w1': 0.24524616077253125}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,889] Trial 77 finished with value: 0.03423287108101902 and parameters: {'w0': 0.4545711678343559, 'w1': 0.06093019002406552}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,903] Trial 78 finished with value: 0.03370383709395253 and parameters: {'w0': 0.298157362133143, 'w1': 0.09635845619465949}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,917] Trial 79 finished with value: 0.033169016226216486 and parameters: {'w0': 0.22752344892371634, 'w1': 0.1473446535952375}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,932] Trial 80 finished with value: 0.034244711368281444 and parameters: {'w0': 0.9165435990815528, 'w1': 0.16664378146340061}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,947] Trial 81 finished with value: 0.033038260561242816 and parameters: {'w0': 0.643824788986435, 'w1': 0.3297910377664541}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,962] Trial 82 finished with value: 0.03403272716146244 and parameters: {'w0': 0.7950191361155197, 'w1': 0.2031347677990561}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,978] Trial 83 finished with value: 0.033038260561242816 and parameters: {'w0': 0.7049961630411802, 'w1': 0.36068162635307593}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:33,992] Trial 84 finished with value: 0.033038260561242816 and parameters: {'w0': 0.8784946312571976, 'w1': 0.44754109865806135}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,007] Trial 85 finished with value: 0.033234025690030644 and parameters: {'w0': 0.15805420479355606, 'w1': 0.27677102014237664}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,023] Trial 86 finished with value: 0.03423887564811223 and parameters: {'w0': 0.7550016413105065, 'w1': 0.11603811469293071}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,037] Trial 87 finished with value: 0.03303344608464254 and parameters: {'w0': 0.37061983362381057, 'w1': 0.3833988870470586}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,052] Trial 88 finished with value: 0.03343664578994687 and parameters: {'w0': 0.20528290229622315, 'w1': 0.07045673532227645}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,067] Trial 89 finished with value: 0.033098298448813845 and parameters: {'w0': 0.25791950931366875, 'w1': 0.41996276566914814}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,081] Trial 90 finished with value: 0.03323310961117787 and parameters: {'w0': 0.8130858484352369, 'w1': 0.6056583642057263}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,096] Trial 91 finished with value: 0.03317148974376294 and parameters: {'w0': 0.8490547601771825, 'w1': 0.3304394015179278}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,110] Trial 92 finished with value: 0.03310553712561448 and parameters: {'w0': 0.9030620459835305, 'w1': 0.4632276841826442}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,125] Trial 93 finished with value: 0.03317148974376294 and parameters: {'w0': 0.9392442493758965, 'w1': 0.3667883063261892}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,139] Trial 94 finished with value: 0.03323688293555971 and parameters: {'w0': 0.8646641750243026, 'w1': 0.555315900681008}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,154] Trial 95 finished with value: 0.03310578048517987 and parameters: {'w0': 0.7071591751106518, 'w1': 0.2910991468377718}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,169] Trial 96 finished with value: 0.03330194282355081 and parameters: {'w0': 0.825943601725102, 'w1': 0.502175450633307}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,184] Trial 97 finished with value: 0.03491215681073756 and parameters: {'w0': 0.32034591002805407, 'w1': 0.025918711309187326}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,199] Trial 98 finished with value: 0.03396627041026845 and parameters: {'w0': 0.7755078049158262, 'w1': 0.18540866431471512}. Best is trial 35 with value: 0.03289713599483912.\n",
            "[I 2025-06-16 10:35:34,214] Trial 99 finished with value: 0.03342987685817733 and parameters: {'w0': 0.28953334915703727, 'w1': 0.24138380423550637}. Best is trial 35 with value: 0.03289713599483912.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 1): 0.9671\n",
            "\n",
            "--- Training combination ('lgbm', 'logreg') ---\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59557, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335990\n",
            "[LightGBM] [Info] Start training from score -3.552782\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.490298\n",
            "[LightGBM] [Info] Start training from score -3.098136\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.889684\n",
            "[LightGBM] [Info] Start training from score -3.745474\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.559841\n",
            "[LightGBM] [Info] Start training from score -3.296660\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.013298\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.864630\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.912287\n",
            "[LightGBM] [Info] Start training from score -2.909510\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.865219\n",
            "[LightGBM] [Info] Start training from score -3.521052\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.558072\n",
            "[LightGBM] [Info] Start training from score -3.457259\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 1): 0.9648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:35:47,264] A new study created in memory with name: no-name-d69129b4-9040-4d24-8372-42779bd5053c\n",
            "[I 2025-06-16 10:35:47,273] Trial 0 finished with value: 0.034145338309124695 and parameters: {'w0': 0.2881794984120478, 'w1': 0.6672315520102653}. Best is trial 0 with value: 0.034145338309124695.\n",
            "[I 2025-06-16 10:35:47,281] Trial 1 finished with value: 0.03421391580775157 and parameters: {'w0': 0.26571303869451535, 'w1': 0.6889889206893501}. Best is trial 0 with value: 0.034145338309124695.\n",
            "[I 2025-06-16 10:35:47,289] Trial 2 finished with value: 0.03407358426750029 and parameters: {'w0': 0.23342311905974944, 'w1': 0.827585081838659}. Best is trial 2 with value: 0.03407358426750029.\n",
            "[I 2025-06-16 10:35:47,297] Trial 3 finished with value: 0.03437712796811543 and parameters: {'w0': 0.24204516436806522, 'w1': 0.07153929146719096}. Best is trial 2 with value: 0.03407358426750029.\n",
            "[I 2025-06-16 10:35:47,305] Trial 4 finished with value: 0.03387767305242717 and parameters: {'w0': 0.5117239150781359, 'w1': 0.8571054575285484}. Best is trial 4 with value: 0.03387767305242717.\n",
            "[I 2025-06-16 10:35:47,313] Trial 5 finished with value: 0.03387424544963169 and parameters: {'w0': 0.5013080695240284, 'w1': 0.4024577803456184}. Best is trial 5 with value: 0.03387424544963169.\n",
            "[I 2025-06-16 10:35:47,320] Trial 6 finished with value: 0.03420676668722822 and parameters: {'w0': 0.2376159665432026, 'w1': 0.913321165574156}. Best is trial 5 with value: 0.03387424544963169.\n",
            "[I 2025-06-16 10:35:47,328] Trial 7 finished with value: 0.0343236145116137 and parameters: {'w0': 0.821980100628543, 'w1': 0.4972382287407454}. Best is trial 5 with value: 0.03387424544963169.\n",
            "[I 2025-06-16 10:35:47,336] Trial 8 finished with value: 0.03373690675232188 and parameters: {'w0': 0.7103517630003153, 'w1': 0.6387086579869075}. Best is trial 8 with value: 0.03373690675232188.\n",
            "[I 2025-06-16 10:35:47,344] Trial 9 finished with value: 0.0344199641524241 and parameters: {'w0': 0.07033345658479295, 'w1': 0.8167179271686178}. Best is trial 8 with value: 0.03373690675232188.\n",
            "[I 2025-06-16 10:35:47,365] Trial 10 finished with value: 0.03437819362445249 and parameters: {'w0': 0.9748254960970103, 'w1': 0.305091145631731}. Best is trial 8 with value: 0.03373690675232188.\n",
            "[I 2025-06-16 10:35:47,380] Trial 11 finished with value: 0.03432344594752634 and parameters: {'w0': 0.6281222437059284, 'w1': 0.36956768132144713}. Best is trial 8 with value: 0.03373690675232188.\n",
            "[I 2025-06-16 10:35:47,394] Trial 12 finished with value: 0.03465102567207423 and parameters: {'w0': 0.6862118368249189, 'w1': 0.18485127560715053}. Best is trial 8 with value: 0.03373690675232188.\n",
            "[I 2025-06-16 10:35:47,409] Trial 13 finished with value: 0.03353980450065186 and parameters: {'w0': 0.46857599391269406, 'w1': 0.5395116612702282}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,423] Trial 14 finished with value: 0.033806091937290006 and parameters: {'w0': 0.7425009966641508, 'w1': 0.5999645307109629}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,437] Trial 15 finished with value: 0.03432344594752634 and parameters: {'w0': 0.871311997451802, 'w1': 0.5152721900900086}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,452] Trial 16 finished with value: 0.03367884354940209 and parameters: {'w0': 0.5790012372848548, 'w1': 0.7239131159190894}. Best is trial 13 with value: 0.03353980450065186.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 1): 0.9654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:35:47,466] Trial 17 finished with value: 0.03421171674274026 and parameters: {'w0': 0.4089647451695168, 'w1': 0.9955932306619282}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,479] Trial 18 finished with value: 0.033946015248710104 and parameters: {'w0': 0.42282307900148736, 'w1': 0.7517901801116533}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,493] Trial 19 finished with value: 0.03387071991681545 and parameters: {'w0': 0.5759504167065455, 'w1': 0.5085884069265375}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,507] Trial 20 finished with value: 0.03432344594752634 and parameters: {'w0': 0.3867819837160626, 'w1': 0.2266086452319186}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,521] Trial 21 finished with value: 0.03387339375351417 and parameters: {'w0': 0.7309111797345484, 'w1': 0.6028019621931648}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,536] Trial 22 finished with value: 0.03353980450065186 and parameters: {'w0': 0.6279705937416674, 'w1': 0.7187447694073821}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,550] Trial 23 finished with value: 0.03367884354940209 and parameters: {'w0': 0.5893621180558837, 'w1': 0.738796710519094}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,563] Trial 24 finished with value: 0.033803486167083396 and parameters: {'w0': 0.5258807927064362, 'w1': 0.5469999445051061}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,577] Trial 25 finished with value: 0.03408118953846362 and parameters: {'w0': 0.35008599663036777, 'w1': 0.7498162947033196}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,591] Trial 26 finished with value: 0.033938916713902256 and parameters: {'w0': 0.6247463150694644, 'w1': 0.4490227594803449}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,604] Trial 27 finished with value: 0.034207221611966876 and parameters: {'w0': 0.13988580280553992, 'w1': 0.9522601782277149}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,618] Trial 28 finished with value: 0.03360755731578402 and parameters: {'w0': 0.4607042193383903, 'w1': 0.6970162157924258}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,632] Trial 29 finished with value: 0.03360946782764185 and parameters: {'w0': 0.45030442169893353, 'w1': 0.6641342345324236}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,646] Trial 30 finished with value: 0.033811622153271714 and parameters: {'w0': 0.3343014004084818, 'w1': 0.5742088604800538}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,660] Trial 31 finished with value: 0.03360946782764185 and parameters: {'w0': 0.44958703115064785, 'w1': 0.6598270744826578}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,675] Trial 32 finished with value: 0.03354713971364187 and parameters: {'w0': 0.4566953006038875, 'w1': 0.6467941041872599}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,690] Trial 33 finished with value: 0.03414899091276946 and parameters: {'w0': 0.3478641797988547, 'w1': 0.7899351815176734}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,704] Trial 34 finished with value: 0.03367884354940209 and parameters: {'w0': 0.5283450792288448, 'w1': 0.6897257191125213}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,719] Trial 35 finished with value: 0.03407623239679802 and parameters: {'w0': 0.2809509870751883, 'w1': 0.8598757107467551}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,733] Trial 36 finished with value: 0.03511173790315536 and parameters: {'w0': 0.1884637260303661, 'w1': 0.016131713207879206}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,748] Trial 37 finished with value: 0.03360313004690563 and parameters: {'w0': 0.642644375925298, 'w1': 0.6203255567653669}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,762] Trial 38 finished with value: 0.03439143794158772 and parameters: {'w0': 0.7893646127724796, 'w1': 0.4713193919872453}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,777] Trial 39 finished with value: 0.03439413404220748 and parameters: {'w0': 0.6499201290641425, 'w1': 0.4178984682862775}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,791] Trial 40 finished with value: 0.033872889891106706 and parameters: {'w0': 0.8808060947460625, 'w1': 0.608361783569274}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,806] Trial 41 finished with value: 0.03354713971364187 and parameters: {'w0': 0.49478738626036967, 'w1': 0.6990380826845337}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,820] Trial 42 finished with value: 0.03373612282275906 and parameters: {'w0': 0.5065903324923945, 'w1': 0.5421589469228787}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,835] Trial 43 finished with value: 0.03354713971364187 and parameters: {'w0': 0.5531799593568959, 'w1': 0.7939833065266643}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,849] Trial 44 finished with value: 0.033946015248710104 and parameters: {'w0': 0.47470208596902136, 'w1': 0.8658695734259139}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,864] Trial 45 finished with value: 0.033542522688100096 and parameters: {'w0': 0.5398175823490203, 'w1': 0.790677498359421}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,878] Trial 46 finished with value: 0.03421171674274026 and parameters: {'w0': 0.3776564438266327, 'w1': 0.9055504567628263}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,893] Trial 47 finished with value: 0.0342831140130716 and parameters: {'w0': 0.3076369784331424, 'w1': 0.7955936057981811}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,907] Trial 48 finished with value: 0.03458989016892933 and parameters: {'w0': 0.6674267523583934, 'w1': 0.34693618128564363}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,921] Trial 49 finished with value: 0.0346263827099631 and parameters: {'w0': 0.008658475150431943, 'w1': 0.7085457887679527}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,936] Trial 50 finished with value: 0.03366986620410228 and parameters: {'w0': 0.6074928891288665, 'w1': 0.6518255639184631}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,951] Trial 51 finished with value: 0.03367962335702246 and parameters: {'w0': 0.5621146874858847, 'w1': 0.7743650849886102}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,966] Trial 52 finished with value: 0.03374071655199584 and parameters: {'w0': 0.54446041109938, 'w1': 0.8447008930600556}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,981] Trial 53 finished with value: 0.033946015248710104 and parameters: {'w0': 0.5010668694887922, 'w1': 0.8893020400618896}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:47,996] Trial 54 finished with value: 0.03387767305242717 and parameters: {'w0': 0.4805896936495575, 'w1': 0.8108361331491634}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:48,011] Trial 55 finished with value: 0.03367884354940209 and parameters: {'w0': 0.5550137193490992, 'w1': 0.7265751833710569}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:48,026] Trial 56 finished with value: 0.03387307362351333 and parameters: {'w0': 0.7040383968119254, 'w1': 0.566167401576074}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:48,040] Trial 57 finished with value: 0.03401459020002795 and parameters: {'w0': 0.41078310029067566, 'w1': 0.7743568201667083}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:48,053] Trial 58 finished with value: 0.0338722652216098 and parameters: {'w0': 0.7626706635988936, 'w1': 0.6411129634434973}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:48,070] Trial 59 finished with value: 0.03401475907717888 and parameters: {'w0': 0.4260810092026262, 'w1': 0.8279799087476185}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:48,084] Trial 60 finished with value: 0.03361454852167434 and parameters: {'w0': 0.6796830677666517, 'w1': 0.9466285472761458}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:48,099] Trial 61 finished with value: 0.033672629802118714 and parameters: {'w0': 0.6321266505691194, 'w1': 0.6183747675311874}. Best is trial 13 with value: 0.03353980450065186.\n",
            "[I 2025-06-16 10:35:48,114] Trial 62 finished with value: 0.03353864583305344 and parameters: {'w0': 0.5963784852019114, 'w1': 0.6979994819756911}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,128] Trial 63 finished with value: 0.03367884354940209 and parameters: {'w0': 0.5793944298841522, 'w1': 0.7509044467600606}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,143] Trial 64 finished with value: 0.03360264899696164 and parameters: {'w0': 0.6089923922505469, 'w1': 0.6851114583263502}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,158] Trial 65 finished with value: 0.033613502537640505 and parameters: {'w0': 0.520860342629589, 'w1': 0.712855303027061}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,173] Trial 66 finished with value: 0.033539960969937055 and parameters: {'w0': 0.47757169865563714, 'w1': 0.5734715551676827}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,187] Trial 67 finished with value: 0.03360755731578402 and parameters: {'w0': 0.3782040379690239, 'w1': 0.5775558626461994}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,202] Trial 68 finished with value: 0.033672629802118714 and parameters: {'w0': 0.4837915573430563, 'w1': 0.4719927507983418}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,215] Trial 69 finished with value: 0.03353864583305344 and parameters: {'w0': 0.4442243327736889, 'w1': 0.5254415192740328}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,229] Trial 70 finished with value: 0.03367884354940209 and parameters: {'w0': 0.410406004379143, 'w1': 0.5267710511520252}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,243] Trial 71 finished with value: 0.0336677701379956 and parameters: {'w0': 0.4441946147272368, 'w1': 0.4925700963624573}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,258] Trial 72 finished with value: 0.033672629802118714 and parameters: {'w0': 0.5934727860738904, 'w1': 0.5769062265711364}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,272] Trial 73 finished with value: 0.03367884354940209 and parameters: {'w0': 0.5262671966747922, 'w1': 0.6726261096765955}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,286] Trial 74 finished with value: 0.03354713971364187 and parameters: {'w0': 0.4504088159315298, 'w1': 0.6385343164729125}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,301] Trial 75 finished with value: 0.033872877386937894 and parameters: {'w0': 0.5029723994465506, 'w1': 0.39130870541191753}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,315] Trial 76 finished with value: 0.033879554753647345 and parameters: {'w0': 0.3088385957377753, 'w1': 0.5403191425303517}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,330] Trial 77 finished with value: 0.03360755731578402 and parameters: {'w0': 0.3961557513653581, 'w1': 0.6026184570980649}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,344] Trial 78 finished with value: 0.03360313004690563 and parameters: {'w0': 0.47720305291727033, 'w1': 0.44811487056609367}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,359] Trial 79 finished with value: 0.03401475907717888 and parameters: {'w0': 0.35661614171585015, 'w1': 0.680651637300615}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,374] Trial 80 finished with value: 0.03360313004690563 and parameters: {'w0': 0.537655239295409, 'w1': 0.5054264503428545}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,390] Trial 81 finished with value: 0.03361374911870063 and parameters: {'w0': 0.5615389942500697, 'w1': 0.7552854592143534}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,405] Trial 82 finished with value: 0.03387767305242717 and parameters: {'w0': 0.4277092977003983, 'w1': 0.7102215711367812}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,420] Trial 83 finished with value: 0.03367884354940209 and parameters: {'w0': 0.6100860429000723, 'w1': 0.7776526887919392}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,434] Trial 84 finished with value: 0.03424632986770104 and parameters: {'w0': 0.4659097795506507, 'w1': 0.150755615689683}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,448] Trial 85 finished with value: 0.033672629802118714 and parameters: {'w0': 0.6497551002280988, 'w1': 0.6374190709304348}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,463] Trial 86 finished with value: 0.03394525601942888 and parameters: {'w0': 0.49033950381478125, 'w1': 0.8132183916546393}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,477] Trial 87 finished with value: 0.03373732336742674 and parameters: {'w0': 0.5860683205107322, 'w1': 0.595674425101641}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,492] Trial 88 finished with value: 0.03361374911870063 and parameters: {'w0': 0.545076726075442, 'w1': 0.7349733224622682}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,505] Trial 89 finished with value: 0.03367884354940209 and parameters: {'w0': 0.5144349569238583, 'w1': 0.6589373594139316}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,521] Trial 90 finished with value: 0.03380486854004483 and parameters: {'w0': 0.7116162822191299, 'w1': 0.5574450464347671}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,536] Trial 91 finished with value: 0.03354713971364187 and parameters: {'w0': 0.44016789812723434, 'w1': 0.6296045211381892}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,552] Trial 92 finished with value: 0.03360755731578402 and parameters: {'w0': 0.45588339069295347, 'w1': 0.6949285750906237}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,568] Trial 93 finished with value: 0.033737076039307534 and parameters: {'w0': 0.49797161909742726, 'w1': 0.5276886106459168}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,583] Trial 94 finished with value: 0.033805039451900165 and parameters: {'w0': 0.5642824342031693, 'w1': 0.5923186390735928}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,598] Trial 95 finished with value: 0.03387767305242717 and parameters: {'w0': 0.3916686842972281, 'w1': 0.6550243228281986}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,613] Trial 96 finished with value: 0.03380763945683796 and parameters: {'w0': 0.4624764843672317, 'w1': 0.7304016852984307}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,627] Trial 97 finished with value: 0.034145338309124695 and parameters: {'w0': 0.3626843221323294, 'w1': 0.8337638731811365}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,642] Trial 98 finished with value: 0.03421171674274026 and parameters: {'w0': 0.3295837137985713, 'w1': 0.793409095397434}. Best is trial 62 with value: 0.03353864583305344.\n",
            "[I 2025-06-16 10:35:48,658] Trial 99 finished with value: 0.03394525601942888 and parameters: {'w0': 0.5315071850730093, 'w1': 0.8797268173998715}. Best is trial 62 with value: 0.03353864583305344.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 1): 0.9665\n",
            "\n",
            "--- Training combination ('mlp', 'logreg') ---\n",
            "F1-weighted mlp (fold 1): 0.9668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:36:09,215] A new study created in memory with name: no-name-afb83713-95b7-4674-9bb4-9e0c20a23320\n",
            "[I 2025-06-16 10:36:09,224] Trial 0 finished with value: 0.0334992530308057 and parameters: {'w0': 0.5364820031925803, 'w1': 0.42898245472102825}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,232] Trial 1 finished with value: 0.03379471579550708 and parameters: {'w0': 0.075792585782679, 'w1': 0.19079761544899299}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,240] Trial 2 finished with value: 0.03419762835065843 and parameters: {'w0': 0.12720385848416504, 'w1': 0.551808387370231}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,248] Trial 3 finished with value: 0.0336952758537975 and parameters: {'w0': 0.5500037135818696, 'w1': 0.045833390094232485}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,259] Trial 4 finished with value: 0.03392917767965331 and parameters: {'w0': 0.3636235408349605, 'w1': 0.9785721175317211}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,267] Trial 5 finished with value: 0.03356934644958387 and parameters: {'w0': 0.6344213981149533, 'w1': 0.5708578362789078}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,275] Trial 6 finished with value: 0.03392917767965331 and parameters: {'w0': 0.250734012731065, 'w1': 0.674186950070207}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,283] Trial 7 finished with value: 0.033519790559332185 and parameters: {'w0': 0.2834537334892755, 'w1': 0.5666088594246459}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,291] Trial 8 finished with value: 0.03356507144873311 and parameters: {'w0': 0.17379123704317545, 'w1': 0.06793349432268836}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,299] Trial 9 finished with value: 0.03356068591407624 and parameters: {'w0': 0.49412332674095816, 'w1': 0.054387621441402856}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,319] Trial 10 finished with value: 0.03356507144873311 and parameters: {'w0': 0.9727477683280324, 'w1': 0.3570109785011962}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,335] Trial 11 finished with value: 0.03350577838183033 and parameters: {'w0': 0.728077298418564, 'w1': 0.7821449752799803}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,348] Trial 12 finished with value: 0.03350577838183033 and parameters: {'w0': 0.7750828666412147, 'w1': 0.8336765287898112}. Best is trial 0 with value: 0.0334992530308057.\n",
            "[I 2025-06-16 10:36:09,362] Trial 13 finished with value: 0.03336306514576459 and parameters: {'w0': 0.7856711489309235, 'w1': 0.37148049487304324}. Best is trial 13 with value: 0.03336306514576459.\n",
            "[I 2025-06-16 10:36:09,375] Trial 14 finished with value: 0.03356507144873311 and parameters: {'w0': 0.9008289237014315, 'w1': 0.35016619451968156}. Best is trial 13 with value: 0.03336306514576459.\n",
            "[I 2025-06-16 10:36:09,388] Trial 15 finished with value: 0.03336269805899561 and parameters: {'w0': 0.4600055181949463, 'w1': 0.3479602535957831}. Best is trial 15 with value: 0.03336269805899561.\n",
            "[I 2025-06-16 10:36:09,402] Trial 16 finished with value: 0.033226458442761175 and parameters: {'w0': 0.4197166900935664, 'w1': 0.2277751377428905}. Best is trial 16 with value: 0.033226458442761175.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 1): 0.9654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:36:09,416] Trial 17 finished with value: 0.033226458442761175 and parameters: {'w0': 0.4207625865626656, 'w1': 0.2213650805246743}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,430] Trial 18 finished with value: 0.03329386160907066 and parameters: {'w0': 0.3916024481688522, 'w1': 0.1998951262530081}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,445] Trial 19 finished with value: 0.03356507144873311 and parameters: {'w0': 0.6409904369545069, 'w1': 0.21046028806219755}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,459] Trial 20 finished with value: 0.03441135226512304 and parameters: {'w0': 0.01006370860620398, 'w1': 0.261633369024723}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,473] Trial 21 finished with value: 0.03356507144873311 and parameters: {'w0': 0.378021208767794, 'w1': 0.1547387791249884}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,487] Trial 22 finished with value: 0.033294404025748014 and parameters: {'w0': 0.3955436138268264, 'w1': 0.2683575730582811}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,500] Trial 23 finished with value: 0.03329386160907066 and parameters: {'w0': 0.3011103815500671, 'w1': 0.15691731287457733}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,514] Trial 24 finished with value: 0.03356356179399422 and parameters: {'w0': 0.43782665724577297, 'w1': 0.12071246904223025}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,528] Trial 25 finished with value: 0.03343099926912385 and parameters: {'w0': 0.6058362752538394, 'w1': 0.46950660471385064}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,542] Trial 26 finished with value: 0.0338254650580635 and parameters: {'w0': 0.21262016840518339, 'w1': 0.0012359012478952436}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,556] Trial 27 finished with value: 0.0334992530308057 and parameters: {'w0': 0.324233709149032, 'w1': 0.27106987484035505}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,570] Trial 28 finished with value: 0.033294404025748014 and parameters: {'w0': 0.43075773361496145, 'w1': 0.27440557177530794}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,584] Trial 29 finished with value: 0.0334992530308057 and parameters: {'w0': 0.5462484909652018, 'w1': 0.44544558015816593}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,599] Trial 30 finished with value: 0.03362679108899158 and parameters: {'w0': 0.5127854809710276, 'w1': 0.10275535407547498}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,614] Trial 31 finished with value: 0.033294404025748014 and parameters: {'w0': 0.31463662290702615, 'w1': 0.19511437436721948}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,628] Trial 32 finished with value: 0.0334992530308057 and parameters: {'w0': 0.21609322490526173, 'w1': 0.17705363645064343}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,642] Trial 33 finished with value: 0.033294404025748014 and parameters: {'w0': 0.34417079266632217, 'w1': 0.22608489173680124}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,656] Trial 34 finished with value: 0.03356934644958387 and parameters: {'w0': 0.14790380943891418, 'w1': 0.13274860712163108}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,669] Trial 35 finished with value: 0.0338254650580635 and parameters: {'w0': 0.27483684596649155, 'w1': 0.004898868157017455}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,683] Trial 36 finished with value: 0.03343099926912385 and parameters: {'w0': 0.4021753039449016, 'w1': 0.3151612784781842}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,697] Trial 37 finished with value: 0.03356934644958387 and parameters: {'w0': 0.4634504195014745, 'w1': 0.4120273026567153}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,711] Trial 38 finished with value: 0.0336400887168129 and parameters: {'w0': 0.07822732015397271, 'w1': 0.0925140469676975}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,725] Trial 39 finished with value: 0.0334992530308057 and parameters: {'w0': 0.594521784048488, 'w1': 0.5064822797432299}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,739] Trial 40 finished with value: 0.03356934644958387 and parameters: {'w0': 0.2508245461186618, 'w1': 0.228502098582259}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,753] Trial 41 finished with value: 0.03336269805899561 and parameters: {'w0': 0.3827122812509403, 'w1': 0.2899176099159604}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,767] Trial 42 finished with value: 0.03322726649641483 and parameters: {'w0': 0.32811131306993657, 'w1': 0.1645353178974136}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,780] Trial 43 finished with value: 0.03343000772043292 and parameters: {'w0': 0.33240267613281366, 'w1': 0.15276775198152343}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,794] Trial 44 finished with value: 0.03356068591407624 and parameters: {'w0': 0.4900445313806633, 'w1': 0.05933386567741125}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,808] Trial 45 finished with value: 0.03350577838183033 and parameters: {'w0': 0.19019379932136962, 'w1': 0.1786295417590171}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,822] Trial 46 finished with value: 0.03343099926912385 and parameters: {'w0': 0.28235556023918174, 'w1': 0.2211187254298206}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,836] Trial 47 finished with value: 0.03352072759308822 and parameters: {'w0': 0.42160747157705514, 'w1': 0.9722772104509201}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,850] Trial 48 finished with value: 0.033926846694635304 and parameters: {'w0': 0.11518273893976896, 'w1': 0.4046682944977152}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,864] Trial 49 finished with value: 0.03362648685412806 and parameters: {'w0': 0.3052833439897635, 'w1': 0.041313175276420866}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,878] Trial 50 finished with value: 0.03351085765851125 and parameters: {'w0': 0.36304349925925394, 'w1': 0.6036437352716713}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,891] Trial 51 finished with value: 0.033294404025748014 and parameters: {'w0': 0.3990365854818952, 'w1': 0.25127492474290725}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,905] Trial 52 finished with value: 0.033294404025748014 and parameters: {'w0': 0.4807295274502538, 'w1': 0.33749219306406264}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,920] Trial 53 finished with value: 0.033294404025748014 and parameters: {'w0': 0.521771915658455, 'w1': 0.3041791047481803}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,934] Trial 54 finished with value: 0.033294404025748014 and parameters: {'w0': 0.24172677001872384, 'w1': 0.14340600859810806}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,949] Trial 55 finished with value: 0.03369291865988111 and parameters: {'w0': 0.5781872552193073, 'w1': 0.08730874414074777}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,964] Trial 56 finished with value: 0.0334992530308057 and parameters: {'w0': 0.44433350563933205, 'w1': 0.37942911544663865}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,978] Trial 57 finished with value: 0.03322726649641483 and parameters: {'w0': 0.3616813984741967, 'w1': 0.18090312895364005}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:09,993] Trial 58 finished with value: 0.033226458442761175 and parameters: {'w0': 0.3619412230297697, 'w1': 0.1997292067369303}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,007] Trial 59 finished with value: 0.033294404025748014 and parameters: {'w0': 0.34968368256180493, 'w1': 0.20958220987954507}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,022] Trial 60 finished with value: 0.03369291865988111 and parameters: {'w0': 0.6571167924711847, 'w1': 0.11014060100203414}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,036] Trial 61 finished with value: 0.033294404025748014 and parameters: {'w0': 0.2995496168643781, 'w1': 0.17349768390924547}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,051] Trial 62 finished with value: 0.033294404025748014 and parameters: {'w0': 0.36509016604008504, 'w1': 0.25082313900290176}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,065] Trial 63 finished with value: 0.03363267344522147 and parameters: {'w0': 0.4132729355049682, 'w1': 0.132253762257723}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,080] Trial 64 finished with value: 0.03369291865988111 and parameters: {'w0': 0.2589621928042224, 'w1': 0.0404966884114622}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,094] Trial 65 finished with value: 0.03356507144873311 and parameters: {'w0': 0.46256192053598666, 'w1': 0.19373775951619776}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,108] Trial 66 finished with value: 0.03336269805899561 and parameters: {'w0': 0.33004573385232155, 'w1': 0.2390495022440908}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,123] Trial 67 finished with value: 0.0334992530308057 and parameters: {'w0': 0.3926464620723039, 'w1': 0.32835266925338435}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,138] Trial 68 finished with value: 0.03336269805899561 and parameters: {'w0': 0.22164408489103293, 'w1': 0.16655403590797174}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,152] Trial 69 finished with value: 0.03369291865988111 and parameters: {'w0': 0.5414593350336424, 'w1': 0.0795135355105475}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,167] Trial 70 finished with value: 0.03358532882851717 and parameters: {'w0': 0.4294085267525565, 'w1': 0.7598783349885702}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,181] Trial 71 finished with value: 0.033226458442761175 and parameters: {'w0': 0.37061288386213637, 'w1': 0.2000952828210979}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,195] Trial 72 finished with value: 0.033294404025748014 and parameters: {'w0': 0.2944133135708874, 'w1': 0.2002712293652158}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,209] Trial 73 finished with value: 0.03336269805899561 and parameters: {'w0': 0.36482681736730627, 'w1': 0.2746547377367351}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,224] Trial 74 finished with value: 0.03356507144873311 and parameters: {'w0': 0.330971189923547, 'w1': 0.11989166188940747}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,239] Trial 75 finished with value: 0.03363267344522147 and parameters: {'w0': 0.49628704212838093, 'w1': 0.16084095710576748}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,254] Trial 76 finished with value: 0.033294404025748014 and parameters: {'w0': 0.4586343934952032, 'w1': 0.29657220327609324}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,270] Trial 77 finished with value: 0.033294404025748014 and parameters: {'w0': 0.3766369283789641, 'w1': 0.22929396224967918}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,284] Trial 78 finished with value: 0.03357372634700795 and parameters: {'w0': 0.17855672939395578, 'w1': 0.19376269760705622}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,298] Trial 79 finished with value: 0.03362935542280143 and parameters: {'w0': 0.2700931859345541, 'w1': 0.026725769487620732}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,312] Trial 80 finished with value: 0.03356507144873311 and parameters: {'w0': 0.3150179487969131, 'w1': 0.10758552053167304}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,326] Trial 81 finished with value: 0.033294404025748014 and parameters: {'w0': 0.4282295227200008, 'w1': 0.2592241840171017}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,340] Trial 82 finished with value: 0.033226458442761175 and parameters: {'w0': 0.40398688393911897, 'w1': 0.21515294672042234}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,355] Trial 83 finished with value: 0.03356507144873311 and parameters: {'w0': 0.3488234676419965, 'w1': 0.1407346686612814}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,370] Trial 84 finished with value: 0.033226458442761175 and parameters: {'w0': 0.4082300234488923, 'w1': 0.21475432007304437}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,384] Trial 85 finished with value: 0.033226458442761175 and parameters: {'w0': 0.39561228887056926, 'w1': 0.2133750175596063}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,398] Trial 86 finished with value: 0.033226458442761175 and parameters: {'w0': 0.40709910780152914, 'w1': 0.21966809881536717}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,412] Trial 87 finished with value: 0.033294404025748014 and parameters: {'w0': 0.47259116839684384, 'w1': 0.29343055706760257}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,426] Trial 88 finished with value: 0.033226458442761175 and parameters: {'w0': 0.40842674703447596, 'w1': 0.22305874730187525}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,442] Trial 89 finished with value: 0.033294404025748014 and parameters: {'w0': 0.509938995529409, 'w1': 0.3174645971589254}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,458] Trial 90 finished with value: 0.0334992530308057 and parameters: {'w0': 0.4472421481445232, 'w1': 0.36049108493648324}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,472] Trial 91 finished with value: 0.033226458442761175 and parameters: {'w0': 0.40575936842831567, 'w1': 0.2264947419323741}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,487] Trial 92 finished with value: 0.033226458442761175 and parameters: {'w0': 0.4007875412532329, 'w1': 0.2276744310857275}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,500] Trial 93 finished with value: 0.033294404025748014 and parameters: {'w0': 0.4099121720593904, 'w1': 0.2724033087628168}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,515] Trial 94 finished with value: 0.033226458442761175 and parameters: {'w0': 0.3829535346147477, 'w1': 0.2097234051042919}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,530] Trial 95 finished with value: 0.033563381166703765 and parameters: {'w0': 0.9786281257081957, 'w1': 0.24967950793924953}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,544] Trial 96 finished with value: 0.03336306514576459 and parameters: {'w0': 0.4404145634126699, 'w1': 0.2149184713632278}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,558] Trial 97 finished with value: 0.03356507144873311 and parameters: {'w0': 0.8512381586948667, 'w1': 0.2768427963151557}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,572] Trial 98 finished with value: 0.03356507144873311 and parameters: {'w0': 0.48638443586627567, 'w1': 0.18584726340647262}. Best is trial 16 with value: 0.033226458442761175.\n",
            "[I 2025-06-16 10:36:10,587] Trial 99 finished with value: 0.033226458442761175 and parameters: {'w0': 0.4140823450847138, 'w1': 0.23205417173951925}. Best is trial 16 with value: 0.033226458442761175.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 1): 0.9668\n",
            "\n",
            "--- Training combination ('lgbm', 'mlp', 'logreg') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003338 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59557, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335990\n",
            "[LightGBM] [Info] Start training from score -3.552782\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.490298\n",
            "[LightGBM] [Info] Start training from score -3.098136\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.889684\n",
            "[LightGBM] [Info] Start training from score -3.745474\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.559841\n",
            "[LightGBM] [Info] Start training from score -3.296660\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.013298\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.864630\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.912287\n",
            "[LightGBM] [Info] Start training from score -2.909510\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.865219\n",
            "[LightGBM] [Info] Start training from score -3.521052\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.558072\n",
            "[LightGBM] [Info] Start training from score -3.457259\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 1): 0.9648\n",
            "F1-weighted mlp (fold 1): 0.9670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:36:36,907] A new study created in memory with name: no-name-3ebb6ea7-373c-45d9-860c-f0802d0597ce\n",
            "[I 2025-06-16 10:36:36,917] Trial 0 finished with value: 0.03336945113661183 and parameters: {'w0': 0.6841590003160316, 'w1': 0.6348572218226902, 'w2': 0.20423913155052698}. Best is trial 0 with value: 0.03336945113661183.\n",
            "[I 2025-06-16 10:36:36,928] Trial 1 finished with value: 0.033673119104524196 and parameters: {'w0': 0.7901811973131023, 'w1': 0.11248753495936703, 'w2': 0.7719228075215062}. Best is trial 0 with value: 0.03336945113661183.\n",
            "[I 2025-06-16 10:36:36,938] Trial 2 finished with value: 0.03311346614057842 and parameters: {'w0': 0.2965255375219499, 'w1': 0.19636832539415816, 'w2': 0.16142100142090832}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:36,950] Trial 3 finished with value: 0.0337183858082023 and parameters: {'w0': 0.7662185864617044, 'w1': 0.9793953891233756, 'w2': 0.7102061252214048}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:36,961] Trial 4 finished with value: 0.03371403406978046 and parameters: {'w0': 0.11714458106158909, 'w1': 0.562258661967536, 'w2': 0.0075394004560802586}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:36,969] Trial 5 finished with value: 0.034049015670705174 and parameters: {'w0': 0.23762995300296597, 'w1': 0.9347912633112011, 'w2': 0.8868232453679621}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:36,978] Trial 6 finished with value: 0.03379323525446076 and parameters: {'w0': 0.5544060146103295, 'w1': 0.7413771967033275, 'w2': 0.7218741861634702}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:36,987] Trial 7 finished with value: 0.033249682398370894 and parameters: {'w0': 0.6857702342351604, 'w1': 0.5951007943387217, 'w2': 0.497548957725634}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:36,996] Trial 8 finished with value: 0.033308857787607726 and parameters: {'w0': 0.7560458008459688, 'w1': 0.35589324441486647, 'w2': 0.33157223482513}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,004] Trial 9 finished with value: 0.03405209046636892 and parameters: {'w0': 0.41635442206967355, 'w1': 0.7715473114230524, 'w2': 0.7496182469212768}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,026] Trial 10 finished with value: 0.03490491372546467 and parameters: {'w0': 0.9949192639688527, 'w1': 0.009671085977441235, 'w2': 0.01954156856739178}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,044] Trial 11 finished with value: 0.03372721966719017 and parameters: {'w0': 0.34011110689219504, 'w1': 0.33773990930422765, 'w2': 0.4922125503336177}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,061] Trial 12 finished with value: 0.03432501060059545 and parameters: {'w0': 0.06270295577320506, 'w1': 0.37423341149796063, 'w2': 0.4697284884560828}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,078] Trial 13 finished with value: 0.03351440915283521 and parameters: {'w0': 0.5391770073130804, 'w1': 0.20687377180293376, 'w2': 0.2673942634747499}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,096] Trial 14 finished with value: 0.033777498981066856 and parameters: {'w0': 0.24891359908243615, 'w1': 0.4470742336811592, 'w2': 0.13615595232314803}. Best is trial 2 with value: 0.03311346614057842.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 1): 0.9654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:36:37,114] Trial 15 finished with value: 0.03398639530350056 and parameters: {'w0': 0.9924940782822983, 'w1': 0.1641062318060137, 'w2': 0.35362492347898317}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,131] Trial 16 finished with value: 0.033386066638611545 and parameters: {'w0': 0.6060876614506014, 'w1': 0.536882665681837, 'w2': 0.5474003381806636}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,149] Trial 17 finished with value: 0.034063021433093144 and parameters: {'w0': 0.47078402644043044, 'w1': 0.7267596161549262, 'w2': 0.9876050717678327}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,166] Trial 18 finished with value: 0.0338013573032131 and parameters: {'w0': 0.8707726974927732, 'w1': 0.27182418820202603, 'w2': 0.6259039448025376}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,183] Trial 19 finished with value: 0.03353907812218715 and parameters: {'w0': 0.34544158627270516, 'w1': 0.013101786186107356, 'w2': 0.3915378291229795}. Best is trial 2 with value: 0.03311346614057842.\n",
            "[I 2025-06-16 10:36:37,201] Trial 20 finished with value: 0.03310320777840048 and parameters: {'w0': 0.639068082637661, 'w1': 0.46127614198550104, 'w2': 0.13237965731083215}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,219] Trial 21 finished with value: 0.03322762968447324 and parameters: {'w0': 0.6461666952728605, 'w1': 0.6482095187921025, 'w2': 0.1644211617023364}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,237] Trial 22 finished with value: 0.03310320777840048 and parameters: {'w0': 0.6704891965201228, 'w1': 0.467163687375567, 'w2': 0.11754910952784743}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,255] Trial 23 finished with value: 0.03342592418289103 and parameters: {'w0': 0.47174487702348783, 'w1': 0.46098266731089804, 'w2': 0.09271516997788859}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,273] Trial 24 finished with value: 0.033725378026613684 and parameters: {'w0': 0.19859647821223925, 'w1': 0.25270020634662593, 'w2': 0.23556019780713566}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,291] Trial 25 finished with value: 0.03316109698122982 and parameters: {'w0': 0.39156643325801116, 'w1': 0.433011937121319, 'w2': 0.09137357470636284}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,309] Trial 26 finished with value: 0.03350899094083404 and parameters: {'w0': 0.8790377653116552, 'w1': 0.2962392665436732, 'w2': 0.2980403909756968}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,327] Trial 27 finished with value: 0.03417491708498499 and parameters: {'w0': 0.6152893899633907, 'w1': 0.11083841354173696, 'w2': 0.08123298168652879}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,345] Trial 28 finished with value: 0.0335748004536639 and parameters: {'w0': 0.3096235853136881, 'w1': 0.4006538380184695, 'w2': 0.18255568706955488}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,363] Trial 29 finished with value: 0.0331722380799504 and parameters: {'w0': 0.7190948046795518, 'w1': 0.508861778133485, 'w2': 0.2544123312101042}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,381] Trial 30 finished with value: 0.03357990948203149 and parameters: {'w0': 0.5428527574648845, 'w1': 0.6520798159592806, 'w2': 0.40793092654573604}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,399] Trial 31 finished with value: 0.03322762968447324 and parameters: {'w0': 0.4090520372136643, 'w1': 0.41748510687431695, 'w2': 0.08209529054186979}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,417] Trial 32 finished with value: 0.033843308226486624 and parameters: {'w0': 0.41193641969145306, 'w1': 0.11793196011573517, 'w2': 0.12888744294814697}. Best is trial 20 with value: 0.03310320777840048.\n",
            "[I 2025-06-16 10:36:37,435] Trial 33 finished with value: 0.03310204133969663 and parameters: {'w0': 0.8629186208360933, 'w1': 0.4887230231049436, 'w2': 0.20005850807798173}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,454] Trial 34 finished with value: 0.033364080017334485 and parameters: {'w0': 0.8712159909518046, 'w1': 0.8391192094900568, 'w2': 0.2141214896716848}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,473] Trial 35 finished with value: 0.03322947019523259 and parameters: {'w0': 0.7872976968731169, 'w1': 0.5708457367567388, 'w2': 0.008187067578640142}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,492] Trial 36 finished with value: 0.03316952048331079 and parameters: {'w0': 0.8168238019608351, 'w1': 0.4789404390047085, 'w2': 0.2021445673893147}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,512] Trial 37 finished with value: 0.03323275193703046 and parameters: {'w0': 0.9290659770673219, 'w1': 0.629115326762318, 'w2': 0.05604357655523469}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,530] Trial 38 finished with value: 0.03310320777840048 and parameters: {'w0': 0.6953757303661978, 'w1': 0.5070795889593367, 'w2': 0.14206727506151356}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,548] Trial 39 finished with value: 0.033171041532516266 and parameters: {'w0': 0.692545119239788, 'w1': 0.5157083935938246, 'w2': 0.1341569447864856}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,567] Trial 40 finished with value: 0.03316656229289494 and parameters: {'w0': 0.728592797976568, 'w1': 0.6895489663913055, 'w2': 0.2771072798290879}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,585] Trial 41 finished with value: 0.03336945113661183 and parameters: {'w0': 0.6169553846554766, 'w1': 0.5947738052924968, 'w2': 0.16346318181650468}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,603] Trial 42 finished with value: 0.03356565692863067 and parameters: {'w0': 0.8116222034800306, 'w1': 0.31595283023685583, 'w2': 0.035387595048282594}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,622] Trial 43 finished with value: 0.03453575087951444 and parameters: {'w0': 0.006964734273324669, 'w1': 0.5583775081091057, 'w2': 0.2152736343332749}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,640] Trial 44 finished with value: 0.03310563542687661 and parameters: {'w0': 0.6612068341934461, 'w1': 0.3655846949739083, 'w2': 0.30005750316963575}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,659] Trial 45 finished with value: 0.033172325202362685 and parameters: {'w0': 0.750285642869047, 'w1': 0.378606107959412, 'w2': 0.3253865621924308}. Best is trial 33 with value: 0.03310204133969663.\n",
            "[I 2025-06-16 10:36:37,677] Trial 46 finished with value: 0.032914432532408444 and parameters: {'w0': 0.665469369693786, 'w1': 0.48604024546490876, 'w2': 0.4215495554390836}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,696] Trial 47 finished with value: 0.03373059931182387 and parameters: {'w0': 0.5860503781734516, 'w1': 0.48865646696969206, 'w2': 0.8575970565925929}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,714] Trial 48 finished with value: 0.033457427288876684 and parameters: {'w0': 0.5060923279688981, 'w1': 0.5276211340440717, 'w2': 0.5514202591391898}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,733] Trial 49 finished with value: 0.03298229288074117 and parameters: {'w0': 0.6913584914157657, 'w1': 0.4500050323012646, 'w2': 0.4368053611438594}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,751] Trial 50 finished with value: 0.03298271575938305 and parameters: {'w0': 0.6537170638809607, 'w1': 0.43457774215420586, 'w2': 0.4375295692173973}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,770] Trial 51 finished with value: 0.03311909836461613 and parameters: {'w0': 0.6596087436425276, 'w1': 0.41698136203643343, 'w2': 0.4442567380682353}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,789] Trial 52 finished with value: 0.033521665787173194 and parameters: {'w0': 0.5615739929487987, 'w1': 0.4630624983041793, 'w2': 0.5326577540135717}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,807] Trial 53 finished with value: 0.033199117294033686 and parameters: {'w0': 0.752869597826025, 'w1': 0.33972897262506097, 'w2': 0.6588101546956174}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,826] Trial 54 finished with value: 0.03310563542687661 and parameters: {'w0': 0.8285779939238546, 'w1': 0.4434915106524205, 'w2': 0.3784698057487242}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,845] Trial 55 finished with value: 0.033039526461486335 and parameters: {'w0': 0.925111025703892, 'w1': 0.5998994779868251, 'w2': 0.4554907932603105}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,864] Trial 56 finished with value: 0.03298229288074117 and parameters: {'w0': 0.9441437591747296, 'w1': 0.6099966066537974, 'w2': 0.5913891715780528}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,883] Trial 57 finished with value: 0.03304651423296412 and parameters: {'w0': 0.9546000079696814, 'w1': 0.6062731556164795, 'w2': 0.5972067327802107}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,902] Trial 58 finished with value: 0.032914432532408444 and parameters: {'w0': 0.9478402547856033, 'w1': 0.701038152929418, 'w2': 0.5951646781388036}. Best is trial 46 with value: 0.032914432532408444.\n",
            "[I 2025-06-16 10:36:37,921] Trial 59 finished with value: 0.032842816121376295 and parameters: {'w0': 0.9480827411633322, 'w1': 0.7622929035829995, 'w2': 0.4635091243853561}. Best is trial 59 with value: 0.032842816121376295.\n",
            "[I 2025-06-16 10:36:37,940] Trial 60 finished with value: 0.033249682398370894 and parameters: {'w0': 0.9651465859598418, 'w1': 0.8218424968419245, 'w2': 0.6921618386254901}. Best is trial 59 with value: 0.032842816121376295.\n",
            "[I 2025-06-16 10:36:37,959] Trial 61 finished with value: 0.03291016183039985 and parameters: {'w0': 0.9217242227339986, 'w1': 0.7035909201197151, 'w2': 0.4423267641712699}. Best is trial 59 with value: 0.032842816121376295.\n",
            "[I 2025-06-16 10:36:37,978] Trial 62 finished with value: 0.03277475717165901 and parameters: {'w0': 0.9987862311420801, 'w1': 0.771062068940648, 'w2': 0.5170398676633036}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:37,997] Trial 63 finished with value: 0.033180163442480315 and parameters: {'w0': 0.9064679427533938, 'w1': 0.7749433686796573, 'w2': 0.5843788047561481}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,016] Trial 64 finished with value: 0.033043187720684486 and parameters: {'w0': 0.9932418393039123, 'w1': 0.7202331349773993, 'w2': 0.49775351932887946}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,036] Trial 65 finished with value: 0.03304498486243812 and parameters: {'w0': 0.9441386381446749, 'w1': 0.873294697637642, 'w2': 0.5253757639095334}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,055] Trial 66 finished with value: 0.03277475717165901 and parameters: {'w0': 0.9048252523421055, 'w1': 0.6891472835393985, 'w2': 0.48261255932674707}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,075] Trial 67 finished with value: 0.033170089157082416 and parameters: {'w0': 0.9057410437909501, 'w1': 0.9516127133816263, 'w2': 0.41631579444644684}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,095] Trial 68 finished with value: 0.03290786577225846 and parameters: {'w0': 0.8432452991919388, 'w1': 0.6805374240096116, 'w2': 0.36871674561197054}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,115] Trial 69 finished with value: 0.0331722380799504 and parameters: {'w0': 0.9750701109427647, 'w1': 0.6792504038457301, 'w2': 0.36107878769064783}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,134] Trial 70 finished with value: 0.03290790164171298 and parameters: {'w0': 0.8967823541189566, 'w1': 0.7662572823817225, 'w2': 0.4796144629039514}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,153] Trial 71 finished with value: 0.03297822727734845 and parameters: {'w0': 0.8493110798746836, 'w1': 0.762103692566485, 'w2': 0.48484037356392756}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,172] Trial 72 finished with value: 0.03304498486243812 and parameters: {'w0': 0.8991164045547334, 'w1': 0.8244011963742476, 'w2': 0.5129554301566787}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,191] Trial 73 finished with value: 0.03317602057516211 and parameters: {'w0': 0.8891420650661306, 'w1': 0.8943906579764264, 'w2': 0.46655456177386195}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,211] Trial 74 finished with value: 0.033249682398370894 and parameters: {'w0': 0.8386063921532374, 'w1': 0.7795646551597272, 'w2': 0.5523133264492551}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,231] Trial 75 finished with value: 0.03290790164171298 and parameters: {'w0': 0.7822451841479854, 'w1': 0.6907177432820337, 'w2': 0.41137277649059045}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,250] Trial 76 finished with value: 0.033108002473967946 and parameters: {'w0': 0.7948286241447601, 'w1': 0.7999442689645122, 'w2': 0.3964731546797799}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,271] Trial 77 finished with value: 0.032900683982994394 and parameters: {'w0': 0.7743033401782677, 'w1': 0.7297483997884598, 'w2': 0.34088161798515226}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,291] Trial 78 finished with value: 0.03296817626988202 and parameters: {'w0': 0.7753443524886947, 'w1': 0.7357121586178961, 'w2': 0.33464861479040214}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,310] Trial 79 finished with value: 0.033036500213762254 and parameters: {'w0': 0.85305226955316, 'w1': 0.654054888316457, 'w2': 0.3579546286576779}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,329] Trial 80 finished with value: 0.03297535127714424 and parameters: {'w0': 0.9969743741472541, 'w1': 0.7472964343278503, 'w2': 0.47778363799200624}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,348] Trial 81 finished with value: 0.033038078509211366 and parameters: {'w0': 0.9263652288613945, 'w1': 0.6727528662532707, 'w2': 0.42799448322881034}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,369] Trial 82 finished with value: 0.032837822963125984 and parameters: {'w0': 0.7958235333830419, 'w1': 0.7121972183534323, 'w2': 0.3836115166801341}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,388] Trial 83 finished with value: 0.032837822963125984 and parameters: {'w0': 0.7978542266143718, 'w1': 0.7159810865048388, 'w2': 0.3819617165961113}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,408] Trial 84 finished with value: 0.033041240873384226 and parameters: {'w0': 0.8033088064138761, 'w1': 0.8017930399125337, 'w2': 0.382685535414107}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,427] Trial 85 finished with value: 0.03309920156852175 and parameters: {'w0': 0.8692780616932747, 'w1': 0.8703025084815957, 'w2': 0.3116912701448467}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,447] Trial 86 finished with value: 0.03303277973992036 and parameters: {'w0': 0.7283153182503025, 'w1': 0.7206848372830296, 'w2': 0.2835069432410826}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,467] Trial 87 finished with value: 0.03296528745303273 and parameters: {'w0': 0.7614091246251412, 'w1': 0.7436099318280393, 'w2': 0.3307998389958506}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,486] Trial 88 finished with value: 0.03290504339682798 and parameters: {'w0': 0.8312601651346215, 'w1': 0.6347348185916306, 'w2': 0.3909824515784133}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,506] Trial 89 finished with value: 0.03317079012767543 and parameters: {'w0': 0.8398866293891674, 'w1': 0.6307385690408883, 'w2': 0.25063620908278106}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,525] Trial 90 finished with value: 0.03303553699425532 and parameters: {'w0': 0.8868370702541215, 'w1': 0.7932152503729042, 'w2': 0.3647380247049642}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,544] Trial 91 finished with value: 0.032842816121376295 and parameters: {'w0': 0.8241766979479093, 'w1': 0.6716065778539063, 'w2': 0.40482552705030345}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,563] Trial 92 finished with value: 0.03277475717165901 and parameters: {'w0': 0.826561797910332, 'w1': 0.6608155366127633, 'w2': 0.3942945484550468}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,582] Trial 93 finished with value: 0.032842816121376295 and parameters: {'w0': 0.8072216141189142, 'w1': 0.6595907404096449, 'w2': 0.3870821066063413}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,601] Trial 94 finished with value: 0.03277475717165901 and parameters: {'w0': 0.823091554938358, 'w1': 0.6545980630714218, 'w2': 0.39485517497746303}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,620] Trial 95 finished with value: 0.033104259433203165 and parameters: {'w0': 0.7974194556154585, 'w1': 0.5730149354978562, 'w2': 0.3361256216772466}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,639] Trial 96 finished with value: 0.033249682398370894 and parameters: {'w0': 0.7120264258844671, 'w1': 0.6646589281627201, 'w2': 0.45394769130068846}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,657] Trial 97 finished with value: 0.032837822963125984 and parameters: {'w0': 0.8177661728999477, 'w1': 0.7104265683154992, 'w2': 0.40369263888697393}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,676] Trial 98 finished with value: 0.03311188182265268 and parameters: {'w0': 0.824787445308152, 'w1': 0.7143697765169371, 'w2': 0.5043929658355075}. Best is trial 62 with value: 0.03277475717165901.\n",
            "[I 2025-06-16 10:36:38,695] Trial 99 finished with value: 0.0331722380799504 and parameters: {'w0': 0.9756230388659651, 'w1': 0.6425960018326708, 'w2': 0.40884456969416927}. Best is trial 62 with value: 0.03277475717165901.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 1): 0.9672\n",
            "\n",
            "=== Fold 2/5 ===\n",
            "\n",
            "--- Training combination ('lgbm',) ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003268 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59557, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335990\n",
            "[LightGBM] [Info] Start training from score -3.553369\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.490298\n",
            "[LightGBM] [Info] Start training from score -3.098136\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.889684\n",
            "[LightGBM] [Info] Start training from score -3.745474\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.559841\n",
            "[LightGBM] [Info] Start training from score -3.296660\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.013298\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.864336\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.912287\n",
            "[LightGBM] [Info] Start training from score -2.909510\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.865514\n",
            "[LightGBM] [Info] Start training from score -3.521052\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.558072\n",
            "[LightGBM] [Info] Start training from score -3.456726\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:36:47,919] A new study created in memory with name: no-name-18a40fca-2653-455c-ac5f-1ff35c2df885\n",
            "[I 2025-06-16 10:36:47,926] Trial 0 finished with value: 0.0348744843163028 and parameters: {'w0': 0.5702704478006241}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,932] Trial 1 finished with value: 0.0348744843163028 and parameters: {'w0': 0.3552357665149486}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,938] Trial 2 finished with value: 0.0348744843163028 and parameters: {'w0': 0.983538630924737}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,944] Trial 3 finished with value: 0.0348744843163028 and parameters: {'w0': 0.7524200408990315}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,949] Trial 4 finished with value: 0.0348744843163028 and parameters: {'w0': 0.12163740528186628}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,956] Trial 5 finished with value: 0.0348744843163028 and parameters: {'w0': 0.9428642987203826}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,961] Trial 6 finished with value: 0.0348744843163028 and parameters: {'w0': 0.4535867051217448}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,966] Trial 7 finished with value: 0.0348744843163028 and parameters: {'w0': 0.732565587693692}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,971] Trial 8 finished with value: 0.0348744843163028 and parameters: {'w0': 0.3886882430205515}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,976] Trial 9 finished with value: 0.0348744843163028 and parameters: {'w0': 0.43922645482687417}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,985] Trial 10 finished with value: 0.0348744843163028 and parameters: {'w0': 0.029033405134637924}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:47,994] Trial 11 finished with value: 0.0348744843163028 and parameters: {'w0': 0.2827731253609546}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,003] Trial 12 finished with value: 0.0348744843163028 and parameters: {'w0': 0.6269369786027734}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,016] Trial 13 finished with value: 0.0348744843163028 and parameters: {'w0': 0.23107381767833735}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,025] Trial 14 finished with value: 0.0348744843163028 and parameters: {'w0': 0.5795151313449372}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,034] Trial 15 finished with value: 0.0348744843163028 and parameters: {'w0': 0.28214079713231577}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,042] Trial 16 finished with value: 0.0348744843163028 and parameters: {'w0': 0.5601324883444215}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,051] Trial 17 finished with value: 0.0348744843163028 and parameters: {'w0': 0.725202530158257}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,060] Trial 18 finished with value: 0.0348744843163028 and parameters: {'w0': 0.35143391239153104}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,069] Trial 19 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8564399283924374}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,077] Trial 20 finished with value: 0.0348744843163028 and parameters: {'w0': 0.1457603544710936}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,086] Trial 21 finished with value: 0.0348744843163028 and parameters: {'w0': 0.9885515687916001}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,094] Trial 22 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8166554946580723}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,103] Trial 23 finished with value: 0.0348744843163028 and parameters: {'w0': 0.49400931083617244}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,112] Trial 24 finished with value: 0.0348744843163028 and parameters: {'w0': 0.6505633667527916}. Best is trial 0 with value: 0.0348744843163028.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 2): 0.9651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:36:48,121] Trial 25 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8951099839697707}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,131] Trial 26 finished with value: 0.0348744843163028 and parameters: {'w0': 0.35645500365196914}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,140] Trial 27 finished with value: 0.0348744843163028 and parameters: {'w0': 0.1893761802314144}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,149] Trial 28 finished with value: 0.0348744843163028 and parameters: {'w0': 0.5537763969695562}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,158] Trial 29 finished with value: 0.0348744843163028 and parameters: {'w0': 0.7767004652471916}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,166] Trial 30 finished with value: 0.0348744843163028 and parameters: {'w0': 0.6591351106553942}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,175] Trial 31 finished with value: 0.0348744843163028 and parameters: {'w0': 0.9200863485816513}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,184] Trial 32 finished with value: 0.0348744843163028 and parameters: {'w0': 0.7156490120509579}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,193] Trial 33 finished with value: 0.0348744843163028 and parameters: {'w0': 0.7946423667038123}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,203] Trial 34 finished with value: 0.0348744843163028 and parameters: {'w0': 0.48679689251245906}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,212] Trial 35 finished with value: 0.0348744843163028 and parameters: {'w0': 0.9862660559490952}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,221] Trial 36 finished with value: 0.0348744843163028 and parameters: {'w0': 0.4319547298037098}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,231] Trial 37 finished with value: 0.0348744843163028 and parameters: {'w0': 0.691119017996158}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,241] Trial 38 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8921110497599434}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,251] Trial 39 finished with value: 0.0348744843163028 and parameters: {'w0': 0.0013018760684289088}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,261] Trial 40 finished with value: 0.0348744843163028 and parameters: {'w0': 0.5939277477141016}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,270] Trial 41 finished with value: 0.0348744843163028 and parameters: {'w0': 0.25648915943433814}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,280] Trial 42 finished with value: 0.0348744843163028 and parameters: {'w0': 0.06776712428268022}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,290] Trial 43 finished with value: 0.0348744843163028 and parameters: {'w0': 0.09185360581551023}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,300] Trial 44 finished with value: 0.0348744843163028 and parameters: {'w0': 0.34143438806495}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,310] Trial 45 finished with value: 0.0348744843163028 and parameters: {'w0': 0.43000018025145703}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,319] Trial 46 finished with value: 0.0348744843163028 and parameters: {'w0': 0.1892785005259371}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,329] Trial 47 finished with value: 0.0348744843163028 and parameters: {'w0': 0.5226491551266146}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,339] Trial 48 finished with value: 0.0348744843163028 and parameters: {'w0': 0.7671093053979816}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,348] Trial 49 finished with value: 0.0348744843163028 and parameters: {'w0': 0.622300010355068}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,357] Trial 50 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8430026614044661}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,368] Trial 51 finished with value: 0.0348744843163028 and parameters: {'w0': 0.9244878197643964}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,377] Trial 52 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8511698969811661}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,387] Trial 53 finished with value: 0.0348744843163028 and parameters: {'w0': 0.9630394317147138}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,397] Trial 54 finished with value: 0.0348744843163028 and parameters: {'w0': 0.9529114419831712}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,408] Trial 55 finished with value: 0.0348744843163028 and parameters: {'w0': 0.9990703125087229}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,417] Trial 56 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8805607280475332}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,427] Trial 57 finished with value: 0.0348744843163028 and parameters: {'w0': 0.3071220857902135}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,438] Trial 58 finished with value: 0.0348744843163028 and parameters: {'w0': 0.7584017172176571}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,448] Trial 59 finished with value: 0.0348744843163028 and parameters: {'w0': 0.38724809169829477}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,459] Trial 60 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8276571932018904}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,469] Trial 61 finished with value: 0.0348744843163028 and parameters: {'w0': 0.4770613284848944}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,480] Trial 62 finished with value: 0.0348744843163028 and parameters: {'w0': 0.546666294875042}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,490] Trial 63 finished with value: 0.0348744843163028 and parameters: {'w0': 0.592562522554082}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,500] Trial 64 finished with value: 0.0348744843163028 and parameters: {'w0': 0.4594203474128325}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,510] Trial 65 finished with value: 0.0348744843163028 and parameters: {'w0': 0.4099913759526926}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,519] Trial 66 finished with value: 0.0348744843163028 and parameters: {'w0': 0.19953321341032423}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,530] Trial 67 finished with value: 0.0348744843163028 and parameters: {'w0': 0.6887895041132619}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,539] Trial 68 finished with value: 0.0348744843163028 and parameters: {'w0': 0.5174779641818996}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,550] Trial 69 finished with value: 0.0348744843163028 and parameters: {'w0': 0.9300446160833061}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,559] Trial 70 finished with value: 0.0348744843163028 and parameters: {'w0': 0.11584181541013282}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,569] Trial 71 finished with value: 0.0348744843163028 and parameters: {'w0': 0.738341910364407}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,579] Trial 72 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8128820536791286}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,588] Trial 73 finished with value: 0.0348744843163028 and parameters: {'w0': 0.6428853410234333}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,599] Trial 74 finished with value: 0.0348744843163028 and parameters: {'w0': 0.6824565634876089}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,608] Trial 75 finished with value: 0.0348744843163028 and parameters: {'w0': 0.33234305675175285}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,618] Trial 76 finished with value: 0.0348744843163028 and parameters: {'w0': 0.3966359497368777}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,627] Trial 77 finished with value: 0.0348744843163028 and parameters: {'w0': 0.6179372999842059}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,637] Trial 78 finished with value: 0.0348744843163028 and parameters: {'w0': 0.9687526679002713}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,647] Trial 79 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8737006845197782}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,656] Trial 80 finished with value: 0.0348744843163028 and parameters: {'w0': 0.3705389951220971}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,666] Trial 81 finished with value: 0.0348744843163028 and parameters: {'w0': 0.2678436081508801}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,675] Trial 82 finished with value: 0.0348744843163028 and parameters: {'w0': 0.4528960626147398}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,684] Trial 83 finished with value: 0.0348744843163028 and parameters: {'w0': 0.3221010502827221}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,694] Trial 84 finished with value: 0.0348744843163028 and parameters: {'w0': 0.5797270356432659}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,703] Trial 85 finished with value: 0.0348744843163028 and parameters: {'w0': 0.29920880781876863}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,713] Trial 86 finished with value: 0.0348744843163028 and parameters: {'w0': 0.42055364799180467}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,723] Trial 87 finished with value: 0.0348744843163028 and parameters: {'w0': 0.5174130453362337}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,733] Trial 88 finished with value: 0.0348744843163028 and parameters: {'w0': 0.7141668685480616}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,742] Trial 89 finished with value: 0.0348744843163028 and parameters: {'w0': 0.21984962199125338}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,752] Trial 90 finished with value: 0.0348744843163028 and parameters: {'w0': 0.8992960903153787}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,762] Trial 91 finished with value: 0.0348744843163028 and parameters: {'w0': 0.45131823101601287}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,772] Trial 92 finished with value: 0.0348744843163028 and parameters: {'w0': 0.3691458922122984}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,781] Trial 93 finished with value: 0.0348744843163028 and parameters: {'w0': 0.5524251653021977}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,791] Trial 94 finished with value: 0.0348744843163028 and parameters: {'w0': 0.1442259116631536}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,800] Trial 95 finished with value: 0.0348744843163028 and parameters: {'w0': 0.7884678748788463}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,810] Trial 96 finished with value: 0.0348744843163028 and parameters: {'w0': 0.4293815338651806}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,820] Trial 97 finished with value: 0.0348744843163028 and parameters: {'w0': 0.4917586800027585}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,830] Trial 98 finished with value: 0.0348744843163028 and parameters: {'w0': 0.47400065731806384}. Best is trial 0 with value: 0.0348744843163028.\n",
            "[I 2025-06-16 10:36:48,840] Trial 99 finished with value: 0.0348744843163028 and parameters: {'w0': 0.03795297366455874}. Best is trial 0 with value: 0.0348744843163028.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 2): 0.9651\n",
            "\n",
            "--- Training combination ('mlp',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:37:06,190] A new study created in memory with name: no-name-772f697d-390d-48ef-8e68-0135b1657df6\n",
            "[I 2025-06-16 10:37:06,197] Trial 0 finished with value: 0.033888245447413756 and parameters: {'w0': 0.6760714403964175}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,202] Trial 1 finished with value: 0.033888245447413756 and parameters: {'w0': 0.06263417235542523}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,207] Trial 2 finished with value: 0.033888245447413756 and parameters: {'w0': 0.15523924844345893}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,212] Trial 3 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9005686022457576}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,218] Trial 4 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9863933336329719}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,223] Trial 5 finished with value: 0.033888245447413756 and parameters: {'w0': 0.1312022795315455}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,228] Trial 6 finished with value: 0.033888245447413756 and parameters: {'w0': 0.4916256166972012}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,233] Trial 7 finished with value: 0.033888245447413756 and parameters: {'w0': 0.2637139747803954}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,239] Trial 8 finished with value: 0.033888245447413756 and parameters: {'w0': 0.994392489002118}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,244] Trial 9 finished with value: 0.033888245447413756 and parameters: {'w0': 0.4473408140800399}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,255] Trial 10 finished with value: 0.033888245447413756 and parameters: {'w0': 0.7006084534179154}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,265] Trial 11 finished with value: 0.033888245447413756 and parameters: {'w0': 0.685615235705123}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,274] Trial 12 finished with value: 0.033888245447413756 and parameters: {'w0': 0.00889503391446346}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,284] Trial 13 finished with value: 0.033888245447413756 and parameters: {'w0': 0.6938422146645774}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,293] Trial 14 finished with value: 0.033888245447413756 and parameters: {'w0': 0.3535783420140882}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,303] Trial 15 finished with value: 0.033888245447413756 and parameters: {'w0': 0.6117355530210071}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,312] Trial 16 finished with value: 0.033888245447413756 and parameters: {'w0': 0.8195187676328726}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,321] Trial 17 finished with value: 0.033888245447413756 and parameters: {'w0': 0.5494823735010352}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,330] Trial 18 finished with value: 0.033888245447413756 and parameters: {'w0': 0.36473196385301493}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,339] Trial 19 finished with value: 0.033888245447413756 and parameters: {'w0': 0.007498273216120038}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,348] Trial 20 finished with value: 0.033888245447413756 and parameters: {'w0': 0.8217096430416643}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,357] Trial 21 finished with value: 0.033888245447413756 and parameters: {'w0': 0.20587338415157863}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,366] Trial 22 finished with value: 0.033888245447413756 and parameters: {'w0': 0.1341034103674122}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,375] Trial 23 finished with value: 0.033888245447413756 and parameters: {'w0': 0.07955405901025717}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,384] Trial 24 finished with value: 0.033888245447413756 and parameters: {'w0': 0.25201868333418653}. Best is trial 0 with value: 0.033888245447413756.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted mlp (fold 2): 0.9664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:37:06,393] Trial 25 finished with value: 0.033888245447413756 and parameters: {'w0': 0.3730866627353056}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,402] Trial 26 finished with value: 0.033888245447413756 and parameters: {'w0': 0.1769797896288302}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,410] Trial 27 finished with value: 0.033888245447413756 and parameters: {'w0': 0.07863426911895144}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,419] Trial 28 finished with value: 0.033888245447413756 and parameters: {'w0': 0.5982606238739915}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,429] Trial 29 finished with value: 0.033888245447413756 and parameters: {'w0': 0.30526943238623083}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,439] Trial 30 finished with value: 0.033888245447413756 and parameters: {'w0': 0.8070687801875307}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,449] Trial 31 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9188588394841706}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,459] Trial 32 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9017950806560142}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,469] Trial 33 finished with value: 0.033888245447413756 and parameters: {'w0': 0.7696318725840445}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,479] Trial 34 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9112766204238623}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,489] Trial 35 finished with value: 0.033888245447413756 and parameters: {'w0': 0.45407401435887884}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,499] Trial 36 finished with value: 0.033888245447413756 and parameters: {'w0': 0.06322494234264904}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,509] Trial 37 finished with value: 0.033888245447413756 and parameters: {'w0': 0.5071313792993568}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,519] Trial 38 finished with value: 0.033888245447413756 and parameters: {'w0': 0.6425512838779509}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,528] Trial 39 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9642953594247369}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,538] Trial 40 finished with value: 0.033888245447413756 and parameters: {'w0': 0.7542267343324445}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,548] Trial 41 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9981135990934012}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,557] Trial 42 finished with value: 0.033888245447413756 and parameters: {'w0': 0.8655382747238513}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,566] Trial 43 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9625965673790642}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,575] Trial 44 finished with value: 0.033888245447413756 and parameters: {'w0': 0.7313263768313055}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,584] Trial 45 finished with value: 0.033888245447413756 and parameters: {'w0': 0.8684574418575887}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,594] Trial 46 finished with value: 0.033888245447413756 and parameters: {'w0': 0.15914557221589226}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,603] Trial 47 finished with value: 0.033888245447413756 and parameters: {'w0': 0.22154245430999986}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,612] Trial 48 finished with value: 0.033888245447413756 and parameters: {'w0': 0.6463001176919885}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,622] Trial 49 finished with value: 0.033888245447413756 and parameters: {'w0': 0.5581736462845628}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,632] Trial 50 finished with value: 0.033888245447413756 and parameters: {'w0': 0.29917061841852566}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,641] Trial 51 finished with value: 0.033888245447413756 and parameters: {'w0': 0.10567245463743347}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,651] Trial 52 finished with value: 0.033888245447413756 and parameters: {'w0': 0.03290298363054536}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,660] Trial 53 finished with value: 0.033888245447413756 and parameters: {'w0': 0.13019617641537817}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,670] Trial 54 finished with value: 0.033888245447413756 and parameters: {'w0': 0.4143234431691142}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,679] Trial 55 finished with value: 0.033888245447413756 and parameters: {'w0': 0.03740854306534576}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,689] Trial 56 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9557311073179916}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,698] Trial 57 finished with value: 0.033888245447413756 and parameters: {'w0': 0.18964684971504991}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,707] Trial 58 finished with value: 0.033888245447413756 and parameters: {'w0': 0.2640002860817772}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,716] Trial 59 finished with value: 0.033888245447413756 and parameters: {'w0': 0.1140130472738725}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,726] Trial 60 finished with value: 0.033888245447413756 and parameters: {'w0': 0.8617373331450128}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,735] Trial 61 finished with value: 0.033888245447413756 and parameters: {'w0': 0.48651201367572994}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,744] Trial 62 finished with value: 0.033888245447413756 and parameters: {'w0': 0.6901155250127377}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,754] Trial 63 finished with value: 0.033888245447413756 and parameters: {'w0': 0.3297671005613899}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,763] Trial 64 finished with value: 0.033888245447413756 and parameters: {'w0': 0.3995760181879987}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,773] Trial 65 finished with value: 0.033888245447413756 and parameters: {'w0': 0.05194277022871106}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,783] Trial 66 finished with value: 0.033888245447413756 and parameters: {'w0': 0.8171991769025884}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,794] Trial 67 finished with value: 0.033888245447413756 and parameters: {'w0': 0.0012760931169392142}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,804] Trial 68 finished with value: 0.033888245447413756 and parameters: {'w0': 0.23546107515809045}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,813] Trial 69 finished with value: 0.033888245447413756 and parameters: {'w0': 0.16532185581304693}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,823] Trial 70 finished with value: 0.033888245447413756 and parameters: {'w0': 0.563469745683137}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,832] Trial 71 finished with value: 0.033888245447413756 and parameters: {'w0': 0.09213864406804231}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,842] Trial 72 finished with value: 0.033888245447413756 and parameters: {'w0': 0.1372050603777289}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,851] Trial 73 finished with value: 0.033888245447413756 and parameters: {'w0': 0.931661619740997}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,861] Trial 74 finished with value: 0.033888245447413756 and parameters: {'w0': 0.7900307748172484}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,870] Trial 75 finished with value: 0.033888245447413756 and parameters: {'w0': 0.19488302737756735}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,880] Trial 76 finished with value: 0.033888245447413756 and parameters: {'w0': 0.2664323887042317}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,890] Trial 77 finished with value: 0.033888245447413756 and parameters: {'w0': 0.7281036378077578}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,900] Trial 78 finished with value: 0.033888245447413756 and parameters: {'w0': 0.6016557323371009}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,909] Trial 79 finished with value: 0.033888245447413756 and parameters: {'w0': 0.6413015145014284}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,918] Trial 80 finished with value: 0.033888245447413756 and parameters: {'w0': 0.8855166097279819}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,928] Trial 81 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9721700621561634}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,937] Trial 82 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9871712081290072}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,947] Trial 83 finished with value: 0.033888245447413756 and parameters: {'w0': 0.06975232095729496}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,957] Trial 84 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9439734032971805}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,967] Trial 85 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9014510524660112}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,977] Trial 86 finished with value: 0.033888245447413756 and parameters: {'w0': 0.8414047795394437}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,987] Trial 87 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9916950696917846}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:06,996] Trial 88 finished with value: 0.033888245447413756 and parameters: {'w0': 0.5036489651371067}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,006] Trial 89 finished with value: 0.033888245447413756 and parameters: {'w0': 0.15559740786634213}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,019] Trial 90 finished with value: 0.033888245447413756 and parameters: {'w0': 0.9312492021951005}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,030] Trial 91 finished with value: 0.033888245447413756 and parameters: {'w0': 0.5263277183495549}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,040] Trial 92 finished with value: 0.033888245447413756 and parameters: {'w0': 0.4719267097169363}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,049] Trial 93 finished with value: 0.033888245447413756 and parameters: {'w0': 0.4172792292420848}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,059] Trial 94 finished with value: 0.033888245447413756 and parameters: {'w0': 0.3617646948392347}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,069] Trial 95 finished with value: 0.033888245447413756 and parameters: {'w0': 0.5316452733611055}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,080] Trial 96 finished with value: 0.033888245447413756 and parameters: {'w0': 0.2923612637459111}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,092] Trial 97 finished with value: 0.033888245447413756 and parameters: {'w0': 0.21581612774853537}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,102] Trial 98 finished with value: 0.033888245447413756 and parameters: {'w0': 0.44812041197828156}. Best is trial 0 with value: 0.033888245447413756.\n",
            "[I 2025-06-16 10:37:07,113] Trial 99 finished with value: 0.033888245447413756 and parameters: {'w0': 0.025133508423401417}. Best is trial 0 with value: 0.033888245447413756.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 2): 0.9661\n",
            "\n",
            "--- Training combination ('logreg',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:37:09,678] A new study created in memory with name: no-name-9af23201-8db5-480c-ad6f-c166f05450cf\n",
            "[I 2025-06-16 10:37:09,686] Trial 0 finished with value: 0.03583714723743736 and parameters: {'w0': 0.3066562761060677}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,693] Trial 1 finished with value: 0.03583714723743736 and parameters: {'w0': 0.8087704151691134}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,700] Trial 2 finished with value: 0.03583714723743736 and parameters: {'w0': 0.646332258419853}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,707] Trial 3 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5713350167900931}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,713] Trial 4 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6728630847739684}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,720] Trial 5 finished with value: 0.03583714723743736 and parameters: {'w0': 0.7659667727475884}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,727] Trial 6 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6559512501948489}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,734] Trial 7 finished with value: 0.03583714723743736 and parameters: {'w0': 0.0833470871922215}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,741] Trial 8 finished with value: 0.03583714723743736 and parameters: {'w0': 0.3061529394876803}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,748] Trial 9 finished with value: 0.03583714723743736 and parameters: {'w0': 0.9516227180630821}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,760] Trial 10 finished with value: 0.03583714723743736 and parameters: {'w0': 0.3726667491805596}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,774] Trial 11 finished with value: 0.03583714723743736 and parameters: {'w0': 0.18026330227494436}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,786] Trial 12 finished with value: 0.03583714723743736 and parameters: {'w0': 0.9479150730531944}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,797] Trial 13 finished with value: 0.03583714723743736 and parameters: {'w0': 0.4354677075437186}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,806] Trial 14 finished with value: 0.03583714723743736 and parameters: {'w0': 0.20003184485796677}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,816] Trial 15 finished with value: 0.03583714723743736 and parameters: {'w0': 0.8146772360147568}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,826] Trial 16 finished with value: 0.03583714723743736 and parameters: {'w0': 0.49033605768742544}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,835] Trial 17 finished with value: 0.03583714723743736 and parameters: {'w0': 0.8287220054438131}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,845] Trial 18 finished with value: 0.03583714723743736 and parameters: {'w0': 0.011691891757982464}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,855] Trial 19 finished with value: 0.03583714723743736 and parameters: {'w0': 0.30755094213645817}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,865] Trial 20 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5680869779773733}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,875] Trial 21 finished with value: 0.03583714723743736 and parameters: {'w0': 0.716488328216862}. Best is trial 0 with value: 0.03583714723743736.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 2): 0.9642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:37:09,886] Trial 22 finished with value: 0.03583714723743736 and parameters: {'w0': 0.8679108090018172}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,897] Trial 23 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5781604346151975}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,907] Trial 24 finished with value: 0.03583714723743736 and parameters: {'w0': 0.4309734696282681}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,917] Trial 25 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6564098630613371}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,927] Trial 26 finished with value: 0.03583714723743736 and parameters: {'w0': 0.2777562013648211}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,937] Trial 27 finished with value: 0.03583714723743736 and parameters: {'w0': 0.9997717705241517}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,947] Trial 28 finished with value: 0.03583714723743736 and parameters: {'w0': 0.7266995423097691}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,960] Trial 29 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5788173232291981}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,970] Trial 30 finished with value: 0.03583714723743736 and parameters: {'w0': 0.50918588818775}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,979] Trial 31 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6489694145933916}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,989] Trial 32 finished with value: 0.03583714723743736 and parameters: {'w0': 0.7690737393748952}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:09,999] Trial 33 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5225735705533124}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,009] Trial 34 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6228883444790376}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,019] Trial 35 finished with value: 0.03583714723743736 and parameters: {'w0': 0.716345747995893}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,029] Trial 36 finished with value: 0.03583714723743736 and parameters: {'w0': 0.883387620665179}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,039] Trial 37 finished with value: 0.03583714723743736 and parameters: {'w0': 0.388038018724045}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,049] Trial 38 finished with value: 0.03583714723743736 and parameters: {'w0': 0.14259465771375135}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,059] Trial 39 finished with value: 0.03583714723743736 and parameters: {'w0': 0.7729479965602788}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,069] Trial 40 finished with value: 0.03583714723743736 and parameters: {'w0': 0.24836206229574553}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,079] Trial 41 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6915701793939559}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,090] Trial 42 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6209912356794838}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,102] Trial 43 finished with value: 0.03583714723743736 and parameters: {'w0': 0.47541160597992516}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,112] Trial 44 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5557617378656703}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,121] Trial 45 finished with value: 0.03583714723743736 and parameters: {'w0': 0.8106149353922987}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,131] Trial 46 finished with value: 0.03583714723743736 and parameters: {'w0': 0.33501202299175126}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,141] Trial 47 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6562184230368024}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,151] Trial 48 finished with value: 0.03583714723743736 and parameters: {'w0': 0.9051770059265363}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,162] Trial 49 finished with value: 0.03583714723743736 and parameters: {'w0': 0.43368567281595505}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,172] Trial 50 finished with value: 0.03583714723743736 and parameters: {'w0': 0.07791545208413875}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,182] Trial 51 finished with value: 0.03583714723743736 and parameters: {'w0': 0.750727878460591}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,192] Trial 52 finished with value: 0.03583714723743736 and parameters: {'w0': 0.847070267911667}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,202] Trial 53 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6865046473308087}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,213] Trial 54 finished with value: 0.03583714723743736 and parameters: {'w0': 0.7875151870733469}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,222] Trial 55 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6091999165632386}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,232] Trial 56 finished with value: 0.03583714723743736 and parameters: {'w0': 0.9511788904329953}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,242] Trial 57 finished with value: 0.03583714723743736 and parameters: {'w0': 0.530953217604972}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,252] Trial 58 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6888356258030517}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,262] Trial 59 finished with value: 0.03583714723743736 and parameters: {'w0': 0.8050715911057909}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,273] Trial 60 finished with value: 0.03583714723743736 and parameters: {'w0': 0.7385537970447906}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,283] Trial 61 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5890940894605735}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,293] Trial 62 finished with value: 0.03583714723743736 and parameters: {'w0': 0.4734573186079973}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,302] Trial 63 finished with value: 0.03583714723743736 and parameters: {'w0': 0.642956716395364}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,312] Trial 64 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6911273905230558}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,322] Trial 65 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5478938242733077}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,332] Trial 66 finished with value: 0.03583714723743736 and parameters: {'w0': 0.39028333541227894}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,341] Trial 67 finished with value: 0.03583714723743736 and parameters: {'w0': 0.8384361971618914}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,351] Trial 68 finished with value: 0.03583714723743736 and parameters: {'w0': 0.9060145518907117}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,361] Trial 69 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5896063036358775}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,371] Trial 70 finished with value: 0.03583714723743736 and parameters: {'w0': 0.7217391082566916}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,380] Trial 71 finished with value: 0.03583714723743736 and parameters: {'w0': 0.013640242644543776}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,391] Trial 72 finished with value: 0.03583714723743736 and parameters: {'w0': 0.17000618277761576}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,401] Trial 73 finished with value: 0.03583714723743736 and parameters: {'w0': 0.228491967300274}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,411] Trial 74 finished with value: 0.03583714723743736 and parameters: {'w0': 0.13335246560759356}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,421] Trial 75 finished with value: 0.03583714723743736 and parameters: {'w0': 0.759545712720262}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,431] Trial 76 finished with value: 0.03583714723743736 and parameters: {'w0': 0.3104272455885191}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,441] Trial 77 finished with value: 0.03583714723743736 and parameters: {'w0': 0.663770811043672}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,452] Trial 78 finished with value: 0.03583714723743736 and parameters: {'w0': 0.07134914770743417}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,462] Trial 79 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6233062099853885}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,472] Trial 80 finished with value: 0.03583714723743736 and parameters: {'w0': 0.7094830181256228}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,482] Trial 81 finished with value: 0.03583714723743736 and parameters: {'w0': 0.2722243620348421}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,492] Trial 82 finished with value: 0.03583714723743736 and parameters: {'w0': 0.3479144521128938}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,501] Trial 83 finished with value: 0.03583714723743736 and parameters: {'w0': 0.18897418922740947}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,511] Trial 84 finished with value: 0.03583714723743736 and parameters: {'w0': 0.4955555499729564}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,520] Trial 85 finished with value: 0.03583714723743736 and parameters: {'w0': 0.4585481483909813}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,530] Trial 86 finished with value: 0.03583714723743736 and parameters: {'w0': 0.7776273272807885}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,540] Trial 87 finished with value: 0.03583714723743736 and parameters: {'w0': 0.08324031144704613}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,550] Trial 88 finished with value: 0.03583714723743736 and parameters: {'w0': 0.39982303869755315}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,560] Trial 89 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5362805745513594}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,569] Trial 90 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6639186497560289}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,580] Trial 91 finished with value: 0.03583714723743736 and parameters: {'w0': 0.9829660620751886}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,590] Trial 92 finished with value: 0.03583714723743736 and parameters: {'w0': 0.8740728161812198}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,601] Trial 93 finished with value: 0.03583714723743736 and parameters: {'w0': 0.9276839329022988}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,611] Trial 94 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6013052488488615}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,621] Trial 95 finished with value: 0.03583714723743736 and parameters: {'w0': 0.5672706830728633}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,631] Trial 96 finished with value: 0.03583714723743736 and parameters: {'w0': 0.22067850488315766}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,642] Trial 97 finished with value: 0.03583714723743736 and parameters: {'w0': 0.6392967748226447}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,652] Trial 98 finished with value: 0.03583714723743736 and parameters: {'w0': 0.8547174367048398}. Best is trial 0 with value: 0.03583714723743736.\n",
            "[I 2025-06-16 10:37:10,662] Trial 99 finished with value: 0.03583714723743736 and parameters: {'w0': 0.7980806320933592}. Best is trial 0 with value: 0.03583714723743736.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 2): 0.9642\n",
            "\n",
            "--- Training combination ('lgbm', 'mlp') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042663 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59557, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335990\n",
            "[LightGBM] [Info] Start training from score -3.553369\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.490298\n",
            "[LightGBM] [Info] Start training from score -3.098136\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.889684\n",
            "[LightGBM] [Info] Start training from score -3.745474\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.559841\n",
            "[LightGBM] [Info] Start training from score -3.296660\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.013298\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.864336\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.912287\n",
            "[LightGBM] [Info] Start training from score -2.909510\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.865514\n",
            "[LightGBM] [Info] Start training from score -3.521052\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.558072\n",
            "[LightGBM] [Info] Start training from score -3.456726\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 2): 0.9651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:37:35,529] A new study created in memory with name: no-name-016ffc90-2065-401d-acd9-473478447216\n",
            "[I 2025-06-16 10:37:35,537] Trial 0 finished with value: 0.03351061099314445 and parameters: {'w0': 0.917523691949984, 'w1': 0.1468707860487417}. Best is trial 0 with value: 0.03351061099314445.\n",
            "[I 2025-06-16 10:37:35,542] Trial 1 finished with value: 0.033625426264824565 and parameters: {'w0': 0.7121371036083408, 'w1': 0.7676657408689143}. Best is trial 0 with value: 0.03351061099314445.\n",
            "[I 2025-06-16 10:37:35,548] Trial 2 finished with value: 0.03335979427510116 and parameters: {'w0': 0.9373168933421439, 'w1': 0.4039514520848778}. Best is trial 2 with value: 0.03335979427510116.\n",
            "[I 2025-06-16 10:37:35,554] Trial 3 finished with value: 0.033818880632990655 and parameters: {'w0': 0.1512660976224074, 'w1': 0.5318907157954157}. Best is trial 2 with value: 0.03335979427510116.\n",
            "[I 2025-06-16 10:37:35,559] Trial 4 finished with value: 0.03376368814390274 and parameters: {'w0': 0.18496255278231988, 'w1': 0.0883475337205527}. Best is trial 2 with value: 0.03335979427510116.\n",
            "[I 2025-06-16 10:37:35,565] Trial 5 finished with value: 0.034354261205978176 and parameters: {'w0': 0.0037186420596900804, 'w1': 0.8894488670573442}. Best is trial 2 with value: 0.03335979427510116.\n",
            "[I 2025-06-16 10:37:35,570] Trial 6 finished with value: 0.03382397790634428 and parameters: {'w0': 0.5668473184903696, 'w1': 0.8716807716442165}. Best is trial 2 with value: 0.03335979427510116.\n",
            "[I 2025-06-16 10:37:35,576] Trial 7 finished with value: 0.03388656736185203 and parameters: {'w0': 0.25337692008118795, 'w1': 0.820783015578264}. Best is trial 2 with value: 0.03335979427510116.\n",
            "[I 2025-06-16 10:37:35,582] Trial 8 finished with value: 0.03375458483369542 and parameters: {'w0': 0.32946064381623275, 'w1': 0.8955322451551566}. Best is trial 2 with value: 0.03335979427510116.\n",
            "[I 2025-06-16 10:37:35,588] Trial 9 finished with value: 0.033685706369284585 and parameters: {'w0': 0.21247056029885336, 'w1': 0.6122030999649567}. Best is trial 2 with value: 0.03335979427510116.\n",
            "[I 2025-06-16 10:37:35,604] Trial 10 finished with value: 0.03329942385191387 and parameters: {'w0': 0.9525312113184385, 'w1': 0.32201878170151926}. Best is trial 10 with value: 0.03329942385191387.\n",
            "[I 2025-06-16 10:37:35,617] Trial 11 finished with value: 0.033503806202378916 and parameters: {'w0': 0.994253369727817, 'w1': 0.30953075614530984}. Best is trial 10 with value: 0.03329942385191387.\n",
            "[I 2025-06-16 10:37:35,630] Trial 12 finished with value: 0.03309094085052944 and parameters: {'w0': 0.820250126930607, 'w1': 0.33243791157230984}. Best is trial 12 with value: 0.03309094085052944.\n",
            "[I 2025-06-16 10:37:35,643] Trial 13 finished with value: 0.03336835202586452 and parameters: {'w0': 0.7703633760998878, 'w1': 0.25296661960442485}. Best is trial 12 with value: 0.03309094085052944.\n",
            "[I 2025-06-16 10:37:35,656] Trial 14 finished with value: 0.03369768530819506 and parameters: {'w0': 0.7770847173401858, 'w1': 0.4019134988215256}. Best is trial 12 with value: 0.03309094085052944.\n",
            "[I 2025-06-16 10:37:35,670] Trial 15 finished with value: 0.032963104280524624 and parameters: {'w0': 0.5411192192022454, 'w1': 0.20221395531068842}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,683] Trial 16 finished with value: 0.033503806202378916 and parameters: {'w0': 0.5112675909256946, 'w1': 0.16451040416147894}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,697] Trial 17 finished with value: 0.0336507786466832 and parameters: {'w0': 0.6325924954925461, 'w1': 0.05776492646011}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,710] Trial 18 finished with value: 0.03454497597319195 and parameters: {'w0': 0.39532466534648186, 'w1': 0.005827521170388095}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,724] Trial 19 finished with value: 0.03382397790634428 and parameters: {'w0': 0.432670316397623, 'w1': 0.6457408782704602}. Best is trial 15 with value: 0.032963104280524624.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted mlp (fold 2): 0.9661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:37:35,737] Trial 20 finished with value: 0.033763683829205804 and parameters: {'w0': 0.8358172037467411, 'w1': 0.44719473507052443}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,751] Trial 21 finished with value: 0.03329135303090758 and parameters: {'w0': 0.6756596040781166, 'w1': 0.28352938239125325}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,764] Trial 22 finished with value: 0.03302899802130521 and parameters: {'w0': 0.6067245986064637, 'w1': 0.21775244796545884}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,778] Trial 23 finished with value: 0.033503806202378916 and parameters: {'w0': 0.5446986161418719, 'w1': 0.16756035367721153}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,792] Trial 24 finished with value: 0.03302899802130521 and parameters: {'w0': 0.6013539164626375, 'w1': 0.22326503800422534}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,805] Trial 25 finished with value: 0.03302899802130521 and parameters: {'w0': 0.6053592232675332, 'w1': 0.21806897901696876}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,821] Trial 26 finished with value: 0.03344027947860495 and parameters: {'w0': 0.40616005863973814, 'w1': 0.09119484100235813}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,834] Trial 27 finished with value: 0.03335979427510116 and parameters: {'w0': 0.49628024134936743, 'w1': 0.21548373764241407}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,848] Trial 28 finished with value: 0.03356212360822186 and parameters: {'w0': 0.660875837358543, 'w1': 0.4719571415500588}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,861] Trial 29 finished with value: 0.033775671811102304 and parameters: {'w0': 0.457540000914457, 'w1': 0.11988170533926353}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,875] Trial 30 finished with value: 0.033625426264824565 and parameters: {'w0': 0.3460525191428985, 'w1': 0.3757159063575035}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,890] Trial 31 finished with value: 0.032963104280524624 and parameters: {'w0': 0.5875900596232072, 'w1': 0.22008998042062664}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,904] Trial 32 finished with value: 0.03363722918608636 and parameters: {'w0': 0.7219350233348695, 'w1': 0.20479222028116162}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,919] Trial 33 finished with value: 0.03375818073237835 and parameters: {'w0': 0.595891498933327, 'w1': 0.9933034403496482}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,933] Trial 34 finished with value: 0.034275334066284024 and parameters: {'w0': 0.7208917184764196, 'w1': 0.015274742311720824}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,947] Trial 35 finished with value: 0.033842226313654744 and parameters: {'w0': 0.5126074985309083, 'w1': 0.13540563776724732}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,963] Trial 36 finished with value: 0.03335979427510116 and parameters: {'w0': 0.5758721327917714, 'w1': 0.24356432001262704}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,977] Trial 37 finished with value: 0.03322365022345297 and parameters: {'w0': 0.8800213594293494, 'w1': 0.3596157764016051}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:35,991] Trial 38 finished with value: 0.03362674529418175 and parameters: {'w0': 0.6477181764874061, 'w1': 0.5361235226348203}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:36,005] Trial 39 finished with value: 0.03356582453970469 and parameters: {'w0': 0.47676968609995163, 'w1': 0.2833271534156081}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:36,019] Trial 40 finished with value: 0.033625426264824565 and parameters: {'w0': 0.06351348542673563, 'w1': 0.06919064889122928}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:36,033] Trial 41 finished with value: 0.03329942385191387 and parameters: {'w0': 0.6079051092772485, 'w1': 0.20212291015922113}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:36,048] Trial 42 finished with value: 0.033503806202378916 and parameters: {'w0': 0.5504075107244749, 'w1': 0.1721898588217735}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:36,062] Trial 43 finished with value: 0.03302899802130521 and parameters: {'w0': 0.6630011972908701, 'w1': 0.2429307096577921}. Best is trial 15 with value: 0.032963104280524624.\n",
            "[I 2025-06-16 10:37:36,076] Trial 44 finished with value: 0.03296012644580981 and parameters: {'w0': 0.7028932450660894, 'w1': 0.2805880549404749}. Best is trial 44 with value: 0.03296012644580981.\n",
            "[I 2025-06-16 10:37:36,091] Trial 45 finished with value: 0.032893954891580424 and parameters: {'w0': 0.7631571883942281, 'w1': 0.2928700800813852}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,106] Trial 46 finished with value: 0.033698660923338175 and parameters: {'w0': 0.7667888555485044, 'w1': 0.43240717606510526}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,120] Trial 47 finished with value: 0.0329603872920643 and parameters: {'w0': 0.7221100039062293, 'w1': 0.2888063135536168}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,134] Trial 48 finished with value: 0.03363266974266843 and parameters: {'w0': 0.852331605337632, 'w1': 0.525810903944899}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,149] Trial 49 finished with value: 0.03336835202586452 and parameters: {'w0': 0.9010870215245458, 'w1': 0.29603044995240646}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,163] Trial 50 finished with value: 0.03369635093543688 and parameters: {'w0': 0.6952922639701722, 'w1': 0.3481166197841594}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,177] Trial 51 finished with value: 0.03302899802130521 and parameters: {'w0': 0.746541941911789, 'w1': 0.27203313474975344}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,192] Trial 52 finished with value: 0.03369635093543688 and parameters: {'w0': 0.7951902611969385, 'w1': 0.40506910559363973}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,206] Trial 53 finished with value: 0.03329307583478591 and parameters: {'w0': 0.708572660700567, 'w1': 0.3109988079004461}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,221] Trial 54 finished with value: 0.033842226313654744 and parameters: {'w0': 0.5375270516830393, 'w1': 0.1429899308011397}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,237] Trial 55 finished with value: 0.03363722918608636 and parameters: {'w0': 0.6274081354650307, 'w1': 0.17476552732853168}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,251] Trial 56 finished with value: 0.033442782800554904 and parameters: {'w0': 0.8068780946417338, 'w1': 0.11534905261295755}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,264] Trial 57 finished with value: 0.033623395165424896 and parameters: {'w0': 0.7432967121172804, 'w1': 0.7465907780959278}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,278] Trial 58 finished with value: 0.03329942385191387 and parameters: {'w0': 0.9608560782278427, 'w1': 0.32737828370996974}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,292] Trial 59 finished with value: 0.03376352150943984 and parameters: {'w0': 0.6816644904847965, 'w1': 0.3576349009590939}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,307] Trial 60 finished with value: 0.033628898910663896 and parameters: {'w0': 0.5686388002408217, 'w1': 0.2627445994529434}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,322] Trial 61 finished with value: 0.0329603872920643 and parameters: {'w0': 0.5914371639080741, 'w1': 0.23677061573333502}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,336] Trial 62 finished with value: 0.033503806202378916 and parameters: {'w0': 0.6261266670176379, 'w1': 0.19770397944157875}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,352] Trial 63 finished with value: 0.033628898910663896 and parameters: {'w0': 0.5214846996470819, 'w1': 0.2468373397154659}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,369] Trial 64 finished with value: 0.03362946205405137 and parameters: {'w0': 0.4399256348451631, 'w1': 0.3037974599682039}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,386] Trial 65 finished with value: 0.03362946205405137 and parameters: {'w0': 0.5690617321348701, 'w1': 0.3861068807991162}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,402] Trial 66 finished with value: 0.03344331550446 and parameters: {'w0': 0.6499943110589944, 'w1': 0.08693720665739607}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,417] Trial 67 finished with value: 0.032893954891580424 and parameters: {'w0': 0.4790222875582267, 'w1': 0.18756859389381525}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,434] Trial 68 finished with value: 0.033233295769282245 and parameters: {'w0': 0.4720827281417372, 'w1': 0.163364416167904}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,449] Trial 69 finished with value: 0.03364927293914066 and parameters: {'w0': 0.31738233142880157, 'w1': 0.03003519593236953}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,465] Trial 70 finished with value: 0.03350263347048221 and parameters: {'w0': 0.3627539733537409, 'w1': 0.10511293559107202}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,481] Trial 71 finished with value: 0.03289409889549366 and parameters: {'w0': 0.5905291694851899, 'w1': 0.22407383086938884}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,496] Trial 72 finished with value: 0.033434873058885706 and parameters: {'w0': 0.5841784006853683, 'w1': 0.1894089355949905}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,511] Trial 73 finished with value: 0.03349332832499419 and parameters: {'w0': 0.501650260782383, 'w1': 0.22685389681663284}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,526] Trial 74 finished with value: 0.03302899802130521 and parameters: {'w0': 0.7450791348026798, 'w1': 0.2669557301458543}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,543] Trial 75 finished with value: 0.033233295769282245 and parameters: {'w0': 0.4130250805457327, 'w1': 0.14351074533832042}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,558] Trial 76 finished with value: 0.03363266974266843 and parameters: {'w0': 0.5374085384752922, 'w1': 0.33544779691342674}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,573] Trial 77 finished with value: 0.03335979427510116 and parameters: {'w0': 0.6902553583599771, 'w1': 0.29300396522299244}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,588] Trial 78 finished with value: 0.03350263347048221 and parameters: {'w0': 0.8500905368396305, 'w1': 0.25205981083753726}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,603] Trial 79 finished with value: 0.033628898910663896 and parameters: {'w0': 0.4855596763750931, 'w1': 0.2288982002543101}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,618] Trial 80 finished with value: 0.03399542173640968 and parameters: {'w0': 0.7818155266097883, 'w1': 0.044215834715791325}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,633] Trial 81 finished with value: 0.033503806202378916 and parameters: {'w0': 0.616508015993081, 'w1': 0.1895302471036982}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,648] Trial 82 finished with value: 0.03336835202586452 and parameters: {'w0': 0.6581922766838995, 'w1': 0.21617875653885102}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,663] Trial 83 finished with value: 0.03363722918608636 and parameters: {'w0': 0.5537843663390815, 'w1': 0.15725249823946616}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,679] Trial 84 finished with value: 0.033628898910663896 and parameters: {'w0': 0.5921036286384518, 'w1': 0.27444354639802154}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,693] Trial 85 finished with value: 0.03384388632695323 and parameters: {'w0': 0.5240006262655963, 'w1': 0.13051714552854157}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,708] Trial 86 finished with value: 0.03335979427510116 and parameters: {'w0': 0.7258478494704551, 'w1': 0.30979648884707106}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,725] Trial 87 finished with value: 0.03350263347048221 and parameters: {'w0': 0.6261144154638524, 'w1': 0.1853880870018101}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,740] Trial 88 finished with value: 0.03302899802130521 and parameters: {'w0': 0.6429666443499397, 'w1': 0.2304984615693525}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,755] Trial 89 finished with value: 0.03363018259522388 and parameters: {'w0': 0.8232021345261723, 'w1': 0.5994006409602931}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,770] Trial 90 finished with value: 0.03369635093543688 and parameters: {'w0': 0.6739420048664905, 'w1': 0.3341162452935694}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,785] Trial 91 finished with value: 0.03309832431547621 and parameters: {'w0': 0.5974146958414893, 'w1': 0.20957684017601835}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,802] Trial 92 finished with value: 0.03329942385191387 and parameters: {'w0': 0.6996807649847129, 'w1': 0.23342320978144876}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,817] Trial 93 finished with value: 0.03356582453970469 and parameters: {'w0': 0.46080233934125553, 'w1': 0.27286117005476296}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,831] Trial 94 finished with value: 0.033434873058885706 and parameters: {'w0': 0.5590932207271329, 'w1': 0.1818068842556076}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,848] Trial 95 finished with value: 0.03329942385191387 and parameters: {'w0': 0.761069127671669, 'w1': 0.25899448899930144}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,865] Trial 96 finished with value: 0.03376368814390274 and parameters: {'w0': 0.6089426008615038, 'w1': 0.2923086391152405}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,880] Trial 97 finished with value: 0.03364348343335799 and parameters: {'w0': 0.5027671778626523, 'w1': 0.09163899444583899}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,895] Trial 98 finished with value: 0.03363159007918881 and parameters: {'w0': 0.5796236046752213, 'w1': 0.3753956359708315}. Best is trial 45 with value: 0.032893954891580424.\n",
            "[I 2025-06-16 10:37:36,909] Trial 99 finished with value: 0.033233295769282245 and parameters: {'w0': 0.43427635190919095, 'w1': 0.15103140301492957}. Best is trial 45 with value: 0.032893954891580424.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 2): 0.9671\n",
            "\n",
            "--- Training combination ('lgbm', 'logreg') ---\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003427 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59557, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335990\n",
            "[LightGBM] [Info] Start training from score -3.553369\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.490298\n",
            "[LightGBM] [Info] Start training from score -3.098136\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.889684\n",
            "[LightGBM] [Info] Start training from score -3.745474\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.559841\n",
            "[LightGBM] [Info] Start training from score -3.296660\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.013298\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.864336\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.912287\n",
            "[LightGBM] [Info] Start training from score -2.909510\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.865514\n",
            "[LightGBM] [Info] Start training from score -3.521052\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.558072\n",
            "[LightGBM] [Info] Start training from score -3.456726\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 2): 0.9651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:37:47,647] A new study created in memory with name: no-name-57b3c329-4ee0-4f77-92e5-62420cb7844b\n",
            "[I 2025-06-16 10:37:47,656] Trial 0 finished with value: 0.03353273295429959 and parameters: {'w0': 0.896209237127855, 'w1': 0.5115379768884175}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,664] Trial 1 finished with value: 0.03461314212446198 and parameters: {'w0': 0.9414944779669552, 'w1': 0.08734257127753253}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,671] Trial 2 finished with value: 0.033740202721893264 and parameters: {'w0': 0.7496143946766868, 'w1': 0.17288681740084932}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,679] Trial 3 finished with value: 0.03401226284135672 and parameters: {'w0': 0.9913844446799567, 'w1': 0.1419745491664165}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,686] Trial 4 finished with value: 0.03480615922564678 and parameters: {'w0': 0.722148747669812, 'w1': 0.018817668640961238}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,693] Trial 5 finished with value: 0.03562899947496334 and parameters: {'w0': 0.05522324126386924, 'w1': 0.7662728161296424}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,701] Trial 6 finished with value: 0.03441736194948719 and parameters: {'w0': 0.45632059281682824, 'w1': 0.6702017297988117}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,708] Trial 7 finished with value: 0.03535713797291584 and parameters: {'w0': 0.07844792822604096, 'w1': 0.5011480734451471}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,716] Trial 8 finished with value: 0.03509233004539514 and parameters: {'w0': 0.1960766951114673, 'w1': 0.9151053462046147}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,723] Trial 9 finished with value: 0.035493717223467725 and parameters: {'w0': 0.09056276729168578, 'w1': 0.8840602678321042}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,742] Trial 10 finished with value: 0.03434740356971544 and parameters: {'w0': 0.3478146362565927, 'w1': 0.36390820475707064}. Best is trial 0 with value: 0.03353273295429959.\n",
            "[I 2025-06-16 10:37:47,759] Trial 11 finished with value: 0.03339783224663928 and parameters: {'w0': 0.7332288360115514, 'w1': 0.3202492857540311}. Best is trial 11 with value: 0.03339783224663928.\n",
            "[I 2025-06-16 10:37:47,772] Trial 12 finished with value: 0.03353186294623656 and parameters: {'w0': 0.7272265348818095, 'w1': 0.40104227424968186}. Best is trial 11 with value: 0.03339783224663928.\n",
            "[I 2025-06-16 10:37:47,785] Trial 13 finished with value: 0.03339781745813031 and parameters: {'w0': 0.702412361090713, 'w1': 0.29890659897355165}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,798] Trial 14 finished with value: 0.03346519587119445 and parameters: {'w0': 0.5719606146514165, 'w1': 0.26273101734368626}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,812] Trial 15 finished with value: 0.03353273295429959 and parameters: {'w0': 0.5956572210377529, 'w1': 0.3422988636845103}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,825] Trial 16 finished with value: 0.03393978021197164 and parameters: {'w0': 0.8218473286604733, 'w1': 0.6022748742510369}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,839] Trial 17 finished with value: 0.03360193110943366 and parameters: {'w0': 0.43422879445768037, 'w1': 0.2576115994531173}. Best is trial 13 with value: 0.03339781745813031.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 2): 0.9642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:37:47,853] Trial 18 finished with value: 0.03387562282780043 and parameters: {'w0': 0.6169132385914387, 'w1': 0.439587815009348}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,867] Trial 19 finished with value: 0.03366945235011398 and parameters: {'w0': 0.8188205836988016, 'w1': 0.24472983206347604}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,882] Trial 20 finished with value: 0.03475778778297056 and parameters: {'w0': 0.3421429777566114, 'w1': 0.6374854643586234}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,897] Trial 21 finished with value: 0.03339781745813031 and parameters: {'w0': 0.6278695034867731, 'w1': 0.2676222626145162}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,913] Trial 22 finished with value: 0.03346519587119445 and parameters: {'w0': 0.6539302343602542, 'w1': 0.3006379841347445}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,928] Trial 23 finished with value: 0.0334686134519534 and parameters: {'w0': 0.5213875470736413, 'w1': 0.1826469976889461}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,942] Trial 24 finished with value: 0.03380955846247358 and parameters: {'w0': 0.6759958933812468, 'w1': 0.458444806536338}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,956] Trial 25 finished with value: 0.03447596625340965 and parameters: {'w0': 0.853494848622445, 'w1': 0.05998547245342728}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,970] Trial 26 finished with value: 0.033874934430988435 and parameters: {'w0': 0.7790319990862486, 'w1': 0.559295616272874}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,984] Trial 27 finished with value: 0.03387478239131103 and parameters: {'w0': 0.529846677686315, 'w1': 0.3364685729124441}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:47,998] Trial 28 finished with value: 0.03366945235011398 and parameters: {'w0': 0.6761431697969207, 'w1': 0.199205244318926}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,013] Trial 29 finished with value: 0.034144244225312814 and parameters: {'w0': 0.8867243036967558, 'w1': 0.09906626717116779}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,027] Trial 30 finished with value: 0.03448309333375521 and parameters: {'w0': 0.3636857319032384, 'w1': 0.39763444310468665}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,042] Trial 31 finished with value: 0.03353139563027452 and parameters: {'w0': 0.5650737992611974, 'w1': 0.265347754818208}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,057] Trial 32 finished with value: 0.0340112353279185 and parameters: {'w0': 0.4607054671125331, 'w1': 0.30686702846616665}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,071] Trial 33 finished with value: 0.03367219172705882 and parameters: {'w0': 0.625657106307966, 'w1': 0.12912382958710872}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,086] Trial 34 finished with value: 0.033740202721893264 and parameters: {'w0': 0.9355063282855625, 'w1': 0.21810846853314544}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,100] Trial 35 finished with value: 0.03360193110943366 and parameters: {'w0': 0.770459610715063, 'w1': 0.4523612297325004}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,115] Trial 36 finished with value: 0.03367219172705882 and parameters: {'w0': 0.7107669792310448, 'w1': 0.1486492137835002}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,131] Trial 37 finished with value: 0.03353131273916243 and parameters: {'w0': 0.5451228578609713, 'w1': 0.29521045739259527}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,145] Trial 38 finished with value: 0.03434535778996928 and parameters: {'w0': 0.6048720695334671, 'w1': 0.5422893798544769}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,161] Trial 39 finished with value: 0.03353273295429959 and parameters: {'w0': 0.7060294298241581, 'w1': 0.3997706856433514}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,178] Trial 40 finished with value: 0.03454391956066738 and parameters: {'w0': 0.4151914183100713, 'w1': 0.03737318850345045}. Best is trial 13 with value: 0.03339781745813031.\n",
            "[I 2025-06-16 10:37:48,194] Trial 41 finished with value: 0.03332984738063671 and parameters: {'w0': 0.6605517681814769, 'w1': 0.29239461518925314}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,210] Trial 42 finished with value: 0.033740545512274234 and parameters: {'w0': 0.7654090145352836, 'w1': 0.1969041805006008}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,225] Trial 43 finished with value: 0.03366518391656592 and parameters: {'w0': 0.4794338440274535, 'w1': 0.2533798132402386}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,239] Trial 44 finished with value: 0.03387478239131103 and parameters: {'w0': 0.5797757155127431, 'w1': 0.366427137328556}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,254] Trial 45 finished with value: 0.03394546627344941 and parameters: {'w0': 0.6704188437996894, 'w1': 0.10517559356243536}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,270] Trial 46 finished with value: 0.03407582963682054 and parameters: {'w0': 0.8041251402539847, 'w1': 0.7096207405127852}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,286] Trial 47 finished with value: 0.03346519587119445 and parameters: {'w0': 0.718624332419349, 'w1': 0.33041493648249426}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,302] Trial 48 finished with value: 0.03360514834415318 and parameters: {'w0': 0.6391106106203344, 'w1': 0.1597066473506357}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,317] Trial 49 finished with value: 0.033599047308429664 and parameters: {'w0': 0.999885367921433, 'w1': 0.4737807638653866}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,332] Trial 50 finished with value: 0.03366945235011398 and parameters: {'w0': 0.7391676397224132, 'w1': 0.22424868655724503}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,347] Trial 51 finished with value: 0.03339781745813031 and parameters: {'w0': 0.6524067121971644, 'w1': 0.2775419477549944}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,363] Trial 52 finished with value: 0.033597828661996565 and parameters: {'w0': 0.5815100964174534, 'w1': 0.2847648362484893}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,377] Trial 53 finished with value: 0.03387562282780043 and parameters: {'w0': 0.5154460930693373, 'w1': 0.3656675238949043}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,391] Trial 54 finished with value: 0.03427806802058453 and parameters: {'w0': 0.6861813013629908, 'w1': 0.8460997428239321}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,406] Trial 55 finished with value: 0.03455402890899062 and parameters: {'w0': 0.6336759394155589, 'w1': 0.9905171952036889}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,420] Trial 56 finished with value: 0.033530370190360204 and parameters: {'w0': 0.8402491724262915, 'w1': 0.32128559063048723}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,435] Trial 57 finished with value: 0.03428000919352814 and parameters: {'w0': 0.203970802633199, 'w1': 0.24446379408948882}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,450] Trial 58 finished with value: 0.03353139563027452 and parameters: {'w0': 0.8752031102361757, 'w1': 0.41234523211203067}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,465] Trial 59 finished with value: 0.03480615922564678 and parameters: {'w0': 0.7520463138110025, 'w1': 0.0019797641803948607}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,481] Trial 60 finished with value: 0.03367464251214891 and parameters: {'w0': 0.6556158414253983, 'w1': 0.182363743954178}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,496] Trial 61 finished with value: 0.033597573414011594 and parameters: {'w0': 0.552506502077863, 'w1': 0.28905698334656116}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,512] Trial 62 finished with value: 0.03373518111018725 and parameters: {'w0': 0.6000749340207194, 'w1': 0.3704244565803779}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,526] Trial 63 finished with value: 0.033399058906693035 and parameters: {'w0': 0.6578760638625718, 'w1': 0.26995571189621476}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,541] Trial 64 finished with value: 0.03366945235011398 and parameters: {'w0': 0.794373514924638, 'w1': 0.23799417120349387}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,556] Trial 65 finished with value: 0.03339847633782722 and parameters: {'w0': 0.6860321705489475, 'w1': 0.2777491646739585}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,570] Trial 66 finished with value: 0.033530370190360204 and parameters: {'w0': 0.6951352794994492, 'w1': 0.2753893096285065}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,585] Trial 67 finished with value: 0.035770623450221195 and parameters: {'w0': 0.003333544844705716, 'w1': 0.32864749075274147}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,599] Trial 68 finished with value: 0.033465150142484856 and parameters: {'w0': 0.7399612030451762, 'w1': 0.4181501718125107}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,615] Trial 69 finished with value: 0.03353131273916243 and parameters: {'w0': 0.6400791922453933, 'w1': 0.34924827006972065}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,629] Trial 70 finished with value: 0.03360804817092067 and parameters: {'w0': 0.6658277303999224, 'w1': 0.21777957157365135}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,643] Trial 71 finished with value: 0.03353273295429959 and parameters: {'w0': 0.7408202416082736, 'w1': 0.42810586034399467}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,657] Trial 72 finished with value: 0.033597573414011594 and parameters: {'w0': 0.7178801308502885, 'w1': 0.37623972362676644}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,671] Trial 73 finished with value: 0.033530370190360204 and parameters: {'w0': 0.7858957546638136, 'w1': 0.30402150353799745}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,686] Trial 74 finished with value: 0.03339783224663928 and parameters: {'w0': 0.6131379224174057, 'w1': 0.2682053716018556}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,701] Trial 75 finished with value: 0.0334686134519534 and parameters: {'w0': 0.6103903582908137, 'w1': 0.21445842600340173}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,716] Trial 76 finished with value: 0.03367259568509051 and parameters: {'w0': 0.49048562395285256, 'w1': 0.1415544171486401}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,729] Trial 77 finished with value: 0.03353423653202303 and parameters: {'w0': 0.7006086592361592, 'w1': 0.2574251621440807}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,743] Trial 78 finished with value: 0.03367464251214891 and parameters: {'w0': 0.6271976762517568, 'w1': 0.17511145830461272}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,757] Trial 79 finished with value: 0.034080909145653315 and parameters: {'w0': 0.5475169349336537, 'w1': 0.07508806946537752}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,771] Trial 80 finished with value: 0.033811510327120264 and parameters: {'w0': 0.6704746230776156, 'w1': 0.11978981508540917}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,787] Trial 81 finished with value: 0.03394391610501535 and parameters: {'w0': 0.7416485184351815, 'w1': 0.48147861621654386}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,801] Trial 82 finished with value: 0.033530370190360204 and parameters: {'w0': 0.8239313963271204, 'w1': 0.31356029854538786}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,816] Trial 83 finished with value: 0.03346519587119445 and parameters: {'w0': 0.5856460627414162, 'w1': 0.27189711039612857}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,830] Trial 84 finished with value: 0.033943641409802994 and parameters: {'w0': 0.7675780511930121, 'w1': 0.512520174814151}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,845] Trial 85 finished with value: 0.03353273295429959 and parameters: {'w0': 0.6868872294921898, 'w1': 0.3902829247882593}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,861] Trial 86 finished with value: 0.03366518391656592 and parameters: {'w0': 0.649109789725767, 'w1': 0.34889096933084157}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,876] Trial 87 finished with value: 0.03339847633782722 and parameters: {'w0': 0.7213953063570199, 'w1': 0.2913062943598151}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,891] Trial 88 finished with value: 0.03374015771628425 and parameters: {'w0': 0.9157940540225035, 'w1': 0.1956655189540646}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,905] Trial 89 finished with value: 0.033530370190360204 and parameters: {'w0': 0.6107034855944499, 'w1': 0.23699911549499222}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,922] Trial 90 finished with value: 0.033399058906693035 and parameters: {'w0': 0.7098536551430243, 'w1': 0.28843014525107763}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,937] Trial 91 finished with value: 0.03339847633782722 and parameters: {'w0': 0.7208805686782703, 'w1': 0.2919654240640582}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,952] Trial 92 finished with value: 0.033599047308429664 and parameters: {'w0': 0.6590501868546834, 'w1': 0.31419557671452064}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,969] Trial 93 finished with value: 0.033599047308429664 and parameters: {'w0': 0.7223737618812102, 'w1': 0.343986481679447}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:48,985] Trial 94 finished with value: 0.033530370190360204 and parameters: {'w0': 0.6855695577457508, 'w1': 0.26331005244675126}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:49,000] Trial 95 finished with value: 0.03360625586704058 and parameters: {'w0': 0.8090787205194375, 'w1': 0.23132731674015278}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:49,014] Trial 96 finished with value: 0.033597573414011594 and parameters: {'w0': 0.5664885101929499, 'w1': 0.28933545678221106}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:49,029] Trial 97 finished with value: 0.033605169583182826 and parameters: {'w0': 0.763603992349037, 'w1': 0.19359907198648296}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:49,043] Trial 98 finished with value: 0.03339847633782722 and parameters: {'w0': 0.6297842907152343, 'w1': 0.25529894271947895}. Best is trial 41 with value: 0.03332984738063671.\n",
            "[I 2025-06-16 10:37:49,057] Trial 99 finished with value: 0.033740545512274234 and parameters: {'w0': 0.6364890640388681, 'w1': 0.163894994764535}. Best is trial 41 with value: 0.03332984738063671.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 2): 0.9667\n",
            "\n",
            "--- Training combination ('mlp', 'logreg') ---\n",
            "F1-weighted mlp (fold 2): 0.9660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:38:09,515] A new study created in memory with name: no-name-0ff5cd2c-e51d-4e92-a087-d1efe52134cf\n",
            "[I 2025-06-16 10:38:09,535] Trial 0 finished with value: 0.034309163888478045 and parameters: {'w0': 0.9278577195169562, 'w1': 0.5437044960750501}. Best is trial 0 with value: 0.034309163888478045.\n",
            "[I 2025-06-16 10:38:09,545] Trial 1 finished with value: 0.034808674146879826 and parameters: {'w0': 0.37520776461154093, 'w1': 0.6597938556082921}. Best is trial 0 with value: 0.034309163888478045.\n",
            "[I 2025-06-16 10:38:09,554] Trial 2 finished with value: 0.03429972707068207 and parameters: {'w0': 0.3147429364639134, 'w1': 0.1193670198912743}. Best is trial 2 with value: 0.03429972707068207.\n",
            "[I 2025-06-16 10:38:09,561] Trial 3 finished with value: 0.03436666002287225 and parameters: {'w0': 0.5566740143412999, 'w1': 0.032517080291534994}. Best is trial 2 with value: 0.03429972707068207.\n",
            "[I 2025-06-16 10:38:09,569] Trial 4 finished with value: 0.03423921060511603 and parameters: {'w0': 0.0974769828962736, 'w1': 0.04529411235764258}. Best is trial 4 with value: 0.03423921060511603.\n",
            "[I 2025-06-16 10:38:09,577] Trial 5 finished with value: 0.03473426422105319 and parameters: {'w0': 0.547278401727247, 'w1': 0.7594152193076943}. Best is trial 4 with value: 0.03423921060511603.\n",
            "[I 2025-06-16 10:38:09,589] Trial 6 finished with value: 0.03436606812642229 and parameters: {'w0': 0.5259563055044845, 'w1': 0.17914169033636285}. Best is trial 4 with value: 0.03423921060511603.\n",
            "[I 2025-06-16 10:38:09,597] Trial 7 finished with value: 0.03423419110218662 and parameters: {'w0': 0.9123628641784289, 'w1': 0.3681817458385549}. Best is trial 7 with value: 0.03423419110218662.\n",
            "[I 2025-06-16 10:38:09,604] Trial 8 finished with value: 0.034871624716443006 and parameters: {'w0': 0.6528478378212647, 'w1': 0.9939996471401421}. Best is trial 7 with value: 0.03423419110218662.\n",
            "[I 2025-06-16 10:38:09,613] Trial 9 finished with value: 0.03446164962773979 and parameters: {'w0': 0.836596218216591, 'w1': 0.9894330369239943}. Best is trial 7 with value: 0.03423419110218662.\n",
            "[I 2025-06-16 10:38:09,628] Trial 10 finished with value: 0.03416836694832526 and parameters: {'w0': 0.7597214867634836, 'w1': 0.330824342176246}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,641] Trial 11 finished with value: 0.034233937425173 and parameters: {'w0': 0.7774860879159988, 'w1': 0.3256992583875644}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,654] Trial 12 finished with value: 0.03429972707068207 and parameters: {'w0': 0.7556217821853559, 'w1': 0.29363897540218675}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,667] Trial 13 finished with value: 0.03430815561978373 and parameters: {'w0': 0.7795741481452495, 'w1': 0.3908034685658059}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,680] Trial 14 finished with value: 0.03436606812642229 and parameters: {'w0': 0.6930489634979319, 'w1': 0.24090282490969428}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,693] Trial 15 finished with value: 0.034374369183510556 and parameters: {'w0': 0.9923625923212962, 'w1': 0.5397772200124856}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,706] Trial 16 finished with value: 0.03452433894348661 and parameters: {'w0': 0.4182977015600903, 'w1': 0.4158719309695273}. Best is trial 10 with value: 0.03416836694832526.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 2): 0.9642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:38:09,719] Trial 17 finished with value: 0.03445801964899953 and parameters: {'w0': 0.6498498284387451, 'w1': 0.6882257882027879}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,732] Trial 18 finished with value: 0.03466514544114352 and parameters: {'w0': 0.21614058001809278, 'w1': 0.28859337298065296}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,745] Trial 19 finished with value: 0.03437166660351365 and parameters: {'w0': 0.8522180978697276, 'w1': 0.1683844358139247}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,759] Trial 20 finished with value: 0.03437647271087463 and parameters: {'w0': 0.7488698277308568, 'w1': 0.4211487424655503}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,774] Trial 21 finished with value: 0.03429972707068207 and parameters: {'w0': 0.925765275216003, 'w1': 0.3530573228547733}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,787] Trial 22 finished with value: 0.03430815561978373 and parameters: {'w0': 0.9947173187611301, 'w1': 0.4731882812555315}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,801] Trial 23 finished with value: 0.03429972707068207 and parameters: {'w0': 0.8702153541948346, 'w1': 0.3217730369195817}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,814] Trial 24 finished with value: 0.03429972707068207 and parameters: {'w0': 0.659737842160858, 'w1': 0.24260702319699046}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,827] Trial 25 finished with value: 0.03437706900019277 and parameters: {'w0': 0.8032558384015953, 'w1': 0.49157306293576464}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,840] Trial 26 finished with value: 0.03444600925498065 and parameters: {'w0': 0.9048021682296427, 'w1': 0.5959319347822175}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,853] Trial 27 finished with value: 0.034302612871060734 and parameters: {'w0': 0.6093286506238031, 'w1': 0.1081884957219994}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,867] Trial 28 finished with value: 0.03429885339340055 and parameters: {'w0': 0.7231702910501175, 'w1': 0.21769055111229962}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,880] Trial 29 finished with value: 0.03452433894348661 and parameters: {'w0': 0.466665376957196, 'w1': 0.4659314327343429}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,893] Trial 30 finished with value: 0.03437706900019277 and parameters: {'w0': 0.9168933050683585, 'w1': 0.5845018022209931}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,906] Trial 31 finished with value: 0.03430357943041762 and parameters: {'w0': 0.16533539972089284, 'w1': 0.0385257883556}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,920] Trial 32 finished with value: 0.035025533834675104 and parameters: {'w0': 0.05997827620015772, 'w1': 0.3484269226590754}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,935] Trial 33 finished with value: 0.03529642189007731 and parameters: {'w0': 0.010292402025212866, 'w1': 0.1429632312722784}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,949] Trial 34 finished with value: 0.03430073202005157 and parameters: {'w0': 0.30866770903374446, 'w1': 0.08430682518168388}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,962] Trial 35 finished with value: 0.03459757582888301 and parameters: {'w0': 0.5998603731177979, 'w1': 0.7938555349366991}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,976] Trial 36 finished with value: 0.03436587213113407 and parameters: {'w0': 0.30114497170426824, 'w1': 0.039787642269533685}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:09,994] Trial 37 finished with value: 0.03437647271087463 and parameters: {'w0': 0.4853346841549129, 'w1': 0.2752504274564913}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,008] Trial 38 finished with value: 0.034229593588928076 and parameters: {'w0': 0.8139138840259789, 'w1': 0.002659804561508411}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,022] Trial 39 finished with value: 0.03430357943041762 and parameters: {'w0': 0.8372719002835801, 'w1': 0.2028370016380549}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,036] Trial 40 finished with value: 0.03445801964899953 and parameters: {'w0': 0.8097709493454042, 'w1': 0.8472002390413769}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,051] Trial 41 finished with value: 0.034229593588928076 and parameters: {'w0': 0.9485429880500995, 'w1': 0.011701349999025393}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,066] Trial 42 finished with value: 0.034298591781171894 and parameters: {'w0': 0.9679258694512904, 'w1': 0.09226996776995237}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,081] Trial 43 finished with value: 0.034229593588928076 and parameters: {'w0': 0.889373310029815, 'w1': 0.01815570942260685}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,095] Trial 44 finished with value: 0.03429750457916392 and parameters: {'w0': 0.8894902528450741, 'w1': 0.031579001717967514}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,110] Trial 45 finished with value: 0.034229593588928076 and parameters: {'w0': 0.9428310752700513, 'w1': 0.02012587965774476}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,125] Trial 46 finished with value: 0.034229593588928076 and parameters: {'w0': 0.95629242969098, 'w1': 0.005948876408587749}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,139] Trial 47 finished with value: 0.034229593588928076 and parameters: {'w0': 0.9452354243116939, 'w1': 0.003987594378056722}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,154] Trial 48 finished with value: 0.034298591781171894 and parameters: {'w0': 0.7069519276111594, 'w1': 0.0725371660707854}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,171] Trial 49 finished with value: 0.03436876476049788 and parameters: {'w0': 0.865369315439452, 'w1': 0.14160115704741139}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,185] Trial 50 finished with value: 0.034302612871060734 and parameters: {'w0': 0.7766491926707567, 'w1': 0.13266246211230165}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,200] Trial 51 finished with value: 0.034229593588928076 and parameters: {'w0': 0.9574127805792658, 'w1': 0.010201353915487906}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,215] Trial 52 finished with value: 0.034298591781171894 and parameters: {'w0': 0.9519322006083125, 'w1': 0.061481138593989154}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,231] Trial 53 finished with value: 0.034229593588928076 and parameters: {'w0': 0.8099997056124881, 'w1': 0.010962362326860159}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,246] Trial 54 finished with value: 0.03437048016972599 and parameters: {'w0': 0.9973896938342874, 'w1': 0.17806963455653646}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,261] Trial 55 finished with value: 0.03436587213113407 and parameters: {'w0': 0.892996035378109, 'w1': 0.10686355178375052}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,277] Trial 56 finished with value: 0.034298591781171894 and parameters: {'w0': 0.8471207580177152, 'w1': 0.06817528959267993}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,291] Trial 57 finished with value: 0.03436666002287225 and parameters: {'w0': 0.9296873453777527, 'w1': 0.05294314817579077}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,307] Trial 58 finished with value: 0.03437048016972599 and parameters: {'w0': 0.8847382847540541, 'w1': 0.16647484553104025}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,321] Trial 59 finished with value: 0.034229593588928076 and parameters: {'w0': 0.7372387427790712, 'w1': 0.0011313419593819013}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,335] Trial 60 finished with value: 0.03430023579488717 and parameters: {'w0': 0.8193629630640871, 'w1': 0.11330646734396714}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,349] Trial 61 finished with value: 0.034229593588928076 and parameters: {'w0': 0.9549384975056895, 'w1': 0.0007101216181182105}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,364] Trial 62 finished with value: 0.03429750457916392 and parameters: {'w0': 0.9386012544667267, 'w1': 0.03170941784729245}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,377] Trial 63 finished with value: 0.034298591781171894 and parameters: {'w0': 0.9964894821272456, 'w1': 0.0794310663856816}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,391] Trial 64 finished with value: 0.03429750457916392 and parameters: {'w0': 0.9054128883580834, 'w1': 0.041734082385881444}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,405] Trial 65 finished with value: 0.034229593588928076 and parameters: {'w0': 0.8613994012831352, 'w1': 0.0021967294110882274}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,419] Trial 66 finished with value: 0.034299614625084685 and parameters: {'w0': 0.9746782063475575, 'w1': 0.14528823843835925}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,433] Trial 67 finished with value: 0.03436587213113407 and parameters: {'w0': 0.7706763660389369, 'w1': 0.10031780268868662}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,449] Trial 68 finished with value: 0.03443777201402487 and parameters: {'w0': 0.9263083214165295, 'w1': 0.23877963581400824}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,463] Trial 69 finished with value: 0.034298591781171894 and parameters: {'w0': 0.6796318735476583, 'w1': 0.057920349502825944}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,477] Trial 70 finished with value: 0.03437166660351365 and parameters: {'w0': 0.8756033583584737, 'w1': 0.18817526821433472}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,491] Trial 71 finished with value: 0.034229593588928076 and parameters: {'w0': 0.9641127596530094, 'w1': 0.023796689114026895}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,508] Trial 72 finished with value: 0.034229593588928076 and parameters: {'w0': 0.9429539040460221, 'w1': 0.024609255092363516}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,522] Trial 73 finished with value: 0.034298591781171894 and parameters: {'w0': 0.9093170346251946, 'w1': 0.07735793729597323}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,536] Trial 74 finished with value: 0.03430119165709822 and parameters: {'w0': 0.8247621453804463, 'w1': 0.11597324713339419}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,550] Trial 75 finished with value: 0.034229593588928076 and parameters: {'w0': 0.9747812481839875, 'w1': 0.002221683091844482}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,564] Trial 76 finished with value: 0.034298591781171894 and parameters: {'w0': 0.7919087334576473, 'w1': 0.05703282916724591}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,580] Trial 77 finished with value: 0.0341809846895047 and parameters: {'w0': 0.8486382533563299, 'w1': 0.6711083862482903}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,594] Trial 78 finished with value: 0.03431685724888789 and parameters: {'w0': 0.8434250672132534, 'w1': 0.7144165886071441}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,610] Trial 79 finished with value: 0.034249292868540504 and parameters: {'w0': 0.7610742822969933, 'w1': 0.6335633649460571}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,624] Trial 80 finished with value: 0.03475421689579472 and parameters: {'w0': 0.3504624882722048, 'w1': 0.9564425153957704}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,640] Trial 81 finished with value: 0.034453553326015296 and parameters: {'w0': 0.9108430730334828, 'w1': 0.870872657919008}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,655] Trial 82 finished with value: 0.034309163888478045 and parameters: {'w0': 0.8743994971003983, 'w1': 0.5184621281288799}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,669] Trial 83 finished with value: 0.03429750457916392 and parameters: {'w0': 0.939024238177551, 'w1': 0.030741960581123565}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,684] Trial 84 finished with value: 0.03423419110218662 and parameters: {'w0': 0.9720348157811365, 'w1': 0.39984790620538346}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,698] Trial 85 finished with value: 0.03430815561978373 and parameters: {'w0': 0.8573871562445825, 'w1': 0.4313331816735253}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,714] Trial 86 finished with value: 0.0341809846895047 and parameters: {'w0': 0.9023282732997446, 'w1': 0.7352247435577719}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,728] Trial 87 finished with value: 0.034453553326015296 and parameters: {'w0': 0.8901318645410551, 'w1': 0.8108070673579583}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,745] Trial 88 finished with value: 0.034453553326015296 and parameters: {'w0': 0.8335227396690851, 'w1': 0.7611217931193879}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,760] Trial 89 finished with value: 0.03431685724888789 and parameters: {'w0': 0.7973638111437843, 'w1': 0.6762718349618269}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,775] Trial 90 finished with value: 0.03437706900019277 and parameters: {'w0': 0.9284312596422303, 'w1': 0.5661070882404199}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,789] Trial 91 finished with value: 0.03437915085374854 and parameters: {'w0': 0.9984436422183928, 'w1': 0.7122322314337437}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,803] Trial 92 finished with value: 0.03417725086497181 and parameters: {'w0': 0.9562410843644968, 'w1': 0.7457044766469677}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,819] Trial 93 finished with value: 0.03437915085374854 and parameters: {'w0': 0.9027845725200994, 'w1': 0.6367709418632728}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,834] Trial 94 finished with value: 0.03473426422105319 and parameters: {'w0': 0.5365639771724762, 'w1': 0.7308780510852182}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,847] Trial 95 finished with value: 0.03438372870122752 and parameters: {'w0': 0.878071561895726, 'w1': 0.7555353931703961}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,862] Trial 96 finished with value: 0.03459757582888301 and parameters: {'w0': 0.6102656523209136, 'w1': 0.8087844422942105}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,876] Trial 97 finished with value: 0.03444897290552673 and parameters: {'w0': 0.978137800203708, 'w1': 0.8674831251664763}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,892] Trial 98 finished with value: 0.03444582428359044 and parameters: {'w0': 0.950504646798138, 'w1': 0.65353574219454}. Best is trial 10 with value: 0.03416836694832526.\n",
            "[I 2025-06-16 10:38:10,907] Trial 99 finished with value: 0.034249292868540504 and parameters: {'w0': 0.9271305828665152, 'w1': 0.7717906077722816}. Best is trial 10 with value: 0.03416836694832526.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 2): 0.9658\n",
            "\n",
            "--- Training combination ('lgbm', 'mlp', 'logreg') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003310 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59557, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335990\n",
            "[LightGBM] [Info] Start training from score -3.553369\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.490298\n",
            "[LightGBM] [Info] Start training from score -3.098136\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.889684\n",
            "[LightGBM] [Info] Start training from score -3.745474\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -3.559841\n",
            "[LightGBM] [Info] Start training from score -3.296660\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.013298\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.864336\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.912287\n",
            "[LightGBM] [Info] Start training from score -2.909510\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Info] Start training from score -2.865514\n",
            "[LightGBM] [Info] Start training from score -3.521052\n",
            "[LightGBM] [Info] Start training from score -2.863158\n",
            "[LightGBM] [Info] Start training from score -3.558072\n",
            "[LightGBM] [Info] Start training from score -3.456726\n",
            "[LightGBM] [Info] Start training from score -3.779449\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 2): 0.9651\n",
            "F1-weighted mlp (fold 2): 0.9662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:38:39,734] A new study created in memory with name: no-name-fb54209b-ea47-4be8-94a9-72d9f21121d1\n",
            "[I 2025-06-16 10:38:39,745] Trial 0 finished with value: 0.0347418247004857 and parameters: {'w0': 0.19524150234655602, 'w1': 0.7734801394634995, 'w2': 0.10135811475223111}. Best is trial 0 with value: 0.0347418247004857.\n",
            "[I 2025-06-16 10:38:39,753] Trial 1 finished with value: 0.033997675762706736 and parameters: {'w0': 0.9187890999976502, 'w1': 0.630830619763839, 'w2': 0.13158963193142237}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,788] Trial 2 finished with value: 0.03496376551100866 and parameters: {'w0': 0.17329178341713447, 'w1': 0.1341922224263763, 'w2': 0.734079231072707}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,806] Trial 3 finished with value: 0.0347419382532389 and parameters: {'w0': 0.7939196544398536, 'w1': 0.38414103945066813, 'w2': 0.9782408177585108}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,816] Trial 4 finished with value: 0.0343415245992712 and parameters: {'w0': 0.7550299944968222, 'w1': 0.6186159012503938, 'w2': 0.1634438756062604}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,825] Trial 5 finished with value: 0.03487618931504921 and parameters: {'w0': 0.16565277303697568, 'w1': 0.17126055007060004, 'w2': 0.2762639727744134}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,834] Trial 6 finished with value: 0.034876347777148875 and parameters: {'w0': 0.25636430846331515, 'w1': 0.4483327667248437, 'w2': 0.32987984529054937}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,843] Trial 7 finished with value: 0.034069557357680025 and parameters: {'w0': 0.47170334293067984, 'w1': 0.5290318194328901, 'w2': 0.035829284841519815}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,852] Trial 8 finished with value: 0.03420338480714613 and parameters: {'w0': 0.7120204002502285, 'w1': 0.23268629721475065, 'w2': 0.38359029890714924}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,860] Trial 9 finished with value: 0.034069557357680025 and parameters: {'w0': 0.7680706710116421, 'w1': 0.9076118491349496, 'w2': 0.05228377103881299}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,879] Trial 10 finished with value: 0.03466715319468916 and parameters: {'w0': 0.9383156886091089, 'w1': 0.7484049434304989, 'w2': 0.5531428480939611}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,896] Trial 11 finished with value: 0.03400108667290369 and parameters: {'w0': 0.4599165508654626, 'w1': 0.6090455338092188, 'w2': 0.006807882528577863}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,913] Trial 12 finished with value: 0.03440542856207707 and parameters: {'w0': 0.5217772720784085, 'w1': 0.6458720315581433, 'w2': 0.21511970255875978}. Best is trial 1 with value: 0.033997675762706736.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 2): 0.9642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:38:39,932] Trial 13 finished with value: 0.03487634451851285 and parameters: {'w0': 0.44567089896083834, 'w1': 0.9846149981360177, 'w2': 0.54019425326879}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,949] Trial 14 finished with value: 0.03474091773679955 and parameters: {'w0': 0.9733407432060434, 'w1': 0.004543259631786811, 'w2': 0.007552535428497191}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,968] Trial 15 finished with value: 0.03453530256309567 and parameters: {'w0': 0.601679008175327, 'w1': 0.3151218659724553, 'w2': 0.41758898445443526}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:39,987] Trial 16 finished with value: 0.034808725552048614 and parameters: {'w0': 0.3417477940831313, 'w1': 0.5806119624943784, 'w2': 0.6899157013532797}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:40,006] Trial 17 finished with value: 0.034271189286548376 and parameters: {'w0': 0.5955441450981296, 'w1': 0.7830330832784729, 'w2': 0.15737288857952605}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:40,025] Trial 18 finished with value: 0.03480947603309226 and parameters: {'w0': 0.0682560427788258, 'w1': 0.7113492208164542, 'w2': 0.25679711862434884}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:40,044] Trial 19 finished with value: 0.03413385905298327 and parameters: {'w0': 0.8695095862603595, 'w1': 0.4677748896098221, 'w2': 0.12486051370319307}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:40,062] Trial 20 finished with value: 0.03487634451851285 and parameters: {'w0': 0.3693512180734211, 'w1': 0.8439342360934167, 'w2': 0.4494469919022229}. Best is trial 1 with value: 0.033997675762706736.\n",
            "[I 2025-06-16 10:38:40,081] Trial 21 finished with value: 0.03393282222848315 and parameters: {'w0': 0.4791143035473123, 'w1': 0.5526095360751029, 'w2': 0.003005416079099772}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,103] Trial 22 finished with value: 0.034067328760718496 and parameters: {'w0': 0.6335045558644783, 'w1': 0.6568273350570994, 'w2': 0.01982081959059523}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,122] Trial 23 finished with value: 0.034599238537442845 and parameters: {'w0': 0.3456850158403614, 'w1': 0.5310879441722509, 'w2': 0.19848018035199066}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,142] Trial 24 finished with value: 0.03440802613772331 and parameters: {'w0': 0.40832380137641233, 'w1': 0.3240963926828725, 'w2': 0.10995529083208169}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,159] Trial 25 finished with value: 0.03459796263769732 and parameters: {'w0': 0.5242081947154105, 'w1': 0.4468010139467782, 'w2': 0.3091577278938994}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,178] Trial 26 finished with value: 0.03420173910993651 and parameters: {'w0': 0.6480586197719453, 'w1': 0.5702419824953552, 'w2': 0.07947698998527221}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,197] Trial 27 finished with value: 0.03400108667290369 and parameters: {'w0': 0.5291607157622831, 'w1': 0.6974472726125871, 'w2': 0.007841313629485274}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,215] Trial 28 finished with value: 0.03427186406358773 and parameters: {'w0': 0.8500013497569863, 'w1': 0.864925890164755, 'w2': 0.21415970962749228}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,235] Trial 29 finished with value: 0.03440792831271733 and parameters: {'w0': 0.28156501858127564, 'w1': 0.7709138151965531, 'w2': 0.08711856581604832}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,253] Trial 30 finished with value: 0.03494402469082181 and parameters: {'w0': 0.6816327899389295, 'w1': 0.3854499265355099, 'w2': 0.9802569227663414}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,274] Trial 31 finished with value: 0.033934549210899 and parameters: {'w0': 0.5548609655206213, 'w1': 0.6916868452219433, 'w2': 0.003176188102264668}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,293] Trial 32 finished with value: 0.03427213968915799 and parameters: {'w0': 0.5666674241061617, 'w1': 0.6102498143528533, 'w2': 0.10772847567150398}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,311] Trial 33 finished with value: 0.03480811711301679 and parameters: {'w0': 0.4341137347060765, 'w1': 0.509471470112295, 'w2': 0.8706476598556884}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,331] Trial 34 finished with value: 0.03453776973827827 and parameters: {'w0': 0.2690115343563191, 'w1': 0.6846146792344364, 'w2': 0.1693509776024689}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,350] Trial 35 finished with value: 0.03488057611271089 and parameters: {'w0': 0.02000956807476817, 'w1': 0.5706263919486381, 'w2': 0.04667476741076933}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,372] Trial 36 finished with value: 0.03494516473759579 and parameters: {'w0': 0.1322384204488184, 'w1': 0.8066815745801323, 'w2': 0.13750746504993955}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,392] Trial 37 finished with value: 0.03487794585113013 and parameters: {'w0': 0.21893021212930708, 'w1': 0.39518712652355137, 'w2': 0.6680979800532144}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,411] Trial 38 finished with value: 0.03406780276386889 and parameters: {'w0': 0.7173060806919548, 'w1': 0.7382635479345575, 'w2': 0.0022134296008355925}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,432] Trial 39 finished with value: 0.03420117171670212 and parameters: {'w0': 0.47582062535911424, 'w1': 0.6275986696528265, 'w2': 0.07394222719474804}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,452] Trial 40 finished with value: 0.03420011766141007 and parameters: {'w0': 0.8369367338314385, 'w1': 0.47636353467534936, 'w2': 0.26803952304600775}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,472] Trial 41 finished with value: 0.03400108667290369 and parameters: {'w0': 0.5457268884165538, 'w1': 0.6977496566446652, 'w2': 0.003997980245097447}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,492] Trial 42 finished with value: 0.03420117171670212 and parameters: {'w0': 0.49678739594759463, 'w1': 0.6703821847646244, 'w2': 0.06391693716678859}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,513] Trial 43 finished with value: 0.034132275335617024 and parameters: {'w0': 0.4024062590371297, 'w1': 0.5977354998530446, 'w2': 0.05560848890392823}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,532] Trial 44 finished with value: 0.03440456411050685 and parameters: {'w0': 0.573811977465018, 'w1': 0.537300210725904, 'w2': 0.16892715522617477}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,552] Trial 45 finished with value: 0.03433982423573112 and parameters: {'w0': 0.3099468839124412, 'w1': 0.7338526253747792, 'w2': 0.11646605511188765}. Best is trial 21 with value: 0.03393282222848315.\n",
            "[I 2025-06-16 10:38:40,571] Trial 46 finished with value: 0.03372775210490109 and parameters: {'w0': 0.993805445086001, 'w1': 0.9201367799014106, 'w2': 7.40260170131379e-05}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,590] Trial 47 finished with value: 0.03440185486606284 and parameters: {'w0': 0.9949765605842826, 'w1': 0.972466740775678, 'w2': 0.3699388776041938}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,610] Trial 48 finished with value: 0.034202748606305455 and parameters: {'w0': 0.9178893317593506, 'w1': 0.8969699475172781, 'w2': 0.050712851108322896}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,629] Trial 49 finished with value: 0.03459931422943563 and parameters: {'w0': 0.9198303216107702, 'w1': 0.9466555352647957, 'w2': 0.8920991644438221}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,648] Trial 50 finished with value: 0.0343354904240486 and parameters: {'w0': 0.806367011749962, 'w1': 0.8182993157404499, 'w2': 0.2305342914415243}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,668] Trial 51 finished with value: 0.03400108667290369 and parameters: {'w0': 0.45879829142124057, 'w1': 0.6211702359449016, 'w2': 0.00965719463593762}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,687] Trial 52 finished with value: 0.033857056371615846 and parameters: {'w0': 0.9425309521278192, 'w1': 0.6535888485966896, 'w2': 0.03738687028960386}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,708] Trial 53 finished with value: 0.03413535409384705 and parameters: {'w0': 0.8853923775753704, 'w1': 0.43490131618757066, 'w2': 0.08397610531680061}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,727] Trial 54 finished with value: 0.033857056371615846 and parameters: {'w0': 0.9605262253320332, 'w1': 0.6630869033938652, 'w2': 0.035596536732928015}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,749] Trial 55 finished with value: 0.033997675762706736 and parameters: {'w0': 0.9595447046731879, 'w1': 0.6497503405227131, 'w2': 0.150908963863961}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,768] Trial 56 finished with value: 0.03392872088750687 and parameters: {'w0': 0.8892582797922279, 'w1': 0.7495720686424241, 'w2': 0.04193395723625122}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,789] Trial 57 finished with value: 0.033791869320745294 and parameters: {'w0': 0.991083661220235, 'w1': 0.7674244967949114, 'w2': 0.0418712981968316}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,809] Trial 58 finished with value: 0.03393214846109682 and parameters: {'w0': 0.9853104217562675, 'w1': 0.8789891566164307, 'w2': 0.05094787698845847}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,830] Trial 59 finished with value: 0.03427376699919349 and parameters: {'w0': 0.9939424687139613, 'w1': 0.9026783971624142, 'w2': 0.17202029441118277}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,849] Trial 60 finished with value: 0.034133902147390094 and parameters: {'w0': 0.8955439020105628, 'w1': 0.859755406071433, 'w2': 0.04634397360519002}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,867] Trial 61 finished with value: 0.03406561012603149 and parameters: {'w0': 0.9500976043217852, 'w1': 0.9389077272767956, 'w2': 0.10065984530926234}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,889] Trial 62 finished with value: 0.03386120719659291 and parameters: {'w0': 0.9336861234860468, 'w1': 0.7599781996995552, 'w2': 0.03685616845466258}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,909] Trial 63 finished with value: 0.03392872088750687 and parameters: {'w0': 0.9296775148014158, 'w1': 0.7765717328822657, 'w2': 0.038507296004331996}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,928] Trial 64 finished with value: 0.03413622692995488 and parameters: {'w0': 0.8125381996494236, 'w1': 0.7797023812575158, 'w2': 0.12197291818628664}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,946] Trial 65 finished with value: 0.03433665261855434 and parameters: {'w0': 0.7718951119930901, 'w1': 0.8316070484078611, 'w2': 0.1905251735633601}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,965] Trial 66 finished with value: 0.033929169929052705 and parameters: {'w0': 0.9225725428904284, 'w1': 0.7429951389450119, 'w2': 0.03675571148099909}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:40,983] Trial 67 finished with value: 0.03420212632455866 and parameters: {'w0': 0.862168547346821, 'w1': 0.7793098513265692, 'w2': 0.09048133755236419}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,003] Trial 68 finished with value: 0.03406673218443523 and parameters: {'w0': 0.9515263445196247, 'w1': 0.7169668121187397, 'w2': 0.13798140174628323}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,022] Trial 69 finished with value: 0.03459796263769732 and parameters: {'w0': 0.8943965938173911, 'w1': 0.8090151785340051, 'w2': 0.5408891687657891}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,042] Trial 70 finished with value: 0.03379303394041222 and parameters: {'w0': 0.9618078255479977, 'w1': 0.7606073479166079, 'w2': 0.040140004012911075}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,060] Trial 71 finished with value: 0.03379303394041222 and parameters: {'w0': 0.9649843004438744, 'w1': 0.758963273713606, 'w2': 0.03159970069338335}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,078] Trial 72 finished with value: 0.0339274395532807 and parameters: {'w0': 0.971971404756539, 'w1': 0.7506409524897806, 'w2': 0.07437877270355867}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,097] Trial 73 finished with value: 0.03413044506944096 and parameters: {'w0': 0.9704649137826681, 'w1': 0.6654706161579051, 'w2': 0.08617661866100051}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,115] Trial 74 finished with value: 0.03446691902670607 and parameters: {'w0': 0.9966519143862381, 'w1': 0.8424682827614351, 'w2': 0.48839430751854174}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,134] Trial 75 finished with value: 0.03406601368792139 and parameters: {'w0': 0.831502476645716, 'w1': 0.8071834690514121, 'w2': 0.028308714453580727}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,153] Trial 76 finished with value: 0.03466801112722451 and parameters: {'w0': 0.94874822406234, 'w1': 0.7580292423530136, 'w2': 0.5969969086725798}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,171] Trial 77 finished with value: 0.03385889652094909 and parameters: {'w0': 0.9641854761206244, 'w1': 0.7105924376592841, 'w2': 0.07233676377185727}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,190] Trial 78 finished with value: 0.034135683921052595 and parameters: {'w0': 0.8591666220217129, 'w1': 0.7098515608120526, 'w2': 0.11439803685018593}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,208] Trial 79 finished with value: 0.03427056642859083 and parameters: {'w0': 0.909781357067392, 'w1': 0.6396307779122057, 'w2': 0.23179707077234082}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,228] Trial 80 finished with value: 0.03392684994254258 and parameters: {'w0': 0.9374279624521946, 'w1': 0.6804297273242623, 'w2': 0.027256299146074393}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,247] Trial 81 finished with value: 0.033791869320745294 and parameters: {'w0': 0.938952272883646, 'w1': 0.7138384525628975, 'w2': 0.02790187756035382}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,268] Trial 82 finished with value: 0.03379130356464033 and parameters: {'w0': 0.960367911019842, 'w1': 0.7256657285931113, 'w2': 0.061835119075373646}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,288] Trial 83 finished with value: 0.03399528241868632 and parameters: {'w0': 0.9665461967469964, 'w1': 0.5949239583461191, 'w2': 0.07448906266239033}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,307] Trial 84 finished with value: 0.034064846772477675 and parameters: {'w0': 0.9989011778096873, 'w1': 0.7244880095275823, 'w2': 0.14046393176530902}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,328] Trial 85 finished with value: 0.03420212632455866 and parameters: {'w0': 0.8690673709655685, 'w1': 0.799121389693918, 'w2': 0.07183934524982816}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,348] Trial 86 finished with value: 0.033996884040018105 and parameters: {'w0': 0.9095774011587798, 'w1': 0.7026767957288275, 'w2': 0.09953112392817828}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,369] Trial 87 finished with value: 0.033859628736620184 and parameters: {'w0': 0.9677185277182071, 'w1': 0.6414478396743981, 'w2': 0.0208021841589204}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,389] Trial 88 finished with value: 0.034135954792144485 and parameters: {'w0': 0.7409700820596425, 'w1': 0.6645259951514283, 'w2': 0.06394510816642084}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,409] Trial 89 finished with value: 0.034204161602720884 and parameters: {'w0': 0.8437049556585478, 'w1': 0.9977606821837786, 'w2': 0.12159803356605206}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,428] Trial 90 finished with value: 0.03460157496165972 and parameters: {'w0': 0.8825799057161774, 'w1': 0.5602257015367101, 'w2': 0.7698280463877926}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,448] Trial 91 finished with value: 0.03385941028110295 and parameters: {'w0': 0.970666726444976, 'w1': 0.6352875478768204, 'w2': 0.0202118740817473}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,468] Trial 92 finished with value: 0.033791869320745294 and parameters: {'w0': 0.944506137648195, 'w1': 0.7241381363582352, 'w2': 0.024721594440872054}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,487] Trial 93 finished with value: 0.03420242562633824 and parameters: {'w0': 0.9430732553713066, 'w1': 0.05474691750919414, 'w2': 0.005250054623446629}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,508] Trial 94 finished with value: 0.03379130356464033 and parameters: {'w0': 0.9214119027992894, 'w1': 0.6807888672585674, 'w2': 0.06029948072934958}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,527] Trial 95 finished with value: 0.03379130356464033 and parameters: {'w0': 0.9056671510641017, 'w1': 0.6881770315644802, 'w2': 0.05504077316272393}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,546] Trial 96 finished with value: 0.03440612591750991 and parameters: {'w0': 0.9137894105282419, 'w1': 0.7364135085893032, 'w2': 0.30559819064771443}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,566] Trial 97 finished with value: 0.0339968047746233 and parameters: {'w0': 0.8256543707123861, 'w1': 0.6869493489743145, 'w2': 0.10026305114418}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,586] Trial 98 finished with value: 0.03427213968915799 and parameters: {'w0': 0.8826698581025414, 'w1': 0.9305562654334739, 'w2': 0.15444793611148022}. Best is trial 46 with value: 0.03372775210490109.\n",
            "[I 2025-06-16 10:38:41,606] Trial 99 finished with value: 0.03386159570863445 and parameters: {'w0': 0.9067896119092848, 'w1': 0.7892126222614113, 'w2': 0.00013578116783794641}. Best is trial 46 with value: 0.03372775210490109.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 2): 0.9663\n",
            "\n",
            "=== Fold 3/5 ===\n",
            "\n",
            "--- Training combination ('lgbm',) ---\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002532 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.336006\n",
            "[LightGBM] [Info] Start training from score -3.553386\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889700\n",
            "[LightGBM] [Info] Start training from score -3.744780\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.559858\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013656\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912304\n",
            "[LightGBM] [Info] Start training from score -2.909219\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521637\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.456743\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:38:49,536] A new study created in memory with name: no-name-724d82b3-c8ef-4932-b962-76a71ba7f943\n",
            "[I 2025-06-16 10:38:49,542] Trial 0 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5496849876617205}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,547] Trial 1 finished with value: 0.034367032487514826 and parameters: {'w0': 0.39254561357209594}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,552] Trial 2 finished with value: 0.034367032487514826 and parameters: {'w0': 0.9160439598645677}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,557] Trial 3 finished with value: 0.034367032487514826 and parameters: {'w0': 0.36895382623372475}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,562] Trial 4 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5554133522500055}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,567] Trial 5 finished with value: 0.034367032487514826 and parameters: {'w0': 0.011314352735751987}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,572] Trial 6 finished with value: 0.034367032487514826 and parameters: {'w0': 0.27545535341882876}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,577] Trial 7 finished with value: 0.034367032487514826 and parameters: {'w0': 0.7026021114971409}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,581] Trial 8 finished with value: 0.034367032487514826 and parameters: {'w0': 0.16761090489511032}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,586] Trial 9 finished with value: 0.034367032487514826 and parameters: {'w0': 0.7201941606829253}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,597] Trial 10 finished with value: 0.034367032487514826 and parameters: {'w0': 0.9927315552849336}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,607] Trial 11 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5156914101359861}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,617] Trial 12 finished with value: 0.034367032487514826 and parameters: {'w0': 0.38916335258886303}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,625] Trial 13 finished with value: 0.034367032487514826 and parameters: {'w0': 0.7320090653503967}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,634] Trial 14 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5993485496239428}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,642] Trial 15 finished with value: 0.034367032487514826 and parameters: {'w0': 0.3337633010833519}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,651] Trial 16 finished with value: 0.034367032487514826 and parameters: {'w0': 0.16842001375781473}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,659] Trial 17 finished with value: 0.034367032487514826 and parameters: {'w0': 0.4616342892492891}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,668] Trial 18 finished with value: 0.034367032487514826 and parameters: {'w0': 0.8384603094331957}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,679] Trial 19 finished with value: 0.034367032487514826 and parameters: {'w0': 0.6113983996603558}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,688] Trial 20 finished with value: 0.034367032487514826 and parameters: {'w0': 0.22610925484683997}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,697] Trial 21 finished with value: 0.034367032487514826 and parameters: {'w0': 0.4472547665475026}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,705] Trial 22 finished with value: 0.034367032487514826 and parameters: {'w0': 0.9580396233362674}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,715] Trial 23 finished with value: 0.034367032487514826 and parameters: {'w0': 0.8681908295498142}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,724] Trial 24 finished with value: 0.034367032487514826 and parameters: {'w0': 0.8267512177023272}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,733] Trial 25 finished with value: 0.034367032487514826 and parameters: {'w0': 0.6749510810264054}. Best is trial 0 with value: 0.034367032487514826.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 3): 0.9656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:38:49,742] Trial 26 finished with value: 0.034367032487514826 and parameters: {'w0': 0.10193347168641409}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,751] Trial 27 finished with value: 0.034367032487514826 and parameters: {'w0': 0.4306061499441905}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,760] Trial 28 finished with value: 0.034367032487514826 and parameters: {'w0': 0.9191070206310131}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,769] Trial 29 finished with value: 0.034367032487514826 and parameters: {'w0': 0.3280524834247716}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,777] Trial 30 finished with value: 0.034367032487514826 and parameters: {'w0': 0.803212700227584}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,789] Trial 31 finished with value: 0.034367032487514826 and parameters: {'w0': 0.544604361983241}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,799] Trial 32 finished with value: 0.034367032487514826 and parameters: {'w0': 0.3680128480512727}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,808] Trial 33 finished with value: 0.034367032487514826 and parameters: {'w0': 0.268871635165773}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,817] Trial 34 finished with value: 0.034367032487514826 and parameters: {'w0': 0.49872381094180074}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,826] Trial 35 finished with value: 0.034367032487514826 and parameters: {'w0': 0.6084959050143128}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,835] Trial 36 finished with value: 0.034367032487514826 and parameters: {'w0': 0.0670877380942409}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,844] Trial 37 finished with value: 0.034367032487514826 and parameters: {'w0': 0.2524622726973712}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,853] Trial 38 finished with value: 0.034367032487514826 and parameters: {'w0': 0.30768920956773094}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,862] Trial 39 finished with value: 0.034367032487514826 and parameters: {'w0': 0.40393149491899966}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,871] Trial 40 finished with value: 0.034367032487514826 and parameters: {'w0': 0.6658202919993088}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,880] Trial 41 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5379853846058873}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,890] Trial 42 finished with value: 0.034367032487514826 and parameters: {'w0': 0.7769602216248377}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,899] Trial 43 finished with value: 0.034367032487514826 and parameters: {'w0': 0.2072523957641888}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,909] Trial 44 finished with value: 0.034367032487514826 and parameters: {'w0': 0.49153543143843015}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,919] Trial 45 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5856959786491136}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,928] Trial 46 finished with value: 0.034367032487514826 and parameters: {'w0': 0.743438375162318}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,938] Trial 47 finished with value: 0.034367032487514826 and parameters: {'w0': 0.3618041350881769}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,947] Trial 48 finished with value: 0.034367032487514826 and parameters: {'w0': 0.667767242671327}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,957] Trial 49 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5616094585994257}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,968] Trial 50 finished with value: 0.034367032487514826 and parameters: {'w0': 0.4741528857477963}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,979] Trial 51 finished with value: 0.034367032487514826 and parameters: {'w0': 0.1288640474160921}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,989] Trial 52 finished with value: 0.034367032487514826 and parameters: {'w0': 0.41726751451982946}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:49,998] Trial 53 finished with value: 0.034367032487514826 and parameters: {'w0': 0.9995344396688302}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,008] Trial 54 finished with value: 0.034367032487514826 and parameters: {'w0': 0.05435831189992768}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,017] Trial 55 finished with value: 0.034367032487514826 and parameters: {'w0': 0.6342764683968946}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,029] Trial 56 finished with value: 0.034367032487514826 and parameters: {'w0': 0.030455598069414225}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,039] Trial 57 finished with value: 0.034367032487514826 and parameters: {'w0': 0.17778019585917887}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,051] Trial 58 finished with value: 0.034367032487514826 and parameters: {'w0': 0.8914113155822077}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,061] Trial 59 finished with value: 0.034367032487514826 and parameters: {'w0': 0.7065467325667636}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,070] Trial 60 finished with value: 0.034367032487514826 and parameters: {'w0': 0.4547564840266402}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,080] Trial 61 finished with value: 0.034367032487514826 and parameters: {'w0': 0.30183067900157545}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,090] Trial 62 finished with value: 0.034367032487514826 and parameters: {'w0': 0.13202588339298027}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,099] Trial 63 finished with value: 0.034367032487514826 and parameters: {'w0': 0.3650386433787194}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,109] Trial 64 finished with value: 0.034367032487514826 and parameters: {'w0': 0.005849344571214346}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,119] Trial 65 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5213896304638417}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,129] Trial 66 finished with value: 0.034367032487514826 and parameters: {'w0': 0.26706005496925556}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,139] Trial 67 finished with value: 0.034367032487514826 and parameters: {'w0': 0.3341153965450843}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,149] Trial 68 finished with value: 0.034367032487514826 and parameters: {'w0': 0.3968609387695166}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,159] Trial 69 finished with value: 0.034367032487514826 and parameters: {'w0': 0.19890032158844845}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,168] Trial 70 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5700260486187924}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,178] Trial 71 finished with value: 0.034367032487514826 and parameters: {'w0': 0.4298708602374695}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,187] Trial 72 finished with value: 0.034367032487514826 and parameters: {'w0': 0.6200952210427617}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,197] Trial 73 finished with value: 0.034367032487514826 and parameters: {'w0': 0.9536422593748112}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,208] Trial 74 finished with value: 0.034367032487514826 and parameters: {'w0': 0.8319121433339038}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,218] Trial 75 finished with value: 0.034367032487514826 and parameters: {'w0': 0.778706340679387}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,228] Trial 76 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5051093227849885}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,238] Trial 77 finished with value: 0.034367032487514826 and parameters: {'w0': 0.7090198254629831}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,248] Trial 78 finished with value: 0.034367032487514826 and parameters: {'w0': 0.23044247454968347}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,258] Trial 79 finished with value: 0.034367032487514826 and parameters: {'w0': 0.4759281027012151}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,268] Trial 80 finished with value: 0.034367032487514826 and parameters: {'w0': 0.29319319096204416}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,278] Trial 81 finished with value: 0.034367032487514826 and parameters: {'w0': 0.3324402501797835}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,288] Trial 82 finished with value: 0.034367032487514826 and parameters: {'w0': 0.08849295775783714}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,297] Trial 83 finished with value: 0.034367032487514826 and parameters: {'w0': 0.14613608872323608}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,307] Trial 84 finished with value: 0.034367032487514826 and parameters: {'w0': 0.86851691426979}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,317] Trial 85 finished with value: 0.034367032487514826 and parameters: {'w0': 0.37862118411186013}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,326] Trial 86 finished with value: 0.034367032487514826 and parameters: {'w0': 0.6334463943299053}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,335] Trial 87 finished with value: 0.034367032487514826 and parameters: {'w0': 0.4415194257876115}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,345] Trial 88 finished with value: 0.034367032487514826 and parameters: {'w0': 0.2319269149139363}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,355] Trial 89 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5303745314866688}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,365] Trial 90 finished with value: 0.034367032487514826 and parameters: {'w0': 0.3527189299736607}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,374] Trial 91 finished with value: 0.034367032487514826 and parameters: {'w0': 0.7495138070021368}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,383] Trial 92 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5859980360068652}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,393] Trial 93 finished with value: 0.034367032487514826 and parameters: {'w0': 0.9406062650802229}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,404] Trial 94 finished with value: 0.034367032487514826 and parameters: {'w0': 0.6909132319130086}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,414] Trial 95 finished with value: 0.034367032487514826 and parameters: {'w0': 0.17003531889253676}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,423] Trial 96 finished with value: 0.034367032487514826 and parameters: {'w0': 0.5514327685517973}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,433] Trial 97 finished with value: 0.034367032487514826 and parameters: {'w0': 0.804960039326984}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,443] Trial 98 finished with value: 0.034367032487514826 and parameters: {'w0': 0.10245087966684668}. Best is trial 0 with value: 0.034367032487514826.\n",
            "[I 2025-06-16 10:38:50,452] Trial 99 finished with value: 0.034367032487514826 and parameters: {'w0': 0.25808791075521403}. Best is trial 0 with value: 0.034367032487514826.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 3): 0.9656\n",
            "\n",
            "--- Training combination ('mlp',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:39:07,787] A new study created in memory with name: no-name-f5b2da0b-5910-4d72-b389-82250d20fe88\n",
            "[I 2025-06-16 10:39:07,794] Trial 0 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6373270049250416}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,799] Trial 1 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6712393283217157}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,804] Trial 2 finished with value: 0.0335251250826325 and parameters: {'w0': 0.23524929672080808}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,809] Trial 3 finished with value: 0.0335251250826325 and parameters: {'w0': 0.4589171751479325}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,814] Trial 4 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5281734353758254}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,819] Trial 5 finished with value: 0.0335251250826325 and parameters: {'w0': 0.16898486445578442}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,823] Trial 6 finished with value: 0.0335251250826325 and parameters: {'w0': 0.3178216650212433}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,828] Trial 7 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6930651760223194}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,833] Trial 8 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7065711891210896}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,838] Trial 9 finished with value: 0.0335251250826325 and parameters: {'w0': 0.704647479009177}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,850] Trial 10 finished with value: 0.0335251250826325 and parameters: {'w0': 0.9816467571768859}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,862] Trial 11 finished with value: 0.0335251250826325 and parameters: {'w0': 0.8609402292549737}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,875] Trial 12 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5108063401420669}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,884] Trial 13 finished with value: 0.0335251250826325 and parameters: {'w0': 0.820373776637524}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,893] Trial 14 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5907825654646446}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,901] Trial 15 finished with value: 0.0335251250826325 and parameters: {'w0': 0.0346775407025125}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,909] Trial 16 finished with value: 0.0335251250826325 and parameters: {'w0': 0.41023660015058494}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,918] Trial 17 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6399947865661119}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,926] Trial 18 finished with value: 0.0335251250826325 and parameters: {'w0': 0.8165426112040753}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,935] Trial 19 finished with value: 0.0335251250826325 and parameters: {'w0': 0.9911285125582238}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,944] Trial 20 finished with value: 0.0335251250826325 and parameters: {'w0': 0.3725568378657239}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,953] Trial 21 finished with value: 0.0335251250826325 and parameters: {'w0': 0.26561370769019044}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,962] Trial 22 finished with value: 0.0335251250826325 and parameters: {'w0': 0.10748024781215873}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,971] Trial 23 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5793463295166181}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,980] Trial 24 finished with value: 0.0335251250826325 and parameters: {'w0': 0.25408829010146217}. Best is trial 0 with value: 0.0335251250826325.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted mlp (fold 3): 0.9669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:39:07,989] Trial 25 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7546747354967783}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:07,998] Trial 26 finished with value: 0.0335251250826325 and parameters: {'w0': 0.616903405683527}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,006] Trial 27 finished with value: 0.0335251250826325 and parameters: {'w0': 0.46654401447370236}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,017] Trial 28 finished with value: 0.0335251250826325 and parameters: {'w0': 0.18230489085649598}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,028] Trial 29 finished with value: 0.0335251250826325 and parameters: {'w0': 0.9117464266846247}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,038] Trial 30 finished with value: 0.0335251250826325 and parameters: {'w0': 0.4175325055940279}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,047] Trial 31 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5382199436036411}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,057] Trial 32 finished with value: 0.0335251250826325 and parameters: {'w0': 0.4891490704482683}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,066] Trial 33 finished with value: 0.0335251250826325 and parameters: {'w0': 0.32231933410782254}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,075] Trial 34 finished with value: 0.0335251250826325 and parameters: {'w0': 0.655857762582275}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,084] Trial 35 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7550864664767186}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,093] Trial 36 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5722867825583773}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,105] Trial 37 finished with value: 0.0335251250826325 and parameters: {'w0': 0.4506722167307682}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,115] Trial 38 finished with value: 0.0335251250826325 and parameters: {'w0': 0.18053696002979502}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,124] Trial 39 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7040881337209722}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,133] Trial 40 finished with value: 0.0335251250826325 and parameters: {'w0': 0.012663690475256506}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,144] Trial 41 finished with value: 0.0335251250826325 and parameters: {'w0': 0.550771640902647}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,156] Trial 42 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6585752036321877}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,165] Trial 43 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7474470066157979}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,175] Trial 44 finished with value: 0.0335251250826325 and parameters: {'w0': 0.3446836308167937}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,184] Trial 45 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5057329241364186}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,192] Trial 46 finished with value: 0.0335251250826325 and parameters: {'w0': 0.2589809011102617}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,201] Trial 47 finished with value: 0.0335251250826325 and parameters: {'w0': 0.10844205442124788}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,210] Trial 48 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6120105569411339}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,220] Trial 49 finished with value: 0.0335251250826325 and parameters: {'w0': 0.39977801340675423}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,230] Trial 50 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6867624001415011}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,241] Trial 51 finished with value: 0.0335251250826325 and parameters: {'w0': 0.0873060042253457}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,251] Trial 52 finished with value: 0.0335251250826325 and parameters: {'w0': 0.16226804955458635}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,260] Trial 53 finished with value: 0.0335251250826325 and parameters: {'w0': 0.2880667185890875}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,269] Trial 54 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7956660657045342}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,278] Trial 55 finished with value: 0.0335251250826325 and parameters: {'w0': 0.2241938053475128}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,288] Trial 56 finished with value: 0.0335251250826325 and parameters: {'w0': 0.06526650666288814}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,298] Trial 57 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5201664429451727}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,308] Trial 58 finished with value: 0.0335251250826325 and parameters: {'w0': 0.13911601160234133}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,317] Trial 59 finished with value: 0.0335251250826325 and parameters: {'w0': 0.22070447397346643}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,327] Trial 60 finished with value: 0.0335251250826325 and parameters: {'w0': 0.8843411958787876}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,336] Trial 61 finished with value: 0.0335251250826325 and parameters: {'w0': 0.3151105145190973}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,346] Trial 62 finished with value: 0.0335251250826325 and parameters: {'w0': 0.44805963427730866}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,355] Trial 63 finished with value: 0.0335251250826325 and parameters: {'w0': 0.3931038318890777}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,366] Trial 64 finished with value: 0.0335251250826325 and parameters: {'w0': 0.2236947220849849}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,376] Trial 65 finished with value: 0.0335251250826325 and parameters: {'w0': 0.36258815022622043}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,386] Trial 66 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6057006806195367}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,396] Trial 67 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5699945705854149}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,406] Trial 68 finished with value: 0.0335251250826325 and parameters: {'w0': 0.2973912153300023}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,416] Trial 69 finished with value: 0.0335251250826325 and parameters: {'w0': 0.4839976263307607}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,425] Trial 70 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6880228158615135}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,435] Trial 71 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6352845414776483}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,444] Trial 72 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7496714751188914}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,454] Trial 73 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5415047071739885}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,464] Trial 74 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6584983732239997}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,474] Trial 75 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7841460510984004}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,483] Trial 76 finished with value: 0.0335251250826325 and parameters: {'w0': 0.207050978834029}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,493] Trial 77 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7087195010498367}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,503] Trial 78 finished with value: 0.0335251250826325 and parameters: {'w0': 0.43247073479965864}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,512] Trial 79 finished with value: 0.0335251250826325 and parameters: {'w0': 0.8447578666602628}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,522] Trial 80 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5920285646086918}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,533] Trial 81 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7159045693534982}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,542] Trial 82 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6361087341558644}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,551] Trial 83 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7796144169538152}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,561] Trial 84 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7319465289770787}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,571] Trial 85 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6640971562598676}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,581] Trial 86 finished with value: 0.0335251250826325 and parameters: {'w0': 0.14313541770633914}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,590] Trial 87 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5249063481013164}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,599] Trial 88 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5594309188680617}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,609] Trial 89 finished with value: 0.0335251250826325 and parameters: {'w0': 0.9427120335527467}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,620] Trial 90 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6873946523807333}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,630] Trial 91 finished with value: 0.0335251250826325 and parameters: {'w0': 0.8314092124328807}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,639] Trial 92 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6258680883681138}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,648] Trial 93 finished with value: 0.0335251250826325 and parameters: {'w0': 0.2514806752922101}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,658] Trial 94 finished with value: 0.0335251250826325 and parameters: {'w0': 0.6668411169026462}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,667] Trial 95 finished with value: 0.0335251250826325 and parameters: {'w0': 0.7296486484055079}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,677] Trial 96 finished with value: 0.0335251250826325 and parameters: {'w0': 0.19308864479907023}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,686] Trial 97 finished with value: 0.0335251250826325 and parameters: {'w0': 0.4717537226062576}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,696] Trial 98 finished with value: 0.0335251250826325 and parameters: {'w0': 0.34034247245242355}. Best is trial 0 with value: 0.0335251250826325.\n",
            "[I 2025-06-16 10:39:08,707] Trial 99 finished with value: 0.0335251250826325 and parameters: {'w0': 0.5925621187354335}. Best is trial 0 with value: 0.0335251250826325.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 3): 0.9665\n",
            "\n",
            "--- Training combination ('logreg',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:39:11,248] A new study created in memory with name: no-name-ddc4dd5b-dfb7-4880-bf1a-1ea0d89f82ea\n",
            "[I 2025-06-16 10:39:11,257] Trial 0 finished with value: 0.03443244477385765 and parameters: {'w0': 0.5897486247903361}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,265] Trial 1 finished with value: 0.03443244477385765 and parameters: {'w0': 0.22820424269062234}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,272] Trial 2 finished with value: 0.03443244477385765 and parameters: {'w0': 0.15621721594715343}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,280] Trial 3 finished with value: 0.03443244477385765 and parameters: {'w0': 0.10096683282968355}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,288] Trial 4 finished with value: 0.03443244477385765 and parameters: {'w0': 0.5829281231676611}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,295] Trial 5 finished with value: 0.03443244477385765 and parameters: {'w0': 0.130128416109778}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,303] Trial 6 finished with value: 0.03443244477385765 and parameters: {'w0': 0.8042638147643444}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,312] Trial 7 finished with value: 0.03443244477385765 and parameters: {'w0': 0.2530001813516687}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,320] Trial 8 finished with value: 0.03443244477385765 and parameters: {'w0': 0.9809691987419625}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,328] Trial 9 finished with value: 0.03443244477385765 and parameters: {'w0': 0.10868178525476013}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,342] Trial 10 finished with value: 0.03443244477385765 and parameters: {'w0': 0.4637216622624125}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,360] Trial 11 finished with value: 0.03443244477385765 and parameters: {'w0': 0.4302060201540795}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,369] Trial 12 finished with value: 0.03443244477385765 and parameters: {'w0': 0.6454172032327822}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,379] Trial 13 finished with value: 0.03443244477385765 and parameters: {'w0': 0.33958271773127685}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,387] Trial 14 finished with value: 0.03443244477385765 and parameters: {'w0': 0.6534177497632463}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,396] Trial 15 finished with value: 0.03443244477385765 and parameters: {'w0': 0.30579827625074196}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,405] Trial 16 finished with value: 0.03443244477385765 and parameters: {'w0': 0.005148093088226002}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,414] Trial 17 finished with value: 0.03443244477385765 and parameters: {'w0': 0.8070552252015724}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,423] Trial 18 finished with value: 0.03443244477385765 and parameters: {'w0': 0.5286964384051752}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,433] Trial 19 finished with value: 0.03443244477385765 and parameters: {'w0': 0.39763053026455447}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,443] Trial 20 finished with value: 0.03443244477385765 and parameters: {'w0': 0.7570776242010179}. Best is trial 0 with value: 0.03443244477385765.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 3): 0.9656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:39:11,452] Trial 21 finished with value: 0.03443244477385765 and parameters: {'w0': 0.192920906528802}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,461] Trial 22 finished with value: 0.03443244477385765 and parameters: {'w0': 0.2222729840443003}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,471] Trial 23 finished with value: 0.03443244477385765 and parameters: {'w0': 0.030554019826765172}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,480] Trial 24 finished with value: 0.03443244477385765 and parameters: {'w0': 0.34601071039496445}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,489] Trial 25 finished with value: 0.03443244477385765 and parameters: {'w0': 0.5275784617173966}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,501] Trial 26 finished with value: 0.03443244477385765 and parameters: {'w0': 0.1740528087778479}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,512] Trial 27 finished with value: 0.03443244477385765 and parameters: {'w0': 0.26093341240193973}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,522] Trial 28 finished with value: 0.03443244477385765 and parameters: {'w0': 0.0651647057984528}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,532] Trial 29 finished with value: 0.03443244477385765 and parameters: {'w0': 0.39559382520290776}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,542] Trial 30 finished with value: 0.03443244477385765 and parameters: {'w0': 0.6501358225689952}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,551] Trial 31 finished with value: 0.03443244477385765 and parameters: {'w0': 0.11942437344724406}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,562] Trial 32 finished with value: 0.03443244477385765 and parameters: {'w0': 0.09330947284906131}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,572] Trial 33 finished with value: 0.03443244477385765 and parameters: {'w0': 0.28626998826682754}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,582] Trial 34 finished with value: 0.03443244477385765 and parameters: {'w0': 0.19062191549489732}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,591] Trial 35 finished with value: 0.03443244477385765 and parameters: {'w0': 0.15865738906103533}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,601] Trial 36 finished with value: 0.03443244477385765 and parameters: {'w0': 0.6025200797807851}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,611] Trial 37 finished with value: 0.03443244477385765 and parameters: {'w0': 0.041897732450583945}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,621] Trial 38 finished with value: 0.03443244477385765 and parameters: {'w0': 0.7364268166812868}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,631] Trial 39 finished with value: 0.03443244477385765 and parameters: {'w0': 0.8979492120381164}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,641] Trial 40 finished with value: 0.03443244477385765 and parameters: {'w0': 0.13632289776884213}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,651] Trial 41 finished with value: 0.03443244477385765 and parameters: {'w0': 0.5947928310192646}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,661] Trial 42 finished with value: 0.03443244477385765 and parameters: {'w0': 0.5137619226189699}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,671] Trial 43 finished with value: 0.03443244477385765 and parameters: {'w0': 0.47807833249294374}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,680] Trial 44 finished with value: 0.03443244477385765 and parameters: {'w0': 0.5668353499579106}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,690] Trial 45 finished with value: 0.03443244477385765 and parameters: {'w0': 0.6773792704153683}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,700] Trial 46 finished with value: 0.03443244477385765 and parameters: {'w0': 0.42887615420736036}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,709] Trial 47 finished with value: 0.03443244477385765 and parameters: {'w0': 0.32921047297191197}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,719] Trial 48 finished with value: 0.03443244477385765 and parameters: {'w0': 0.23219874567164378}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,729] Trial 49 finished with value: 0.03443244477385765 and parameters: {'w0': 0.08156769118429101}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,738] Trial 50 finished with value: 0.03443244477385765 and parameters: {'w0': 0.8186026369198659}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,748] Trial 51 finished with value: 0.03443244477385765 and parameters: {'w0': 0.014544986039838115}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,757] Trial 52 finished with value: 0.03443244477385765 and parameters: {'w0': 0.14186541105819075}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,767] Trial 53 finished with value: 0.03443244477385765 and parameters: {'w0': 0.7108847132179148}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,777] Trial 54 finished with value: 0.03443244477385765 and parameters: {'w0': 0.21793506851559577}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,787] Trial 55 finished with value: 0.03443244477385765 and parameters: {'w0': 0.5624673113390102}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,796] Trial 56 finished with value: 0.03443244477385765 and parameters: {'w0': 0.05500009834228209}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,805] Trial 57 finished with value: 0.03443244477385765 and parameters: {'w0': 0.2580630441707821}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,815] Trial 58 finished with value: 0.03443244477385765 and parameters: {'w0': 0.1013381784304864}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,824] Trial 59 finished with value: 0.03443244477385765 and parameters: {'w0': 0.37036382557010566}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,834] Trial 60 finished with value: 0.03443244477385765 and parameters: {'w0': 0.0017463283456939649}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,843] Trial 61 finished with value: 0.03443244477385765 and parameters: {'w0': 0.9400647354632505}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,853] Trial 62 finished with value: 0.03443244477385765 and parameters: {'w0': 0.45896786820403973}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,863] Trial 63 finished with value: 0.03443244477385765 and parameters: {'w0': 0.7995180321392941}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,872] Trial 64 finished with value: 0.03443244477385765 and parameters: {'w0': 0.2913236462290923}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,882] Trial 65 finished with value: 0.03443244477385765 and parameters: {'w0': 0.6195442907053885}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,892] Trial 66 finished with value: 0.03443244477385765 and parameters: {'w0': 0.8543217744270735}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,901] Trial 67 finished with value: 0.03443244477385765 and parameters: {'w0': 0.1841792033810783}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,910] Trial 68 finished with value: 0.03443244477385765 and parameters: {'w0': 0.6751552708180568}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,920] Trial 69 finished with value: 0.03443244477385765 and parameters: {'w0': 0.12230517972554675}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,931] Trial 70 finished with value: 0.03443244477385765 and parameters: {'w0': 0.15858621526909217}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,945] Trial 71 finished with value: 0.03443244477385765 and parameters: {'w0': 0.999280830051725}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,954] Trial 72 finished with value: 0.03443244477385765 and parameters: {'w0': 0.22167486438613637}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,964] Trial 73 finished with value: 0.03443244477385765 and parameters: {'w0': 0.07603742226288268}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,973] Trial 74 finished with value: 0.03443244477385765 and parameters: {'w0': 0.31569162607507273}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,983] Trial 75 finished with value: 0.03443244477385765 and parameters: {'w0': 0.20331582603044648}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:11,993] Trial 76 finished with value: 0.03443244477385765 and parameters: {'w0': 0.1617859509599866}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,003] Trial 77 finished with value: 0.03443244477385765 and parameters: {'w0': 0.2521965007293888}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,013] Trial 78 finished with value: 0.03443244477385765 and parameters: {'w0': 0.5615912372996477}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,022] Trial 79 finished with value: 0.03443244477385765 and parameters: {'w0': 0.10790485421064056}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,032] Trial 80 finished with value: 0.03443244477385765 and parameters: {'w0': 0.4237803847604113}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,042] Trial 81 finished with value: 0.03443244477385765 and parameters: {'w0': 0.7786103429693828}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,051] Trial 82 finished with value: 0.03443244477385765 and parameters: {'w0': 0.8971303177494759}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,061] Trial 83 finished with value: 0.03443244477385765 and parameters: {'w0': 0.9879889225603854}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,070] Trial 84 finished with value: 0.03443244477385765 and parameters: {'w0': 0.8483541794777307}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,079] Trial 85 finished with value: 0.03443244477385765 and parameters: {'w0': 0.9301806159741138}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,089] Trial 86 finished with value: 0.03443244477385765 and parameters: {'w0': 0.7053360074696899}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,099] Trial 87 finished with value: 0.03443244477385765 and parameters: {'w0': 0.7505505708089888}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,109] Trial 88 finished with value: 0.03443244477385765 and parameters: {'w0': 0.4951576965665814}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,119] Trial 89 finished with value: 0.03443244477385765 and parameters: {'w0': 0.615994614705932}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,129] Trial 90 finished with value: 0.03443244477385765 and parameters: {'w0': 0.2765090610486721}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,139] Trial 91 finished with value: 0.03443244477385765 and parameters: {'w0': 0.04038555861700037}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,149] Trial 92 finished with value: 0.03443244477385765 and parameters: {'w0': 0.15120456029234142}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,159] Trial 93 finished with value: 0.03443244477385765 and parameters: {'w0': 0.13119598106067398}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,169] Trial 94 finished with value: 0.03443244477385765 and parameters: {'w0': 0.3564118282909132}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,179] Trial 95 finished with value: 0.03443244477385765 and parameters: {'w0': 0.19809718870241264}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,189] Trial 96 finished with value: 0.03443244477385765 and parameters: {'w0': 0.08851982279302695}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,199] Trial 97 finished with value: 0.03443244477385765 and parameters: {'w0': 0.535530614560534}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,209] Trial 98 finished with value: 0.03443244477385765 and parameters: {'w0': 0.06506594358028392}. Best is trial 0 with value: 0.03443244477385765.\n",
            "[I 2025-06-16 10:39:12,220] Trial 99 finished with value: 0.03443244477385765 and parameters: {'w0': 0.24660684003496736}. Best is trial 0 with value: 0.03443244477385765.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 3): 0.9656\n",
            "\n",
            "--- Training combination ('lgbm', 'mlp') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003205 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.336006\n",
            "[LightGBM] [Info] Start training from score -3.553386\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889700\n",
            "[LightGBM] [Info] Start training from score -3.744780\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.559858\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013656\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912304\n",
            "[LightGBM] [Info] Start training from score -2.909219\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521637\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.456743\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 3): 0.9656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:39:38,340] A new study created in memory with name: no-name-b6eda22f-a357-42cc-a77c-a8f1c6a243b5\n",
            "[I 2025-06-16 10:39:38,348] Trial 0 finished with value: 0.032829761896171816 and parameters: {'w0': 0.1535640619408054, 'w1': 0.7771309860881923}. Best is trial 0 with value: 0.032829761896171816.\n",
            "[I 2025-06-16 10:39:38,354] Trial 1 finished with value: 0.0318795130614854 and parameters: {'w0': 0.9381232954465724, 'w1': 0.26498860123644974}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,360] Trial 2 finished with value: 0.03201582371226852 and parameters: {'w0': 0.8337416541754248, 'w1': 0.6891901616905287}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,365] Trial 3 finished with value: 0.032154327333474675 and parameters: {'w0': 0.743659042053462, 'w1': 0.7213547387779583}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,370] Trial 4 finished with value: 0.03276255314239729 and parameters: {'w0': 0.10799730104115712, 'w1': 0.3498294438640397}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,376] Trial 5 finished with value: 0.031949055725711606 and parameters: {'w0': 0.703315703848154, 'w1': 0.3933467605220835}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,381] Trial 6 finished with value: 0.03296324755523983 and parameters: {'w0': 0.07227118622783257, 'w1': 0.4511706398070061}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,386] Trial 7 finished with value: 0.03274148902554819 and parameters: {'w0': 0.6213699115494162, 'w1': 0.088804417960197}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,392] Trial 8 finished with value: 0.032697214199779556 and parameters: {'w0': 0.2785651156132475, 'w1': 0.8060335335378165}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,397] Trial 9 finished with value: 0.032697214199779556 and parameters: {'w0': 0.24390662635525218, 'w1': 0.7711779026091891}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,417] Trial 10 finished with value: 0.033155602587300215 and parameters: {'w0': 0.9982541707236297, 'w1': 0.07891926383401432}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,435] Trial 11 finished with value: 0.0318795130614854 and parameters: {'w0': 0.998640474773811, 'w1': 0.2814690874749708}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,448] Trial 12 finished with value: 0.032282242283880436 and parameters: {'w0': 0.9552784723235422, 'w1': 0.23864191552337105}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,461] Trial 13 finished with value: 0.032013792220837334 and parameters: {'w0': 0.46183252734546737, 'w1': 0.20580541254200493}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,474] Trial 14 finished with value: 0.03201707122413522 and parameters: {'w0': 0.8533742714832143, 'w1': 0.5397719362316409}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,487] Trial 15 finished with value: 0.032560615238933055 and parameters: {'w0': 0.4926525318699112, 'w1': 0.9567139941055918}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,500] Trial 16 finished with value: 0.0318795130614854 and parameters: {'w0': 0.8740310432527257, 'w1': 0.2511781241417901}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,513] Trial 17 finished with value: 0.03376045508722658 and parameters: {'w0': 0.6496904674827981, 'w1': 0.021240790042475366}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,525] Trial 18 finished with value: 0.03201707122413522 and parameters: {'w0': 0.9220731755515432, 'w1': 0.5661473531984871}. Best is trial 1 with value: 0.0318795130614854.\n",
            "[I 2025-06-16 10:39:38,539] Trial 19 finished with value: 0.03207563910534228 and parameters: {'w0': 0.7982121253817356, 'w1': 0.2954907804901738}. Best is trial 1 with value: 0.0318795130614854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted mlp (fold 3): 0.9670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:39:38,552] Trial 20 finished with value: 0.031877816473093845 and parameters: {'w0': 0.6038266963196295, 'w1': 0.16445553762501788}. Best is trial 20 with value: 0.031877816473093845.\n",
            "[I 2025-06-16 10:39:38,565] Trial 21 finished with value: 0.03214784324529085 and parameters: {'w0': 0.3769735872065094, 'w1': 0.14731174154332743}. Best is trial 20 with value: 0.031877816473093845.\n",
            "[I 2025-06-16 10:39:38,579] Trial 22 finished with value: 0.0318795130614854 and parameters: {'w0': 0.577886730855879, 'w1': 0.16309173016868406}. Best is trial 20 with value: 0.031877816473093845.\n",
            "[I 2025-06-16 10:39:38,592] Trial 23 finished with value: 0.03187606934274756 and parameters: {'w0': 0.9946169051877296, 'w1': 0.33638995208555034}. Best is trial 23 with value: 0.03187606934274756.\n",
            "[I 2025-06-16 10:39:38,606] Trial 24 finished with value: 0.03201548932736842 and parameters: {'w0': 0.7555449613259249, 'w1': 0.42658498549475415}. Best is trial 23 with value: 0.03187606934274756.\n",
            "[I 2025-06-16 10:39:38,620] Trial 25 finished with value: 0.03214784324529085 and parameters: {'w0': 0.8847704624791497, 'w1': 0.34664520659633097}. Best is trial 23 with value: 0.03187606934274756.\n",
            "[I 2025-06-16 10:39:38,633] Trial 26 finished with value: 0.03235777670806261 and parameters: {'w0': 0.3989048092621067, 'w1': 0.4897265861534619}. Best is trial 23 with value: 0.03187606934274756.\n",
            "[I 2025-06-16 10:39:38,646] Trial 27 finished with value: 0.03221545234538625 and parameters: {'w0': 0.5719155466008139, 'w1': 0.1467920169935028}. Best is trial 23 with value: 0.03187606934274756.\n",
            "[I 2025-06-16 10:39:38,660] Trial 28 finished with value: 0.033633088229484076 and parameters: {'w0': 0.6866417999044155, 'w1': 0.024622258491059312}. Best is trial 23 with value: 0.03187606934274756.\n",
            "[I 2025-06-16 10:39:38,676] Trial 29 finished with value: 0.03208205244012652 and parameters: {'w0': 0.7941247705834134, 'w1': 0.3483200801671057}. Best is trial 23 with value: 0.03187606934274756.\n",
            "[I 2025-06-16 10:39:38,689] Trial 30 finished with value: 0.03201707122413522 and parameters: {'w0': 0.9112258045756125, 'w1': 0.5796586746338573}. Best is trial 23 with value: 0.03187606934274756.\n",
            "[I 2025-06-16 10:39:38,703] Trial 31 finished with value: 0.031811119572470736 and parameters: {'w0': 0.9979759802625926, 'w1': 0.3115355619550384}. Best is trial 31 with value: 0.031811119572470736.\n",
            "[I 2025-06-16 10:39:38,717] Trial 32 finished with value: 0.03248363879647076 and parameters: {'w0': 0.9445280561209224, 'w1': 0.2029280394591118}. Best is trial 31 with value: 0.031811119572470736.\n",
            "[I 2025-06-16 10:39:38,730] Trial 33 finished with value: 0.031875779509207725 and parameters: {'w0': 0.9976456546512504, 'w1': 0.3334242463085138}. Best is trial 31 with value: 0.031811119572470736.\n",
            "[I 2025-06-16 10:39:38,744] Trial 34 finished with value: 0.031675602241050815 and parameters: {'w0': 0.9982851743080267, 'w1': 0.30515862882821326}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,758] Trial 35 finished with value: 0.03187824477671375 and parameters: {'w0': 0.9903089027608161, 'w1': 0.3196361222360362}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,774] Trial 36 finished with value: 0.03194654421291143 and parameters: {'w0': 0.8212535137398329, 'w1': 0.3933814634049809}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,788] Trial 37 finished with value: 0.03194756200349291 and parameters: {'w0': 0.9253100679583389, 'w1': 0.48732751828257026}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,801] Trial 38 finished with value: 0.03201582371226852 and parameters: {'w0': 0.7434587292044048, 'w1': 0.6185051445081067}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,815] Trial 39 finished with value: 0.03194654421291143 and parameters: {'w0': 0.8519334676136341, 'w1': 0.3990652917758847}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,829] Trial 40 finished with value: 0.031875779509207725 and parameters: {'w0': 0.9558200731832127, 'w1': 0.31684766623419075}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,844] Trial 41 finished with value: 0.03194654421291143 and parameters: {'w0': 0.9507561241997122, 'w1': 0.4564777778699566}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,859] Trial 42 finished with value: 0.03187824477671375 and parameters: {'w0': 0.9955618454220917, 'w1': 0.3182632965142201}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,873] Trial 43 finished with value: 0.032012118896105335 and parameters: {'w0': 0.8908753139857227, 'w1': 0.37504984337350455}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,888] Trial 44 finished with value: 0.03214740605495747 and parameters: {'w0': 0.9615501372294359, 'w1': 0.2496806990938184}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,902] Trial 45 finished with value: 0.03194654421291143 and parameters: {'w0': 0.9107105355294782, 'w1': 0.4368846743738569}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,916] Trial 46 finished with value: 0.03200999379358804 and parameters: {'w0': 0.8399031033737326, 'w1': 0.29502063230357645}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,931] Trial 47 finished with value: 0.032751657892377106 and parameters: {'w0': 0.9983061937088704, 'w1': 0.20232300440715884}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,946] Trial 48 finished with value: 0.0328148819032541 and parameters: {'w0': 0.9562017832890297, 'w1': 0.10279477552871341}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,960] Trial 49 finished with value: 0.032560615238933055 and parameters: {'w0': 0.1844066756052416, 'w1': 0.35705621282345607}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,974] Trial 50 finished with value: 0.031741475160929955 and parameters: {'w0': 0.7651325919634675, 'w1': 0.22839848762073292}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:38,988] Trial 51 finished with value: 0.03214740605495747 and parameters: {'w0': 0.8806797211310001, 'w1': 0.22730689469241885}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,002] Trial 52 finished with value: 0.032143831322726135 and parameters: {'w0': 0.7852636028361659, 'w1': 0.28660691404605465}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,017] Trial 53 finished with value: 0.03303176817988507 and parameters: {'w0': 0.015915882834248163, 'w1': 0.2657622957044712}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,031] Trial 54 finished with value: 0.031875779509207725 and parameters: {'w0': 0.967952283022181, 'w1': 0.32228926773115996}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,045] Trial 55 finished with value: 0.03274640454434008 and parameters: {'w0': 0.9503913837544032, 'w1': 0.10521576715537329}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,060] Trial 56 finished with value: 0.031877816473093845 and parameters: {'w0': 0.7098160477609223, 'w1': 0.1920621755108282}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,073] Trial 57 finished with value: 0.03229108789890889 and parameters: {'w0': 0.8295522556463201, 'w1': 0.9296952198890235}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,087] Trial 58 finished with value: 0.031877816473093845 and parameters: {'w0': 0.8719217709005328, 'w1': 0.23801560316352466}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,102] Trial 59 finished with value: 0.03201368585923636 and parameters: {'w0': 0.9347765133750612, 'w1': 0.41251747376608083}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,116] Trial 60 finished with value: 0.031945757279220666 and parameters: {'w0': 0.9071039247668812, 'w1': 0.4607531943094424}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,130] Trial 61 finished with value: 0.03187606934274756 and parameters: {'w0': 0.9749071913773235, 'w1': 0.3329014997937735}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,143] Trial 62 finished with value: 0.031675602241050815 and parameters: {'w0': 0.9987098926733129, 'w1': 0.3066807316171603}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,157] Trial 63 finished with value: 0.0318795130614854 and parameters: {'w0': 0.962105524275054, 'w1': 0.2780272157720729}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,172] Trial 64 finished with value: 0.03201548932736842 and parameters: {'w0': 0.9208619284731622, 'w1': 0.5213763636851438}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,186] Trial 65 finished with value: 0.03201390595704601 and parameters: {'w0': 0.8720268822126389, 'w1': 0.37325593313886735}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,201] Trial 66 finished with value: 0.032683211535953216 and parameters: {'w0': 0.971577625249749, 'w1': 0.17736159527638728}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,215] Trial 67 finished with value: 0.032080597527519905 and parameters: {'w0': 0.7667476826062194, 'w1': 0.3116103357441857}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,229] Trial 68 finished with value: 0.03274406794470286 and parameters: {'w0': 0.9993395828155331, 'w1': 0.13172847813716948}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,243] Trial 69 finished with value: 0.031947369868768005 and parameters: {'w0': 0.8121704415742304, 'w1': 0.22845662409578157}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,258] Trial 70 finished with value: 0.03194756200349291 and parameters: {'w0': 0.5239476008295414, 'w1': 0.274693937811428}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,272] Trial 71 finished with value: 0.03200999379358804 and parameters: {'w0': 0.933116905474529, 'w1': 0.3344204547742849}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,287] Trial 72 finished with value: 0.032083068264606274 and parameters: {'w0': 0.9714224767652815, 'w1': 0.3819741648147643}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,301] Trial 73 finished with value: 0.031875779509207725 and parameters: {'w0': 0.8955400130577389, 'w1': 0.3016343043392098}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,315] Trial 74 finished with value: 0.0318795130614854 and parameters: {'w0': 0.9054257954221225, 'w1': 0.2563306410707563}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,330] Trial 75 finished with value: 0.03200999379358804 and parameters: {'w0': 0.8594359510948257, 'w1': 0.30126919101028704}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,344] Trial 76 finished with value: 0.03207563910534228 and parameters: {'w0': 0.9370681565739938, 'w1': 0.35334757260619454}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,358] Trial 77 finished with value: 0.032282242283880436 and parameters: {'w0': 0.8949073401348564, 'w1': 0.2195579874352661}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,373] Trial 78 finished with value: 0.0323576243842989 and parameters: {'w0': 0.31437744913826077, 'w1': 0.42633122778682686}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,387] Trial 79 finished with value: 0.03329528065136811 and parameters: {'w0': 0.9720083924495073, 'w1': 0.04892269812109795}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,403] Trial 80 finished with value: 0.03194654421291143 and parameters: {'w0': 0.6545970421079345, 'w1': 0.3126506332850022}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,418] Trial 81 finished with value: 0.032143831322726135 and parameters: {'w0': 0.9871859782247627, 'w1': 0.3637426383140551}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,434] Trial 82 finished with value: 0.03208257124986902 and parameters: {'w0': 0.9988788224874207, 'w1': 0.39872168936404784}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,452] Trial 83 finished with value: 0.03181300734994563 and parameters: {'w0': 0.9326375755852702, 'w1': 0.2580729630234761}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,467] Trial 84 finished with value: 0.0318795130614854 and parameters: {'w0': 0.9377903982480059, 'w1': 0.2642344710945263}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,481] Trial 85 finished with value: 0.032751657892377106 and parameters: {'w0': 0.902665471475273, 'w1': 0.1797376025669713}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,497] Trial 86 finished with value: 0.03200999379358804 and parameters: {'w0': 0.8479013472220952, 'w1': 0.3000521077547327}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,513] Trial 87 finished with value: 0.03187606934274756 and parameters: {'w0': 0.9571716424397584, 'w1': 0.32727130696439777}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,528] Trial 88 finished with value: 0.031881835294988004 and parameters: {'w0': 0.9237763100157886, 'w1': 0.6958566041938237}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,542] Trial 89 finished with value: 0.031947369868768005 and parameters: {'w0': 0.8831170064633219, 'w1': 0.24812107851870957}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,557] Trial 90 finished with value: 0.03268649553134739 and parameters: {'w0': 0.9780658155985179, 'w1': 0.19994810397629198}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,574] Trial 91 finished with value: 0.031741475160929955 and parameters: {'w0': 0.9492538726600486, 'w1': 0.282956023058336}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,589] Trial 92 finished with value: 0.031675602241050815 and parameters: {'w0': 0.9454683330021227, 'w1': 0.28785369857698057}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,606] Trial 93 finished with value: 0.03180980991049687 and parameters: {'w0': 0.9467087910605119, 'w1': 0.2770415039294544}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,621] Trial 94 finished with value: 0.032282242283880436 and parameters: {'w0': 0.9433039560965005, 'w1': 0.23600124588425916}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,638] Trial 95 finished with value: 0.031741475160929955 and parameters: {'w0': 0.9195193680980828, 'w1': 0.27364299445749524}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,653] Trial 96 finished with value: 0.032676852353736185 and parameters: {'w0': 0.9255189252445388, 'w1': 0.14480125520602294}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,668] Trial 97 finished with value: 0.03207563910534228 and parameters: {'w0': 0.7256084220674257, 'w1': 0.2696657765811336}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,683] Trial 98 finished with value: 0.032282242283880436 and parameters: {'w0': 0.8585320221822991, 'w1': 0.2074418584731102}. Best is trial 34 with value: 0.031675602241050815.\n",
            "[I 2025-06-16 10:39:39,698] Trial 99 finished with value: 0.0318795130614854 and parameters: {'w0': 0.9774213357656379, 'w1': 0.2785054449993184}. Best is trial 34 with value: 0.031675602241050815.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 3): 0.9683\n",
            "\n",
            "--- Training combination ('lgbm', 'logreg') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003316 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.336006\n",
            "[LightGBM] [Info] Start training from score -3.553386\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889700\n",
            "[LightGBM] [Info] Start training from score -3.744780\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.559858\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013656\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912304\n",
            "[LightGBM] [Info] Start training from score -2.909219\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521637\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.456743\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 3): 0.9656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:39:51,031] A new study created in memory with name: no-name-3bc2f6f4-0389-4ea3-8c2e-92495ff87fa2\n",
            "[I 2025-06-16 10:39:51,041] Trial 0 finished with value: 0.033422761663013945 and parameters: {'w0': 0.6320717969901086, 'w1': 0.9342141573496385}. Best is trial 0 with value: 0.033422761663013945.\n",
            "[I 2025-06-16 10:39:51,049] Trial 1 finished with value: 0.03377182397601963 and parameters: {'w0': 0.7154129592496552, 'w1': 0.09049814432306935}. Best is trial 0 with value: 0.033422761663013945.\n",
            "[I 2025-06-16 10:39:51,057] Trial 2 finished with value: 0.03397014496339501 and parameters: {'w0': 0.960206832747064, 'w1': 0.08411023322823052}. Best is trial 0 with value: 0.033422761663013945.\n",
            "[I 2025-06-16 10:39:51,066] Trial 3 finished with value: 0.033084450888761996 and parameters: {'w0': 0.7026690169795773, 'w1': 0.9780169812708385}. Best is trial 3 with value: 0.033084450888761996.\n",
            "[I 2025-06-16 10:39:51,074] Trial 4 finished with value: 0.03381905056370371 and parameters: {'w0': 0.17366064931815284, 'w1': 0.7762770692570233}. Best is trial 3 with value: 0.033084450888761996.\n",
            "[I 2025-06-16 10:39:51,082] Trial 5 finished with value: 0.03244113308430119 and parameters: {'w0': 0.6474278119793591, 'w1': 0.20527810555885728}. Best is trial 5 with value: 0.03244113308430119.\n",
            "[I 2025-06-16 10:39:51,089] Trial 6 finished with value: 0.03212884802384397 and parameters: {'w0': 0.39417162783560067, 'w1': 0.40571182242492954}. Best is trial 6 with value: 0.03212884802384397.\n",
            "[I 2025-06-16 10:39:51,097] Trial 7 finished with value: 0.03416697458878559 and parameters: {'w0': 0.8171134336196675, 'w1': 0.018145646100918622}. Best is trial 6 with value: 0.03212884802384397.\n",
            "[I 2025-06-16 10:39:51,105] Trial 8 finished with value: 0.03210980010063735 and parameters: {'w0': 0.19210948624718172, 'w1': 0.10270038743472909}. Best is trial 8 with value: 0.03210980010063735.\n",
            "[I 2025-06-16 10:39:51,113] Trial 9 finished with value: 0.032440039836126644 and parameters: {'w0': 0.31263544031354396, 'w1': 0.1017665157638803}. Best is trial 8 with value: 0.03210980010063735.\n",
            "[I 2025-06-16 10:39:51,132] Trial 10 finished with value: 0.03416306784724721 and parameters: {'w0': 0.02943952636304145, 'w1': 0.4567201737769886}. Best is trial 8 with value: 0.03210980010063735.\n",
            "[I 2025-06-16 10:39:51,147] Trial 11 finished with value: 0.03198731069468763 and parameters: {'w0': 0.4134426243930583, 'w1': 0.37645327769397574}. Best is trial 11 with value: 0.03198731069468763.\n",
            "[I 2025-06-16 10:39:51,160] Trial 12 finished with value: 0.03246964688563403 and parameters: {'w0': 0.27354081748522496, 'w1': 0.30283353933139634}. Best is trial 11 with value: 0.03198731069468763.\n",
            "[I 2025-06-16 10:39:51,172] Trial 13 finished with value: 0.032945811507324896 and parameters: {'w0': 0.4786528467467861, 'w1': 0.6503434468090289}. Best is trial 11 with value: 0.03198731069468763.\n",
            "[I 2025-06-16 10:39:51,185] Trial 14 finished with value: 0.033886980016192725 and parameters: {'w0': 0.08383843256621956, 'w1': 0.2867326215370381}. Best is trial 11 with value: 0.03198731069468763.\n",
            "[I 2025-06-16 10:39:51,199] Trial 15 finished with value: 0.033886980016192725 and parameters: {'w0': 0.18652418645943503, 'w1': 0.6006730091613577}. Best is trial 11 with value: 0.03198731069468763.\n",
            "[I 2025-06-16 10:39:51,212] Trial 16 finished with value: 0.032106528998908535 and parameters: {'w0': 0.5157804766033093, 'w1': 0.2329488550920154}. Best is trial 11 with value: 0.03198731069468763.\n",
            "[I 2025-06-16 10:39:51,228] Trial 17 finished with value: 0.03204914199771103 and parameters: {'w0': 0.49303358051973245, 'w1': 0.3535296311017312}. Best is trial 11 with value: 0.03198731069468763.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 3): 0.9656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:39:51,241] Trial 18 finished with value: 0.032264191593179836 and parameters: {'w0': 0.5264900966113146, 'w1': 0.5453840813996611}. Best is trial 11 with value: 0.03198731069468763.\n",
            "[I 2025-06-16 10:39:51,254] Trial 19 finished with value: 0.03192045670634269 and parameters: {'w0': 0.40535828287155706, 'w1': 0.37458400383503965}. Best is trial 19 with value: 0.03192045670634269.\n",
            "[I 2025-06-16 10:39:51,268] Trial 20 finished with value: 0.03382153926160647 and parameters: {'w0': 0.3784420796474325, 'w1': 0.7640638052585139}. Best is trial 19 with value: 0.03192045670634269.\n",
            "[I 2025-06-16 10:39:51,282] Trial 21 finished with value: 0.03191980854234955 and parameters: {'w0': 0.42814705930949065, 'w1': 0.3857418348718482}. Best is trial 21 with value: 0.03191980854234955.\n",
            "[I 2025-06-16 10:39:51,300] Trial 22 finished with value: 0.032805884410953445 and parameters: {'w0': 0.3910031714809262, 'w1': 0.47644622230420736}. Best is trial 21 with value: 0.03191980854234955.\n",
            "[I 2025-06-16 10:39:51,314] Trial 23 finished with value: 0.03294248564717006 and parameters: {'w0': 0.30062662120401795, 'w1': 0.38404557948722523}. Best is trial 21 with value: 0.03191980854234955.\n",
            "[I 2025-06-16 10:39:51,328] Trial 24 finished with value: 0.03294248564717006 and parameters: {'w0': 0.4338649548994588, 'w1': 0.5536204153093731}. Best is trial 21 with value: 0.03191980854234955.\n",
            "[I 2025-06-16 10:39:51,341] Trial 25 finished with value: 0.03197164818127807 and parameters: {'w0': 0.5542320317175933, 'w1': 0.2044636905673431}. Best is trial 21 with value: 0.03191980854234955.\n",
            "[I 2025-06-16 10:39:51,355] Trial 26 finished with value: 0.03263742260746472 and parameters: {'w0': 0.8085661647756204, 'w1': 0.1817380721034667}. Best is trial 21 with value: 0.03191980854234955.\n",
            "[I 2025-06-16 10:39:51,370] Trial 27 finished with value: 0.03204148371691684 and parameters: {'w0': 0.5794111829078632, 'w1': 0.2781082689072737}. Best is trial 21 with value: 0.03191980854234955.\n",
            "[I 2025-06-16 10:39:51,384] Trial 28 finished with value: 0.032440039836126644 and parameters: {'w0': 0.5808259069388391, 'w1': 0.18809768021397574}. Best is trial 21 with value: 0.03191980854234955.\n",
            "[I 2025-06-16 10:39:51,398] Trial 29 finished with value: 0.03273757881573791 and parameters: {'w0': 0.6028978572243073, 'w1': 0.7025088776349624}. Best is trial 21 with value: 0.03191980854234955.\n",
            "[I 2025-06-16 10:39:51,412] Trial 30 finished with value: 0.03294248564717006 and parameters: {'w0': 0.33141013268118263, 'w1': 0.4200644189106597}. Best is trial 21 with value: 0.03191980854234955.\n",
            "[I 2025-06-16 10:39:51,425] Trial 31 finished with value: 0.03177739873055052 and parameters: {'w0': 0.4306550819048351, 'w1': 0.3401649642198592}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,440] Trial 32 finished with value: 0.03204914199771103 and parameters: {'w0': 0.46190145637399305, 'w1': 0.32554351357395067}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,454] Trial 33 finished with value: 0.03375494356408604 and parameters: {'w0': 0.24267914286823097, 'w1': 0.5067841017361379}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,469] Trial 34 finished with value: 0.03197164818127807 and parameters: {'w0': 0.7279154632871252, 'w1': 0.26377768678444097}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,483] Trial 35 finished with value: 0.03250094440101814 and parameters: {'w0': 0.6533271392134206, 'w1': 0.16042183184093659}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,497] Trial 36 finished with value: 0.03328363452082905 and parameters: {'w0': 0.5486817082013534, 'w1': 0.8928308947367602}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,512] Trial 37 finished with value: 0.03294248564717006 and parameters: {'w0': 0.3524127236796069, 'w1': 0.44265240409353596}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,527] Trial 38 finished with value: 0.03204914199771103 and parameters: {'w0': 0.4592551020157057, 'w1': 0.33363848559240883}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,541] Trial 39 finished with value: 0.03284149451488372 and parameters: {'w0': 0.7056485221778709, 'w1': 0.1448865979400589}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,556] Trial 40 finished with value: 0.03416597905483165 and parameters: {'w0': 0.9722656006086166, 'w1': 0.028627547300299594}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,571] Trial 41 finished with value: 0.032713113398948 and parameters: {'w0': 0.7809539625685039, 'w1': 0.23268498533615206}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,586] Trial 42 finished with value: 0.032440039836126644 and parameters: {'w0': 0.8553445038697625, 'w1': 0.28058899619999}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,601] Trial 43 finished with value: 0.032113848813341006 and parameters: {'w0': 0.6250846996224062, 'w1': 0.3984146435861873}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,615] Trial 44 finished with value: 0.032704232478632744 and parameters: {'w0': 0.9248051264444623, 'w1': 0.24272715537741868}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,630] Trial 45 finished with value: 0.03204148371691684 and parameters: {'w0': 0.7496205518561248, 'w1': 0.35941217075269977}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,645] Trial 46 finished with value: 0.03324071993851363 and parameters: {'w0': 0.6806528631438795, 'w1': 0.12003811137199086}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,661] Trial 47 finished with value: 0.032671281339210045 and parameters: {'w0': 0.43715970502102836, 'w1': 0.500449175419454}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,676] Trial 48 finished with value: 0.03270749190084132 and parameters: {'w0': 0.23027845521047585, 'w1': 0.062485541297845726}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,690] Trial 49 finished with value: 0.032106528998908535 and parameters: {'w0': 0.5530315044729543, 'w1': 0.2540859958929805}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,705] Trial 50 finished with value: 0.031848579442486535 and parameters: {'w0': 0.37924796787255677, 'w1': 0.32736955284776825}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,721] Trial 51 finished with value: 0.031848579442486535 and parameters: {'w0': 0.3701040031302985, 'w1': 0.3190251801190189}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,735] Trial 52 finished with value: 0.03177976800231119 and parameters: {'w0': 0.378782670449869, 'w1': 0.31064194497100317}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,749] Trial 53 finished with value: 0.031848579442486535 and parameters: {'w0': 0.36846870042165397, 'w1': 0.3149540014653083}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,764] Trial 54 finished with value: 0.03382126032384081 and parameters: {'w0': 0.1278196120172702, 'w1': 0.30877210568941876}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,778] Trial 55 finished with value: 0.03273757881573791 and parameters: {'w0': 0.36149548533760995, 'w1': 0.42375899606059714}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,792] Trial 56 finished with value: 0.032805884410953445 and parameters: {'w0': 0.2818167017822088, 'w1': 0.34352728316195297}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,807] Trial 57 finished with value: 0.033289116950703024 and parameters: {'w0': 0.3234205562635573, 'w1': 0.4607763903404868}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,822] Trial 58 finished with value: 0.031847280378717535 and parameters: {'w0': 0.41512518476830784, 'w1': 0.3119474532428117}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,837] Trial 59 finished with value: 0.03294248564717006 and parameters: {'w0': 0.24716400564759766, 'w1': 0.313329419664006}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,851] Trial 60 finished with value: 0.03204323954124999 and parameters: {'w0': 0.3864615945320809, 'w1': 0.22230278783401353}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,865] Trial 61 finished with value: 0.03212242559590461 and parameters: {'w0': 0.4155958326059938, 'w1': 0.3994802259793083}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,880] Trial 62 finished with value: 0.0319811751887219 and parameters: {'w0': 0.498098256374965, 'w1': 0.3653419248321535}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,894] Trial 63 finished with value: 0.03177967542920623 and parameters: {'w0': 0.34789754390715866, 'w1': 0.2920577997966691}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,908] Trial 64 finished with value: 0.031848579442486535 and parameters: {'w0': 0.3492476933369883, 'w1': 0.2978401878866324}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,924] Trial 65 finished with value: 0.03219133236011118 and parameters: {'w0': 0.2787040185355391, 'w1': 0.27147791715048314}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,938] Trial 66 finished with value: 0.03204914199771103 and parameters: {'w0': 0.4635802500824154, 'w1': 0.3320541128619629}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,953] Trial 67 finished with value: 0.03210888034608006 and parameters: {'w0': 0.3757228642912354, 'w1': 0.20445049851792735}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,969] Trial 68 finished with value: 0.0335532273376663 and parameters: {'w0': 0.3113601764618765, 'w1': 0.5378197908133482}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,983] Trial 69 finished with value: 0.03239714574812669 and parameters: {'w0': 0.40472037385217596, 'w1': 0.43456161253775394}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:51,998] Trial 70 finished with value: 0.033084450888761996 and parameters: {'w0': 0.21375217500652655, 'w1': 0.29810433211231885}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,012] Trial 71 finished with value: 0.031848579442486535 and parameters: {'w0': 0.35506774972930416, 'w1': 0.3020610809000824}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,027] Trial 72 finished with value: 0.03219848139038861 and parameters: {'w0': 0.33170546376232213, 'w1': 0.34294610475837445}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,042] Trial 73 finished with value: 0.03204323954124999 and parameters: {'w0': 0.4468362644472636, 'w1': 0.25780763218277636}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,056] Trial 74 finished with value: 0.0324410755925737 and parameters: {'w0': 0.5198296654337057, 'w1': 0.1607500826483549}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,071] Trial 75 finished with value: 0.03239799018987166 and parameters: {'w0': 0.341258111841726, 'w1': 0.3707877959926277}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,087] Trial 76 finished with value: 0.031847280378717535 and parameters: {'w0': 0.29984510875201414, 'w1': 0.2251448104987469}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,102] Trial 77 finished with value: 0.0319811751887219 and parameters: {'w0': 0.2872120048899751, 'w1': 0.2107051200829687}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,116] Trial 78 finished with value: 0.03342343934175629 and parameters: {'w0': 0.17063936894964768, 'w1': 0.25335730160074615}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,131] Trial 79 finished with value: 0.032371416141297904 and parameters: {'w0': 0.3881309656365934, 'w1': 0.12907824166759582}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,145] Trial 80 finished with value: 0.03203841220305359 and parameters: {'w0': 0.4827336361989752, 'w1': 0.1790873234425041}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,160] Trial 81 finished with value: 0.03192045670634269 and parameters: {'w0': 0.3080397561426829, 'w1': 0.2850198489871956}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,174] Trial 82 finished with value: 0.032805162873163596 and parameters: {'w0': 0.2685772808251536, 'w1': 0.309389195773775}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,189] Trial 83 finished with value: 0.03210888034608006 and parameters: {'w0': 0.4227872228255808, 'w1': 0.22997244693092764}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,203] Trial 84 finished with value: 0.03239711976000559 and parameters: {'w0': 0.36924862121173757, 'w1': 0.388451061484699}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,217] Trial 85 finished with value: 0.03184811671852028 and parameters: {'w0': 0.4055130591893862, 'w1': 0.3424361118398041}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,233] Trial 86 finished with value: 0.031848579442486535 and parameters: {'w0': 0.40020472493471493, 'w1': 0.3424680794217813}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,248] Trial 87 finished with value: 0.03198670571048823 and parameters: {'w0': 0.43960822877598693, 'w1': 0.4106011778581057}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,262] Trial 88 finished with value: 0.03239714574812669 and parameters: {'w0': 0.2548491083492451, 'w1': 0.2744941750784421}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,279] Trial 89 finished with value: 0.032127075563786356 and parameters: {'w0': 0.4690047545328717, 'w1': 0.4753570063893774}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,294] Trial 90 finished with value: 0.03253610071704893 and parameters: {'w0': 0.2978986781388849, 'w1': 0.3251947820797979}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,309] Trial 91 finished with value: 0.03212884802384397 and parameters: {'w0': 0.34736684150037, 'w1': 0.3575337774648173}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,324] Trial 92 finished with value: 0.031916120073152476 and parameters: {'w0': 0.3686515604208699, 'w1': 0.2873656604766151}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,340] Trial 93 finished with value: 0.031847280378717535 and parameters: {'w0': 0.3182214661545306, 'w1': 0.23990395620259142}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,355] Trial 94 finished with value: 0.03204323954124999 and parameters: {'w0': 0.4132503127742863, 'w1': 0.2383708884462394}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,371] Trial 95 finished with value: 0.03177976800231119 and parameters: {'w0': 0.39560129063886407, 'w1': 0.32376116433008423}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,386] Trial 96 finished with value: 0.03204323954124999 and parameters: {'w0': 0.33079433638675815, 'w1': 0.1873317942087218}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,401] Trial 97 finished with value: 0.03368922067594371 and parameters: {'w0': 0.49860809214715146, 'w1': 0.9314606586364486}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,416] Trial 98 finished with value: 0.031848579442486535 and parameters: {'w0': 0.4458594728314544, 'w1': 0.3801535080199667}. Best is trial 31 with value: 0.03177739873055052.\n",
            "[I 2025-06-16 10:39:52,432] Trial 99 finished with value: 0.03210980010063735 and parameters: {'w0': 0.3944339916757993, 'w1': 0.20976096516792242}. Best is trial 31 with value: 0.03177739873055052.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 3): 0.9682\n",
            "\n",
            "--- Training combination ('mlp', 'logreg') ---\n",
            "F1-weighted mlp (fold 3): 0.9673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:40:11,871] A new study created in memory with name: no-name-390adcb7-8850-4653-8e72-a4a13032953a\n",
            "[I 2025-06-16 10:40:11,880] Trial 0 finished with value: 0.03340636196412339 and parameters: {'w0': 0.7837996578225098, 'w1': 0.16311438193003736}. Best is trial 0 with value: 0.03340636196412339.\n",
            "[I 2025-06-16 10:40:11,890] Trial 1 finished with value: 0.03355128333069335 and parameters: {'w0': 0.1609104989261747, 'w1': 0.2654908532229271}. Best is trial 0 with value: 0.03340636196412339.\n",
            "[I 2025-06-16 10:40:11,902] Trial 2 finished with value: 0.033139446532036154 and parameters: {'w0': 0.8769096735713786, 'w1': 0.7674457604250103}. Best is trial 2 with value: 0.033139446532036154.\n",
            "[I 2025-06-16 10:40:11,911] Trial 3 finished with value: 0.03355124804292586 and parameters: {'w0': 0.6098028919968473, 'w1': 0.9088970507669323}. Best is trial 2 with value: 0.033139446532036154.\n",
            "[I 2025-06-16 10:40:11,920] Trial 4 finished with value: 0.03313663279486745 and parameters: {'w0': 0.7540527221179294, 'w1': 0.44697895591091885}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:11,930] Trial 5 finished with value: 0.03340636196412339 and parameters: {'w0': 0.9093171962317816, 'w1': 0.2216599457277224}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:11,946] Trial 6 finished with value: 0.03355268871799455 and parameters: {'w0': 0.490780798824777, 'w1': 0.9031950909561741}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:11,955] Trial 7 finished with value: 0.03340636196412339 and parameters: {'w0': 0.5226262704673338, 'w1': 0.11768438891848343}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:11,971] Trial 8 finished with value: 0.033270408830966325 and parameters: {'w0': 0.7278668417920363, 'w1': 0.33580735503823556}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:11,977] Trial 9 finished with value: 0.03409331023764439 and parameters: {'w0': 0.06845865242589877, 'w1': 0.7050663474838533}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:11,991] Trial 10 finished with value: 0.03355128333069335 and parameters: {'w0': 0.3246534487839095, 'w1': 0.549159856922517}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:12,006] Trial 11 finished with value: 0.03327172062492334 and parameters: {'w0': 0.9018048939788355, 'w1': 0.5979768568233756}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:12,019] Trial 12 finished with value: 0.03327172062492334 and parameters: {'w0': 0.9624742044073606, 'w1': 0.7351859678338685}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:12,033] Trial 13 finished with value: 0.03313663279486745 and parameters: {'w0': 0.7333486466376743, 'w1': 0.4319130749644475}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:12,047] Trial 14 finished with value: 0.03313663279486745 and parameters: {'w0': 0.6786617484098203, 'w1': 0.3939359943164761}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:12,061] Trial 15 finished with value: 0.033481285690381 and parameters: {'w0': 0.40746681876753044, 'w1': 0.4535234705447437}. Best is trial 4 with value: 0.03313663279486745.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 3): 0.9656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:40:12,077] Trial 16 finished with value: 0.03320515577578598 and parameters: {'w0': 0.7949545589109555, 'w1': 0.5000162939043992}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:12,092] Trial 17 finished with value: 0.03320413611922313 and parameters: {'w0': 0.6374893893797873, 'w1': 0.34592101028386124}. Best is trial 4 with value: 0.03313663279486745.\n",
            "[I 2025-06-16 10:40:12,107] Trial 18 finished with value: 0.03307140999080449 and parameters: {'w0': 0.5476511509695333, 'w1': 0.02932657355872159}. Best is trial 18 with value: 0.03307140999080449.\n",
            "[I 2025-06-16 10:40:12,122] Trial 19 finished with value: 0.03334391324953656 and parameters: {'w0': 0.3727232313697435, 'w1': 0.0569629327502807}. Best is trial 18 with value: 0.03307140999080449.\n",
            "[I 2025-06-16 10:40:12,136] Trial 20 finished with value: 0.03279923619898795 and parameters: {'w0': 0.2758757975314964, 'w1': 0.0022381408531439995}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,152] Trial 21 finished with value: 0.03286757835726384 and parameters: {'w0': 0.2090531270693081, 'w1': 0.006654636160138172}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,166] Trial 22 finished with value: 0.03334391324953656 and parameters: {'w0': 0.21813784262067307, 'w1': 0.032227593300035315}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,181] Trial 23 finished with value: 0.03326979369614669 and parameters: {'w0': 0.25460938816481793, 'w1': 0.026101462880072236}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,194] Trial 24 finished with value: 0.03443244477385765 and parameters: {'w0': 0.0004630238940602771, 'w1': 0.12500463806935505}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,208] Trial 25 finished with value: 0.03279923619898795 and parameters: {'w0': 0.13110486334645738, 'w1': 0.001954227552706335}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,222] Trial 26 finished with value: 0.03355128333069335 and parameters: {'w0': 0.12632170709547755, 'w1': 0.20392308496162193}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,237] Trial 27 finished with value: 0.03340636196412339 and parameters: {'w0': 0.28576241695956167, 'w1': 0.09303113887106715}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,252] Trial 28 finished with value: 0.03347789214556862 and parameters: {'w0': 0.18282911581139166, 'w1': 0.23102126433918835}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,266] Trial 29 finished with value: 0.03355128333069335 and parameters: {'w0': 0.08604347479168775, 'w1': 0.13916960084193447}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,282] Trial 30 finished with value: 0.03327172062492334 and parameters: {'w0': 0.4272640566314827, 'w1': 0.2973412092936374}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,297] Trial 31 finished with value: 0.03279923619898795 and parameters: {'w0': 0.5503703118883656, 'w1': 0.005316293878277809}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,311] Trial 32 finished with value: 0.03279923619898795 and parameters: {'w0': 0.32436481752737245, 'w1': 0.006944703111645276}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,325] Trial 33 finished with value: 0.03320413611922313 and parameters: {'w0': 0.32279949310297895, 'w1': 0.17020034131694278}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,339] Trial 34 finished with value: 0.03347733369679773 and parameters: {'w0': 0.4525751776787126, 'w1': 0.08023857510390858}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,353] Trial 35 finished with value: 0.03340636196412339 and parameters: {'w0': 0.5662221392966693, 'w1': 0.17666085117234137}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,368] Trial 36 finished with value: 0.03340636196412339 and parameters: {'w0': 0.37036273372868617, 'w1': 0.08598401861579283}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,381] Trial 37 finished with value: 0.03279923619898795 and parameters: {'w0': 0.2819065872078861, 'w1': 0.0030471716188475695}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,395] Trial 38 finished with value: 0.033624795703457444 and parameters: {'w0': 0.13007548027625923, 'w1': 0.2698576354023978}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,409] Trial 39 finished with value: 0.033339205700374186 and parameters: {'w0': 0.459140318258996, 'w1': 0.15673733664991588}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,424] Trial 40 finished with value: 0.0336902923258936 and parameters: {'w0': 0.020873731806501095, 'w1': 0.06837238397035073}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,438] Trial 41 finished with value: 0.03279923619898795 and parameters: {'w0': 0.26448920532546566, 'w1': 0.0026067300030973707}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,452] Trial 42 finished with value: 0.03340636196412339 and parameters: {'w0': 0.3170104578681384, 'w1': 0.10543007679944687}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,466] Trial 43 finished with value: 0.033339205700374186 and parameters: {'w0': 0.16033796459666627, 'w1': 0.05761286696680736}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,480] Trial 44 finished with value: 0.033692125949162266 and parameters: {'w0': 0.3681565151437654, 'w1': 0.856832633827236}. Best is trial 20 with value: 0.03279923619898795.\n",
            "[I 2025-06-16 10:40:12,494] Trial 45 finished with value: 0.03273253398687459 and parameters: {'w0': 0.600714722411793, 'w1': 0.003447651806287232}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,508] Trial 46 finished with value: 0.033546332837921744 and parameters: {'w0': 0.5023379146043518, 'w1': 0.6525813896626367}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,523] Trial 47 finished with value: 0.033339205700374186 and parameters: {'w0': 0.6011739067761624, 'w1': 0.21545275383102924}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,537] Trial 48 finished with value: 0.03347733369679773 and parameters: {'w0': 0.6805832137224562, 'w1': 0.11908867857164608}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,551] Trial 49 finished with value: 0.03307140999080449 and parameters: {'w0': 0.8423893572963784, 'w1': 0.04735739066977195}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,565] Trial 50 finished with value: 0.03340636196412339 and parameters: {'w0': 0.5787580620047259, 'w1': 0.1773097559697034}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,579] Trial 51 finished with value: 0.03293617374926938 and parameters: {'w0': 0.2297492580276912, 'w1': 0.008927938839248499}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,593] Trial 52 finished with value: 0.033201925156229994 and parameters: {'w0': 0.6318391274874571, 'w1': 0.05866945193769386}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,606] Trial 53 finished with value: 0.03355268871799455 and parameters: {'w0': 0.5151856279711858, 'w1': 0.9809546239842291}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,620] Trial 54 finished with value: 0.033201925156229994 and parameters: {'w0': 0.08259039190534098, 'w1': 0.006513599643791483}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,633] Trial 55 finished with value: 0.03334391324953656 and parameters: {'w0': 0.6910930044722583, 'w1': 0.1064171726127976}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,648] Trial 56 finished with value: 0.03327301149886741 and parameters: {'w0': 0.4133405511031793, 'w1': 0.048252510308911326}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,662] Trial 57 finished with value: 0.03340636196412339 and parameters: {'w0': 0.4710833346081952, 'w1': 0.1386724281759819}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,676] Trial 58 finished with value: 0.03273253398687459 and parameters: {'w0': 0.29897708709178983, 'w1': 0.00018030352639776493}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,691] Trial 59 finished with value: 0.03334391324953656 and parameters: {'w0': 0.5392103715247016, 'w1': 0.0787809582979341}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,705] Trial 60 finished with value: 0.033201925156229994 and parameters: {'w0': 0.34459062788101397, 'w1': 0.03087335571796245}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,719] Trial 61 finished with value: 0.03279923619898795 and parameters: {'w0': 0.2815289897494416, 'w1': 0.005471610087147015}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,733] Trial 62 finished with value: 0.03340636196412339 and parameters: {'w0': 0.19005846752607494, 'w1': 0.04941733513726987}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,748] Trial 63 finished with value: 0.03279923619898795 and parameters: {'w0': 0.24858663782364532, 'w1': 0.002476322432108824}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,762] Trial 64 finished with value: 0.03340636196412339 and parameters: {'w0': 0.2969134568285126, 'w1': 0.09916725625410004}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,776] Trial 65 finished with value: 0.03340636196412339 and parameters: {'w0': 0.14158795943084304, 'w1': 0.03497116872768994}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,791] Trial 66 finished with value: 0.03340636196412339 and parameters: {'w0': 0.3842303233699107, 'w1': 0.1288081645154321}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,806] Trial 67 finished with value: 0.03333772592486561 and parameters: {'w0': 0.19957158188587387, 'w1': 0.0764954878545666}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,823] Trial 68 finished with value: 0.03326979369614669 and parameters: {'w0': 0.3380624724794158, 'w1': 0.03323170725753331}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,838] Trial 69 finished with value: 0.03340636196412339 and parameters: {'w0': 0.6481062297905127, 'w1': 0.19097445050398276}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,853] Trial 70 finished with value: 0.03369178382284066 and parameters: {'w0': 0.11329927096596035, 'w1': 0.2544717940987179}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,869] Trial 71 finished with value: 0.033002859395174444 and parameters: {'w0': 0.25673843180188827, 'w1': 0.011877805215551202}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,886] Trial 72 finished with value: 0.03279923619898795 and parameters: {'w0': 0.27434279646076587, 'w1': 0.003160545780001283}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,900] Trial 73 finished with value: 0.033339205700374186 and parameters: {'w0': 0.23262285943577965, 'w1': 0.08332490204149659}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,915] Trial 74 finished with value: 0.033139446532036154 and parameters: {'w0': 0.04406704823631126, 'w1': 0.03637165090884255}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,930] Trial 75 finished with value: 0.03369010353918134 and parameters: {'w0': 0.17186169575141058, 'w1': 0.5127239355784448}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,944] Trial 76 finished with value: 0.033270408830966325 and parameters: {'w0': 0.3133795822699277, 'w1': 0.1408880847515476}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,959] Trial 77 finished with value: 0.03334391324953656 and parameters: {'w0': 0.4313220449506051, 'w1': 0.06591012103264382}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,974] Trial 78 finished with value: 0.03340636196412339 and parameters: {'w0': 0.346928705404629, 'w1': 0.10576739040577939}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:12,988] Trial 79 finished with value: 0.03334348348738858 and parameters: {'w0': 0.3930856677041812, 'w1': 0.3891339783782409}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,003] Trial 80 finished with value: 0.03340636196412339 and parameters: {'w0': 0.5934964188663755, 'w1': 0.15589995164996764}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,017] Trial 81 finished with value: 0.03273253398687459 and parameters: {'w0': 0.2804675301880197, 'w1': 0.00044126611487064457}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,032] Trial 82 finished with value: 0.033201925156229994 and parameters: {'w0': 0.3022916694975736, 'w1': 0.02481037784301981}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,047] Trial 83 finished with value: 0.03340636196412339 and parameters: {'w0': 0.27283467314518595, 'w1': 0.059598986174656685}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,061] Trial 84 finished with value: 0.03327301149886741 and parameters: {'w0': 0.22606652210855677, 'w1': 0.02802899256535985}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,078] Trial 85 finished with value: 0.03273253398687459 and parameters: {'w0': 0.5493762442213509, 'w1': 0.0036678914508220814}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,093] Trial 86 finished with value: 0.03347733369679773 and parameters: {'w0': 0.4825335157692382, 'w1': 0.08541313616359636}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,108] Trial 87 finished with value: 0.033201925156229994 and parameters: {'w0': 0.5587763930344433, 'w1': 0.052597586635761785}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,123] Trial 88 finished with value: 0.03355128333069335 and parameters: {'w0': 0.5194773484806474, 'w1': 0.8325268574399982}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,138] Trial 89 finished with value: 0.033481285690381 and parameters: {'w0': 0.5340172263499106, 'w1': 0.5957259355134011}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,153] Trial 90 finished with value: 0.03334332931915829 and parameters: {'w0': 0.7123854950001111, 'w1': 0.10105041134771602}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,169] Trial 91 finished with value: 0.03273253398687459 and parameters: {'w0': 0.6093271786529659, 'w1': 0.0002663198338988433}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,184] Trial 92 finished with value: 0.03293617374926938 and parameters: {'w0': 0.6150008949126903, 'w1': 0.02359747313788717}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,199] Trial 93 finished with value: 0.03273253398687459 and parameters: {'w0': 0.6440950759789316, 'w1': 0.0017138101454823975}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,215] Trial 94 finished with value: 0.03307140999080449 and parameters: {'w0': 0.7711277890603894, 'w1': 0.044931009393727975}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,230] Trial 95 finished with value: 0.03326979369614669 and parameters: {'w0': 0.647305429687529, 'w1': 0.06445586405475962}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,245] Trial 96 finished with value: 0.03273253398687459 and parameters: {'w0': 0.5682801834435304, 'w1': 0.0013515641850400547}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,260] Trial 97 finished with value: 0.033002859395174444 and parameters: {'w0': 0.5833384322152333, 'w1': 0.025959120464160695}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,276] Trial 98 finished with value: 0.03273253398687459 and parameters: {'w0': 0.661796164112591, 'w1': 0.0018450003539673767}. Best is trial 45 with value: 0.03273253398687459.\n",
            "[I 2025-06-16 10:40:13,291] Trial 99 finished with value: 0.03333914518620662 and parameters: {'w0': 0.6192668679714399, 'w1': 0.06581005057488012}. Best is trial 45 with value: 0.03273253398687459.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 3): 0.9673\n",
            "\n",
            "--- Training combination ('lgbm', 'mlp', 'logreg') ---\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003379 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.336006\n",
            "[LightGBM] [Info] Start training from score -3.553386\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889700\n",
            "[LightGBM] [Info] Start training from score -3.744780\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.559858\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013656\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912304\n",
            "[LightGBM] [Info] Start training from score -2.909219\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521637\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.456743\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 3): 0.9656\n",
            "F1-weighted mlp (fold 3): 0.9671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:40:39,581] A new study created in memory with name: no-name-f570151d-2257-4d11-a793-61f534b932c7\n",
            "[I 2025-06-16 10:40:39,591] Trial 0 finished with value: 0.03205822715989848 and parameters: {'w0': 0.3963500657891387, 'w1': 0.1739023388749945, 'w2': 0.2550727875211659}. Best is trial 0 with value: 0.03205822715989848.\n",
            "[I 2025-06-16 10:40:39,600] Trial 1 finished with value: 0.03206045800192481 and parameters: {'w0': 0.7231353776459534, 'w1': 0.49339306831536767, 'w2': 0.40731228189089086}. Best is trial 0 with value: 0.03205822715989848.\n",
            "[I 2025-06-16 10:40:39,609] Trial 2 finished with value: 0.03322042395577485 and parameters: {'w0': 0.10087044881255869, 'w1': 0.7645174746923503, 'w2': 0.10104069671045823}. Best is trial 0 with value: 0.03205822715989848.\n",
            "[I 2025-06-16 10:40:39,617] Trial 3 finished with value: 0.03204804702555841 and parameters: {'w0': 0.9177925080384078, 'w1': 0.23207092979818422, 'w2': 0.5778448851537065}. Best is trial 3 with value: 0.03204804702555841.\n",
            "[I 2025-06-16 10:40:39,626] Trial 4 finished with value: 0.03226666997875771 and parameters: {'w0': 0.951666311001878, 'w1': 0.7424599768328286, 'w2': 0.7485539681527927}. Best is trial 3 with value: 0.03204804702555841.\n",
            "[I 2025-06-16 10:40:39,634] Trial 5 finished with value: 0.03301591638807877 and parameters: {'w0': 0.0776904389593781, 'w1': 0.22669579958919017, 'w2': 0.07560173854854435}. Best is trial 3 with value: 0.03204804702555841.\n",
            "[I 2025-06-16 10:40:39,643] Trial 6 finished with value: 0.033487748975162046 and parameters: {'w0': 0.19166725503197501, 'w1': 0.7015204218891822, 'w2': 0.8698364866715753}. Best is trial 3 with value: 0.03204804702555841.\n",
            "[I 2025-06-16 10:40:39,652] Trial 7 finished with value: 0.03355338515480333 and parameters: {'w0': 0.043995674493951364, 'w1': 0.822648661023779, 'w2': 0.18312616398341963}. Best is trial 3 with value: 0.03204804702555841.\n",
            "[I 2025-06-16 10:40:39,660] Trial 8 finished with value: 0.03348442271337493 and parameters: {'w0': 0.002282774466997206, 'w1': 0.803473807424825, 'w2': 0.31444401130085964}. Best is trial 3 with value: 0.03204804702555841.\n",
            "[I 2025-06-16 10:40:39,669] Trial 9 finished with value: 0.03178464706347672 and parameters: {'w0': 0.37699566809340246, 'w1': 0.22996783456861813, 'w2': 0.17787467894546882}. Best is trial 9 with value: 0.03178464706347672.\n",
            "[I 2025-06-16 10:40:39,695] Trial 10 finished with value: 0.03239742463834505 and parameters: {'w0': 0.49006862177873106, 'w1': 0.03653281548640394, 'w2': 0.494586239284664}. Best is trial 9 with value: 0.03178464706347672.\n",
            "[I 2025-06-16 10:40:39,715] Trial 11 finished with value: 0.03260493923850849 and parameters: {'w0': 0.7091078771648365, 'w1': 0.43717206132001285, 'w2': 0.6626972177565136}. Best is trial 9 with value: 0.03178464706347672.\n",
            "[I 2025-06-16 10:40:39,733] Trial 12 finished with value: 0.033080712393378287 and parameters: {'w0': 0.3411678398019872, 'w1': 0.32464769397677407, 'w2': 0.604862448957418}. Best is trial 9 with value: 0.03178464706347672.\n",
            "[I 2025-06-16 10:40:39,751] Trial 13 finished with value: 0.03341653619857832 and parameters: {'w0': 0.6915596107476163, 'w1': 0.08780827337339009, 'w2': 0.9909294684616957}. Best is trial 9 with value: 0.03178464706347672.\n",
            "[I 2025-06-16 10:40:39,770] Trial 14 finished with value: 0.03171115880129993 and parameters: {'w0': 0.9835458141214732, 'w1': 0.3275950092269724, 'w2': 0.4533673895785134}. Best is trial 14 with value: 0.03171115880129993.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 3): 0.9656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:40:39,789] Trial 15 finished with value: 0.03240113005569267 and parameters: {'w0': 0.272933017398174, 'w1': 0.3761958178317306, 'w2': 0.009526461439540918}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,808] Trial 16 finished with value: 0.03267308995496743 and parameters: {'w0': 0.6184433748827713, 'w1': 0.6166881486438256, 'w2': 0.3567922423298773}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,827] Trial 17 finished with value: 0.03260748100317501 and parameters: {'w0': 0.8311400661414645, 'w1': 0.9569629884034511, 'w2': 0.48476450562692464}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,845] Trial 18 finished with value: 0.03185146488208068 and parameters: {'w0': 0.5269415200038062, 'w1': 0.31814565632280944, 'w2': 0.20739157594206759}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,864] Trial 19 finished with value: 0.033076793242726166 and parameters: {'w0': 0.45053454849091035, 'w1': 0.5786438007264039, 'w2': 0.3932671421935961}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,883] Trial 20 finished with value: 0.03203279239026802 and parameters: {'w0': 0.5738826297596481, 'w1': 0.13301459804921495, 'w2': 0.14252014851207218}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,902] Trial 21 finished with value: 0.03308020270711998 and parameters: {'w0': 0.25053757649283714, 'w1': 0.3193869355051533, 'w2': 0.23324651669224278}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,921] Trial 22 finished with value: 0.03177187821685845 and parameters: {'w0': 0.8110991812248372, 'w1': 0.2915682041231512, 'w2': 0.2827529221497383}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,940] Trial 23 finished with value: 0.03184794320886297 and parameters: {'w0': 0.8373367266097405, 'w1': 0.41867360013406696, 'w2': 0.29237002693590897}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,960] Trial 24 finished with value: 0.03203741862682674 and parameters: {'w0': 0.9965652145060772, 'w1': 0.2450588771328056, 'w2': 0.43860537578037523}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,980] Trial 25 finished with value: 0.03210741676681772 and parameters: {'w0': 0.8427171657578506, 'w1': 0.007237671124670997, 'w2': 0.32674944048964516}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:39,999] Trial 26 finished with value: 0.03231663419279507 and parameters: {'w0': 0.8910011160738749, 'w1': 0.4829543358125026, 'w2': 0.003135306808052518}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:40,018] Trial 27 finished with value: 0.03218512137753737 and parameters: {'w0': 0.7674442134277469, 'w1': 0.1621799004343235, 'w2': 0.5453189743194194}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:40,038] Trial 28 finished with value: 0.032257834616613024 and parameters: {'w0': 0.6259997464563197, 'w1': 0.5770360795660407, 'w2': 0.14141889124833049}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:40,057] Trial 29 finished with value: 0.032198942532163266 and parameters: {'w0': 0.3924096697133003, 'w1': 0.257447108425116, 'w2': 0.2639438651923446}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:40,075] Trial 30 finished with value: 0.03205134791260256 and parameters: {'w0': 0.9785452018178592, 'w1': 0.122415892101166, 'w2': 0.7069709252818448}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:40,094] Trial 31 finished with value: 0.03184781788525237 and parameters: {'w0': 0.8542259412069059, 'w1': 0.40079928672682374, 'w2': 0.2852707308604651}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:40,113] Trial 32 finished with value: 0.031854002359406386 and parameters: {'w0': 0.7575742182634411, 'w1': 0.3831978934179546, 'w2': 0.4044650209185845}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:40,132] Trial 33 finished with value: 0.03203858229429268 and parameters: {'w0': 0.9107886605422721, 'w1': 0.29206477023542954, 'w2': 0.2549322039506514}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:40,150] Trial 34 finished with value: 0.03183865715956391 and parameters: {'w0': 0.8644191576676499, 'w1': 0.19780438956223562, 'w2': 0.44554476566087614}. Best is trial 14 with value: 0.03171115880129993.\n",
            "[I 2025-06-16 10:40:40,170] Trial 35 finished with value: 0.03164279385043034 and parameters: {'w0': 0.7815003574318606, 'w1': 0.21086839776846036, 'w2': 0.4372395927480269}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,189] Trial 36 finished with value: 0.03218512137753737 and parameters: {'w0': 0.7908082506596779, 'w1': 0.18419956575653432, 'w2': 0.5452229243427528}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,207] Trial 37 finished with value: 0.03203753216991667 and parameters: {'w0': 0.6662223405251646, 'w1': 0.07539550138138432, 'w2': 0.35156677363608874}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,226] Trial 38 finished with value: 0.03237529715475784 and parameters: {'w0': 0.9453467359682737, 'w1': 0.27238362010536454, 'w2': 0.08023437192858988}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,246] Trial 39 finished with value: 0.03273966067788914 and parameters: {'w0': 0.31078524518039485, 'w1': 0.49795514502662436, 'w2': 0.17468825493693352}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,265] Trial 40 finished with value: 0.03294122580533965 and parameters: {'w0': 0.46111467229957004, 'w1': 0.35184635518415464, 'w2': 0.6260001202859005}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,285] Trial 41 finished with value: 0.031839680527625536 and parameters: {'w0': 0.8962958163049651, 'w1': 0.1933760013808818, 'w2': 0.43754988413205476}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,305] Trial 42 finished with value: 0.03190576702748715 and parameters: {'w0': 0.9399896671201239, 'w1': 0.2066875413266341, 'w2': 0.46964823288050567}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,324] Trial 43 finished with value: 0.03197275804383881 and parameters: {'w0': 0.7963150605192316, 'w1': 0.14129336884846488, 'w2': 0.37668167912403205}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,343] Trial 44 finished with value: 0.03225907260062355 and parameters: {'w0': 0.7325709899095313, 'w1': 0.25035757485997373, 'w2': 0.5358538086081105}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,363] Trial 45 finished with value: 0.033286133839769305 and parameters: {'w0': 0.16335581445004088, 'w1': 0.45766867887804197, 'w2': 0.44727407486947457}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,385] Trial 46 finished with value: 0.03244216416187118 and parameters: {'w0': 0.8792064921171838, 'w1': 0.07306876585408795, 'w2': 0.3280167914347224}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,405] Trial 47 finished with value: 0.03287095590461098 and parameters: {'w0': 0.39597427019283815, 'w1': 0.2080079042489541, 'w2': 0.5111095785824779}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,429] Trial 48 finished with value: 0.0317721278419093 and parameters: {'w0': 0.9615763506095211, 'w1': 0.10005583273142016, 'w2': 0.5851176234824664}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,449] Trial 49 finished with value: 0.03233469641769271 and parameters: {'w0': 0.9672008732689916, 'w1': 0.3474264210995543, 'w2': 0.7890188088132062}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,470] Trial 50 finished with value: 0.03273472568353386 and parameters: {'w0': 0.53485359199969, 'w1': 0.08724740639940012, 'w2': 0.5809088149936324}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,493] Trial 51 finished with value: 0.03197468427774275 and parameters: {'w0': 0.9983268236549832, 'w1': 0.1686734933495942, 'w2': 0.6158019595955287}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,513] Trial 52 finished with value: 0.03217260175544978 and parameters: {'w0': 0.9296467173437063, 'w1': 0.03547887996036991, 'w2': 0.5056624605438816}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,534] Trial 53 finished with value: 0.03226906973486099 and parameters: {'w0': 0.8110729474684161, 'w1': 0.300951189349717, 'w2': 0.6567896779898341}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,556] Trial 54 finished with value: 0.03237255527063965 and parameters: {'w0': 0.8606390139040374, 'w1': 0.1272035618576376, 'w2': 0.2125994402844522}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,576] Trial 55 finished with value: 0.031915645483676314 and parameters: {'w0': 0.6753735451325162, 'w1': 0.21304092848876546, 'w2': 0.40478372496596937}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,599] Trial 56 finished with value: 0.032398265967982565 and parameters: {'w0': 0.9244584167715496, 'w1': 0.2760020289467091, 'w2': 0.7816785687307264}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,618] Trial 57 finished with value: 0.03170955890226346 and parameters: {'w0': 0.34684940604442316, 'w1': 0.11026860602675645, 'w2': 0.14343512185254348}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,639] Trial 58 finished with value: 0.03177223752734182 and parameters: {'w0': 0.32284951786098076, 'w1': 0.11623538796291855, 'w2': 0.11572268762384558}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,660] Trial 59 finished with value: 0.03204125227247989 and parameters: {'w0': 0.1804003571722923, 'w1': 0.004175562936301724, 'w2': 0.11633586382104498}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,680] Trial 60 finished with value: 0.03191152334058389 and parameters: {'w0': 0.23279164783584805, 'w1': 0.10904737281291103, 'w2': 0.046662190612618115}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,701] Trial 61 finished with value: 0.03197207995583262 and parameters: {'w0': 0.35252801361323083, 'w1': 0.04855360033280838, 'w2': 0.1858967110347691}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,721] Trial 62 finished with value: 0.03177223752734182 and parameters: {'w0': 0.42729397679236747, 'w1': 0.15723171775484746, 'w2': 0.1481206892137234}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,743] Trial 63 finished with value: 0.03217382255303558 and parameters: {'w0': 0.4577111154404767, 'w1': 0.15727261320159794, 'w2': 0.04358144569131199}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,763] Trial 64 finished with value: 0.032167557269358826 and parameters: {'w0': 0.30086704076506443, 'w1': 0.051130307223746924, 'w2': 0.10612875247949931}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,787] Trial 65 finished with value: 0.03196917281712608 and parameters: {'w0': 0.42565683992849024, 'w1': 0.10324949836491121, 'w2': 0.15613365943603988}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,807] Trial 66 finished with value: 0.03206045800192481 and parameters: {'w0': 0.3612801205734412, 'w1': 0.23409663836267952, 'w2': 0.227668361912983}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,830] Trial 67 finished with value: 0.03224098122036889 and parameters: {'w0': 0.42863299908414204, 'w1': 0.15135246196974605, 'w2': 0.05321369114930877}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,850] Trial 68 finished with value: 0.03253991817563173 and parameters: {'w0': 0.49918477317640175, 'w1': 0.5483719130417121, 'w2': 0.2736270985655818}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,871] Trial 69 finished with value: 0.03273966067788914 and parameters: {'w0': 0.3035826967360462, 'w1': 0.6447922685151324, 'w2': 0.1213118696483636}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,894] Trial 70 finished with value: 0.03267408078646239 and parameters: {'w0': 0.5923003457342898, 'w1': 0.98177641032143, 'w2': 0.3063691701296152}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,916] Trial 71 finished with value: 0.03178285240052803 and parameters: {'w0': 0.3866925401537403, 'w1': 0.1705623497815797, 'w2': 0.1790591746139693}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,937] Trial 72 finished with value: 0.03178696385821944 and parameters: {'w0': 0.3207973907572636, 'w1': 0.17055535742402483, 'w2': 0.19255406989869434}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,957] Trial 73 finished with value: 0.03178096666495955 and parameters: {'w0': 0.224123646552767, 'w1': 0.11969357565761025, 'w2': 0.087384341364331}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,977] Trial 74 finished with value: 0.03322042395577485 and parameters: {'w0': 0.11480052295069654, 'w1': 0.9103723072057238, 'w2': 0.08275451021849867}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:40,997] Trial 75 finished with value: 0.03178696385821944 and parameters: {'w0': 0.21859728208367252, 'w1': 0.10927993853728564, 'w2': 0.13969265027742703}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,018] Trial 76 finished with value: 0.03263056648355411 and parameters: {'w0': 0.26833904189210683, 'w1': 0.034038520033594866, 'w2': 0.024279860739068182}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,038] Trial 77 finished with value: 0.03178696385821944 and parameters: {'w0': 0.140828832826696, 'w1': 0.07366935196302941, 'w2': 0.08362010689077147}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,059] Trial 78 finished with value: 0.032803542802406715 and parameters: {'w0': 0.2112903117697126, 'w1': 0.22614109925543058, 'w2': 0.23574367349538816}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,081] Trial 79 finished with value: 0.03362190820086863 and parameters: {'w0': 0.2715587624616517, 'w1': 0.13168331003950237, 'w2': 0.9726345137585375}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,102] Trial 80 finished with value: 0.033354986786238716 and parameters: {'w0': 0.02470032028589264, 'w1': 0.3440182215155291, 'w2': 0.5706441281867485}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,123] Trial 81 finished with value: 0.031786209474617855 and parameters: {'w0': 0.33068216108768217, 'w1': 0.18649909108577067, 'w2': 0.16404372246808957}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,144] Trial 82 finished with value: 0.03198623763148645 and parameters: {'w0': 0.430012962630213, 'w1': 0.2742801055877146, 'w2': 0.13861483014482667}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,165] Trial 83 finished with value: 0.03280251105194165 and parameters: {'w0': 0.36664147335655023, 'w1': 0.14176326782188434, 'w2': 0.3604932556582324}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,188] Trial 84 finished with value: 0.03250455592185708 and parameters: {'w0': 0.9673127304025442, 'w1': 0.10933339027555988, 'w2': 0.20383371694155583}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,209] Trial 85 finished with value: 0.03185336704117103 and parameters: {'w0': 0.38588178458459227, 'w1': 0.17703133832161777, 'w2': 0.24510459241890778}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,231] Trial 86 finished with value: 0.03256583498064625 and parameters: {'w0': 0.5408218337788323, 'w1': 0.0568354231070578, 'w2': 0.10124592366257301}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,253] Trial 87 finished with value: 0.032173431085565585 and parameters: {'w0': 0.7581145296552882, 'w1': 0.25011659354080384, 'w2': 0.07073053709068408}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,274] Trial 88 finished with value: 0.032317299244860376 and parameters: {'w0': 0.48271149612551373, 'w1': 0.30910607749431107, 'w2': 0.020875943864492763}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,295] Trial 89 finished with value: 0.032803137571282726 and parameters: {'w0': 0.4187920327148726, 'w1': 0.22574318521741957, 'w2': 0.4685302759288956}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,315] Trial 90 finished with value: 0.03250500275847146 and parameters: {'w0': 0.7214308333085192, 'w1': 0.024680402444564375, 'w2': 0.12693423002936416}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,336] Trial 91 finished with value: 0.03178762786846978 and parameters: {'w0': 0.37614268179017274, 'w1': 0.2002391892740665, 'w2': 0.2068733079638079}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,357] Trial 92 finished with value: 0.03171253847267086 and parameters: {'w0': 0.2482096279123414, 'w1': 0.09620837637728738, 'w2': 0.09595225036234403}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,380] Trial 93 finished with value: 0.03191724533596385 and parameters: {'w0': 0.29474375123147867, 'w1': 0.10515283768244565, 'w2': 0.16345880878735308}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,401] Trial 94 finished with value: 0.03369046051804825 and parameters: {'w0': 0.24382441784221975, 'w1': 0.07717592098300717, 'w2': 0.6441390688047612}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,424] Trial 95 finished with value: 0.033210070078746656 and parameters: {'w0': 0.19685431097699274, 'w1': 0.17023362343909754, 'w2': 0.6942283225811957}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,445] Trial 96 finished with value: 0.033005735670075254 and parameters: {'w0': 0.34622953351417274, 'w1': 0.14683553662520094, 'w2': 0.42132162905229076}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,469] Trial 97 finished with value: 0.032563966531845456 and parameters: {'w0': 0.6460459249166739, 'w1': 0.09218374190792569, 'w2': 0.06378333792329308}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,489] Trial 98 finished with value: 0.03249849987159825 and parameters: {'w0': 0.8879890473446801, 'w1': 0.12841223870722712, 'w2': 0.0929320360877098}. Best is trial 35 with value: 0.03164279385043034.\n",
            "[I 2025-06-16 10:40:41,513] Trial 99 finished with value: 0.0336866326822296 and parameters: {'w0': 0.2870085920188422, 'w1': 0.06188033760180997, 'w2': 0.5881725213135878}. Best is trial 35 with value: 0.03164279385043034.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 3): 0.9684\n",
            "\n",
            "=== Fold 4/5 ===\n",
            "\n",
            "--- Training combination ('lgbm',) ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003257 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.336006\n",
            "[LightGBM] [Info] Start training from score -3.552799\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889700\n",
            "[LightGBM] [Info] Start training from score -3.745491\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.560449\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013656\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912304\n",
            "[LightGBM] [Info] Start training from score -2.909219\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521069\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.456743\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:40:48,919] A new study created in memory with name: no-name-e7baeab1-9799-4c15-8549-c2a9c3d98663\n",
            "[I 2025-06-16 10:40:48,926] Trial 0 finished with value: 0.03574031701211289 and parameters: {'w0': 0.306153406691395}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,931] Trial 1 finished with value: 0.03574031701211289 and parameters: {'w0': 0.8219582738890236}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,936] Trial 2 finished with value: 0.03574031701211289 and parameters: {'w0': 0.7999231695241313}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,941] Trial 3 finished with value: 0.03574031701211289 and parameters: {'w0': 0.34953251493849136}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,946] Trial 4 finished with value: 0.03574031701211289 and parameters: {'w0': 0.1674388327908608}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,951] Trial 5 finished with value: 0.03574031701211289 and parameters: {'w0': 0.0007363239205347982}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,956] Trial 6 finished with value: 0.03574031701211289 and parameters: {'w0': 0.29041229409406766}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,963] Trial 7 finished with value: 0.03574031701211289 and parameters: {'w0': 0.3901049121299248}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,970] Trial 8 finished with value: 0.03574031701211289 and parameters: {'w0': 0.918255059370763}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,975] Trial 9 finished with value: 0.03574031701211289 and parameters: {'w0': 0.40591483240685056}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,985] Trial 10 finished with value: 0.03574031701211289 and parameters: {'w0': 0.6211320253566407}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:48,994] Trial 11 finished with value: 0.03574031701211289 and parameters: {'w0': 0.6007967726048922}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,003] Trial 12 finished with value: 0.03574031701211289 and parameters: {'w0': 0.7710167843034006}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,013] Trial 13 finished with value: 0.03574031701211289 and parameters: {'w0': 0.5609212802628134}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,022] Trial 14 finished with value: 0.03574031701211289 and parameters: {'w0': 0.9856838007413065}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,031] Trial 15 finished with value: 0.03574031701211289 and parameters: {'w0': 0.15071272226606852}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,040] Trial 16 finished with value: 0.03574031701211289 and parameters: {'w0': 0.737921111633641}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,049] Trial 17 finished with value: 0.03574031701211289 and parameters: {'w0': 0.4558108737043642}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,059] Trial 18 finished with value: 0.03574031701211289 and parameters: {'w0': 0.22373821943390476}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,072] Trial 19 finished with value: 0.03574031701211289 and parameters: {'w0': 0.021951377446364218}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,081] Trial 20 finished with value: 0.03574031701211289 and parameters: {'w0': 0.6983195823652487}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,090] Trial 21 finished with value: 0.03574031701211289 and parameters: {'w0': 0.8520697783110764}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,100] Trial 22 finished with value: 0.03574031701211289 and parameters: {'w0': 0.8385502484542008}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,110] Trial 23 finished with value: 0.03574031701211289 and parameters: {'w0': 0.5000733990772663}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,119] Trial 24 finished with value: 0.03574031701211289 and parameters: {'w0': 0.9941916045005382}. Best is trial 0 with value: 0.03574031701211289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 4): 0.9643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:40:49,128] Trial 25 finished with value: 0.03574031701211289 and parameters: {'w0': 0.6641531923712672}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,138] Trial 26 finished with value: 0.03574031701211289 and parameters: {'w0': 0.8440194626190742}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,147] Trial 27 finished with value: 0.03574031701211289 and parameters: {'w0': 0.5150167298191588}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,156] Trial 28 finished with value: 0.03574031701211289 and parameters: {'w0': 0.778966929811357}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,166] Trial 29 finished with value: 0.03574031701211289 and parameters: {'w0': 0.31270398354828594}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,175] Trial 30 finished with value: 0.03574031701211289 and parameters: {'w0': 0.9447130394168461}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,184] Trial 31 finished with value: 0.03574031701211289 and parameters: {'w0': 0.13985212832655644}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,193] Trial 32 finished with value: 0.03574031701211289 and parameters: {'w0': 0.3376325924104465}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,204] Trial 33 finished with value: 0.03574031701211289 and parameters: {'w0': 0.21020535783325034}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,214] Trial 34 finished with value: 0.03574031701211289 and parameters: {'w0': 0.4001485280855341}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,224] Trial 35 finished with value: 0.03574031701211289 and parameters: {'w0': 0.2926939064353331}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,233] Trial 36 finished with value: 0.03574031701211289 and parameters: {'w0': 0.45615670414831416}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,242] Trial 37 finished with value: 0.03574031701211289 and parameters: {'w0': 0.23426798185277362}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,252] Trial 38 finished with value: 0.03574031701211289 and parameters: {'w0': 0.36040453586051063}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,262] Trial 39 finished with value: 0.03574031701211289 and parameters: {'w0': 0.8907321133506425}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,272] Trial 40 finished with value: 0.03574031701211289 and parameters: {'w0': 0.08066872249070195}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,282] Trial 41 finished with value: 0.03574031701211289 and parameters: {'w0': 0.17531633318494155}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,294] Trial 42 finished with value: 0.03574031701211289 and parameters: {'w0': 0.2548402070074004}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,306] Trial 43 finished with value: 0.03574031701211289 and parameters: {'w0': 0.1019707677254934}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,315] Trial 44 finished with value: 0.03574031701211289 and parameters: {'w0': 0.6072424077326601}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,324] Trial 45 finished with value: 0.03574031701211289 and parameters: {'w0': 0.44204809478135093}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,334] Trial 46 finished with value: 0.03574031701211289 and parameters: {'w0': 0.2692994220754209}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,343] Trial 47 finished with value: 0.03574031701211289 and parameters: {'w0': 0.5649984645591598}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,353] Trial 48 finished with value: 0.03574031701211289 and parameters: {'w0': 0.7821949051888867}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,363] Trial 49 finished with value: 0.03574031701211289 and parameters: {'w0': 0.36432773583105005}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,372] Trial 50 finished with value: 0.03574031701211289 and parameters: {'w0': 0.6842912046319468}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,382] Trial 51 finished with value: 0.03574031701211289 and parameters: {'w0': 0.004820846457981774}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,394] Trial 52 finished with value: 0.03574031701211289 and parameters: {'w0': 0.054372137336673926}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,406] Trial 53 finished with value: 0.03574031701211289 and parameters: {'w0': 0.1351407058290536}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,416] Trial 54 finished with value: 0.03574031701211289 and parameters: {'w0': 0.19578720811619768}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,425] Trial 55 finished with value: 0.03574031701211289 and parameters: {'w0': 0.048411682887338776}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,435] Trial 56 finished with value: 0.03574031701211289 and parameters: {'w0': 0.10379864708496489}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,444] Trial 57 finished with value: 0.03574031701211289 and parameters: {'w0': 0.8993615406482884}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,454] Trial 58 finished with value: 0.03574031701211289 and parameters: {'w0': 0.7482726655830101}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,464] Trial 59 finished with value: 0.03574031701211289 and parameters: {'w0': 0.30958712637473845}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,474] Trial 60 finished with value: 0.03574031701211289 and parameters: {'w0': 0.17771606855467728}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,483] Trial 61 finished with value: 0.03574031701211289 and parameters: {'w0': 0.27030047107808014}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,493] Trial 62 finished with value: 0.03574031701211289 and parameters: {'w0': 0.811107904339145}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,503] Trial 63 finished with value: 0.03574031701211289 and parameters: {'w0': 0.40733590911677564}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,514] Trial 64 finished with value: 0.03574031701211289 and parameters: {'w0': 0.6416185382488988}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,524] Trial 65 finished with value: 0.03574031701211289 and parameters: {'w0': 0.32929640039030533}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,534] Trial 66 finished with value: 0.03574031701211289 and parameters: {'w0': 0.42920247495848485}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,545] Trial 67 finished with value: 0.03574031701211289 and parameters: {'w0': 0.5478615826463296}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,554] Trial 68 finished with value: 0.03574031701211289 and parameters: {'w0': 0.2413876818299185}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,564] Trial 69 finished with value: 0.03574031701211289 and parameters: {'w0': 0.9613092518759541}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,574] Trial 70 finished with value: 0.03574031701211289 and parameters: {'w0': 0.47271598577892726}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,584] Trial 71 finished with value: 0.03574031701211289 and parameters: {'w0': 0.37682692964709175}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,594] Trial 72 finished with value: 0.03574031701211289 and parameters: {'w0': 0.288076411269383}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,604] Trial 73 finished with value: 0.03574031701211289 and parameters: {'w0': 0.3450010669851424}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,614] Trial 74 finished with value: 0.03574031701211289 and parameters: {'w0': 0.39494856180513044}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,625] Trial 75 finished with value: 0.03574031701211289 and parameters: {'w0': 0.4819393541605236}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,635] Trial 76 finished with value: 0.03574031701211289 and parameters: {'w0': 0.867059415110118}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,645] Trial 77 finished with value: 0.03574031701211289 and parameters: {'w0': 0.16142502825631502}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,655] Trial 78 finished with value: 0.03574031701211289 and parameters: {'w0': 0.31268003672999467}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,666] Trial 79 finished with value: 0.03574031701211289 and parameters: {'w0': 0.7151015901346506}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,675] Trial 80 finished with value: 0.03574031701211289 and parameters: {'w0': 0.8144295943565185}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,685] Trial 81 finished with value: 0.03574031701211289 and parameters: {'w0': 0.9039176847130709}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,695] Trial 82 finished with value: 0.03574031701211289 and parameters: {'w0': 0.9253783419986067}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,705] Trial 83 finished with value: 0.03574031701211289 and parameters: {'w0': 0.20963904552810797}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,714] Trial 84 finished with value: 0.03574031701211289 and parameters: {'w0': 0.9617078528118588}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,724] Trial 85 finished with value: 0.03574031701211289 and parameters: {'w0': 0.8757291754578029}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,734] Trial 86 finished with value: 0.03574031701211289 and parameters: {'w0': 0.12744249401865662}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,744] Trial 87 finished with value: 0.03574031701211289 and parameters: {'w0': 0.29095491705904675}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,754] Trial 88 finished with value: 0.03574031701211289 and parameters: {'w0': 0.8266628686353813}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,763] Trial 89 finished with value: 0.03574031701211289 and parameters: {'w0': 0.37815415709225453}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,777] Trial 90 finished with value: 0.03574031701211289 and parameters: {'w0': 0.9997435132392319}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,790] Trial 91 finished with value: 0.03574031701211289 and parameters: {'w0': 0.42525753766876995}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,800] Trial 92 finished with value: 0.03574031701211289 and parameters: {'w0': 0.3397442580624195}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,810] Trial 93 finished with value: 0.03574031701211289 and parameters: {'w0': 0.5063705301980939}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,820] Trial 94 finished with value: 0.03574031701211289 and parameters: {'w0': 0.034539179093398986}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,830] Trial 95 finished with value: 0.03574031701211289 and parameters: {'w0': 0.35497257598507814}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,840] Trial 96 finished with value: 0.03574031701211289 and parameters: {'w0': 0.4086081800066203}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,851] Trial 97 finished with value: 0.03574031701211289 and parameters: {'w0': 0.2614737955344859}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,862] Trial 98 finished with value: 0.03574031701211289 and parameters: {'w0': 0.2237693961560872}. Best is trial 0 with value: 0.03574031701211289.\n",
            "[I 2025-06-16 10:40:49,877] Trial 99 finished with value: 0.03574031701211289 and parameters: {'w0': 0.07977250874730886}. Best is trial 0 with value: 0.03574031701211289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 4): 0.9643\n",
            "\n",
            "--- Training combination ('mlp',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:41:07,193] A new study created in memory with name: no-name-dfd98c49-bb32-424c-b2d5-add1043b1843\n",
            "[I 2025-06-16 10:41:07,200] Trial 0 finished with value: 0.03450119631023085 and parameters: {'w0': 0.40602151429409206}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,205] Trial 1 finished with value: 0.03450119631023085 and parameters: {'w0': 0.25317681365771827}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,210] Trial 2 finished with value: 0.03450119631023085 and parameters: {'w0': 0.927113067394643}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,215] Trial 3 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9072569621992788}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,220] Trial 4 finished with value: 0.03450119631023085 and parameters: {'w0': 0.1303556606792704}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,225] Trial 5 finished with value: 0.03450119631023085 and parameters: {'w0': 0.6935085257976178}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,230] Trial 6 finished with value: 0.03450119631023085 and parameters: {'w0': 0.4403747837461569}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,235] Trial 7 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9413810011837304}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,241] Trial 8 finished with value: 0.03450119631023085 and parameters: {'w0': 0.18859498340135394}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,248] Trial 9 finished with value: 0.03450119631023085 and parameters: {'w0': 0.6899501888227991}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,260] Trial 10 finished with value: 0.03450119631023085 and parameters: {'w0': 0.336831313219108}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,270] Trial 11 finished with value: 0.03450119631023085 and parameters: {'w0': 0.3387908673108931}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,278] Trial 12 finished with value: 0.03450119631023085 and parameters: {'w0': 0.5760353810569108}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,289] Trial 13 finished with value: 0.03450119631023085 and parameters: {'w0': 0.05040035075552107}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,301] Trial 14 finished with value: 0.03450119631023085 and parameters: {'w0': 0.2810934565489183}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,310] Trial 15 finished with value: 0.03450119631023085 and parameters: {'w0': 0.5079006421075141}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,319] Trial 16 finished with value: 0.03450119631023085 and parameters: {'w0': 0.007728328998635847}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,328] Trial 17 finished with value: 0.03450119631023085 and parameters: {'w0': 0.22235534975705756}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,336] Trial 18 finished with value: 0.03450119631023085 and parameters: {'w0': 0.4474395371281051}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,345] Trial 19 finished with value: 0.03450119631023085 and parameters: {'w0': 0.57616915226604}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,354] Trial 20 finished with value: 0.03450119631023085 and parameters: {'w0': 0.3479205627408125}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,364] Trial 21 finished with value: 0.03450119631023085 and parameters: {'w0': 0.8016846673166433}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,373] Trial 22 finished with value: 0.03450119631023085 and parameters: {'w0': 0.6993341057102995}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,383] Trial 23 finished with value: 0.03450119631023085 and parameters: {'w0': 0.843169814841471}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,392] Trial 24 finished with value: 0.03450119631023085 and parameters: {'w0': 0.43060705740046057}. Best is trial 0 with value: 0.03450119631023085.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted mlp (fold 4): 0.9655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:41:07,402] Trial 25 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9992242414906268}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,412] Trial 26 finished with value: 0.03450119631023085 and parameters: {'w0': 0.11505108815212772}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,421] Trial 27 finished with value: 0.03450119631023085 and parameters: {'w0': 0.575311961559373}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,431] Trial 28 finished with value: 0.03450119631023085 and parameters: {'w0': 0.2471173585199957}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,440] Trial 29 finished with value: 0.03450119631023085 and parameters: {'w0': 0.3717585045903319}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,451] Trial 30 finished with value: 0.03450119631023085 and parameters: {'w0': 0.502775962819278}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,461] Trial 31 finished with value: 0.03450119631023085 and parameters: {'w0': 0.8786291748352548}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,471] Trial 32 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9065742695562095}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,481] Trial 33 finished with value: 0.03450119631023085 and parameters: {'w0': 0.7579350112612613}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,491] Trial 34 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9823113542767936}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,503] Trial 35 finished with value: 0.03450119631023085 and parameters: {'w0': 0.7698111343349116}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,517] Trial 36 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9373860385352879}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,527] Trial 37 finished with value: 0.03450119631023085 and parameters: {'w0': 0.12141374074195119}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,536] Trial 38 finished with value: 0.03450119631023085 and parameters: {'w0': 0.6407032012676637}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,546] Trial 39 finished with value: 0.03450119631023085 and parameters: {'w0': 0.18285725466754285}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,556] Trial 40 finished with value: 0.03450119631023085 and parameters: {'w0': 0.299428905537219}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,566] Trial 41 finished with value: 0.03450119631023085 and parameters: {'w0': 0.1377701901947973}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,576] Trial 42 finished with value: 0.03450119631023085 and parameters: {'w0': 0.3970406114183447}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,587] Trial 43 finished with value: 0.03450119631023085 and parameters: {'w0': 0.1750647742782016}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,597] Trial 44 finished with value: 0.03450119631023085 and parameters: {'w0': 0.07949969923710798}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,608] Trial 45 finished with value: 0.03450119631023085 and parameters: {'w0': 0.2915244002820795}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,618] Trial 46 finished with value: 0.03450119631023085 and parameters: {'w0': 0.22571709123905825}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,628] Trial 47 finished with value: 0.03450119631023085 and parameters: {'w0': 0.8403050333047991}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,639] Trial 48 finished with value: 0.03450119631023085 and parameters: {'w0': 0.0064742828236243055}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,649] Trial 49 finished with value: 0.03450119631023085 and parameters: {'w0': 0.06144708278899226}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,659] Trial 50 finished with value: 0.03450119631023085 and parameters: {'w0': 0.6880581022735804}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,669] Trial 51 finished with value: 0.03450119631023085 and parameters: {'w0': 0.5482547193234566}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,681] Trial 52 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9304214540580475}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,691] Trial 53 finished with value: 0.03450119631023085 and parameters: {'w0': 0.852197387053656}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,701] Trial 54 finished with value: 0.03450119631023085 and parameters: {'w0': 0.4490963027179359}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,710] Trial 55 finished with value: 0.03450119631023085 and parameters: {'w0': 0.6380187483819554}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,722] Trial 56 finished with value: 0.03450119631023085 and parameters: {'w0': 0.7803950408215982}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,732] Trial 57 finished with value: 0.03450119631023085 and parameters: {'w0': 0.7354970994582553}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,742] Trial 58 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9655887527710088}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,752] Trial 59 finished with value: 0.03450119631023085 and parameters: {'w0': 0.254473094445967}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,762] Trial 60 finished with value: 0.03450119631023085 and parameters: {'w0': 0.8949630956517368}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,772] Trial 61 finished with value: 0.03450119631023085 and parameters: {'w0': 0.4688279262636762}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,782] Trial 62 finished with value: 0.03450119631023085 and parameters: {'w0': 0.3442032114152455}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,792] Trial 63 finished with value: 0.03450119631023085 and parameters: {'w0': 0.39589852243302937}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,802] Trial 64 finished with value: 0.03450119631023085 and parameters: {'w0': 0.8158363748993586}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,812] Trial 65 finished with value: 0.03450119631023085 and parameters: {'w0': 0.31636790836047757}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,821] Trial 66 finished with value: 0.03450119631023085 and parameters: {'w0': 0.5449765315605853}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,831] Trial 67 finished with value: 0.03450119631023085 and parameters: {'w0': 0.6346571133160489}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,842] Trial 68 finished with value: 0.03450119631023085 and parameters: {'w0': 0.3904098322289616}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,852] Trial 69 finished with value: 0.03450119631023085 and parameters: {'w0': 0.1488523126178595}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,862] Trial 70 finished with value: 0.03450119631023085 and parameters: {'w0': 0.42847290878096544}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,872] Trial 71 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9570744235206838}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,881] Trial 72 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9237069643581727}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,891] Trial 73 finished with value: 0.03450119631023085 and parameters: {'w0': 0.880070000311243}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,901] Trial 74 finished with value: 0.03450119631023085 and parameters: {'w0': 0.48133165226993524}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,911] Trial 75 finished with value: 0.03450119631023085 and parameters: {'w0': 0.6036360944973627}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,921] Trial 76 finished with value: 0.03450119631023085 and parameters: {'w0': 0.2110055702946072}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,931] Trial 77 finished with value: 0.03450119631023085 and parameters: {'w0': 0.5311686772264739}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,941] Trial 78 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9804882868989167}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,951] Trial 79 finished with value: 0.03450119631023085 and parameters: {'w0': 0.2679667491353863}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,961] Trial 80 finished with value: 0.03450119631023085 and parameters: {'w0': 0.08696867947522753}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,970] Trial 81 finished with value: 0.03450119631023085 and parameters: {'w0': 0.1864115358822878}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,981] Trial 82 finished with value: 0.03450119631023085 and parameters: {'w0': 0.15547537307201048}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:07,991] Trial 83 finished with value: 0.03450119631023085 and parameters: {'w0': 0.8654439018513919}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,001] Trial 84 finished with value: 0.03450119631023085 and parameters: {'w0': 0.04018257480032915}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,011] Trial 85 finished with value: 0.03450119631023085 and parameters: {'w0': 0.8181955852735412}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,022] Trial 86 finished with value: 0.03450119631023085 and parameters: {'w0': 0.22203374196669906}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,032] Trial 87 finished with value: 0.03450119631023085 and parameters: {'w0': 0.1142253660415927}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,042] Trial 88 finished with value: 0.03450119631023085 and parameters: {'w0': 0.6785805406409987}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,052] Trial 89 finished with value: 0.03450119631023085 and parameters: {'w0': 0.3235402211649465}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,063] Trial 90 finished with value: 0.03450119631023085 and parameters: {'w0': 0.7416077761687632}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,073] Trial 91 finished with value: 0.03450119631023085 and parameters: {'w0': 0.42603421646379}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,083] Trial 92 finished with value: 0.03450119631023085 and parameters: {'w0': 0.36280136222850046}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,093] Trial 93 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9095931277235507}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,102] Trial 94 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9520827283495273}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,112] Trial 95 finished with value: 0.03450119631023085 and parameters: {'w0': 0.5890473352715155}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,122] Trial 96 finished with value: 0.03450119631023085 and parameters: {'w0': 0.9795980497814154}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,132] Trial 97 finished with value: 0.03450119631023085 and parameters: {'w0': 0.49681726625844813}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,142] Trial 98 finished with value: 0.03450119631023085 and parameters: {'w0': 0.7848409972006631}. Best is trial 0 with value: 0.03450119631023085.\n",
            "[I 2025-06-16 10:41:08,151] Trial 99 finished with value: 0.03450119631023085 and parameters: {'w0': 0.7192320356626801}. Best is trial 0 with value: 0.03450119631023085.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 4): 0.9655\n",
            "\n",
            "--- Training combination ('logreg',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:41:09,752] A new study created in memory with name: no-name-f5daa63e-ab9e-4e64-9529-33c6be9e8237\n",
            "[I 2025-06-16 10:41:09,761] Trial 0 finished with value: 0.03513999491593389 and parameters: {'w0': 0.48667002219048927}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,768] Trial 1 finished with value: 0.03513999491593389 and parameters: {'w0': 0.7244783139576231}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,775] Trial 2 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5596112030804273}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,782] Trial 3 finished with value: 0.03513999491593389 and parameters: {'w0': 0.29780146731676604}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,788] Trial 4 finished with value: 0.03513999491593389 and parameters: {'w0': 0.8738684386762898}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,795] Trial 5 finished with value: 0.03513999491593389 and parameters: {'w0': 0.9901855959045356}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,802] Trial 6 finished with value: 0.03513999491593389 and parameters: {'w0': 0.38502029266501925}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,809] Trial 7 finished with value: 0.03513999491593389 and parameters: {'w0': 0.7457205192706445}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,816] Trial 8 finished with value: 0.03513999491593389 and parameters: {'w0': 0.2731240822592994}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,823] Trial 9 finished with value: 0.03513999491593389 and parameters: {'w0': 0.39810714696395744}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,836] Trial 10 finished with value: 0.03513999491593389 and parameters: {'w0': 0.03495797662481126}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,848] Trial 11 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6363067846123502}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,861] Trial 12 finished with value: 0.03513999491593389 and parameters: {'w0': 0.7267063269595107}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,870] Trial 13 finished with value: 0.03513999491593389 and parameters: {'w0': 0.4860977249957057}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,879] Trial 14 finished with value: 0.03513999491593389 and parameters: {'w0': 0.1083784029232665}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,888] Trial 15 finished with value: 0.03513999491593389 and parameters: {'w0': 0.7696523546638099}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,897] Trial 16 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6027636252634131}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,906] Trial 17 finished with value: 0.03513999491593389 and parameters: {'w0': 0.8938454553080546}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,915] Trial 18 finished with value: 0.03513999491593389 and parameters: {'w0': 0.4990114410169809}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,924] Trial 19 finished with value: 0.03513999491593389 and parameters: {'w0': 0.19845608199883424}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,933] Trial 20 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6559149306554158}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,941] Trial 21 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5699095217233696}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,950] Trial 22 finished with value: 0.03513999491593389 and parameters: {'w0': 0.4264227692641709}. Best is trial 0 with value: 0.03513999491593389.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 4): 0.9649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:41:09,959] Trial 23 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5663349230208925}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,968] Trial 24 finished with value: 0.03513999491593389 and parameters: {'w0': 0.8389115772437582}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,978] Trial 25 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6924925045378965}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,987] Trial 26 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5367808790542506}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:09,996] Trial 27 finished with value: 0.03513999491593389 and parameters: {'w0': 0.4508028820372647}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,005] Trial 28 finished with value: 0.03513999491593389 and parameters: {'w0': 0.32195929924556266}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,016] Trial 29 finished with value: 0.03513999491593389 and parameters: {'w0': 0.787372482389053}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,025] Trial 30 finished with value: 0.03513999491593389 and parameters: {'w0': 0.32307124699213596}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,034] Trial 31 finished with value: 0.03513999491593389 and parameters: {'w0': 0.20306437628518492}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,044] Trial 32 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6633377436201167}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,053] Trial 33 finished with value: 0.03513999491593389 and parameters: {'w0': 0.9799817937926034}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,063] Trial 34 finished with value: 0.03513999491593389 and parameters: {'w0': 0.3275434801407101}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,072] Trial 35 finished with value: 0.03513999491593389 and parameters: {'w0': 0.1859253431474116}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,081] Trial 36 finished with value: 0.03513999491593389 and parameters: {'w0': 0.36960737802699434}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,091] Trial 37 finished with value: 0.03513999491593389 and parameters: {'w0': 0.46413596310162114}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,100] Trial 38 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5266535809631264}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,110] Trial 39 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6201005059451853}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,119] Trial 40 finished with value: 0.03513999491593389 and parameters: {'w0': 0.2589572591447997}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,129] Trial 41 finished with value: 0.03513999491593389 and parameters: {'w0': 0.9049189423802413}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,138] Trial 42 finished with value: 0.03513999491593389 and parameters: {'w0': 0.8360723580844424}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,148] Trial 43 finished with value: 0.03513999491593389 and parameters: {'w0': 0.709293355001098}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,158] Trial 44 finished with value: 0.03513999491593389 and parameters: {'w0': 0.0022542432398719447}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,172] Trial 45 finished with value: 0.03513999491593389 and parameters: {'w0': 0.9338505824173378}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,186] Trial 46 finished with value: 0.03513999491593389 and parameters: {'w0': 0.8133910672524002}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,196] Trial 47 finished with value: 0.03513999491593389 and parameters: {'w0': 0.7620602127050076}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,205] Trial 48 finished with value: 0.03513999491593389 and parameters: {'w0': 0.8818661140347825}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,214] Trial 49 finished with value: 0.03513999491593389 and parameters: {'w0': 0.37940686157471215}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,223] Trial 50 finished with value: 0.03513999491593389 and parameters: {'w0': 0.10082334749320795}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,234] Trial 51 finished with value: 0.03513999491593389 and parameters: {'w0': 0.9548176199126295}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,246] Trial 52 finished with value: 0.03513999491593389 and parameters: {'w0': 0.8729800344594272}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,255] Trial 53 finished with value: 0.03513999491593389 and parameters: {'w0': 0.9952911981977721}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,265] Trial 54 finished with value: 0.03513999491593389 and parameters: {'w0': 0.730887355371061}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,274] Trial 55 finished with value: 0.03513999491593389 and parameters: {'w0': 0.9362236900318948}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,283] Trial 56 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5645969471452111}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,292] Trial 57 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6638873168777046}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,302] Trial 58 finished with value: 0.03513999491593389 and parameters: {'w0': 0.40893728991046996}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,311] Trial 59 finished with value: 0.03513999491593389 and parameters: {'w0': 0.7933418217013765}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,321] Trial 60 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5963348467498207}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,330] Trial 61 finished with value: 0.03513999491593389 and parameters: {'w0': 0.266425591453192}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,340] Trial 62 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5082877182040925}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,349] Trial 63 finished with value: 0.03513999491593389 and parameters: {'w0': 0.4433713290820225}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,359] Trial 64 finished with value: 0.03513999491593389 and parameters: {'w0': 0.47416651183213254}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,368] Trial 65 finished with value: 0.03513999491593389 and parameters: {'w0': 0.3331238080272819}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,378] Trial 66 finished with value: 0.03513999491593389 and parameters: {'w0': 0.3609719029465144}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,392] Trial 67 finished with value: 0.03513999491593389 and parameters: {'w0': 0.8517383315246325}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,402] Trial 68 finished with value: 0.03513999491593389 and parameters: {'w0': 0.4083456513003683}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,412] Trial 69 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5469638129511766}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,421] Trial 70 finished with value: 0.03513999491593389 and parameters: {'w0': 0.21407497989149205}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,431] Trial 71 finished with value: 0.03513999491593389 and parameters: {'w0': 0.9645204612431678}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,441] Trial 72 finished with value: 0.03513999491593389 and parameters: {'w0': 0.7474030080819019}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,451] Trial 73 finished with value: 0.03513999491593389 and parameters: {'w0': 0.2935861027157732}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,462] Trial 74 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6918405595637165}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,471] Trial 75 finished with value: 0.03513999491593389 and parameters: {'w0': 0.9047135268242326}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,480] Trial 76 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6198046937261624}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,492] Trial 77 finished with value: 0.03513999491593389 and parameters: {'w0': 0.785662879975529}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,502] Trial 78 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5105141802092776}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,512] Trial 79 finished with value: 0.03513999491593389 and parameters: {'w0': 0.2910214178015584}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,521] Trial 80 finished with value: 0.03513999491593389 and parameters: {'w0': 0.8170048542704574}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,531] Trial 81 finished with value: 0.03513999491593389 and parameters: {'w0': 0.35431193394880023}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,541] Trial 82 finished with value: 0.03513999491593389 and parameters: {'w0': 0.21513475961427656}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,550] Trial 83 finished with value: 0.03513999491593389 and parameters: {'w0': 0.5892158629920279}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,560] Trial 84 finished with value: 0.03513999491593389 and parameters: {'w0': 0.43011563383140095}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,570] Trial 85 finished with value: 0.03513999491593389 and parameters: {'w0': 0.1641038292913014}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,579] Trial 86 finished with value: 0.03513999491593389 and parameters: {'w0': 0.24867621352679098}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,589] Trial 87 finished with value: 0.03513999491593389 and parameters: {'w0': 0.3855103362439135}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,599] Trial 88 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6393984626368605}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,609] Trial 89 finished with value: 0.03513999491593389 and parameters: {'w0': 0.9260246459057146}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,618] Trial 90 finished with value: 0.03513999491593389 and parameters: {'w0': 0.6890586424041194}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,628] Trial 91 finished with value: 0.03513999491593389 and parameters: {'w0': 0.47742665596698186}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,638] Trial 92 finished with value: 0.03513999491593389 and parameters: {'w0': 0.2984007312834554}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,648] Trial 93 finished with value: 0.03513999491593389 and parameters: {'w0': 0.39277152318710484}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,658] Trial 94 finished with value: 0.03513999491593389 and parameters: {'w0': 0.8521050021719756}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,669] Trial 95 finished with value: 0.03513999491593389 and parameters: {'w0': 0.45681520568232514}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,681] Trial 96 finished with value: 0.03513999491593389 and parameters: {'w0': 0.32386615066056307}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,691] Trial 97 finished with value: 0.03513999491593389 and parameters: {'w0': 0.23675077411012557}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,700] Trial 98 finished with value: 0.03513999491593389 and parameters: {'w0': 0.42455131124060025}. Best is trial 0 with value: 0.03513999491593389.\n",
            "[I 2025-06-16 10:41:10,709] Trial 99 finished with value: 0.03513999491593389 and parameters: {'w0': 0.3496449775968017}. Best is trial 0 with value: 0.03513999491593389.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 4): 0.9649\n",
            "\n",
            "--- Training combination ('lgbm', 'mlp') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003102 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.336006\n",
            "[LightGBM] [Info] Start training from score -3.552799\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889700\n",
            "[LightGBM] [Info] Start training from score -3.745491\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.560449\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013656\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912304\n",
            "[LightGBM] [Info] Start training from score -2.909219\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521069\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.456743\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 4): 0.9643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:41:36,919] A new study created in memory with name: no-name-a80460af-2fb9-4ec1-b838-310c99419153\n",
            "[I 2025-06-16 10:41:36,927] Trial 0 finished with value: 0.03550143497782188 and parameters: {'w0': 0.29885350351582685, 'w1': 0.4456344059173425}. Best is trial 0 with value: 0.03550143497782188.\n",
            "[I 2025-06-16 10:41:36,933] Trial 1 finished with value: 0.035304596682102285 and parameters: {'w0': 0.35743535354565803, 'w1': 0.3942184909465488}. Best is trial 1 with value: 0.035304596682102285.\n",
            "[I 2025-06-16 10:41:36,938] Trial 2 finished with value: 0.034020012785095255 and parameters: {'w0': 0.8197353146555678, 'w1': 0.13263498098812976}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:36,943] Trial 3 finished with value: 0.03556764029391024 and parameters: {'w0': 0.24381263995575664, 'w1': 0.519315508354902}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:36,949] Trial 4 finished with value: 0.03556923179033966 and parameters: {'w0': 0.4298375814056985, 'w1': 0.7968261972577318}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:36,954] Trial 5 finished with value: 0.03563453949560069 and parameters: {'w0': 0.10126805779319015, 'w1': 0.5296816584642082}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:36,959] Trial 6 finished with value: 0.035299280077979 and parameters: {'w0': 0.3669741015452964, 'w1': 0.9775178677150881}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:36,965] Trial 7 finished with value: 0.03435865623808698 and parameters: {'w0': 0.8919279321195756, 'w1': 0.3600100135667551}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:36,972] Trial 8 finished with value: 0.03544139020013093 and parameters: {'w0': 0.1447430371962437, 'w1': 0.16561853358145373}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:36,978] Trial 9 finished with value: 0.034209577929047 and parameters: {'w0': 0.7863520605120689, 'w1': 0.05190051946441765}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:36,991] Trial 10 finished with value: 0.034032412619506625 and parameters: {'w0': 0.637549750309071, 'w1': 0.17554506832673356}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:37,004] Trial 11 finished with value: 0.0352092603857217 and parameters: {'w0': 0.6492537770650088, 'w1': 0.01702874426870271}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:37,017] Trial 12 finished with value: 0.034225549149913936 and parameters: {'w0': 0.6398481432272927, 'w1': 0.2295701015865665}. Best is trial 2 with value: 0.034020012785095255.\n",
            "[I 2025-06-16 10:41:37,030] Trial 13 finished with value: 0.03395544373332482 and parameters: {'w0': 0.9582690970437331, 'w1': 0.2225877074924977}. Best is trial 13 with value: 0.03395544373332482.\n",
            "[I 2025-06-16 10:41:37,044] Trial 14 finished with value: 0.03389712512280485 and parameters: {'w0': 0.9608002290324161, 'w1': 0.2537732608094772}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,058] Trial 15 finished with value: 0.03402582236159546 and parameters: {'w0': 0.9841252467707315, 'w1': 0.2908843187802454}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,071] Trial 16 finished with value: 0.03510840918404401 and parameters: {'w0': 0.9962909960123003, 'w1': 0.6467609815865271}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,084] Trial 17 finished with value: 0.034159888537848015 and parameters: {'w0': 0.7795599971726308, 'w1': 0.27656518252561674}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,096] Trial 18 finished with value: 0.03537324386065932 and parameters: {'w0': 0.5268102977831197, 'w1': 0.6613366633457203}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,111] Trial 19 finished with value: 0.034362269337327556 and parameters: {'w0': 0.8963958085455999, 'w1': 0.34433084045763074}. Best is trial 14 with value: 0.03389712512280485.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted mlp (fold 4): 0.9651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:41:37,125] Trial 20 finished with value: 0.03402073568099406 and parameters: {'w0': 0.5444823371290585, 'w1': 0.08918496986097832}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,140] Trial 21 finished with value: 0.034151358156021216 and parameters: {'w0': 0.8265636074985234, 'w1': 0.12728950838869157}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,153] Trial 22 finished with value: 0.03395932672908242 and parameters: {'w0': 0.8927323421499416, 'w1': 0.227167073944473}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,166] Trial 23 finished with value: 0.03396551117691127 and parameters: {'w0': 0.9058564268643636, 'w1': 0.24389533923131343}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,179] Trial 24 finished with value: 0.03504019204458775 and parameters: {'w0': 0.6916012142061865, 'w1': 0.4648758350165235}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,193] Trial 25 finished with value: 0.0340228256778613 and parameters: {'w0': 0.9964742871464703, 'w1': 0.1986211271314433}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,208] Trial 26 finished with value: 0.03574031701211289 and parameters: {'w0': 0.7368165651686538, 'w1': 8.621443678080709e-05}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,223] Trial 27 finished with value: 0.035433384557105874 and parameters: {'w0': 0.00845418742833326, 'w1': 0.2977869022698151}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,236] Trial 28 finished with value: 0.03455980344033882 and parameters: {'w0': 0.9358806134841993, 'w1': 0.40138474371593935}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,249] Trial 29 finished with value: 0.035304361334448586 and parameters: {'w0': 0.8587965167473749, 'w1': 0.4411075627105894}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,264] Trial 30 finished with value: 0.03503786785753216 and parameters: {'w0': 0.7469836428446408, 'w1': 0.5895696234202996}. Best is trial 14 with value: 0.03389712512280485.\n",
            "[I 2025-06-16 10:41:37,278] Trial 31 finished with value: 0.03389458555319058 and parameters: {'w0': 0.9069013593903272, 'w1': 0.23430321015169026}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,291] Trial 32 finished with value: 0.03416309619150626 and parameters: {'w0': 0.9331544963909765, 'w1': 0.3237021847866396}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,305] Trial 33 finished with value: 0.034219418778173916 and parameters: {'w0': 0.8474968796091112, 'w1': 0.10936138458169305}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,319] Trial 34 finished with value: 0.03396337474273503 and parameters: {'w0': 0.9373058794204349, 'w1': 0.24585325065975733}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,333] Trial 35 finished with value: 0.03409010220700892 and parameters: {'w0': 0.8366785732643636, 'w1': 0.18536665507395478}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,346] Trial 36 finished with value: 0.03517692182081089 and parameters: {'w0': 0.7086017246501286, 'w1': 0.39124536782874675}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,361] Trial 37 finished with value: 0.034348465143024365 and parameters: {'w0': 0.9535203473574179, 'w1': 0.09793161330346989}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,375] Trial 38 finished with value: 0.03550143497782188 and parameters: {'w0': 0.5813767556221946, 'w1': 0.9050915884732063}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,389] Trial 39 finished with value: 0.03544139020013093 and parameters: {'w0': 0.43698114655155224, 'w1': 0.5229405851781841}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,403] Trial 40 finished with value: 0.0340228256778613 and parameters: {'w0': 0.7947313196058502, 'w1': 0.1545560104929926}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,417] Trial 41 finished with value: 0.03409813907713943 and parameters: {'w0': 0.8909747092913617, 'w1': 0.24917382546126843}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,432] Trial 42 finished with value: 0.03395544373332482 and parameters: {'w0': 0.9557989350667035, 'w1': 0.2203069829123615}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,446] Trial 43 finished with value: 0.03395932672908242 and parameters: {'w0': 0.8559317844526491, 'w1': 0.2173569810281904}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,460] Trial 44 finished with value: 0.034276799570117644 and parameters: {'w0': 0.9667202500019763, 'w1': 0.06095533683845797}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,474] Trial 45 finished with value: 0.03543328735285345 and parameters: {'w0': 0.25530755151493395, 'w1': 0.37450224270843047}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,488] Trial 46 finished with value: 0.03416301609436534 and parameters: {'w0': 0.8944815731123597, 'w1': 0.3157722243485678}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,502] Trial 47 finished with value: 0.0340877416227231 and parameters: {'w0': 0.7934619997216003, 'w1': 0.1479342595497085}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,515] Trial 48 finished with value: 0.03482984148839696 and parameters: {'w0': 0.9579861593930131, 'w1': 0.4272541193837055}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,529] Trial 49 finished with value: 0.03441111895652016 and parameters: {'w0': 0.8861043501834648, 'w1': 0.04667225012756171}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,542] Trial 50 finished with value: 0.034032412619506625 and parameters: {'w0': 0.9866069695236731, 'w1': 0.2722584174365185}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,557] Trial 51 finished with value: 0.034022272197600345 and parameters: {'w0': 0.8618231443949989, 'w1': 0.19327631625683134}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,571] Trial 52 finished with value: 0.03409010220700892 and parameters: {'w0': 0.9238066888338246, 'w1': 0.2052992389452094}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,586] Trial 53 finished with value: 0.03403279419440408 and parameters: {'w0': 0.8224675430373134, 'w1': 0.22262816570331917}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,601] Trial 54 finished with value: 0.03503349176428694 and parameters: {'w0': 0.7660085943972633, 'w1': 0.3498143424357214}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,614] Trial 55 finished with value: 0.03409319404381228 and parameters: {'w0': 0.8569391128777394, 'w1': 0.2718752101267363}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,628] Trial 56 finished with value: 0.034020012785095255 and parameters: {'w0': 0.9690005481686942, 'w1': 0.15630865967583965}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,642] Trial 57 finished with value: 0.034159888537848015 and parameters: {'w0': 0.9229272304207389, 'w1': 0.3291067944687489}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,656] Trial 58 finished with value: 0.035171777332551835 and parameters: {'w0': 0.8131655702660642, 'w1': 0.7449240635448087}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,669] Trial 59 finished with value: 0.03516990226204186 and parameters: {'w0': 0.9977726720322835, 'w1': 0.48657124992047707}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,683] Trial 60 finished with value: 0.03414716018215025 and parameters: {'w0': 0.8772117058800909, 'w1': 0.071480307851917}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,697] Trial 61 finished with value: 0.03396337474273503 and parameters: {'w0': 0.9297934356927501, 'w1': 0.24276477017864279}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,711] Trial 62 finished with value: 0.03415264504896143 and parameters: {'w0': 0.956277054814633, 'w1': 0.12940433609447405}. Best is trial 31 with value: 0.03389458555319058.\n",
            "[I 2025-06-16 10:41:37,725] Trial 63 finished with value: 0.033755241252915735 and parameters: {'w0': 0.9106915296010004, 'w1': 0.22001867602888595}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,739] Trial 64 finished with value: 0.03382361631116648 and parameters: {'w0': 0.9047248036461121, 'w1': 0.22133275949151845}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,753] Trial 65 finished with value: 0.03403163437483625 and parameters: {'w0': 0.9110931036206094, 'w1': 0.3002381177835835}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,766] Trial 66 finished with value: 0.03550352657510791 and parameters: {'w0': 0.133605474505325, 'w1': 0.1770839808581457}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,780] Trial 67 finished with value: 0.03503786785753216 and parameters: {'w0': 0.3617828930362962, 'w1': 0.27963430708815673}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,793] Trial 68 finished with value: 0.034154477807108674 and parameters: {'w0': 0.7016045000238558, 'w1': 0.12206480429199168}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,807] Trial 69 finished with value: 0.03416309619150626 and parameters: {'w0': 0.7411611966718454, 'w1': 0.26075675281426136}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,821] Trial 70 finished with value: 0.03510228191491338 and parameters: {'w0': 0.4543580961847245, 'w1': 0.21698786536141276}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,835] Trial 71 finished with value: 0.03395932672908242 and parameters: {'w0': 0.8747469084037653, 'w1': 0.22324913290510642}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,848] Trial 72 finished with value: 0.03388986004198613 and parameters: {'w0': 0.8455841412852138, 'w1': 0.20068346615880545}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,862] Trial 73 finished with value: 0.0340228256778613 and parameters: {'w0': 0.9063127022626531, 'w1': 0.17823789988467073}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,876] Trial 74 finished with value: 0.034151358156021216 and parameters: {'w0': 0.9701602490218348, 'w1': 0.1470073193793473}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,891] Trial 75 finished with value: 0.03435262235614611 and parameters: {'w0': 0.8257444557863088, 'w1': 0.09542911822689568}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,905] Trial 76 finished with value: 0.03402885156390112 and parameters: {'w0': 0.9430902713663076, 'w1': 0.30163247111890373}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,919] Trial 77 finished with value: 0.03435865623808698 and parameters: {'w0': 0.9103306367141375, 'w1': 0.3717168219417894}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,934] Trial 78 finished with value: 0.03534179306029417 and parameters: {'w0': 0.9936630043187489, 'w1': 0.023327266363386112}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,948] Trial 79 finished with value: 0.03388986004198613 and parameters: {'w0': 0.8052868382251012, 'w1': 0.19117593455876047}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,963] Trial 80 finished with value: 0.033755241252915735 and parameters: {'w0': 0.7929311903424169, 'w1': 0.19262965091991305}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,978] Trial 81 finished with value: 0.03395932672908242 and parameters: {'w0': 0.7690511793937036, 'w1': 0.19685720208259408}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:37,992] Trial 82 finished with value: 0.033891667052073804 and parameters: {'w0': 0.6589187104658909, 'w1': 0.16387973264532824}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,006] Trial 83 finished with value: 0.03409065568726999 and parameters: {'w0': 0.8031846774107584, 'w1': 0.16799254528511756}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,021] Trial 84 finished with value: 0.0344286524954206 and parameters: {'w0': 0.6548107275761659, 'w1': 0.24876820279151338}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,035] Trial 85 finished with value: 0.034151358156021216 and parameters: {'w0': 0.7340004918760814, 'w1': 0.11579360073320166}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,049] Trial 86 finished with value: 0.03415244952441232 and parameters: {'w0': 0.6001058737208654, 'w1': 0.07713967319691406}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,063] Trial 87 finished with value: 0.03402073568099406 and parameters: {'w0': 0.8455612314784516, 'w1': 0.14070682528491785}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,077] Trial 88 finished with value: 0.03395932672908242 and parameters: {'w0': 0.7771652622243815, 'w1': 0.19885818675671155}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,091] Trial 89 finished with value: 0.0340228256778613 and parameters: {'w0': 0.8274483198606484, 'w1': 0.1670694187336245}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,105] Trial 90 finished with value: 0.034425800946568885 and parameters: {'w0': 0.663123630847003, 'w1': 0.2668705333354973}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,119] Trial 91 finished with value: 0.034032412619506625 and parameters: {'w0': 0.8742306957871006, 'w1': 0.24187295179295856}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,134] Trial 92 finished with value: 0.03409010220700892 and parameters: {'w0': 0.9555894475256436, 'w1': 0.21025858807736308}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,148] Trial 93 finished with value: 0.034225549149913936 and parameters: {'w0': 0.9313543542686917, 'w1': 0.33605316695863674}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,162] Trial 94 finished with value: 0.035241248082232945 and parameters: {'w0': 0.891290139557332, 'w1': 0.5706778949738103}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,176] Trial 95 finished with value: 0.03409010220700892 and parameters: {'w0': 0.8519287299278139, 'w1': 0.1817562809137079}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,191] Trial 96 finished with value: 0.03402594734437281 and parameters: {'w0': 0.972284903621168, 'w1': 0.29875923625677375}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,205] Trial 97 finished with value: 0.03402582236159546 and parameters: {'w0': 0.8022329580589017, 'w1': 0.23713819213178422}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,220] Trial 98 finished with value: 0.03469469204384534 and parameters: {'w0': 0.30645765496675353, 'w1': 0.13413794580004867}. Best is trial 63 with value: 0.033755241252915735.\n",
            "[I 2025-06-16 10:41:38,236] Trial 99 finished with value: 0.03422373104033627 and parameters: {'w0': 0.6166189603348552, 'w1': 0.1103583868214867}. Best is trial 63 with value: 0.033755241252915735.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 4): 0.9662\n",
            "\n",
            "--- Training combination ('lgbm', 'logreg') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003125 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.336006\n",
            "[LightGBM] [Info] Start training from score -3.552799\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889700\n",
            "[LightGBM] [Info] Start training from score -3.745491\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.560449\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013656\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912304\n",
            "[LightGBM] [Info] Start training from score -2.909219\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521069\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.456743\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 4): 0.9643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:41:48,867] A new study created in memory with name: no-name-811042bd-5b35-4d1b-9691-8c77d686d8c5\n",
            "[I 2025-06-16 10:41:48,876] Trial 0 finished with value: 0.0347202905930859 and parameters: {'w0': 0.19463382075356894, 'w1': 0.256789021079597}. Best is trial 0 with value: 0.0347202905930859.\n",
            "[I 2025-06-16 10:41:48,883] Trial 1 finished with value: 0.034366036309295134 and parameters: {'w0': 0.8026343911183107, 'w1': 0.5447278459020393}. Best is trial 1 with value: 0.034366036309295134.\n",
            "[I 2025-06-16 10:41:48,904] Trial 2 finished with value: 0.034739658279087426 and parameters: {'w0': 0.09532830154187577, 'w1': 0.8362475333010007}. Best is trial 1 with value: 0.034366036309295134.\n",
            "[I 2025-06-16 10:41:48,911] Trial 3 finished with value: 0.03423144079881091 and parameters: {'w0': 0.14486349708980473, 'w1': 0.0723747266029594}. Best is trial 3 with value: 0.03423144079881091.\n",
            "[I 2025-06-16 10:41:48,919] Trial 4 finished with value: 0.03436623807218586 and parameters: {'w0': 0.8231048444859382, 'w1': 0.41889361008137516}. Best is trial 3 with value: 0.03423144079881091.\n",
            "[I 2025-06-16 10:41:48,927] Trial 5 finished with value: 0.03574095649652753 and parameters: {'w0': 0.8698132582679271, 'w1': 0.004873104838732267}. Best is trial 3 with value: 0.03423144079881091.\n",
            "[I 2025-06-16 10:41:48,934] Trial 6 finished with value: 0.03485022282007588 and parameters: {'w0': 0.7759034165936636, 'w1': 0.8504070343152047}. Best is trial 3 with value: 0.03423144079881091.\n",
            "[I 2025-06-16 10:41:48,941] Trial 7 finished with value: 0.03409440930444263 and parameters: {'w0': 0.6862594813525155, 'w1': 0.3167767960179291}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:48,949] Trial 8 finished with value: 0.03500235696481058 and parameters: {'w0': 0.0481255558153163, 'w1': 0.8148545063339135}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:48,956] Trial 9 finished with value: 0.0349209194302289 and parameters: {'w0': 0.7371778288473027, 'w1': 0.904176658452887}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:48,975] Trial 10 finished with value: 0.0347861575291305 and parameters: {'w0': 0.4746857450711036, 'w1': 0.5494843486871641}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:48,994] Trial 11 finished with value: 0.03487644587626326 and parameters: {'w0': 0.4438769540764429, 'w1': 0.048310514550301886}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,009] Trial 12 finished with value: 0.03437022131720324 and parameters: {'w0': 0.30979211783075117, 'w1': 0.21887001656681834}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,021] Trial 13 finished with value: 0.034555816142057716 and parameters: {'w0': 0.6183156581164282, 'w1': 0.203672423872593}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,034] Trial 14 finished with value: 0.03428319521201917 and parameters: {'w0': 0.9764330168086738, 'w1': 0.3525182238032394}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,047] Trial 15 finished with value: 0.0351579011105716 and parameters: {'w0': 0.627047571368764, 'w1': 0.12561182299582785}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,060] Trial 16 finished with value: 0.03465226911589858 and parameters: {'w0': 0.35019174206519255, 'w1': 0.6883367199874814}. Best is trial 7 with value: 0.03409440930444263.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 4): 0.9649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:41:49,074] Trial 17 finished with value: 0.03423323542038992 and parameters: {'w0': 0.5942093482425008, 'w1': 0.3463668846782866}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,087] Trial 18 finished with value: 0.03443338059446133 and parameters: {'w0': 0.20701681268408922, 'w1': 0.12870250215113338}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,100] Trial 19 finished with value: 0.03484983883029602 and parameters: {'w0': 0.4033274070938763, 'w1': 0.4453339590275851}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,113] Trial 20 finished with value: 0.03513999491593389 and parameters: {'w0': 0.00011509037286297485, 'w1': 0.9987703513927244}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,127] Trial 21 finished with value: 0.03436842764059378 and parameters: {'w0': 0.5652612058780373, 'w1': 0.30703327958521376}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,141] Trial 22 finished with value: 0.034786694645512095 and parameters: {'w0': 0.6894927475458508, 'w1': 0.6582060036661704}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,154] Trial 23 finished with value: 0.03423049569929626 and parameters: {'w0': 0.5448938810528653, 'w1': 0.35365915361923345}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,168] Trial 24 finished with value: 0.03515818032314222 and parameters: {'w0': 0.5190148428283661, 'w1': 0.09582227482616655}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,181] Trial 25 finished with value: 0.03479045838656747 and parameters: {'w0': 0.19212320471469724, 'w1': 0.4455351502950093}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,195] Trial 26 finished with value: 0.03468947743514417 and parameters: {'w0': 0.6911923333588099, 'w1': 0.21428971415426148}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,209] Trial 27 finished with value: 0.03465324903511913 and parameters: {'w0': 0.28819104880092133, 'w1': 0.6169734131403092}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,222] Trial 28 finished with value: 0.034369944630002536 and parameters: {'w0': 0.5356389615095992, 'w1': 0.2888969266075057}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,236] Trial 29 finished with value: 0.03436052125094691 and parameters: {'w0': 0.9425390195763383, 'w1': 0.402936559486005}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,249] Trial 30 finished with value: 0.03485418499316362 and parameters: {'w0': 0.16455592918605294, 'w1': 0.16075805566228585}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,263] Trial 31 finished with value: 0.03430075224460616 and parameters: {'w0': 0.6133409468167234, 'w1': 0.3469694436636114}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,277] Trial 32 finished with value: 0.03442307883413709 and parameters: {'w0': 0.6872709865477233, 'w1': 0.27606765790987153}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,293] Trial 33 finished with value: 0.03492008616211273 and parameters: {'w0': 0.430900425389911, 'w1': 0.5121080489356677}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,306] Trial 34 finished with value: 0.03430036520339863 and parameters: {'w0': 0.580608855997515, 'w1': 0.366075565502017}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,320] Trial 35 finished with value: 0.03462122941482193 and parameters: {'w0': 0.8410477833995909, 'w1': 0.24866076772201437}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,337] Trial 36 finished with value: 0.035210069592986226 and parameters: {'w0': 0.7531536343004606, 'w1': 0.0564735546669205}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,350] Trial 37 finished with value: 0.03478657754550096 and parameters: {'w0': 0.4939282675678614, 'w1': 0.49222404430329597}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,365] Trial 38 finished with value: 0.03409440930444263 and parameters: {'w0': 0.3871096419569636, 'w1': 0.17943837428869658}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,379] Trial 39 finished with value: 0.03472450763925994 and parameters: {'w0': 0.10767053816271688, 'w1': 0.14545925567569198}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,399] Trial 40 finished with value: 0.035606625945363235 and parameters: {'w0': 0.24759132612825396, 'w1': 0.00753864518593339}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,414] Trial 41 finished with value: 0.034308679411582 and parameters: {'w0': 0.3683293100644875, 'w1': 0.31630688406037943}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,428] Trial 42 finished with value: 0.034366005716295445 and parameters: {'w0': 0.6584791298553231, 'w1': 0.3928448801149835}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,442] Trial 43 finished with value: 0.034233025244764126 and parameters: {'w0': 0.46479104140413346, 'w1': 0.24854140074754671}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,457] Trial 44 finished with value: 0.034292453288539027 and parameters: {'w0': 0.4584574511536979, 'w1': 0.19115020368568433}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,473] Trial 45 finished with value: 0.03443338059446133 and parameters: {'w0': 0.4052548922937993, 'w1': 0.24812993540731806}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,487] Trial 46 finished with value: 0.03462122941482193 and parameters: {'w0': 0.3230656003449485, 'w1': 0.09825435758059392}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,504] Trial 47 finished with value: 0.03452052456349819 and parameters: {'w0': 0.1313639254235949, 'w1': 0.1851179795331335}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,517] Trial 48 finished with value: 0.03487644587626326 and parameters: {'w0': 0.5339928549891622, 'w1': 0.05792069584009507}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,530] Trial 49 finished with value: 0.034710377301070294 and parameters: {'w0': 0.2619656646472176, 'w1': 0.2441919471134532}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,544] Trial 50 finished with value: 0.03509481903141831 and parameters: {'w0': 0.8018797595540503, 'w1': 0.16989057020355536}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,560] Trial 51 finished with value: 0.03430075224460616 and parameters: {'w0': 0.5787891334704435, 'w1': 0.32141406019637603}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,574] Trial 52 finished with value: 0.034733002692746706 and parameters: {'w0': 0.054730962996932864, 'w1': 0.4430022977776393}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,587] Trial 53 finished with value: 0.03428319521201917 and parameters: {'w0': 0.7266201575555571, 'w1': 0.2743328750310471}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,601] Trial 54 finished with value: 0.03423551211045661 and parameters: {'w0': 0.48509013589615235, 'w1': 0.3526985806208694}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,615] Trial 55 finished with value: 0.03462122941482193 and parameters: {'w0': 0.3646086490372516, 'w1': 0.10580157458409617}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,629] Trial 56 finished with value: 0.034417748867917375 and parameters: {'w0': 0.6557252511119429, 'w1': 0.22040118843594178}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,643] Trial 57 finished with value: 0.035742240218593624 and parameters: {'w0': 0.5560527326367186, 'w1': 0.006288551195730296}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,657] Trial 58 finished with value: 0.03429790142870548 and parameters: {'w0': 0.6034754499484701, 'w1': 0.39528821501823497}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,676] Trial 59 finished with value: 0.03423145620741841 and parameters: {'w0': 0.8995139970724682, 'w1': 0.5725820791189938}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,692] Trial 60 finished with value: 0.03431047550831379 and parameters: {'w0': 0.9198548121375199, 'w1': 0.7212660407072247}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,706] Trial 61 finished with value: 0.034366036309295134 and parameters: {'w0': 0.8527592906130416, 'w1': 0.57894574131333}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,721] Trial 62 finished with value: 0.0347861575291305 and parameters: {'w0': 0.43227802219278827, 'w1': 0.49657047046615665}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,735] Trial 63 finished with value: 0.03444150844356586 and parameters: {'w0': 0.5193648291137596, 'w1': 0.45586410051467197}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,750] Trial 64 finished with value: 0.034368741688044824 and parameters: {'w0': 0.892480935045366, 'w1': 0.6090761194818941}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,765] Trial 65 finished with value: 0.034368741688044824 and parameters: {'w0': 0.7999890602872419, 'w1': 0.5454655948724749}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,780] Trial 66 finished with value: 0.03424129416722499 and parameters: {'w0': 0.9957771177746706, 'w1': 0.759012330193294}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,795] Trial 67 finished with value: 0.03436193994709025 and parameters: {'w0': 0.7190548489280708, 'w1': 0.31458692701716695}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,810] Trial 68 finished with value: 0.034484932009014924 and parameters: {'w0': 0.6503336424719196, 'w1': 0.21664479871015346}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,824] Trial 69 finished with value: 0.03468947743514417 and parameters: {'w0': 0.40799558134010444, 'w1': 0.12666474680159406}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,839] Trial 70 finished with value: 0.03422901854086002 and parameters: {'w0': 0.7658692918266465, 'w1': 0.3678044759473825}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,854] Trial 71 finished with value: 0.03436623807218586 and parameters: {'w0': 0.7450130996530079, 'w1': 0.3778844576551044}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,869] Trial 72 finished with value: 0.03429680769674659 and parameters: {'w0': 0.8782286364102494, 'w1': 0.4239009578194477}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,884] Trial 73 finished with value: 0.03436193994709025 and parameters: {'w0': 0.779360729638044, 'w1': 0.34053710365446066}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,900] Trial 74 finished with value: 0.034378397849185505 and parameters: {'w0': 0.6017579705447584, 'w1': 0.4685326002656551}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,916] Trial 75 finished with value: 0.03429680769674659 and parameters: {'w0': 0.5530659018858193, 'w1': 0.2692519953994942}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,931] Trial 76 finished with value: 0.03436052125094691 and parameters: {'w0': 0.6934960013863356, 'w1': 0.29648282042753693}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,949] Trial 77 finished with value: 0.03481356836272609 and parameters: {'w0': 0.47425424285657664, 'w1': 0.07011492324730706}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,964] Trial 78 finished with value: 0.034896066340644794 and parameters: {'w0': 0.6428042103015236, 'w1': 0.15160850673515733}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,982] Trial 79 finished with value: 0.03436842764059378 and parameters: {'w0': 0.948098528578771, 'w1': 0.5167491472900603}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:49,997] Trial 80 finished with value: 0.03436842764059378 and parameters: {'w0': 0.7728170858036343, 'w1': 0.4196203987563566}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,011] Trial 81 finished with value: 0.03437022131720324 and parameters: {'w0': 0.4978901651530125, 'w1': 0.35661716724430054}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,026] Trial 82 finished with value: 0.03430496937726957 and parameters: {'w0': 0.4713038606165098, 'w1': 0.33868191720794033}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,043] Trial 83 finished with value: 0.03430368975806719 and parameters: {'w0': 0.5059543064995601, 'w1': 0.36635743090853734}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,057] Trial 84 finished with value: 0.03437022131720324 and parameters: {'w0': 0.3355224257778567, 'w1': 0.2374551033037925}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,071] Trial 85 finished with value: 0.034368741688044824 and parameters: {'w0': 0.4486518442441555, 'w1': 0.3078063582159374}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,087] Trial 86 finished with value: 0.03416173435476477 and parameters: {'w0': 0.5841419823765429, 'w1': 0.27877838560450746}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,101] Trial 87 finished with value: 0.03429680769674659 and parameters: {'w0': 0.5875306941229628, 'w1': 0.2841696167136615}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,116] Trial 88 finished with value: 0.034917826095856475 and parameters: {'w0': 0.2211113411760552, 'w1': 0.25873107226937453}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,130] Trial 89 finished with value: 0.034850228793989246 and parameters: {'w0': 0.62399645058318, 'w1': 0.6626334293651943}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,144] Trial 90 finished with value: 0.03469365857278972 and parameters: {'w0': 0.7062481010978199, 'w1': 0.1956315491015791}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,159] Trial 91 finished with value: 0.034366005716295445 and parameters: {'w0': 0.5396985952883824, 'w1': 0.3261273414905966}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,174] Trial 92 finished with value: 0.034367880017457164 and parameters: {'w0': 0.6804287202246881, 'w1': 0.3892110411472288}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,190] Trial 93 finished with value: 0.034234978871276245 and parameters: {'w0': 0.5644018521317613, 'w1': 0.2935772645983758}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,204] Trial 94 finished with value: 0.03534030632953189 and parameters: {'w0': 0.5761723103826819, 'w1': 0.03139853079846022}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,219] Trial 95 finished with value: 0.034733002692746706 and parameters: {'w0': 0.02939574842898636, 'w1': 0.23907172616606054}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,234] Trial 96 finished with value: 0.034375971780469694 and parameters: {'w0': 0.6741134871305582, 'w1': 0.5707704604646349}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,249] Trial 97 finished with value: 0.03422901854086002 and parameters: {'w0': 0.37893802014629097, 'w1': 0.1814210945859711}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,265] Trial 98 finished with value: 0.03409440930444263 and parameters: {'w0': 0.39470465846332314, 'w1': 0.1812435415212282}. Best is trial 7 with value: 0.03409440930444263.\n",
            "[I 2025-06-16 10:41:50,281] Trial 99 finished with value: 0.03455491467914451 and parameters: {'w0': 0.3679554561609034, 'w1': 0.11813399803601818}. Best is trial 7 with value: 0.03409440930444263.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 4): 0.9659\n",
            "\n",
            "--- Training combination ('mlp', 'logreg') ---\n",
            "F1-weighted mlp (fold 4): 0.9652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:42:09,690] A new study created in memory with name: no-name-147c0118-9c95-4b0d-8188-b12662e1f67b\n",
            "[I 2025-06-16 10:42:09,699] Trial 0 finished with value: 0.03549119800364975 and parameters: {'w0': 0.6909225552466042, 'w1': 0.7038975457369357}. Best is trial 0 with value: 0.03549119800364975.\n",
            "[I 2025-06-16 10:42:09,708] Trial 1 finished with value: 0.03556028339424977 and parameters: {'w0': 0.3651650728391136, 'w1': 0.42311350175826545}. Best is trial 0 with value: 0.03549119800364975.\n",
            "[I 2025-06-16 10:42:09,716] Trial 2 finished with value: 0.03531236351091849 and parameters: {'w0': 0.20021751000955634, 'w1': 0.5378387219327768}. Best is trial 2 with value: 0.03531236351091849.\n",
            "[I 2025-06-16 10:42:09,723] Trial 3 finished with value: 0.03547786512578621 and parameters: {'w0': 0.8807336918694846, 'w1': 0.6896381532052053}. Best is trial 2 with value: 0.03531236351091849.\n",
            "[I 2025-06-16 10:42:09,731] Trial 4 finished with value: 0.03549119800364975 and parameters: {'w0': 0.19547068906192777, 'w1': 0.20902030722648357}. Best is trial 2 with value: 0.03531236351091849.\n",
            "[I 2025-06-16 10:42:09,739] Trial 5 finished with value: 0.03547786512578621 and parameters: {'w0': 0.7886765971120365, 'w1': 0.5703191265737165}. Best is trial 2 with value: 0.03531236351091849.\n",
            "[I 2025-06-16 10:42:09,747] Trial 6 finished with value: 0.035340840045100075 and parameters: {'w0': 0.6473334768513851, 'w1': 0.3828077921328257}. Best is trial 2 with value: 0.03531236351091849.\n",
            "[I 2025-06-16 10:42:09,756] Trial 7 finished with value: 0.03547786512578621 and parameters: {'w0': 0.5032111483399934, 'w1': 0.3541324476283879}. Best is trial 2 with value: 0.03531236351091849.\n",
            "[I 2025-06-16 10:42:09,765] Trial 8 finished with value: 0.03573169408529686 and parameters: {'w0': 0.992839308965608, 'w1': 0.12817986561002448}. Best is trial 2 with value: 0.03531236351091849.\n",
            "[I 2025-06-16 10:42:09,774] Trial 9 finished with value: 0.035667823093371354 and parameters: {'w0': 0.8261737296306979, 'w1': 0.12664661520343035}. Best is trial 2 with value: 0.03531236351091849.\n",
            "[I 2025-06-16 10:42:09,795] Trial 10 finished with value: 0.0352593867672637 and parameters: {'w0': 0.13186438640578146, 'w1': 0.9948942341988157}. Best is trial 10 with value: 0.0352593867672637.\n",
            "[I 2025-06-16 10:42:09,811] Trial 11 finished with value: 0.035335499246103796 and parameters: {'w0': 0.018895132780286678, 'w1': 0.9678737087687026}. Best is trial 10 with value: 0.0352593867672637.\n",
            "[I 2025-06-16 10:42:09,824] Trial 12 finished with value: 0.0352593867672637 and parameters: {'w0': 0.13290929011752364, 'w1': 0.9821122064302519}. Best is trial 10 with value: 0.0352593867672637.\n",
            "[I 2025-06-16 10:42:09,838] Trial 13 finished with value: 0.035267434910868145 and parameters: {'w0': 0.045011012979808085, 'w1': 0.9758089895461468}. Best is trial 10 with value: 0.0352593867672637.\n",
            "[I 2025-06-16 10:42:09,851] Trial 14 finished with value: 0.03524759151254531 and parameters: {'w0': 0.29003186343663345, 'w1': 0.8512136681334118}. Best is trial 14 with value: 0.03524759151254531.\n",
            "[I 2025-06-16 10:42:09,864] Trial 15 finished with value: 0.03538164229082197 and parameters: {'w0': 0.3583544488617415, 'w1': 0.8024159511709991}. Best is trial 14 with value: 0.03524759151254531.\n",
            "[I 2025-06-16 10:42:09,878] Trial 16 finished with value: 0.03531236351091849 and parameters: {'w0': 0.33742338463413457, 'w1': 0.823942111023383}. Best is trial 14 with value: 0.03524759151254531.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 4): 0.9649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:42:09,892] Trial 17 finished with value: 0.03570190096308845 and parameters: {'w0': 0.45568575428067204, 'w1': 0.8365093383035522}. Best is trial 14 with value: 0.03524759151254531.\n",
            "[I 2025-06-16 10:42:09,906] Trial 18 finished with value: 0.03531236351091849 and parameters: {'w0': 0.25628301411263604, 'w1': 0.6744692658533983}. Best is trial 14 with value: 0.03524759151254531.\n",
            "[I 2025-06-16 10:42:09,919] Trial 19 finished with value: 0.03563407866951396 and parameters: {'w0': 0.5246070805116133, 'w1': 0.8918433791435861}. Best is trial 14 with value: 0.03524759151254531.\n",
            "[I 2025-06-16 10:42:09,932] Trial 20 finished with value: 0.035326448481801886 and parameters: {'w0': 0.1140507891265409, 'w1': 0.7439850582574188}. Best is trial 14 with value: 0.03524759151254531.\n",
            "[I 2025-06-16 10:42:09,946] Trial 21 finished with value: 0.03539724849145809 and parameters: {'w0': 0.12240655364372295, 'w1': 0.9917947729191298}. Best is trial 14 with value: 0.03524759151254531.\n",
            "[I 2025-06-16 10:42:09,960] Trial 22 finished with value: 0.03518278430344435 and parameters: {'w0': 0.24335727249232653, 'w1': 0.8988121460749617}. Best is trial 22 with value: 0.03518278430344435.\n",
            "[I 2025-06-16 10:42:09,975] Trial 23 finished with value: 0.035047691850885965 and parameters: {'w0': 0.2652485360733308, 'w1': 0.8949445878322704}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:09,988] Trial 24 finished with value: 0.035376827827687585 and parameters: {'w0': 0.2761373882028931, 'w1': 0.601659267384069}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,002] Trial 25 finished with value: 0.035637031778373296 and parameters: {'w0': 0.44721438368368893, 'w1': 0.8860698646104034}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,016] Trial 26 finished with value: 0.03518278430344435 and parameters: {'w0': 0.2352745805304848, 'w1': 0.8825350452390991}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,030] Trial 27 finished with value: 0.03542777616786785 and parameters: {'w0': 0.5851981181937921, 'w1': 0.754007473492025}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,044] Trial 28 finished with value: 0.03573198090802743 and parameters: {'w0': 0.4154837216387885, 'w1': 0.02167463675685055}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,058] Trial 29 finished with value: 0.03511477987859102 and parameters: {'w0': 0.2050778979374503, 'w1': 0.6457518513692395}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,072] Trial 30 finished with value: 0.035327042267125464 and parameters: {'w0': 0.07970794082111951, 'w1': 0.6241025603491331}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,087] Trial 31 finished with value: 0.03512293174076908 and parameters: {'w0': 0.2035438352581874, 'w1': 0.9084592863961126}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,102] Trial 32 finished with value: 0.035188486466363855 and parameters: {'w0': 0.17842759010079345, 'w1': 0.769069727998767}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,116] Trial 33 finished with value: 0.035498357717891005 and parameters: {'w0': 0.3473980049257136, 'w1': 0.47807523537618185}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,130] Trial 34 finished with value: 0.03511477987859102 and parameters: {'w0': 0.2943186685289718, 'w1': 0.9239290918631057}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,144] Trial 35 finished with value: 0.03563407866951396 and parameters: {'w0': 0.40521164386329683, 'w1': 0.7029773980755648}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,158] Trial 36 finished with value: 0.03524759151254531 and parameters: {'w0': 0.32960853302697873, 'w1': 0.9293032380330848}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,174] Trial 37 finished with value: 0.035115416723437654 and parameters: {'w0': 0.1923750552448009, 'w1': 0.6656016154342842}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,188] Trial 38 finished with value: 0.03524759151254531 and parameters: {'w0': 0.1725174157271117, 'w1': 0.49117633653734555}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,202] Trial 39 finished with value: 0.03550678245009753 and parameters: {'w0': 0.3099651714560547, 'w1': 0.6553755497163035}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,216] Trial 40 finished with value: 0.03549119800364975 and parameters: {'w0': 0.5505619070270809, 'w1': 0.5540190936204146}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,230] Trial 41 finished with value: 0.03525328600393096 and parameters: {'w0': 0.19153293859204712, 'w1': 0.7816343264908844}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,245] Trial 42 finished with value: 0.03542777616786785 and parameters: {'w0': 0.2313672346842829, 'w1': 0.31006281542737246}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,260] Trial 43 finished with value: 0.03519219294381948 and parameters: {'w0': 0.07867955430620077, 'w1': 0.9336083142442506}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,275] Trial 44 finished with value: 0.035188486466363855 and parameters: {'w0': 0.16407917462978672, 'w1': 0.705170670736274}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,289] Trial 45 finished with value: 0.03531236351091849 and parameters: {'w0': 0.2234357489671456, 'w1': 0.6044392436303168}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,303] Trial 46 finished with value: 0.03556564396864492 and parameters: {'w0': 0.28792489155318335, 'w1': 0.4514509079658803}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,317] Trial 47 finished with value: 0.03526830166275019 and parameters: {'w0': 0.012024145569562078, 'w1': 0.5351092856604192}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,333] Trial 48 finished with value: 0.03570190096308845 and parameters: {'w0': 0.39039604264453087, 'w1': 0.7225496824927857}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,355] Trial 49 finished with value: 0.03556028339424977 and parameters: {'w0': 0.7098907638016074, 'w1': 0.8506540663315012}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,371] Trial 50 finished with value: 0.03519219294381948 and parameters: {'w0': 0.07760047338685291, 'w1': 0.9425010835822655}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,385] Trial 51 finished with value: 0.03518278430344435 and parameters: {'w0': 0.24743798651137316, 'w1': 0.90875547128898}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,400] Trial 52 finished with value: 0.035259895400591046 and parameters: {'w0': 0.1512145704997936, 'w1': 0.8000073006165235}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,414] Trial 53 finished with value: 0.03525328600393096 and parameters: {'w0': 0.20664948250430326, 'w1': 0.8531109291424879}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,428] Trial 54 finished with value: 0.03511477987859102 and parameters: {'w0': 0.30352473362427146, 'w1': 0.9533248323491639}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,442] Trial 55 finished with value: 0.03531236351091849 and parameters: {'w0': 0.29608210439328764, 'w1': 0.8099268156075475}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,456] Trial 56 finished with value: 0.03549119800364975 and parameters: {'w0': 0.961307502831855, 'w1': 0.9498872542581022}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,471] Trial 57 finished with value: 0.03531236351091849 and parameters: {'w0': 0.385515429524375, 'w1': 0.9953670265138692}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,487] Trial 58 finished with value: 0.03539724849145809 and parameters: {'w0': 0.10672166211592307, 'w1': 0.866863043075555}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,501] Trial 59 finished with value: 0.035115416723437654 and parameters: {'w0': 0.2661909413872202, 'w1': 0.9160972890081277}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,516] Trial 60 finished with value: 0.03547786512578621 and parameters: {'w0': 0.43979998825885064, 'w1': 0.2972715184928807}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,530] Trial 61 finished with value: 0.035115416723437654 and parameters: {'w0': 0.2743532064286296, 'w1': 0.9578255999216782}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,545] Trial 62 finished with value: 0.0351105481027032 and parameters: {'w0': 0.3179626430999755, 'w1': 0.9686709895792492}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,559] Trial 63 finished with value: 0.03556028339424977 and parameters: {'w0': 0.33629583200796387, 'w1': 0.38806995849692827}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,574] Trial 64 finished with value: 0.03550678245009753 and parameters: {'w0': 0.4732814855111765, 'w1': 0.9997203315203859}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,589] Trial 65 finished with value: 0.03570380643841864 and parameters: {'w0': 0.3717947850656618, 'w1': 0.6572815145364604}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,604] Trial 66 finished with value: 0.03531236351091849 and parameters: {'w0': 0.3151700614026645, 'w1': 0.8304580127993912}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,618] Trial 67 finished with value: 0.03511477987859102 and parameters: {'w0': 0.27828462134551507, 'w1': 0.9205908688915263}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,633] Trial 68 finished with value: 0.03539250711775488 and parameters: {'w0': 0.15127683944586115, 'w1': 0.879007208574499}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,649] Trial 69 finished with value: 0.03531236351091849 and parameters: {'w0': 0.35647949664363104, 'w1': 0.9747314680066459}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,670] Trial 70 finished with value: 0.03518278430344435 and parameters: {'w0': 0.2177047933336726, 'w1': 0.7865660899916782}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,685] Trial 71 finished with value: 0.03518278430344435 and parameters: {'w0': 0.2564843541839977, 'w1': 0.9236971620450618}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,700] Trial 72 finished with value: 0.035115416723437654 and parameters: {'w0': 0.27352079060937673, 'w1': 0.9611586395549997}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,715] Trial 73 finished with value: 0.03512293174076908 and parameters: {'w0': 0.1968768154561416, 'w1': 0.8860176351130361}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,729] Trial 74 finished with value: 0.03524759151254531 and parameters: {'w0': 0.3135514718330058, 'w1': 0.91597624696616}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,744] Trial 75 finished with value: 0.03570380643841864 and parameters: {'w0': 0.4195936324774444, 'w1': 0.7443894900932608}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,759] Trial 76 finished with value: 0.03511477987859102 and parameters: {'w0': 0.2650186850987287, 'w1': 0.8344541455262353}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,773] Trial 77 finished with value: 0.03524759151254531 and parameters: {'w0': 0.2984129223149699, 'w1': 0.8503822230341309}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,787] Trial 78 finished with value: 0.035115416723437654 and parameters: {'w0': 0.23649801582356794, 'w1': 0.825274397593067}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,801] Trial 79 finished with value: 0.03563407866951396 and parameters: {'w0': 0.3370036069801531, 'w1': 0.5807239900450982}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,816] Trial 80 finished with value: 0.03518278430344435 and parameters: {'w0': 0.1372637656747145, 'w1': 0.532377284003833}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,831] Trial 81 finished with value: 0.035047691850885965 and parameters: {'w0': 0.2621666277129782, 'w1': 0.8953415873101647}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,848] Trial 82 finished with value: 0.035259895400591046 and parameters: {'w0': 0.18753254275951076, 'w1': 0.9466390642936602}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,862] Trial 83 finished with value: 0.035115416723437654 and parameters: {'w0': 0.24906335892065773, 'w1': 0.8736085730557243}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,880] Trial 84 finished with value: 0.03512293174076908 and parameters: {'w0': 0.21625921625081243, 'w1': 0.9698684123348478}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,894] Trial 85 finished with value: 0.03531236351091849 and parameters: {'w0': 0.3665779553785062, 'w1': 0.9041287496611417}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,908] Trial 86 finished with value: 0.03519219294381948 and parameters: {'w0': 0.05134185392452542, 'w1': 0.6375975566138078}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,922] Trial 87 finished with value: 0.035327238215272616 and parameters: {'w0': 0.171843967763053, 'w1': 0.9321570985220908}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,937] Trial 88 finished with value: 0.03531236351091849 and parameters: {'w0': 0.3279701421135507, 'w1': 0.771566957659521}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,951] Trial 89 finished with value: 0.0352593867672637 and parameters: {'w0': 0.10808154144793941, 'w1': 0.8126538059424023}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,966] Trial 90 finished with value: 0.03511477987859102 and parameters: {'w0': 0.27543427807480403, 'w1': 0.8926560293992668}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,980] Trial 91 finished with value: 0.03524759151254531 and parameters: {'w0': 0.2974954828519951, 'w1': 0.8521192015792163}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:10,995] Trial 92 finished with value: 0.03511477987859102 and parameters: {'w0': 0.271074784719138, 'w1': 0.8987801620823186}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:11,010] Trial 93 finished with value: 0.035047691850885965 and parameters: {'w0': 0.28529408546252505, 'w1': 0.9759952529530243}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:11,024] Trial 94 finished with value: 0.035188486466363855 and parameters: {'w0': 0.22935372498599318, 'w1': 0.9727417875208019}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:11,039] Trial 95 finished with value: 0.03511477987859102 and parameters: {'w0': 0.2817208435058499, 'w1': 0.9364531876985628}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:11,053] Trial 96 finished with value: 0.03531236351091849 and parameters: {'w0': 0.32272624881882483, 'w1': 0.8733565855661559}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:11,068] Trial 97 finished with value: 0.03531236351091849 and parameters: {'w0': 0.3847805581137393, 'w1': 0.9973100577204758}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:11,083] Trial 98 finished with value: 0.03531236351091849 and parameters: {'w0': 0.3511451961278218, 'w1': 0.9585132149059605}. Best is trial 23 with value: 0.035047691850885965.\n",
            "[I 2025-06-16 10:42:11,097] Trial 99 finished with value: 0.03518278430344435 and parameters: {'w0': 0.24294247249175804, 'w1': 0.897462460431834}. Best is trial 23 with value: 0.035047691850885965.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 4): 0.9650\n",
            "\n",
            "--- Training combination ('lgbm', 'mlp', 'logreg') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003250 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.336006\n",
            "[LightGBM] [Info] Start training from score -3.552799\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889700\n",
            "[LightGBM] [Info] Start training from score -3.745491\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.560449\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013656\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912304\n",
            "[LightGBM] [Info] Start training from score -2.909219\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521069\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.456743\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 4): 0.9643\n",
            "F1-weighted mlp (fold 4): 0.9652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:42:36,188] A new study created in memory with name: no-name-9df59cbb-f92e-4eee-b137-a5a9be487b91\n",
            "[I 2025-06-16 10:42:36,198] Trial 0 finished with value: 0.034715768314614426 and parameters: {'w0': 0.847202510845664, 'w1': 0.3599399180519408, 'w2': 0.8172887398801144}. Best is trial 0 with value: 0.034715768314614426.\n",
            "[I 2025-06-16 10:42:36,206] Trial 1 finished with value: 0.0345101980114253 and parameters: {'w0': 0.27207704028390756, 'w1': 0.04869562230130531, 'w2': 0.209730475075098}. Best is trial 1 with value: 0.0345101980114253.\n",
            "[I 2025-06-16 10:42:36,215] Trial 2 finished with value: 0.03497882617104753 and parameters: {'w0': 0.35567152263665003, 'w1': 0.4108247539305828, 'w2': 0.030150496310958563}. Best is trial 1 with value: 0.0345101980114253.\n",
            "[I 2025-06-16 10:42:36,223] Trial 3 finished with value: 0.034156600247915 and parameters: {'w0': 0.7961824176980348, 'w1': 0.10299277730785594, 'w2': 0.1895009569044842}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,232] Trial 4 finished with value: 0.034850532289897096 and parameters: {'w0': 0.5320786454766787, 'w1': 0.22305995186116778, 'w2': 0.353660536254219}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,240] Trial 5 finished with value: 0.03484497956560195 and parameters: {'w0': 0.7619374861658124, 'w1': 0.46023143130816424, 'w2': 0.2655749450467161}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,249] Trial 6 finished with value: 0.03491721563063688 and parameters: {'w0': 0.34101844342802046, 'w1': 0.5182729515949801, 'w2': 0.1914272218311922}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,258] Trial 7 finished with value: 0.034771185187108866 and parameters: {'w0': 0.5914391278334113, 'w1': 0.4310608944164209, 'w2': 0.1080881187080418}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,288] Trial 8 finished with value: 0.03498261263738678 and parameters: {'w0': 0.6347432235546567, 'w1': 0.9888153572879209, 'w2': 0.46089250914426494}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,296] Trial 9 finished with value: 0.03470268607847382 and parameters: {'w0': 0.513046791922987, 'w1': 0.23241945424793675, 'w2': 0.5935460383939499}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,314] Trial 10 finished with value: 0.03505357537714926 and parameters: {'w0': 0.01059600752384715, 'w1': 0.7050654051276251, 'w2': 0.6463381508214091}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,332] Trial 11 finished with value: 0.03423197063636407 and parameters: {'w0': 0.9774199508289045, 'w1': 0.04109498821828554, 'w2': 0.3803308370534134}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,351] Trial 12 finished with value: 0.03422378204652565 and parameters: {'w0': 0.9937589549254636, 'w1': 0.010070129673666675, 'w2': 0.3868454170680763}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,368] Trial 13 finished with value: 0.03457667393847519 and parameters: {'w0': 0.9920966873673096, 'w1': 0.17548779582547774, 'w2': 0.5476737129342882}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,384] Trial 14 finished with value: 0.03498748603384849 and parameters: {'w0': 0.7983036796828241, 'w1': 0.023819400272671126, 'w2': 0.9534272443417217}. Best is trial 3 with value: 0.034156600247915.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 4): 0.9649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:42:36,402] Trial 15 finished with value: 0.03498108085820373 and parameters: {'w0': 0.8720860657235756, 'w1': 0.6549055767237255, 'w2': 0.33425911739033143}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,419] Trial 16 finished with value: 0.034712244635651035 and parameters: {'w0': 0.762629925235251, 'w1': 0.15721393030888042, 'w2': 0.7224236533298803}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,437] Trial 17 finished with value: 0.03443577088247962 and parameters: {'w0': 0.6735681168314296, 'w1': 0.3247746720186752, 'w2': 0.009455527656157092}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,455] Trial 18 finished with value: 0.034640958772298225 and parameters: {'w0': 0.9159410915300369, 'w1': 0.10595596835567601, 'w2': 0.45212883172443075}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,472] Trial 19 finished with value: 0.03457383688341642 and parameters: {'w0': 0.7136062176845541, 'w1': 0.27002926441065866, 'w2': 0.15273284441518475}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,489] Trial 20 finished with value: 0.03484465484197874 and parameters: {'w0': 0.9087806938919097, 'w1': 0.5832642808670478, 'w2': 0.30533935208687635}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,507] Trial 21 finished with value: 0.03422378204652565 and parameters: {'w0': 0.9907592216777984, 'w1': 0.004651495270182021, 'w2': 0.40740839023552994}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,525] Trial 22 finished with value: 0.03422773666211687 and parameters: {'w0': 0.967870038895767, 'w1': 0.014792333412445784, 'w2': 0.4104527852576897}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,542] Trial 23 finished with value: 0.03457810683546925 and parameters: {'w0': 0.8358513466444368, 'w1': 0.13178027993074998, 'w2': 0.5033248590367738}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,560] Trial 24 finished with value: 0.03490245253343338 and parameters: {'w0': 0.9992510527064058, 'w1': 0.8179511228362667, 'w2': 0.09040243745483717}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,577] Trial 25 finished with value: 0.034224915617191765 and parameters: {'w0': 0.9269348721020106, 'w1': 0.10031413089278689, 'w2': 0.26808097035454426}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,594] Trial 26 finished with value: 0.03464628019860416 and parameters: {'w0': 0.8537521463984854, 'w1': 0.29939794425599653, 'w2': 0.2287893111624254}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,612] Trial 27 finished with value: 0.034507330794459334 and parameters: {'w0': 0.7350716990789862, 'w1': 0.19511473395534562, 'w2': 0.6385142124690621}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,629] Trial 28 finished with value: 0.034733766797348076 and parameters: {'w0': 0.059062114097083396, 'w1': 0.001546780485443655, 'w2': 0.421628691277781}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,649] Trial 29 finished with value: 0.03444263269395598 and parameters: {'w0': 0.8302467320454163, 'w1': 0.08439895696700828, 'w2': 0.7569907433598522}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,666] Trial 30 finished with value: 0.035046337947381434 and parameters: {'w0': 0.42153734740395365, 'w1': 0.3535384748692379, 'w2': 0.5182584698021341}. Best is trial 3 with value: 0.034156600247915.\n",
            "[I 2025-06-16 10:42:36,685] Trial 31 finished with value: 0.03409782092883362 and parameters: {'w0': 0.9189752282150254, 'w1': 0.10903535387403526, 'w2': 0.2826963786647155}. Best is trial 31 with value: 0.03409782092883362.\n",
            "[I 2025-06-16 10:42:36,705] Trial 32 finished with value: 0.034167266604837376 and parameters: {'w0': 0.9118239129885812, 'w1': 0.12866066045118366, 'w2': 0.2935266575750948}. Best is trial 31 with value: 0.03409782092883362.\n",
            "[I 2025-06-16 10:42:36,725] Trial 33 finished with value: 0.0342255364620917 and parameters: {'w0': 0.8938292000491708, 'w1': 0.09074614234230814, 'w2': 0.15035340217905685}. Best is trial 31 with value: 0.03409782092883362.\n",
            "[I 2025-06-16 10:42:36,743] Trial 34 finished with value: 0.03497979003672835 and parameters: {'w0': 0.1750750867597105, 'w1': 0.24951035337174557, 'w2': 0.2926907440603041}. Best is trial 31 with value: 0.03409782092883362.\n",
            "[I 2025-06-16 10:42:36,761] Trial 35 finished with value: 0.034643401435544785 and parameters: {'w0': 0.8146872434052816, 'w1': 0.16764348925177766, 'w2': 0.35778588148701623}. Best is trial 31 with value: 0.03409782092883362.\n",
            "[I 2025-06-16 10:42:36,779] Trial 36 finished with value: 0.03450973468815577 and parameters: {'w0': 0.9436951999385125, 'w1': 0.3831284776693096, 'w2': 0.22091583014381977}. Best is trial 31 with value: 0.03409782092883362.\n",
            "[I 2025-06-16 10:42:36,796] Trial 37 finished with value: 0.034222337939502134 and parameters: {'w0': 0.5938569251581393, 'w1': 0.06732942463684508, 'w2': 0.08016744801447684}. Best is trial 31 with value: 0.03409782092883362.\n",
            "[I 2025-06-16 10:42:36,816] Trial 38 finished with value: 0.03450626206568741 and parameters: {'w0': 0.5842126412242667, 'w1': 0.22110684182138168, 'w2': 0.0932335606287018}. Best is trial 31 with value: 0.03409782092883362.\n",
            "[I 2025-06-16 10:42:36,836] Trial 39 finished with value: 0.0340264973460318 and parameters: {'w0': 0.46456348532806907, 'w1': 0.07922632281688627, 'w2': 0.05281419335115738}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:36,856] Trial 40 finished with value: 0.03497882617104753 and parameters: {'w0': 0.40954824782138666, 'w1': 0.49963215271299766, 'w2': 0.05007594774429642}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:36,874] Trial 41 finished with value: 0.034222665724342405 and parameters: {'w0': 0.5828398050158816, 'w1': 0.06584224046881382, 'w2': 0.16345193309967318}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:36,893] Trial 42 finished with value: 0.03457170475976501 and parameters: {'w0': 0.4510755434258799, 'w1': 0.14975036670321323, 'w2': 0.05375848020769767}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:36,915] Trial 43 finished with value: 0.03457287304569845 and parameters: {'w0': 0.31607799872801934, 'w1': 0.06769413150379813, 'w2': 0.12015223008087339}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:36,933] Trial 44 finished with value: 0.034645028173073245 and parameters: {'w0': 0.4872539435198066, 'w1': 0.19943067194536396, 'w2': 0.19949451148515615}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:36,952] Trial 45 finished with value: 0.03436267220726408 and parameters: {'w0': 0.6638822675484796, 'w1': 0.12624358253869206, 'w2': 0.004171570053096416}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:36,971] Trial 46 finished with value: 0.0342972473357791 and parameters: {'w0': 0.7890172339969843, 'w1': 0.05338602329119117, 'w2': 0.2476281718358263}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:36,990] Trial 47 finished with value: 0.034912024371267614 and parameters: {'w0': 0.5447791578124331, 'w1': 0.8998169339692784, 'w2': 0.07085614783904287}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,009] Trial 48 finished with value: 0.03457637532657487 and parameters: {'w0': 0.6984459227066703, 'w1': 0.2790051370107076, 'w2': 0.1808408273230697}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,028] Trial 49 finished with value: 0.03477039171812102 and parameters: {'w0': 0.28004310701367335, 'w1': 0.12596005358416507, 'w2': 0.32925353762665216}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,047] Trial 50 finished with value: 0.03464181418983403 and parameters: {'w0': 0.6346138745920229, 'w1': 0.23688368103718838, 'w2': 0.11990938339733745}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,068] Trial 51 finished with value: 0.034097848702337896 and parameters: {'w0': 0.5604840836924143, 'w1': 0.06580106146643006, 'w2': 0.1704271671037282}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,087] Trial 52 finished with value: 0.034100177288927336 and parameters: {'w0': 0.4802110926594516, 'w1': 0.06843805495923308, 'w2': 0.1401195602876263}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,106] Trial 53 finished with value: 0.034716034040773724 and parameters: {'w0': 0.39717689670110146, 'w1': 0.17717749754836457, 'w2': 0.25841586839384023}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,124] Trial 54 finished with value: 0.03429136033235303 and parameters: {'w0': 0.4881831846900638, 'w1': 0.040668067720028574, 'w2': 0.12894164644917927}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,143] Trial 55 finished with value: 0.03477930293892373 and parameters: {'w0': 0.35651526269053546, 'w1': 0.12379116158430846, 'w2': 0.2055046220711454}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,162] Trial 56 finished with value: 0.03457184524390722 and parameters: {'w0': 0.5335969259002712, 'w1': 0.20771897816917087, 'w2': 0.03511321443648624}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,185] Trial 57 finished with value: 0.03429379562168089 and parameters: {'w0': 0.8772695723615634, 'w1': 0.03911739461936825, 'w2': 0.2849079237909908}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,205] Trial 58 finished with value: 0.03512346816059131 and parameters: {'w0': 0.21140989917884656, 'w1': 0.16386948358092848, 'w2': 0.9153943436152632}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,225] Trial 59 finished with value: 0.034508961175797714 and parameters: {'w0': 0.4571126560005713, 'w1': 0.0965288850784557, 'w2': 0.17671099862190354}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,246] Trial 60 finished with value: 0.034778864096416395 and parameters: {'w0': 0.7382172124761899, 'w1': 0.3185305745128481, 'w2': 0.22411750707114075}. Best is trial 39 with value: 0.0340264973460318.\n",
            "[I 2025-06-16 10:42:37,265] Trial 61 finished with value: 0.03395432787521235 and parameters: {'w0': 0.6079692180558549, 'w1': 0.06387325279192568, 'w2': 0.07938214112008483}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,284] Trial 62 finished with value: 0.0342847135522808 and parameters: {'w0': 0.9482093787071396, 'w1': 0.04724431536478034, 'w2': 0.14003140001009762}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,302] Trial 63 finished with value: 0.03547189066396883 and parameters: {'w0': 0.5608656861158273, 'w1': 0.0016674573095233278, 'w2': 0.02284481228302362}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,321] Trial 64 finished with value: 0.03450615570231852 and parameters: {'w0': 0.5121735177668606, 'w1': 0.11113237293816289, 'w2': 0.08917041618525356}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,339] Trial 65 finished with value: 0.03470973663569721 and parameters: {'w0': 0.6334760982067601, 'w1': 0.08625461068999563, 'w2': 0.311287680548562}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,359] Trial 66 finished with value: 0.03471295605864111 and parameters: {'w0': 0.7792509573560503, 'w1': 0.1480809814801337, 'w2': 0.3640547060768551}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,378] Trial 67 finished with value: 0.034781927801547874 and parameters: {'w0': 0.4508942693902042, 'w1': 0.7094949658979405, 'w2': 0.1625545363067329}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,397] Trial 68 finished with value: 0.03471201684719705 and parameters: {'w0': 0.666025261492246, 'w1': 0.18556326662427572, 'w2': 0.2453623638379296}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,417] Trial 69 finished with value: 0.03409782092883362 and parameters: {'w0': 0.37068321959711725, 'w1': 0.04415278068998178, 'w2': 0.11139235394827124}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,436] Trial 70 finished with value: 0.03415335997597979 and parameters: {'w0': 0.31741412721020207, 'w1': 0.03695474290401028, 'w2': 0.06587462686812022}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,455] Trial 71 finished with value: 0.03422814572194499 and parameters: {'w0': 0.31725042866852066, 'w1': 0.05065975063713471, 'w2': 0.052939267143357366}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,474] Trial 72 finished with value: 0.03436281749474768 and parameters: {'w0': 0.3743794406017685, 'w1': 0.03013177832212669, 'w2': 0.12268807903811463}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,493] Trial 73 finished with value: 0.03477905335764775 and parameters: {'w0': 0.21295939212397677, 'w1': 0.07798859108040926, 'w2': 0.10057249443018737}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,512] Trial 74 finished with value: 0.03421956131594539 and parameters: {'w0': 0.43382776138400964, 'w1': 0.024229354103117204, 'w2': 0.06844021624230023}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,530] Trial 75 finished with value: 0.03423237945551516 and parameters: {'w0': 0.37563608038362334, 'w1': 0.10001127635454683, 'w2': 0.032318333762558445}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,551] Trial 76 finished with value: 0.034710189405912306 and parameters: {'w0': 0.478946395643148, 'w1': 0.1521680130308251, 'w2': 0.1469555918853489}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,570] Trial 77 finished with value: 0.03511681268682998 and parameters: {'w0': 0.324064279561657, 'w1': 0.4438280815493407, 'w2': 0.19153820396785043}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,590] Trial 78 finished with value: 0.03491677241574764 and parameters: {'w0': 0.2664614626806363, 'w1': 0.0852255419174686, 'w2': 0.10831287260455157}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,609] Trial 79 finished with value: 0.03494364181108467 and parameters: {'w0': 0.614223760479244, 'w1': 0.001537432137224487, 'w2': 0.062279224218233925}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,628] Trial 80 finished with value: 0.03484325354575779 and parameters: {'w0': 0.5121822299764477, 'w1': 0.5923252666935972, 'w2': 0.011488882316032178}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,648] Trial 81 finished with value: 0.03416441985091501 and parameters: {'w0': 0.8542062729699256, 'w1': 0.1350217230022404, 'w2': 0.17883858279222078}. Best is trial 61 with value: 0.03395432787521235.\n",
            "[I 2025-06-16 10:42:37,667] Trial 82 finished with value: 0.033949344140954074 and parameters: {'w0': 0.8524561083020517, 'w1': 0.05473440119858149, 'w2': 0.17778337875456704}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,691] Trial 83 finished with value: 0.034225594912612345 and parameters: {'w0': 0.5665586864086165, 'w1': 0.06256667916631826, 'w2': 0.14230437875422822}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,710] Trial 84 finished with value: 0.034418012776144646 and parameters: {'w0': 0.8107493601303343, 'w1': 0.020153234767956968, 'w2': 0.2082363551506416}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,729] Trial 85 finished with value: 0.03464195489590782 and parameters: {'w0': 0.27857568602065347, 'w1': 0.06316852419019192, 'w2': 0.09414432878738803}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,754] Trial 86 finished with value: 0.03437778972480976 and parameters: {'w0': 0.4131144602054053, 'w1': 0.1004358730283335, 'w2': 0.23768861849450995}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,775] Trial 87 finished with value: 0.03454764887524797 and parameters: {'w0': 0.8814981634048963, 'w1': 0.034582862163573036, 'w2': 0.04250703483646996}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,795] Trial 88 finished with value: 0.0348479764721088 and parameters: {'w0': 0.3526874841614801, 'w1': 0.1155660695862691, 'w2': 0.1614807328376854}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,816] Trial 89 finished with value: 0.03448850881236154 and parameters: {'w0': 0.6948223699753767, 'w1': 0.02458083652239501, 'w2': 0.11392318989682737}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,835] Trial 90 finished with value: 0.03430932371345663 and parameters: {'w0': 0.3877673680601451, 'w1': 0.07629518240665864, 'w2': 0.27239743769584307}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,858] Trial 91 finished with value: 0.034155598526039777 and parameters: {'w0': 0.8367572025259152, 'w1': 0.13875002908291145, 'w2': 0.0795993954003841}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,877] Trial 92 finished with value: 0.034159994954685025 and parameters: {'w0': 0.7671341357063236, 'w1': 0.1385920082945969, 'w2': 0.0002213135021315038}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,901] Trial 93 finished with value: 0.034302181433659706 and parameters: {'w0': 0.8457844353536476, 'w1': 0.17204726730825157, 'w2': 0.08463455751173016}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,920] Trial 94 finished with value: 0.03448505599618534 and parameters: {'w0': 0.9452653696431207, 'w1': 0.055256559855146006, 'w2': 0.07707659177372414}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,939] Trial 95 finished with value: 0.03401919555438371 and parameters: {'w0': 0.8176551139328263, 'w1': 0.10842018657183779, 'w2': 0.14339827746595551}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,959] Trial 96 finished with value: 0.03422406045464266 and parameters: {'w0': 0.9286146573130236, 'w1': 0.11028079843503892, 'w2': 0.13133370374919354}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,979] Trial 97 finished with value: 0.034280982125665216 and parameters: {'w0': 0.8987381141799915, 'w1': 0.0806134186996658, 'w2': 0.0362195710369648}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:37,997] Trial 98 finished with value: 0.03477567131462833 and parameters: {'w0': 0.7326866288103752, 'w1': 0.20785116675821252, 'w2': 0.1721030729056905}. Best is trial 82 with value: 0.033949344140954074.\n",
            "[I 2025-06-16 10:42:38,018] Trial 99 finished with value: 0.03448503692709726 and parameters: {'w0': 0.96810710874711, 'w1': 0.03504518763539632, 'w2': 0.10316363108274113}. Best is trial 82 with value: 0.033949344140954074.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 4): 0.9661\n",
            "\n",
            "=== Fold 5/5 ===\n",
            "\n",
            "--- Training combination ('lgbm',) ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003164 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335535\n",
            "[LightGBM] [Info] Start training from score -3.552799\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889398\n",
            "[LightGBM] [Info] Start training from score -3.745491\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.560449\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013314\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912613\n",
            "[LightGBM] [Info] Start training from score -2.909527\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521069\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.457276\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:42:46,669] A new study created in memory with name: no-name-77860872-84aa-4b8a-b502-49697e7856fb\n",
            "[I 2025-06-16 10:42:46,675] Trial 0 finished with value: 0.03792499608218347 and parameters: {'w0': 0.27007075967410077}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,681] Trial 1 finished with value: 0.03792499608218347 and parameters: {'w0': 0.27978108904430343}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,686] Trial 2 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5406103608228758}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,692] Trial 3 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5896456474285604}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,697] Trial 4 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4432200077345757}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,702] Trial 5 finished with value: 0.03792499608218347 and parameters: {'w0': 0.9654821596916445}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,707] Trial 6 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4041704232869825}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,712] Trial 7 finished with value: 0.03792499608218347 and parameters: {'w0': 0.16142442560838255}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,718] Trial 8 finished with value: 0.03792499608218347 and parameters: {'w0': 0.41030379079814405}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,725] Trial 9 finished with value: 0.03792499608218347 and parameters: {'w0': 0.6408403868795572}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,739] Trial 10 finished with value: 0.03792499608218347 and parameters: {'w0': 0.06064763296757192}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,751] Trial 11 finished with value: 0.03792499608218347 and parameters: {'w0': 0.25139250995694423}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,760] Trial 12 finished with value: 0.03792499608218347 and parameters: {'w0': 0.24405367005505724}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,769] Trial 13 finished with value: 0.03792499608218347 and parameters: {'w0': 0.015129861276906298}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,777] Trial 14 finished with value: 0.03792499608218347 and parameters: {'w0': 0.7458189784700069}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,786] Trial 15 finished with value: 0.03792499608218347 and parameters: {'w0': 0.30042673502924505}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,795] Trial 16 finished with value: 0.03792499608218347 and parameters: {'w0': 0.1354983587076637}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,804] Trial 17 finished with value: 0.03792499608218347 and parameters: {'w0': 0.3317992255799494}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,812] Trial 18 finished with value: 0.03792499608218347 and parameters: {'w0': 0.15727850355793427}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,820] Trial 19 finished with value: 0.03792499608218347 and parameters: {'w0': 0.7157023360308208}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,829] Trial 20 finished with value: 0.03792499608218347 and parameters: {'w0': 0.9852835462224602}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,838] Trial 21 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5375618061201841}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,847] Trial 22 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4772094060995979}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,856] Trial 23 finished with value: 0.03792499608218347 and parameters: {'w0': 0.3460070435983093}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,865] Trial 24 finished with value: 0.03792499608218347 and parameters: {'w0': 0.8424893820813515}. Best is trial 0 with value: 0.03792499608218347.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 5): 0.9621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:42:46,877] Trial 25 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5450466634878778}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,887] Trial 26 finished with value: 0.03792499608218347 and parameters: {'w0': 0.21668810246668743}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,896] Trial 27 finished with value: 0.03792499608218347 and parameters: {'w0': 0.3657062289134764}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,905] Trial 28 finished with value: 0.03792499608218347 and parameters: {'w0': 0.6622719435864717}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,914] Trial 29 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5870548150795311}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,924] Trial 30 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4952241432847244}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,933] Trial 31 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4460739376876449}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,942] Trial 32 finished with value: 0.03792499608218347 and parameters: {'w0': 0.7719509097186088}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,952] Trial 33 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5879479272290503}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,961] Trial 34 finished with value: 0.03792499608218347 and parameters: {'w0': 0.8697262721754285}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,971] Trial 35 finished with value: 0.03792499608218347 and parameters: {'w0': 0.43777533038269006}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,981] Trial 36 finished with value: 0.03792499608218347 and parameters: {'w0': 0.6444982070892457}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:46,990] Trial 37 finished with value: 0.03792499608218347 and parameters: {'w0': 0.3928526935988932}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,000] Trial 38 finished with value: 0.03792499608218347 and parameters: {'w0': 0.0923437411263297}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,009] Trial 39 finished with value: 0.03792499608218347 and parameters: {'w0': 0.30205880299082244}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,019] Trial 40 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5586201838685302}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,028] Trial 41 finished with value: 0.03792499608218347 and parameters: {'w0': 0.22583701086376684}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,039] Trial 42 finished with value: 0.03792499608218347 and parameters: {'w0': 0.40955066939719575}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,049] Trial 43 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4782142445685666}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,059] Trial 44 finished with value: 0.03792499608218347 and parameters: {'w0': 0.26691548118185343}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,069] Trial 45 finished with value: 0.03792499608218347 and parameters: {'w0': 0.18553842571813184}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,078] Trial 46 finished with value: 0.03792499608218347 and parameters: {'w0': 0.6994444435965624}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,090] Trial 47 finished with value: 0.03792499608218347 and parameters: {'w0': 0.28716519372412647}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,099] Trial 48 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5804555727955732}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,109] Trial 49 finished with value: 0.03792499608218347 and parameters: {'w0': 0.6213894628744878}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,124] Trial 50 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5233441181055027}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,134] Trial 51 finished with value: 0.03792499608218347 and parameters: {'w0': 0.8204215483276716}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,145] Trial 52 finished with value: 0.03792499608218347 and parameters: {'w0': 0.9712449280251195}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,155] Trial 53 finished with value: 0.03792499608218347 and parameters: {'w0': 0.9079277398509707}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,164] Trial 54 finished with value: 0.03792499608218347 and parameters: {'w0': 0.12282328309011076}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,174] Trial 55 finished with value: 0.03792499608218347 and parameters: {'w0': 0.03836732811080962}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,183] Trial 56 finished with value: 0.03792499608218347 and parameters: {'w0': 0.3689069140684487}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,193] Trial 57 finished with value: 0.03792499608218347 and parameters: {'w0': 0.3160899054478558}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,202] Trial 58 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4449470960608447}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,212] Trial 59 finished with value: 0.03792499608218347 and parameters: {'w0': 0.18287917757270644}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,222] Trial 60 finished with value: 0.03792499608218347 and parameters: {'w0': 0.3450421408488823}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,232] Trial 61 finished with value: 0.03792499608218347 and parameters: {'w0': 0.3856173549137104}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,242] Trial 62 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5122222880387715}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,252] Trial 63 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4356223899338304}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,262] Trial 64 finished with value: 0.03792499608218347 and parameters: {'w0': 0.47257876005564997}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,273] Trial 65 finished with value: 0.03792499608218347 and parameters: {'w0': 0.25112931417622103}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,283] Trial 66 finished with value: 0.03792499608218347 and parameters: {'w0': 0.6943677766192499}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,293] Trial 67 finished with value: 0.03792499608218347 and parameters: {'w0': 0.32737295160823787}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,303] Trial 68 finished with value: 0.03792499608218347 and parameters: {'w0': 0.2746778950409732}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,313] Trial 69 finished with value: 0.03792499608218347 and parameters: {'w0': 0.7475376573022403}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,322] Trial 70 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4069179280480623}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,332] Trial 71 finished with value: 0.03792499608218347 and parameters: {'w0': 0.18397497639084393}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,342] Trial 72 finished with value: 0.03792499608218347 and parameters: {'w0': 0.10216999530663157}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,351] Trial 73 finished with value: 0.03792499608218347 and parameters: {'w0': 0.00492718426484795}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,362] Trial 74 finished with value: 0.03792499608218347 and parameters: {'w0': 0.22408462018484193}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,372] Trial 75 finished with value: 0.03792499608218347 and parameters: {'w0': 0.15806930983829998}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,382] Trial 76 finished with value: 0.03792499608218347 and parameters: {'w0': 0.06157320309330805}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,392] Trial 77 finished with value: 0.03792499608218347 and parameters: {'w0': 0.611387227585368}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,401] Trial 78 finished with value: 0.03792499608218347 and parameters: {'w0': 0.35720733754505163}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,411] Trial 79 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5486418059745413}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,420] Trial 80 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4738734192522387}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,431] Trial 81 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4936199485944216}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,441] Trial 82 finished with value: 0.03792499608218347 and parameters: {'w0': 0.41193372542942813}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,451] Trial 83 finished with value: 0.03792499608218347 and parameters: {'w0': 0.3054475673166581}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,461] Trial 84 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5694632987272696}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,471] Trial 85 finished with value: 0.03792499608218347 and parameters: {'w0': 0.9577180382549783}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,481] Trial 86 finished with value: 0.03792499608218347 and parameters: {'w0': 0.20088894098859583}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,493] Trial 87 finished with value: 0.03792499608218347 and parameters: {'w0': 0.2469062301033182}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,506] Trial 88 finished with value: 0.03792499608218347 and parameters: {'w0': 0.789759239772736}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,516] Trial 89 finished with value: 0.03792499608218347 and parameters: {'w0': 0.1508237924337545}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,527] Trial 90 finished with value: 0.03792499608218347 and parameters: {'w0': 0.3778477914458742}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,537] Trial 91 finished with value: 0.03792499608218347 and parameters: {'w0': 0.6422937824517413}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,547] Trial 92 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5261559660733485}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,556] Trial 93 finished with value: 0.03792499608218347 and parameters: {'w0': 0.448790607135523}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,566] Trial 94 finished with value: 0.03792499608218347 and parameters: {'w0': 0.5885301445237492}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,575] Trial 95 finished with value: 0.03792499608218347 and parameters: {'w0': 0.6814403663747981}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,590] Trial 96 finished with value: 0.03792499608218347 and parameters: {'w0': 0.6129511426355589}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,604] Trial 97 finished with value: 0.03792499608218347 and parameters: {'w0': 0.9099339514158935}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,615] Trial 98 finished with value: 0.03792499608218347 and parameters: {'w0': 0.4204031470000427}. Best is trial 0 with value: 0.03792499608218347.\n",
            "[I 2025-06-16 10:42:47,625] Trial 99 finished with value: 0.03792499608218347 and parameters: {'w0': 0.33860482963068494}. Best is trial 0 with value: 0.03792499608218347.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 5): 0.9621\n",
            "\n",
            "--- Training combination ('mlp',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:43:04,897] A new study created in memory with name: no-name-a0d2d92e-fcd8-43a4-83f8-215ff2707df5\n",
            "[I 2025-06-16 10:43:04,906] Trial 0 finished with value: 0.037212284425126585 and parameters: {'w0': 0.17338939046589208}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,911] Trial 1 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8732134799445644}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,916] Trial 2 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9811201593560863}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,921] Trial 3 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9080760439390299}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,926] Trial 4 finished with value: 0.037212284425126585 and parameters: {'w0': 0.06893682343981422}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,931] Trial 5 finished with value: 0.037212284425126585 and parameters: {'w0': 0.6462114797895515}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,936] Trial 6 finished with value: 0.037212284425126585 and parameters: {'w0': 0.5559424930308466}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,940] Trial 7 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7942862134669479}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,945] Trial 8 finished with value: 0.037212284425126585 and parameters: {'w0': 0.6995320861035865}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,950] Trial 9 finished with value: 0.037212284425126585 and parameters: {'w0': 0.17173943328545382}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,959] Trial 10 finished with value: 0.037212284425126585 and parameters: {'w0': 0.3042904142050424}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,971] Trial 11 finished with value: 0.037212284425126585 and parameters: {'w0': 0.3669074114627802}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,983] Trial 12 finished with value: 0.037212284425126585 and parameters: {'w0': 0.40973652154717344}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:04,991] Trial 13 finished with value: 0.037212284425126585 and parameters: {'w0': 0.012180935849619434}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,000] Trial 14 finished with value: 0.037212284425126585 and parameters: {'w0': 0.1883164071468051}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,008] Trial 15 finished with value: 0.037212284425126585 and parameters: {'w0': 0.5016221622459701}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,018] Trial 16 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8046637227320619}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,030] Trial 17 finished with value: 0.037212284425126585 and parameters: {'w0': 0.29985835577600584}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,041] Trial 18 finished with value: 0.037212284425126585 and parameters: {'w0': 0.5729936917421556}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,049] Trial 19 finished with value: 0.037212284425126585 and parameters: {'w0': 0.17768925544598255}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,058] Trial 20 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7838358634016651}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,067] Trial 21 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9651126836762425}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,075] Trial 22 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9991309069436474}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,084] Trial 23 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8693210005916587}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,093] Trial 24 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7068663291135934}. Best is trial 0 with value: 0.037212284425126585.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted mlp (fold 5): 0.9633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:43:05,103] Trial 25 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9063002124765047}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,112] Trial 26 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8632276043029057}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,121] Trial 27 finished with value: 0.037212284425126585 and parameters: {'w0': 0.46123652702379375}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,130] Trial 28 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9516811343518163}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,140] Trial 29 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7307095072407241}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,149] Trial 30 finished with value: 0.037212284425126585 and parameters: {'w0': 0.6215751413546677}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,158] Trial 31 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9190450107444218}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,168] Trial 32 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8415665328522915}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,178] Trial 33 finished with value: 0.037212284425126585 and parameters: {'w0': 0.07925748220545156}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,187] Trial 34 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9897431340005671}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,196] Trial 35 finished with value: 0.037212284425126585 and parameters: {'w0': 0.760301403404649}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,206] Trial 36 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9037826481794254}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,220] Trial 37 finished with value: 0.037212284425126585 and parameters: {'w0': 0.6788895910904329}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,231] Trial 38 finished with value: 0.037212284425126585 and parameters: {'w0': 0.6280341979017299}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,241] Trial 39 finished with value: 0.037212284425126585 and parameters: {'w0': 0.281476227644753}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,250] Trial 40 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8219127273312603}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,260] Trial 41 finished with value: 0.037212284425126585 and parameters: {'w0': 0.09697851217872398}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,271] Trial 42 finished with value: 0.037212284425126585 and parameters: {'w0': 0.0039050091450615054}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,281] Trial 43 finished with value: 0.037212284425126585 and parameters: {'w0': 0.0916472695796694}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,291] Trial 44 finished with value: 0.037212284425126585 and parameters: {'w0': 0.255623647972664}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,301] Trial 45 finished with value: 0.037212284425126585 and parameters: {'w0': 0.38525537378251895}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,310] Trial 46 finished with value: 0.037212284425126585 and parameters: {'w0': 0.1292516004703953}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,322] Trial 47 finished with value: 0.037212284425126585 and parameters: {'w0': 0.34954195785307696}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,335] Trial 48 finished with value: 0.037212284425126585 and parameters: {'w0': 0.03441185492240381}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,344] Trial 49 finished with value: 0.037212284425126585 and parameters: {'w0': 0.22634099126462862}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,354] Trial 50 finished with value: 0.037212284425126585 and parameters: {'w0': 0.5107841951656369}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,364] Trial 51 finished with value: 0.037212284425126585 and parameters: {'w0': 0.4343133666159732}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,373] Trial 52 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9424541260857031}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,383] Trial 53 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7807619372646173}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,392] Trial 54 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8779930869628684}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,401] Trial 55 finished with value: 0.037212284425126585 and parameters: {'w0': 0.5675512386904228}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,412] Trial 56 finished with value: 0.037212284425126585 and parameters: {'w0': 0.15618693094409586}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,421] Trial 57 finished with value: 0.037212284425126585 and parameters: {'w0': 0.981960225212311}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,431] Trial 58 finished with value: 0.037212284425126585 and parameters: {'w0': 0.21938519792857553}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,441] Trial 59 finished with value: 0.037212284425126585 and parameters: {'w0': 0.6559505482892374}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,450] Trial 60 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9297369044699706}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,460] Trial 61 finished with value: 0.037212284425126585 and parameters: {'w0': 0.5336895179648262}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,469] Trial 62 finished with value: 0.037212284425126585 and parameters: {'w0': 0.5857753234780495}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,478] Trial 63 finished with value: 0.037212284425126585 and parameters: {'w0': 0.47482373508117764}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,487] Trial 64 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8387867889981205}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,497] Trial 65 finished with value: 0.037212284425126585 and parameters: {'w0': 0.05011997160541763}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,506] Trial 66 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9085945228266488}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,516] Trial 67 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7003584597688917}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,525] Trial 68 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7418323153445201}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,535] Trial 69 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9629499779476235}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,544] Trial 70 finished with value: 0.037212284425126585 and parameters: {'w0': 0.606070899394854}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,553] Trial 71 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8798174778332684}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,564] Trial 72 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7991303705516326}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,573] Trial 73 finished with value: 0.037212284425126585 and parameters: {'w0': 0.6607103012418026}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,582] Trial 74 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7246786702269041}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,592] Trial 75 finished with value: 0.037212284425126585 and parameters: {'w0': 0.5441063095294338}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,601] Trial 76 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8527957782260657}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,611] Trial 77 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8112722894568469}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,620] Trial 78 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7628008653971351}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,630] Trial 79 finished with value: 0.037212284425126585 and parameters: {'w0': 0.14557630379550884}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,640] Trial 80 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9960017702582108}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,650] Trial 81 finished with value: 0.037212284425126585 and parameters: {'w0': 0.6968399780886292}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,659] Trial 82 finished with value: 0.037212284425126585 and parameters: {'w0': 0.6236007580619637}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,668] Trial 83 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8935483057097684}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,678] Trial 84 finished with value: 0.037212284425126585 and parameters: {'w0': 0.8351995881514228}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,687] Trial 85 finished with value: 0.037212284425126585 and parameters: {'w0': 0.6624753515859506}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,697] Trial 86 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9310651120673136}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,707] Trial 87 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7637596140874069}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,716] Trial 88 finished with value: 0.037212284425126585 and parameters: {'w0': 0.34821212997172124}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,725] Trial 89 finished with value: 0.037212284425126585 and parameters: {'w0': 0.9625946964339314}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,734] Trial 90 finished with value: 0.037212284425126585 and parameters: {'w0': 0.06316980022960035}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,744] Trial 91 finished with value: 0.037212284425126585 and parameters: {'w0': 0.11006256590035524}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,754] Trial 92 finished with value: 0.037212284425126585 and parameters: {'w0': 0.18850346139377075}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,764] Trial 93 finished with value: 0.037212284425126585 and parameters: {'w0': 0.019791756271170635}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,773] Trial 94 finished with value: 0.037212284425126585 and parameters: {'w0': 0.30071783706301075}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,783] Trial 95 finished with value: 0.037212284425126585 and parameters: {'w0': 0.18011249385207911}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,793] Trial 96 finished with value: 0.037212284425126585 and parameters: {'w0': 0.21079272652235187}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,803] Trial 97 finished with value: 0.037212284425126585 and parameters: {'w0': 0.2633554715556842}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,812] Trial 98 finished with value: 0.037212284425126585 and parameters: {'w0': 0.4301424148616665}. Best is trial 0 with value: 0.037212284425126585.\n",
            "[I 2025-06-16 10:43:05,822] Trial 99 finished with value: 0.037212284425126585 and parameters: {'w0': 0.7941886243625175}. Best is trial 0 with value: 0.037212284425126585.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 5): 0.9628\n",
            "\n",
            "--- Training combination ('logreg',) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:43:07,114] A new study created in memory with name: no-name-3bfeab71-72bf-49a4-8d83-066e997cf0e2\n",
            "[I 2025-06-16 10:43:07,122] Trial 0 finished with value: 0.03739816297523457 and parameters: {'w0': 0.15703955731509334}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,129] Trial 1 finished with value: 0.03739816297523457 and parameters: {'w0': 0.4440905030282176}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,135] Trial 2 finished with value: 0.03739816297523457 and parameters: {'w0': 0.23102631567435983}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,142] Trial 3 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7050834006042427}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,148] Trial 4 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6568901556388664}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,155] Trial 5 finished with value: 0.03739816297523457 and parameters: {'w0': 0.9970508551629602}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,162] Trial 6 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7122225534717834}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,168] Trial 7 finished with value: 0.03739816297523457 and parameters: {'w0': 0.18813136068237613}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,175] Trial 8 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7269522251650338}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,182] Trial 9 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7468915553352659}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,195] Trial 10 finished with value: 0.03739816297523457 and parameters: {'w0': 0.006943780535358046}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,207] Trial 11 finished with value: 0.03739816297523457 and parameters: {'w0': 0.3914036958329695}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,219] Trial 12 finished with value: 0.03739816297523457 and parameters: {'w0': 0.4078221500243622}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,229] Trial 13 finished with value: 0.03739816297523457 and parameters: {'w0': 0.02002999825509133}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,238] Trial 14 finished with value: 0.03739816297523457 and parameters: {'w0': 0.21777131382060289}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,248] Trial 15 finished with value: 0.03739816297523457 and parameters: {'w0': 0.5046831265961501}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,257] Trial 16 finished with value: 0.03739816297523457 and parameters: {'w0': 0.5407449778315296}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,265] Trial 17 finished with value: 0.03739816297523457 and parameters: {'w0': 0.3443729512298235}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,274] Trial 18 finished with value: 0.03739816297523457 and parameters: {'w0': 0.11820956567083783}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,283] Trial 19 finished with value: 0.03739816297523457 and parameters: {'w0': 0.9013049514703628}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,293] Trial 20 finished with value: 0.03739816297523457 and parameters: {'w0': 0.3017424654336759}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,302] Trial 21 finished with value: 0.03739816297523457 and parameters: {'w0': 0.23442414954385538}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,311] Trial 22 finished with value: 0.03739816297523457 and parameters: {'w0': 0.14409799496962766}. Best is trial 0 with value: 0.03739816297523457.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 5): 0.9626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:43:07,321] Trial 23 finished with value: 0.03739816297523457 and parameters: {'w0': 0.2881423949819519}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,331] Trial 24 finished with value: 0.03739816297523457 and parameters: {'w0': 0.09056281231895472}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,340] Trial 25 finished with value: 0.03739816297523457 and parameters: {'w0': 0.4763428140627303}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,350] Trial 26 finished with value: 0.03739816297523457 and parameters: {'w0': 0.5857607622985285}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,360] Trial 27 finished with value: 0.03739816297523457 and parameters: {'w0': 0.4331306976220407}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,369] Trial 28 finished with value: 0.03739816297523457 and parameters: {'w0': 0.28133438327648586}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,380] Trial 29 finished with value: 0.03739816297523457 and parameters: {'w0': 0.08976348376904908}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,390] Trial 30 finished with value: 0.03739816297523457 and parameters: {'w0': 0.346982022310535}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,400] Trial 31 finished with value: 0.03739816297523457 and parameters: {'w0': 0.601026647892122}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,409] Trial 32 finished with value: 0.03739816297523457 and parameters: {'w0': 0.8146625024663765}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,419] Trial 33 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6529381780951645}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,429] Trial 34 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6418721922860137}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,439] Trial 35 finished with value: 0.03739816297523457 and parameters: {'w0': 0.9233119996445982}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,448] Trial 36 finished with value: 0.03739816297523457 and parameters: {'w0': 0.16473338284159658}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,458] Trial 37 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7825203073606215}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,468] Trial 38 finished with value: 0.03739816297523457 and parameters: {'w0': 0.23207676337855632}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,478] Trial 39 finished with value: 0.03739816297523457 and parameters: {'w0': 0.05477702831989392}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,487] Trial 40 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7196537238739569}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,497] Trial 41 finished with value: 0.03739816297523457 and parameters: {'w0': 0.8597826494666181}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,507] Trial 42 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6706010326812137}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,517] Trial 43 finished with value: 0.03739816297523457 and parameters: {'w0': 0.4510120189080148}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,526] Trial 44 finished with value: 0.03739816297523457 and parameters: {'w0': 0.5256619204213118}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,536] Trial 45 finished with value: 0.03739816297523457 and parameters: {'w0': 0.5689440148450926}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,546] Trial 46 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6913787842140884}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,555] Trial 47 finished with value: 0.03739816297523457 and parameters: {'w0': 0.3537056880251175}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,565] Trial 48 finished with value: 0.03739816297523457 and parameters: {'w0': 0.770396180020176}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,574] Trial 49 finished with value: 0.03739816297523457 and parameters: {'w0': 0.2008375195398011}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,584] Trial 50 finished with value: 0.03739816297523457 and parameters: {'w0': 0.9549317215733659}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,593] Trial 51 finished with value: 0.03739816297523457 and parameters: {'w0': 0.8429995348231639}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,603] Trial 52 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7380322256433406}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,613] Trial 53 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6300070014350005}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,623] Trial 54 finished with value: 0.03739816297523457 and parameters: {'w0': 0.26280506523332664}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,632] Trial 55 finished with value: 0.03739816297523457 and parameters: {'w0': 0.9943877092217885}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,642] Trial 56 finished with value: 0.03739816297523457 and parameters: {'w0': 0.3958899551295456}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,652] Trial 57 finished with value: 0.03739816297523457 and parameters: {'w0': 0.48717837412613874}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,661] Trial 58 finished with value: 0.03739816297523457 and parameters: {'w0': 0.17247822305018326}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,671] Trial 59 finished with value: 0.03739816297523457 and parameters: {'w0': 0.013203660876644818}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,680] Trial 60 finished with value: 0.03739816297523457 and parameters: {'w0': 0.127139714435003}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,690] Trial 61 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7048090645216695}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,699] Trial 62 finished with value: 0.03739816297523457 and parameters: {'w0': 0.5566553428314909}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,709] Trial 63 finished with value: 0.03739816297523457 and parameters: {'w0': 0.603423417793528}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,719] Trial 64 finished with value: 0.03739816297523457 and parameters: {'w0': 0.3126446668816254}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,729] Trial 65 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7808385585752659}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,738] Trial 66 finished with value: 0.03739816297523457 and parameters: {'w0': 0.9006111635829966}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,747] Trial 67 finished with value: 0.03739816297523457 and parameters: {'w0': 0.82840222706579}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,757] Trial 68 finished with value: 0.03739816297523457 and parameters: {'w0': 0.08394208887974101}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,765] Trial 69 finished with value: 0.03739816297523457 and parameters: {'w0': 0.426641660155219}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,775] Trial 70 finished with value: 0.03739816297523457 and parameters: {'w0': 0.5284892931207761}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,784] Trial 71 finished with value: 0.03739816297523457 and parameters: {'w0': 0.19514794856689116}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,794] Trial 72 finished with value: 0.03739816297523457 and parameters: {'w0': 0.14701691097652989}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,803] Trial 73 finished with value: 0.03739816297523457 and parameters: {'w0': 0.25822577793374146}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,813] Trial 74 finished with value: 0.03739816297523457 and parameters: {'w0': 0.3627120132612617}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,823] Trial 75 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6641425613487872}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,832] Trial 76 finished with value: 0.03739816297523457 and parameters: {'w0': 0.03975764475605516}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,842] Trial 77 finished with value: 0.03739816297523457 and parameters: {'w0': 0.3203295440539813}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,852] Trial 78 finished with value: 0.03739816297523457 and parameters: {'w0': 0.4610205001144271}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,862] Trial 79 finished with value: 0.03739816297523457 and parameters: {'w0': 0.8049264056899678}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,872] Trial 80 finished with value: 0.03739816297523457 and parameters: {'w0': 0.8658761480160284}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,881] Trial 81 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7410974830404257}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,891] Trial 82 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6215680777673138}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,900] Trial 83 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6869047127280962}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,911] Trial 84 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7210131325621656}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,920] Trial 85 finished with value: 0.03739816297523457 and parameters: {'w0': 0.21167642476213167}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,929] Trial 86 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7617991050677607}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,939] Trial 87 finished with value: 0.03739816297523457 and parameters: {'w0': 0.17680984448464046}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,948] Trial 88 finished with value: 0.03739816297523457 and parameters: {'w0': 0.11534637876010832}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,957] Trial 89 finished with value: 0.03739816297523457 and parameters: {'w0': 0.8020508226607894}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,970] Trial 90 finished with value: 0.03739816297523457 and parameters: {'w0': 0.24385617522945274}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,979] Trial 91 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7555254095582243}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,989] Trial 92 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6790453648017896}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:07,999] Trial 93 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6478774565705501}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:08,008] Trial 94 finished with value: 0.03739816297523457 and parameters: {'w0': 0.7225713911217657}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:08,018] Trial 95 finished with value: 0.03739816297523457 and parameters: {'w0': 0.5702965946838541}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:08,028] Trial 96 finished with value: 0.03739816297523457 and parameters: {'w0': 0.5088524511552341}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:08,039] Trial 97 finished with value: 0.03739816297523457 and parameters: {'w0': 0.6075716761887215}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:08,049] Trial 98 finished with value: 0.03739816297523457 and parameters: {'w0': 0.9600762820997196}. Best is trial 0 with value: 0.03739816297523457.\n",
            "[I 2025-06-16 10:43:08,059] Trial 99 finished with value: 0.03739816297523457 and parameters: {'w0': 0.8751571087538417}. Best is trial 0 with value: 0.03739816297523457.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 5): 0.9626\n",
            "\n",
            "--- Training combination ('lgbm', 'mlp') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003179 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335535\n",
            "[LightGBM] [Info] Start training from score -3.552799\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889398\n",
            "[LightGBM] [Info] Start training from score -3.745491\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.560449\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013314\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912613\n",
            "[LightGBM] [Info] Start training from score -2.909527\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521069\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.457276\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 5): 0.9621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:43:34,492] A new study created in memory with name: no-name-d1f0efa1-25d2-4b8c-9318-fa3f896e73da\n",
            "[I 2025-06-16 10:43:34,499] Trial 0 finished with value: 0.03581224196571786 and parameters: {'w0': 0.5134088560647675, 'w1': 0.26985474359352324}. Best is trial 0 with value: 0.03581224196571786.\n",
            "[I 2025-06-16 10:43:34,506] Trial 1 finished with value: 0.036455315110969666 and parameters: {'w0': 0.02225543326228907, 'w1': 0.11014595607792621}. Best is trial 0 with value: 0.03581224196571786.\n",
            "[I 2025-06-16 10:43:34,511] Trial 2 finished with value: 0.03588804972656334 and parameters: {'w0': 0.8827847587278852, 'w1': 0.5738540584055896}. Best is trial 0 with value: 0.03581224196571786.\n",
            "[I 2025-06-16 10:43:34,517] Trial 3 finished with value: 0.03652219293292891 and parameters: {'w0': 0.28771000437627203, 'w1': 0.6412615300172301}. Best is trial 0 with value: 0.03581224196571786.\n",
            "[I 2025-06-16 10:43:34,522] Trial 4 finished with value: 0.03575162546898014 and parameters: {'w0': 0.8404920720988667, 'w1': 0.6634657312299251}. Best is trial 4 with value: 0.03575162546898014.\n",
            "[I 2025-06-16 10:43:34,527] Trial 5 finished with value: 0.0371077128303976 and parameters: {'w0': 0.6206686995822747, 'w1': 0.04591495918326516}. Best is trial 4 with value: 0.03575162546898014.\n",
            "[I 2025-06-16 10:43:34,533] Trial 6 finished with value: 0.03568516350309947 and parameters: {'w0': 0.8046450107946141, 'w1': 0.6558280741203909}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,540] Trial 7 finished with value: 0.03615477354667418 and parameters: {'w0': 0.9000019594662765, 'w1': 0.9225163809766158}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,548] Trial 8 finished with value: 0.03602387970860177 and parameters: {'w0': 0.8926023391194585, 'w1': 0.817618472798906}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,556] Trial 9 finished with value: 0.03658793711558039 and parameters: {'w0': 0.2491939639704127, 'w1': 0.7543431198798696}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,574] Trial 10 finished with value: 0.035889339406641074 and parameters: {'w0': 0.6891974470614018, 'w1': 0.4112937356419939}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,589] Trial 11 finished with value: 0.035889339406641074 and parameters: {'w0': 0.7306407903337336, 'w1': 0.4389862899878957}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,607] Trial 12 finished with value: 0.035817426968372756 and parameters: {'w0': 0.9910954078478559, 'w1': 0.6971105330824255}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,624] Trial 13 finished with value: 0.036172949055781944 and parameters: {'w0': 0.7610194337743621, 'w1': 0.9996863091500835}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,637] Trial 14 finished with value: 0.036226279257930205 and parameters: {'w0': 0.4694978515024126, 'w1': 0.5150559756105586}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,649] Trial 15 finished with value: 0.036309615977640264 and parameters: {'w0': 0.5548147076488648, 'w1': 0.8142275579093704}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,662] Trial 16 finished with value: 0.03582078469598693 and parameters: {'w0': 0.7977477219403846, 'w1': 0.6097235827902623}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,676] Trial 17 finished with value: 0.03582036556654822 and parameters: {'w0': 0.3760976366711266, 'w1': 0.2782787167745293}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,688] Trial 18 finished with value: 0.03586025681145988 and parameters: {'w0': 0.9680910893825405, 'w1': 0.3336679336166339}. Best is trial 6 with value: 0.03568516350309947.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted mlp (fold 5): 0.9633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:43:34,702] Trial 19 finished with value: 0.03617533051139188 and parameters: {'w0': 0.6385593532277807, 'w1': 0.8765826583308443}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,714] Trial 20 finished with value: 0.03568516350309947 and parameters: {'w0': 0.8486662472679127, 'w1': 0.697321832148242}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,728] Trial 21 finished with value: 0.035886909677128376 and parameters: {'w0': 0.8184288295367018, 'w1': 0.7089197115481998}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,741] Trial 22 finished with value: 0.035889339406641074 and parameters: {'w0': 0.84187423384571, 'w1': 0.5307678634689716}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,758] Trial 23 finished with value: 0.03602387970860177 and parameters: {'w0': 0.707710330588879, 'w1': 0.661647418584183}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,771] Trial 24 finished with value: 0.03568516350309947 and parameters: {'w0': 0.9421897812579467, 'w1': 0.7637975683860283}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,784] Trial 25 finished with value: 0.03582078469598693 and parameters: {'w0': 0.9887672699851285, 'w1': 0.760136105387591}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,801] Trial 26 finished with value: 0.03602387970860177 and parameters: {'w0': 0.9258990615307416, 'w1': 0.8712599420507988}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,814] Trial 27 finished with value: 0.03631730969089764 and parameters: {'w0': 0.5969418839214243, 'w1': 0.9830390451033649}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,827] Trial 28 finished with value: 0.03615477354667418 and parameters: {'w0': 0.7634511300636546, 'w1': 0.7803786169383884}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,841] Trial 29 finished with value: 0.0358204398351748 and parameters: {'w0': 0.5092482607535154, 'w1': 0.4314844783449455}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,854] Trial 30 finished with value: 0.03672524428208612 and parameters: {'w0': 0.036100732397657764, 'w1': 0.5633917837975048}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,867] Trial 31 finished with value: 0.03568516350309947 and parameters: {'w0': 0.8434503051684961, 'w1': 0.6909242209600999}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,886] Trial 32 finished with value: 0.03575162546898014 and parameters: {'w0': 0.9291342070190015, 'w1': 0.7385633469791808}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,900] Trial 33 finished with value: 0.035751653672066896 and parameters: {'w0': 0.8708438813976181, 'w1': 0.6137046707492766}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,913] Trial 34 finished with value: 0.03623803177035623 and parameters: {'w0': 0.674366569688849, 'w1': 0.8452115804713797}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,926] Trial 35 finished with value: 0.035886909677128376 and parameters: {'w0': 0.7980005768810798, 'w1': 0.6938282510293666}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,940] Trial 36 finished with value: 0.035889339406641074 and parameters: {'w0': 0.9334345078905176, 'w1': 0.5828914746383991}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,954] Trial 37 finished with value: 0.03595541999066454 and parameters: {'w0': 0.8344607357648608, 'w1': 0.47951300628258414}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,968] Trial 38 finished with value: 0.0365167542698438 and parameters: {'w0': 0.7389646069165079, 'w1': 0.12364022098792071}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,982] Trial 39 finished with value: 0.03615554713205804 and parameters: {'w0': 0.8710764907387831, 'w1': 0.9347164716371432}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:34,995] Trial 40 finished with value: 0.03624633228605789 and parameters: {'w0': 0.42351944150001775, 'w1': 0.6479440909448846}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,009] Trial 41 finished with value: 0.03582036556654822 and parameters: {'w0': 0.8769846207915722, 'w1': 0.6451392424111282}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,022] Trial 42 finished with value: 0.035818021641657816 and parameters: {'w0': 0.9343346630373545, 'w1': 0.6992300423419839}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,036] Trial 43 finished with value: 0.036087792591774526 and parameters: {'w0': 0.7966229123263744, 'w1': 0.7906560649010486}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,050] Trial 44 finished with value: 0.03582036556654822 and parameters: {'w0': 0.9995181724202323, 'w1': 0.7344288798273032}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,064] Trial 45 finished with value: 0.03615477354667418 and parameters: {'w0': 0.6492868225639316, 'w1': 0.670577220759471}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,077] Trial 46 finished with value: 0.0357513175819566 and parameters: {'w0': 0.7564378735875864, 'w1': 0.5482810612029776}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,091] Trial 47 finished with value: 0.0357513175819566 and parameters: {'w0': 0.755332124179573, 'w1': 0.5461887063465776}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,105] Trial 48 finished with value: 0.03615554713205804 and parameters: {'w0': 0.5636269952597095, 'w1': 0.605764385089723}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,119] Trial 49 finished with value: 0.03638865441895012 and parameters: {'w0': 0.13376226511165334, 'w1': 0.35768035615372495}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,133] Trial 50 finished with value: 0.03582036556654822 and parameters: {'w0': 0.6911176812221211, 'w1': 0.5126881706596107}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,147] Trial 51 finished with value: 0.03582036556654822 and parameters: {'w0': 0.762938448174728, 'w1': 0.5591999384291954}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,162] Trial 52 finished with value: 0.035886538489456665 and parameters: {'w0': 0.8444408653576, 'w1': 0.4617913772952761}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,176] Trial 53 finished with value: 0.035889339406641074 and parameters: {'w0': 0.9018191986626707, 'w1': 0.5572337104934821}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,190] Trial 54 finished with value: 0.035886909677128376 and parameters: {'w0': 0.7244938376947812, 'w1': 0.6157710958536486}. Best is trial 6 with value: 0.03568516350309947.\n",
            "[I 2025-06-16 10:43:35,204] Trial 55 finished with value: 0.0356766014136457 and parameters: {'w0': 0.7886127501535826, 'w1': 0.3862645800007425}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,219] Trial 56 finished with value: 0.03586242137364304 and parameters: {'w0': 0.8009431246003478, 'w1': 0.2710661735843768}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,233] Trial 57 finished with value: 0.035933721650167505 and parameters: {'w0': 0.902276954428541, 'w1': 0.3680392813335257}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,253] Trial 58 finished with value: 0.03617533051139188 and parameters: {'w0': 0.6019254267618259, 'w1': 0.8218841368143487}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,274] Trial 59 finished with value: 0.03582078469598693 and parameters: {'w0': 0.9462103750939517, 'w1': 0.7158984339388917}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,289] Trial 60 finished with value: 0.036784953990422364 and parameters: {'w0': 0.8428854171820955, 'w1': 0.13270828551222302}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,305] Trial 61 finished with value: 0.03588804972656334 and parameters: {'w0': 0.7669184643367608, 'w1': 0.49772321098255073}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,320] Trial 62 finished with value: 0.035889339406641074 and parameters: {'w0': 0.6702760382762197, 'w1': 0.3872145726651255}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,335] Trial 63 finished with value: 0.035995241257021915 and parameters: {'w0': 0.7481944763343171, 'w1': 0.22685072981509813}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,350] Trial 64 finished with value: 0.036454763450709415 and parameters: {'w0': 0.28385524596716183, 'w1': 0.7675757199895591}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,365] Trial 65 finished with value: 0.035817426968372756 and parameters: {'w0': 0.7822419760251366, 'w1': 0.5441108947575093}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,381] Trial 66 finished with value: 0.035817426968372756 and parameters: {'w0': 0.9694565061052309, 'w1': 0.6737827046760183}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,401] Trial 67 finished with value: 0.03595087273201425 and parameters: {'w0': 0.8254363228198238, 'w1': 0.4497070957200927}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,416] Trial 68 finished with value: 0.03568516350309947 and parameters: {'w0': 0.7242878740746478, 'w1': 0.5957610817649538}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,430] Trial 69 finished with value: 0.0358031153774262 and parameters: {'w0': 0.725476468309739, 'w1': 0.3111397689170202}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,446] Trial 70 finished with value: 0.035817426968372756 and parameters: {'w0': 0.8560761492798635, 'w1': 0.6018724973348729}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,462] Trial 71 finished with value: 0.035889339406641074 and parameters: {'w0': 0.8974484887277996, 'w1': 0.526384562471689}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,476] Trial 72 finished with value: 0.03575162546898014 and parameters: {'w0': 0.8085791997028989, 'w1': 0.6360139724942343}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,490] Trial 73 finished with value: 0.03568516350309947 and parameters: {'w0': 0.6981555639269474, 'w1': 0.5726696398970195}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,504] Trial 74 finished with value: 0.03568516350309947 and parameters: {'w0': 0.7063348391438646, 'w1': 0.5817484978031432}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,519] Trial 75 finished with value: 0.03568516350309947 and parameters: {'w0': 0.7089809382651588, 'w1': 0.5845753891969138}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,539] Trial 76 finished with value: 0.036309615977640264 and parameters: {'w0': 0.4727858698157428, 'w1': 0.6913395333073915}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,554] Trial 77 finished with value: 0.036226279257930205 and parameters: {'w0': 0.5663730957365444, 'w1': 0.6316983907931895}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,569] Trial 78 finished with value: 0.0361585910279566 and parameters: {'w0': 0.6375345887080981, 'w1': 0.7233115872867648}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,582] Trial 79 finished with value: 0.035889339406641074 and parameters: {'w0': 0.6894287046141927, 'w1': 0.4160953976584961}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,596] Trial 80 finished with value: 0.03615477354667418 and parameters: {'w0': 0.7820475555103579, 'w1': 0.8036492768005522}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,611] Trial 81 finished with value: 0.03568516350309947 and parameters: {'w0': 0.7128253366045725, 'w1': 0.583199410676703}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,625] Trial 82 finished with value: 0.035886909677128376 and parameters: {'w0': 0.6737895827596493, 'w1': 0.5876583634773099}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,639] Trial 83 finished with value: 0.03609738329927792 and parameters: {'w0': 0.6216156863403565, 'w1': 0.7462087512861976}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,653] Trial 84 finished with value: 0.03575162546898014 and parameters: {'w0': 0.865359225628505, 'w1': 0.6751440099742843}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,670] Trial 85 finished with value: 0.035889339406641074 and parameters: {'w0': 0.8236601687661843, 'w1': 0.49380803269684953}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,684] Trial 86 finished with value: 0.03602387970860177 and parameters: {'w0': 0.706815193137213, 'w1': 0.6459471416770369}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,703] Trial 87 finished with value: 0.035886909677128376 and parameters: {'w0': 0.6599575526636906, 'w1': 0.5798825147168778}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,717] Trial 88 finished with value: 0.03602387970860177 and parameters: {'w0': 0.530884036473742, 'w1': 0.47814557038189576}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,731] Trial 89 finished with value: 0.0358210369786105 and parameters: {'w0': 0.9633278406936184, 'w1': 0.6194313580913202}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,746] Trial 90 finished with value: 0.03602387970860177 and parameters: {'w0': 0.9128911010983198, 'w1': 0.8523994798431701}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,760] Trial 91 finished with value: 0.035753508218178576 and parameters: {'w0': 0.7089897479545553, 'w1': 0.5869149492046651}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,775] Trial 92 finished with value: 0.0358204398351748 and parameters: {'w0': 0.7800349433645046, 'w1': 0.6593312810623237}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,789] Trial 93 finished with value: 0.03602387970860177 and parameters: {'w0': 0.7250208026796988, 'w1': 0.6874309224800343}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,804] Trial 94 finished with value: 0.03581888979715675 and parameters: {'w0': 0.8820740812069177, 'w1': 0.5951342340910827}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,818] Trial 95 finished with value: 0.03581740130265998 and parameters: {'w0': 0.7375237477787346, 'w1': 0.5300669114326628}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,833] Trial 96 finished with value: 0.03615554713205804 and parameters: {'w0': 0.7017456399547244, 'w1': 0.7607030416984832}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,847] Trial 97 finished with value: 0.03602387970860177 and parameters: {'w0': 0.6009595879422376, 'w1': 0.5681253084954739}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,862] Trial 98 finished with value: 0.03595740157841809 and parameters: {'w0': 0.8067539106379367, 'w1': 0.7177375682454299}. Best is trial 55 with value: 0.0356766014136457.\n",
            "[I 2025-06-16 10:43:35,877] Trial 99 finished with value: 0.03631730969089764 and parameters: {'w0': 0.3639270572482633, 'w1': 0.6171647890484595}. Best is trial 55 with value: 0.0356766014136457.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 5): 0.9643\n",
            "\n",
            "--- Training combination ('lgbm', 'logreg') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003319 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335535\n",
            "[LightGBM] [Info] Start training from score -3.552799\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889398\n",
            "[LightGBM] [Info] Start training from score -3.745491\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.560449\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013314\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912613\n",
            "[LightGBM] [Info] Start training from score -2.909527\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521069\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.457276\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 5): 0.9621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:43:46,018] A new study created in memory with name: no-name-96c70bf7-2bb1-48f6-9f83-8bd18af28ebb\n",
            "[I 2025-06-16 10:43:46,028] Trial 0 finished with value: 0.0353930999197033 and parameters: {'w0': 0.9252723784068753, 'w1': 0.6466869639175742}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,036] Trial 1 finished with value: 0.03664299010707839 and parameters: {'w0': 0.048737512451837994, 'w1': 0.384802497301457}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,043] Trial 2 finished with value: 0.03614976602420439 and parameters: {'w0': 0.37291590010879183, 'w1': 0.41938801327119546}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,051] Trial 3 finished with value: 0.03712070472229834 and parameters: {'w0': 0.6303293078056441, 'w1': 0.1533581022580527}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,059] Trial 4 finished with value: 0.03595930459201946 and parameters: {'w0': 0.2810255700233495, 'w1': 0.8963525924434184}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,066] Trial 5 finished with value: 0.036789428123852 and parameters: {'w0': 0.7336552889353609, 'w1': 0.18583410658226862}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,074] Trial 6 finished with value: 0.03792344523806712 and parameters: {'w0': 0.8901816403962314, 'w1': 0.03523311856105871}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,081] Trial 7 finished with value: 0.03608541647845176 and parameters: {'w0': 0.2988623983359858, 'w1': 0.34695297175830864}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,089] Trial 8 finished with value: 0.03589282306042463 and parameters: {'w0': 0.1813398328936041, 'w1': 0.6092616307138775}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,096] Trial 9 finished with value: 0.03678931119063278 and parameters: {'w0': 0.1478022589488498, 'w1': 0.0407665258429909}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,115] Trial 10 finished with value: 0.0355259488811599 and parameters: {'w0': 0.9700352619282794, 'w1': 0.7647542751940686}. Best is trial 0 with value: 0.0353930999197033.\n",
            "[I 2025-06-16 10:43:46,131] Trial 11 finished with value: 0.035389632632360724 and parameters: {'w0': 0.9935682909983097, 'w1': 0.7008143704712291}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,144] Trial 12 finished with value: 0.03552381302291363 and parameters: {'w0': 0.8102547917221635, 'w1': 0.6008875814783583}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,157] Trial 13 finished with value: 0.036089533916511374 and parameters: {'w0': 0.5645719038680315, 'w1': 0.7606265578293133}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,170] Trial 14 finished with value: 0.035808552327203036 and parameters: {'w0': 0.9954046574164758, 'w1': 0.950774581674371}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,183] Trial 15 finished with value: 0.035730663450328715 and parameters: {'w0': 0.7345804969653509, 'w1': 0.6024599984601279}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,195] Trial 16 finished with value: 0.03560027179452774 and parameters: {'w0': 0.8625217215634042, 'w1': 0.771743926530581}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,208] Trial 17 finished with value: 0.03594848510334214 and parameters: {'w0': 0.43515956385950993, 'w1': 0.520749844996795}. Best is trial 11 with value: 0.035389632632360724.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 5): 0.9626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:43:46,222] Trial 18 finished with value: 0.036154837340188095 and parameters: {'w0': 0.6489635217634955, 'w1': 0.8333905312822738}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,236] Trial 19 finished with value: 0.03545598904082525 and parameters: {'w0': 0.909302584134744, 'w1': 0.665221929140471}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,248] Trial 20 finished with value: 0.036089533916511374 and parameters: {'w0': 0.7573594582935053, 'w1': 0.9826092061107876}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,263] Trial 21 finished with value: 0.03552381302291363 and parameters: {'w0': 0.9151278430507934, 'w1': 0.6788898960795917}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,281] Trial 22 finished with value: 0.03557833932155874 and parameters: {'w0': 0.9943064042628491, 'w1': 0.5109451169299486}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,294] Trial 23 finished with value: 0.03579582492992839 and parameters: {'w0': 0.828779629829017, 'w1': 0.6866673439434995}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,308] Trial 24 finished with value: 0.03552381302291363 and parameters: {'w0': 0.9101985626454476, 'w1': 0.6799628702766519}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,321] Trial 25 finished with value: 0.03615482149420113 and parameters: {'w0': 0.6302607591989191, 'w1': 0.8627963979309962}. Best is trial 11 with value: 0.035389632632360724.\n",
            "[I 2025-06-16 10:43:46,334] Trial 26 finished with value: 0.035258948609203866 and parameters: {'w0': 0.7953809109314355, 'w1': 0.5373898543285144}. Best is trial 26 with value: 0.035258948609203866.\n",
            "[I 2025-06-16 10:43:46,348] Trial 27 finished with value: 0.03518236228756877 and parameters: {'w0': 0.7898603427561822, 'w1': 0.4856524489853221}. Best is trial 27 with value: 0.03518236228756877.\n",
            "[I 2025-06-16 10:43:46,362] Trial 28 finished with value: 0.03566540527802675 and parameters: {'w0': 0.5316634393189311, 'w1': 0.4608512782568413}. Best is trial 27 with value: 0.03518236228756877.\n",
            "[I 2025-06-16 10:43:46,376] Trial 29 finished with value: 0.03611703721050952 and parameters: {'w0': 0.7688705452276424, 'w1': 0.3059957361403396}. Best is trial 27 with value: 0.03518236228756877.\n",
            "[I 2025-06-16 10:43:46,391] Trial 30 finished with value: 0.035592363937411275 and parameters: {'w0': 0.669105912621559, 'w1': 0.5336254358028888}. Best is trial 27 with value: 0.03518236228756877.\n",
            "[I 2025-06-16 10:43:46,404] Trial 31 finished with value: 0.035513260117403855 and parameters: {'w0': 0.8250136369054767, 'w1': 0.4171768575952899}. Best is trial 27 with value: 0.03518236228756877.\n",
            "[I 2025-06-16 10:43:46,419] Trial 32 finished with value: 0.03518143519346373 and parameters: {'w0': 0.9395078508811905, 'w1': 0.5679173359525289}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,433] Trial 33 finished with value: 0.03524693233015297 and parameters: {'w0': 0.9497898575399928, 'w1': 0.5656555227195255}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,447] Trial 34 finished with value: 0.03604846829971975 and parameters: {'w0': 0.7000578373078972, 'w1': 0.3110532986517546}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,461] Trial 35 finished with value: 0.035258948609203866 and parameters: {'w0': 0.8423471863284138, 'w1': 0.5691852646033602}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,475] Trial 36 finished with value: 0.03577734932868171 and parameters: {'w0': 0.9459566732026299, 'w1': 0.47212649829129205}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,489] Trial 37 finished with value: 0.035258948609203866 and parameters: {'w0': 0.5904915442769532, 'w1': 0.3887202200654062}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,503] Trial 38 finished with value: 0.03672011072043879 and parameters: {'w0': 0.773630752834315, 'w1': 0.247859343803136}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,517] Trial 39 finished with value: 0.03567063458130182 and parameters: {'w0': 0.4850967417127831, 'w1': 0.45301432751975895}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,531] Trial 40 finished with value: 0.037258842352209 and parameters: {'w0': 0.019289371828637214, 'w1': 0.5540080496561173}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,545] Trial 41 finished with value: 0.035258948609203866 and parameters: {'w0': 0.8577942693729591, 'w1': 0.5722205420096718}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,559] Trial 42 finished with value: 0.03538236560291852 and parameters: {'w0': 0.8790236544027051, 'w1': 0.48742334365641454}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,574] Trial 43 finished with value: 0.03532680104899055 and parameters: {'w0': 0.9317210592035641, 'w1': 0.6306589645116327}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,588] Trial 44 finished with value: 0.035392022769391795 and parameters: {'w0': 0.8126355046037498, 'w1': 0.5606526465999652}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,602] Trial 45 finished with value: 0.03574160164877904 and parameters: {'w0': 0.7055617067688312, 'w1': 0.722082841580316}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,617] Trial 46 finished with value: 0.03611887668847602 and parameters: {'w0': 0.9481038094764005, 'w1': 0.3968542144865372}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,632] Trial 47 finished with value: 0.03545598904082525 and parameters: {'w0': 0.8507870199283164, 'w1': 0.6286010393123774}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,646] Trial 48 finished with value: 0.03604846829971975 and parameters: {'w0': 0.8029085619540803, 'w1': 0.35508691567683204}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,661] Trial 49 finished with value: 0.03532530106052878 and parameters: {'w0': 0.8718496484340458, 'w1': 0.6032711791383217}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,676] Trial 50 finished with value: 0.036089533916511374 and parameters: {'w0': 0.3388519743137809, 'w1': 0.4474222830391042}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,697] Trial 51 finished with value: 0.035730663450328715 and parameters: {'w0': 0.6138368342178859, 'w1': 0.5068344431461737}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,713] Trial 52 finished with value: 0.03587379637858734 and parameters: {'w0': 0.437188869525397, 'w1': 0.41985755486649873}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,727] Trial 53 finished with value: 0.03518143519346373 and parameters: {'w0': 0.5882527347864339, 'w1': 0.3562117139289313}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,742] Trial 54 finished with value: 0.03672011072043879 and parameters: {'w0': 0.7043651881880777, 'w1': 0.22602617344761752}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,757] Trial 55 finished with value: 0.03524693233015297 and parameters: {'w0': 0.9606321008001488, 'w1': 0.5704278058880846}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,771] Trial 56 finished with value: 0.03651704238760611 and parameters: {'w0': 0.9690142124054066, 'w1': 0.34943445589924}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,786] Trial 57 finished with value: 0.03589282306042463 and parameters: {'w0': 0.21733982756622827, 'w1': 0.728813954323948}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,801] Trial 58 finished with value: 0.035258948609203866 and parameters: {'w0': 0.9625606771398877, 'w1': 0.6493762484241858}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,816] Trial 59 finished with value: 0.03524693233015297 and parameters: {'w0': 0.9016209057434776, 'w1': 0.5330687281078352}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,830] Trial 60 finished with value: 0.03792499608218347 and parameters: {'w0': 0.9009481702014719, 'w1': 0.0037950535259466678}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,845] Trial 61 finished with value: 0.03738358455939872 and parameters: {'w0': 0.7888729638620833, 'w1': 0.1261628363752005}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,860] Trial 62 finished with value: 0.03551594759202392 and parameters: {'w0': 0.9984662993082632, 'w1': 0.5323131845638455}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,878] Trial 63 finished with value: 0.03551961560769734 and parameters: {'w0': 0.9229079474922284, 'w1': 0.4957302387722182}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,894] Trial 64 finished with value: 0.035592363937411275 and parameters: {'w0': 0.7407089982607591, 'w1': 0.6014505745539636}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,909] Trial 65 finished with value: 0.03525024212859573 and parameters: {'w0': 0.8995741285833008, 'w1': 0.574594579877001}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,929] Trial 66 finished with value: 0.035258948609203866 and parameters: {'w0': 0.8819889079080601, 'w1': 0.5853633472550529}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,944] Trial 67 finished with value: 0.03598218665529063 and parameters: {'w0': 0.9639660251363719, 'w1': 0.43879699167286096}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,958] Trial 68 finished with value: 0.035389632632360724 and parameters: {'w0': 0.9053365643461362, 'w1': 0.6375762414045755}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,972] Trial 69 finished with value: 0.03665089944202271 and parameters: {'w0': 0.9304907879187495, 'w1': 0.3081881913394362}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,986] Trial 70 finished with value: 0.035592363937411275 and parameters: {'w0': 0.9789543559567149, 'w1': 0.7985370701643837}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:46,999] Trial 71 finished with value: 0.03525024212859573 and parameters: {'w0': 0.8384221738677065, 'w1': 0.53208817738421}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,014] Trial 72 finished with value: 0.03531316695655484 and parameters: {'w0': 0.8378620620665381, 'w1': 0.4839165714774825}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,028] Trial 73 finished with value: 0.03518143519346373 and parameters: {'w0': 0.8857851711291536, 'w1': 0.5398952795363257}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,045] Trial 74 finished with value: 0.035258948609203866 and parameters: {'w0': 0.8904708385811017, 'w1': 0.5846541754988409}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,058] Trial 75 finished with value: 0.0354587650194127 and parameters: {'w0': 0.9433289344860853, 'w1': 0.662537448301517}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,073] Trial 76 finished with value: 0.03525024212859573 and parameters: {'w0': 0.8645646304421242, 'w1': 0.5510799475363443}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,088] Trial 77 finished with value: 0.03538236560291852 and parameters: {'w0': 0.8987655268371819, 'w1': 0.516897065382029}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,106] Trial 78 finished with value: 0.03614976602420439 and parameters: {'w0': 0.549227131322159, 'w1': 0.613289009216791}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,120] Trial 79 finished with value: 0.035389632632360724 and parameters: {'w0': 0.9977215041530044, 'w1': 0.7130750040557731}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,134] Trial 80 finished with value: 0.03604846829971975 and parameters: {'w0': 0.9278666456663275, 'w1': 0.41998052545239756}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,147] Trial 81 finished with value: 0.03650654918791507 and parameters: {'w0': 0.08408920794825736, 'w1': 0.5316478081665816}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,161] Trial 82 finished with value: 0.03538236560291852 and parameters: {'w0': 0.8361921250717893, 'w1': 0.4763856554545255}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,175] Trial 83 finished with value: 0.0354587650194127 and parameters: {'w0': 0.7835821519505753, 'w1': 0.5504024468967942}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,189] Trial 84 finished with value: 0.03518236228756877 and parameters: {'w0': 0.9554143449989395, 'w1': 0.585227444250062}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,203] Trial 85 finished with value: 0.03518236228756877 and parameters: {'w0': 0.9483433682830574, 'w1': 0.579742548833365}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,217] Trial 86 finished with value: 0.03551548858156761 and parameters: {'w0': 0.965187101502045, 'w1': 0.5084264852200426}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,230] Trial 87 finished with value: 0.035258948609203866 and parameters: {'w0': 0.9464785922913991, 'w1': 0.62564802726962}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,245] Trial 88 finished with value: 0.036585957872441566 and parameters: {'w0': 0.8687009600625188, 'w1': 0.2685101798426893}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,259] Trial 89 finished with value: 0.03638209409383286 and parameters: {'w0': 0.9731679690835096, 'w1': 0.3687739451972891}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,278] Trial 90 finished with value: 0.036089533916511374 and parameters: {'w0': 0.5058036193555502, 'w1': 0.6884764863115422}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,292] Trial 91 finished with value: 0.0352490696496367 and parameters: {'w0': 0.9083495965760151, 'w1': 0.5838277817558115}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,310] Trial 92 finished with value: 0.0352490696496367 and parameters: {'w0': 0.9161921792355008, 'w1': 0.5906907625903001}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,325] Trial 93 finished with value: 0.0353930999197033 and parameters: {'w0': 0.9489017213753326, 'w1': 0.661049476447564}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,339] Trial 94 finished with value: 0.03579582492992839 and parameters: {'w0': 0.6708111545536354, 'w1': 0.5577685990945324}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,353] Trial 95 finished with value: 0.03538236560291852 and parameters: {'w0': 0.8114440624473347, 'w1': 0.4641691522229622}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,369] Trial 96 finished with value: 0.03518236228756877 and parameters: {'w0': 0.9778746254562478, 'w1': 0.6127389826923668}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,384] Trial 97 finished with value: 0.03518236228756877 and parameters: {'w0': 0.9838197356052563, 'w1': 0.6148345956611178}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,398] Trial 98 finished with value: 0.03518236228756877 and parameters: {'w0': 0.9871240261720791, 'w1': 0.613544400259617}. Best is trial 32 with value: 0.03518143519346373.\n",
            "[I 2025-06-16 10:43:47,412] Trial 99 finished with value: 0.03518236228756877 and parameters: {'w0': 0.9828050134950784, 'w1': 0.6120181899672407}. Best is trial 32 with value: 0.03518143519346373.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 5): 0.9648\n",
            "\n",
            "--- Training combination ('mlp', 'logreg') ---\n",
            "F1-weighted mlp (fold 5): 0.9634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:44:06,746] A new study created in memory with name: no-name-0dc1e6b7-94ab-4636-99f6-9d570b9f0708\n",
            "[I 2025-06-16 10:44:06,755] Trial 0 finished with value: 0.03699086158643383 and parameters: {'w0': 0.10555383825383102, 'w1': 0.2558314687375354}. Best is trial 0 with value: 0.03699086158643383.\n",
            "[I 2025-06-16 10:44:06,762] Trial 1 finished with value: 0.03686376950012915 and parameters: {'w0': 0.20632458949844013, 'w1': 0.1339552555829664}. Best is trial 1 with value: 0.03686376950012915.\n",
            "[I 2025-06-16 10:44:06,770] Trial 2 finished with value: 0.03733179581879886 and parameters: {'w0': 0.3020274029821707, 'w1': 0.8952772273686912}. Best is trial 1 with value: 0.03686376950012915.\n",
            "[I 2025-06-16 10:44:06,778] Trial 3 finished with value: 0.03706206336000828 and parameters: {'w0': 0.24189313701420811, 'w1': 0.24253026748816986}. Best is trial 1 with value: 0.03686376950012915.\n",
            "[I 2025-06-16 10:44:06,786] Trial 4 finished with value: 0.03739968583071562 and parameters: {'w0': 0.1618309330570683, 'w1': 0.5510388231128961}. Best is trial 1 with value: 0.03686376950012915.\n",
            "[I 2025-06-16 10:44:06,793] Trial 5 finished with value: 0.03706591855711583 and parameters: {'w0': 0.5637824485157739, 'w1': 0.8970687733737502}. Best is trial 1 with value: 0.03686376950012915.\n",
            "[I 2025-06-16 10:44:06,801] Trial 6 finished with value: 0.03692825121571053 and parameters: {'w0': 0.8938667056190912, 'w1': 0.3782401172872053}. Best is trial 1 with value: 0.03686376950012915.\n",
            "[I 2025-06-16 10:44:06,808] Trial 7 finished with value: 0.03679465945444893 and parameters: {'w0': 0.9902852359743503, 'w1': 0.5629807611518709}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,817] Trial 8 finished with value: 0.03705878766775217 and parameters: {'w0': 0.21943392874199674, 'w1': 0.49913886415472186}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,825] Trial 9 finished with value: 0.036996979318020595 and parameters: {'w0': 0.7289386431293586, 'w1': 0.8999120961482945}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,843] Trial 10 finished with value: 0.036795154443885925 and parameters: {'w0': 0.9990031137140714, 'w1': 0.6616082625161359}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,860] Trial 11 finished with value: 0.036795154443885925 and parameters: {'w0': 0.9431148263536675, 'w1': 0.6684079574023521}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,873] Trial 12 finished with value: 0.036795154443885925 and parameters: {'w0': 0.9987598205419393, 'w1': 0.699867442830196}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,885] Trial 13 finished with value: 0.03706206336000828 and parameters: {'w0': 0.728349798403773, 'w1': 0.7131102396070956}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,898] Trial 14 finished with value: 0.036795154443885925 and parameters: {'w0': 0.766331928363934, 'w1': 0.5463726867842612}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,912] Trial 15 finished with value: 0.03685828540073677 and parameters: {'w0': 0.4890193690298005, 'w1': 0.4024450677704988}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,926] Trial 16 finished with value: 0.03706183178877309 and parameters: {'w0': 0.8336695467046096, 'w1': 0.7332294383562701}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,940] Trial 17 finished with value: 0.03713271215871572 and parameters: {'w0': 0.5917249684325933, 'w1': 0.7837508876121387}. Best is trial 7 with value: 0.03679465945444893.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 5): 0.9626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:44:06,952] Trial 18 finished with value: 0.037134552518497954 and parameters: {'w0': 0.3856295118043389, 'w1': 0.5780335223067162}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,965] Trial 19 finished with value: 0.037062626530574794 and parameters: {'w0': 0.010670206011028305, 'w1': 0.019462486771468}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,978] Trial 20 finished with value: 0.03686074115099114 and parameters: {'w0': 0.8365191636904346, 'w1': 0.4310725698749257}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:06,993] Trial 21 finished with value: 0.03686376950012915 and parameters: {'w0': 0.9966325892053133, 'w1': 0.6380138161252018}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:07,007] Trial 22 finished with value: 0.03706183178877309 and parameters: {'w0': 0.9132766829606679, 'w1': 0.8139343553518179}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:07,021] Trial 23 finished with value: 0.036795154443885925 and parameters: {'w0': 0.9175475427023355, 'w1': 0.6316570010482989}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:07,034] Trial 24 finished with value: 0.036795154443885925 and parameters: {'w0': 0.6404479139778247, 'w1': 0.4554844819964295}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:07,048] Trial 25 finished with value: 0.03686376950012915 and parameters: {'w0': 0.9990468016342056, 'w1': 0.6496234425226299}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:07,061] Trial 26 finished with value: 0.036996979318020595 and parameters: {'w0': 0.8273314318974954, 'w1': 0.9898344104380368}. Best is trial 7 with value: 0.03679465945444893.\n",
            "[I 2025-06-16 10:44:07,075] Trial 27 finished with value: 0.03679403964659744 and parameters: {'w0': 0.9244336551151341, 'w1': 0.3545669680980809}. Best is trial 27 with value: 0.03679403964659744.\n",
            "[I 2025-06-16 10:44:07,091] Trial 28 finished with value: 0.03686074115099114 and parameters: {'w0': 0.6728475030363934, 'w1': 0.3325309717629549}. Best is trial 27 with value: 0.03679403964659744.\n",
            "[I 2025-06-16 10:44:07,104] Trial 29 finished with value: 0.03679671245006988 and parameters: {'w0': 0.8172212836222936, 'w1': 0.24929551593510485}. Best is trial 27 with value: 0.03679403964659744.\n",
            "[I 2025-06-16 10:44:07,118] Trial 30 finished with value: 0.036795154443885925 and parameters: {'w0': 0.4640845219462719, 'w1': 0.3373023718029819}. Best is trial 27 with value: 0.03679403964659744.\n",
            "[I 2025-06-16 10:44:07,131] Trial 31 finished with value: 0.03686074115099114 and parameters: {'w0': 0.8899674507785911, 'w1': 0.4770188566157818}. Best is trial 27 with value: 0.03679403964659744.\n",
            "[I 2025-06-16 10:44:07,145] Trial 32 finished with value: 0.036666443121464276 and parameters: {'w0': 0.9320301567914182, 'w1': 0.179099545376765}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,158] Trial 33 finished with value: 0.036801978580964456 and parameters: {'w0': 0.9504940427123589, 'w1': 0.13516801850160304}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,172] Trial 34 finished with value: 0.03673147075631977 and parameters: {'w0': 0.8667692335852899, 'w1': 0.20508013622190224}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,186] Trial 35 finished with value: 0.03673680582269112 and parameters: {'w0': 0.7792508414879061, 'w1': 0.13208065087490672}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,200] Trial 36 finished with value: 0.036666443121464276 and parameters: {'w0': 0.7705642842455331, 'w1': 0.16719265708233028}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,214] Trial 37 finished with value: 0.036666443121464276 and parameters: {'w0': 0.7650127937734077, 'w1': 0.1697523118866261}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,227] Trial 38 finished with value: 0.03673147075631977 and parameters: {'w0': 0.6867035506521695, 'w1': 0.17987245956978104}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,241] Trial 39 finished with value: 0.03693499100653397 and parameters: {'w0': 0.572455518604224, 'w1': 0.029766154664356614}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,255] Trial 40 finished with value: 0.03693439545332289 and parameters: {'w0': 0.8553674800176677, 'w1': 0.08364030188962245}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,269] Trial 41 finished with value: 0.03679671245006988 and parameters: {'w0': 0.678568766404133, 'w1': 0.19567777326876157}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,283] Trial 42 finished with value: 0.03673147075631977 and parameters: {'w0': 0.7502681394490479, 'w1': 0.19517091191296332}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,298] Trial 43 finished with value: 0.03692825121571053 and parameters: {'w0': 0.7077298859842338, 'w1': 0.2850238751604507}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,312] Trial 44 finished with value: 0.03679671245006988 and parameters: {'w0': 0.6336555470257625, 'w1': 0.1874238622705684}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,326] Trial 45 finished with value: 0.036801978580964456 and parameters: {'w0': 0.7763721529831987, 'w1': 0.09811800750887112}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,340] Trial 46 finished with value: 0.03679671245006988 and parameters: {'w0': 0.8692230405140806, 'w1': 0.2800151554363042}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,353] Trial 47 finished with value: 0.03679671245006988 and parameters: {'w0': 0.5208832989083997, 'w1': 0.1596190135136524}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,368] Trial 48 finished with value: 0.03679671245006988 and parameters: {'w0': 0.8001283687981713, 'w1': 0.22999687837083738}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,382] Trial 49 finished with value: 0.03693439545332289 and parameters: {'w0': 0.7144711036845375, 'w1': 0.05864127529276175}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,397] Trial 50 finished with value: 0.036927942656937884 and parameters: {'w0': 0.6325482560733928, 'w1': 0.3014748362235624}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,411] Trial 51 finished with value: 0.03673147075631977 and parameters: {'w0': 0.7593689392338829, 'w1': 0.191791577288384}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,425] Trial 52 finished with value: 0.036801978580964456 and parameters: {'w0': 0.740203155876528, 'w1': 0.10975335992120892}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,439] Trial 53 finished with value: 0.03673147075631977 and parameters: {'w0': 0.8610868249050362, 'w1': 0.22407780136076477}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,453] Trial 54 finished with value: 0.03673147075631977 and parameters: {'w0': 0.6931722915826006, 'w1': 0.17542309307185944}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,468] Trial 55 finished with value: 0.036865457073913976 and parameters: {'w0': 0.9531249569449862, 'w1': 0.0027121933492024464}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,482] Trial 56 finished with value: 0.03673517592567721 and parameters: {'w0': 0.8056726859665151, 'w1': 0.13312818986881997}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,496] Trial 57 finished with value: 0.036666443121464276 and parameters: {'w0': 0.3212670216208254, 'w1': 0.06561620901719825}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,510] Trial 58 finished with value: 0.036666443121464276 and parameters: {'w0': 0.3330952517348771, 'w1': 0.06297454803513211}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,524] Trial 59 finished with value: 0.036666443121464276 and parameters: {'w0': 0.27500992870480057, 'w1': 0.05176539640627614}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,538] Trial 60 finished with value: 0.03673517592567721 and parameters: {'w0': 0.3239498701795227, 'w1': 0.05124383695487797}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,553] Trial 61 finished with value: 0.036927942656937884 and parameters: {'w0': 0.1599243851810757, 'w1': 0.07718399866520656}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,574] Trial 62 finished with value: 0.036801978580964456 and parameters: {'w0': 0.31689714500503524, 'w1': 0.04618684552674597}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,593] Trial 63 finished with value: 0.036859045193233575 and parameters: {'w0': 0.28046768323287524, 'w1': 0.10798434736035713}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,607] Trial 64 finished with value: 0.03679403964659744 and parameters: {'w0': 0.37628542497567335, 'w1': 0.14409095235562855}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,621] Trial 65 finished with value: 0.03693499100653397 and parameters: {'w0': 0.186799473150531, 'w1': 0.006262372247738297}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,635] Trial 66 finished with value: 0.03679671245006988 and parameters: {'w0': 0.2633930390972777, 'w1': 0.07371924871569219}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,649] Trial 67 finished with value: 0.03679465945444893 and parameters: {'w0': 0.39317980117437645, 'w1': 0.21816736742771917}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,663] Trial 68 finished with value: 0.036795154443885925 and parameters: {'w0': 0.3498838148967698, 'w1': 0.2593376635323409}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,677] Trial 69 finished with value: 0.03673147075631977 and parameters: {'w0': 0.42901112276786163, 'w1': 0.10152770030144749}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,692] Trial 70 finished with value: 0.03706183178877309 and parameters: {'w0': 0.04557314192534756, 'w1': 0.04015702169359621}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,707] Trial 71 finished with value: 0.036795154443885925 and parameters: {'w0': 0.23208328350314594, 'w1': 0.1629716851241623}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,721] Trial 72 finished with value: 0.036996979318020595 and parameters: {'w0': 0.10835065426411603, 'w1': 0.12478058006456222}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,735] Trial 73 finished with value: 0.03679465945444893 and parameters: {'w0': 0.27847459587939966, 'w1': 0.15669123285401582}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,750] Trial 74 finished with value: 0.036927942656937884 and parameters: {'w0': 0.44081841192819377, 'w1': 0.21241022004956253}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,765] Trial 75 finished with value: 0.036927942656937884 and parameters: {'w0': 0.5315474107056009, 'w1': 0.2612969897141571}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,780] Trial 76 finished with value: 0.036927942656937884 and parameters: {'w0': 0.8940325176784392, 'w1': 0.39002907848561785}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,796] Trial 77 finished with value: 0.03692825121571053 and parameters: {'w0': 0.20912093859000552, 'w1': 0.08632619645935691}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,811] Trial 78 finished with value: 0.03679671245006988 and parameters: {'w0': 0.9628499152904203, 'w1': 0.3056859045377496}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,826] Trial 79 finished with value: 0.036666443121464276 and parameters: {'w0': 0.34736906902337017, 'w1': 0.06629417067383914}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,844] Trial 80 finished with value: 0.03700126036187468 and parameters: {'w0': 0.34692025432905077, 'w1': 0.02452075173898252}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,866] Trial 81 finished with value: 0.03679671245006988 and parameters: {'w0': 0.2598822195033981, 'w1': 0.07676106872687961}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,887] Trial 82 finished with value: 0.03679671245006988 and parameters: {'w0': 0.3731452354372021, 'w1': 0.12276216751426444}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,904] Trial 83 finished with value: 0.036666443121464276 and parameters: {'w0': 0.8396052818521843, 'w1': 0.16027047624801724}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,919] Trial 84 finished with value: 0.036801978580964456 and parameters: {'w0': 0.4197425322003774, 'w1': 0.058824077519073585}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,933] Trial 85 finished with value: 0.036927942656937884 and parameters: {'w0': 0.29650828498922754, 'w1': 0.14443253282343727}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,949] Trial 86 finished with value: 0.03693499100653397 and parameters: {'w0': 0.8389527641813935, 'w1': 0.030363554041437257}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,966] Trial 87 finished with value: 0.03686861971385991 and parameters: {'w0': 0.8914449722748006, 'w1': 0.10989363424025993}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,981] Trial 88 finished with value: 0.036666443121464276 and parameters: {'w0': 0.9736308549910397, 'w1': 0.20993229453704118}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:07,996] Trial 89 finished with value: 0.03673680582269112 and parameters: {'w0': 0.975687455951861, 'w1': 0.1704012874340181}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:08,015] Trial 90 finished with value: 0.036865457073913976 and parameters: {'w0': 0.9329059697704992, 'w1': 0.004302283262662118}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:08,030] Trial 91 finished with value: 0.03679671245006988 and parameters: {'w0': 0.9055993901213532, 'w1': 0.23904685056145186}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:08,049] Trial 92 finished with value: 0.03673147075631977 and parameters: {'w0': 0.8718408851213985, 'w1': 0.20616485761983078}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:08,065] Trial 93 finished with value: 0.03693439545332289 and parameters: {'w0': 0.7967175038122817, 'w1': 0.067260476965882}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:08,080] Trial 94 finished with value: 0.03673680582269112 and parameters: {'w0': 0.9273843459002894, 'w1': 0.1562696643068343}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:08,095] Trial 95 finished with value: 0.036795154443885925 and parameters: {'w0': 0.8450377840234132, 'w1': 0.5869791235710089}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:08,110] Trial 96 finished with value: 0.036666443121464276 and parameters: {'w0': 0.9723032246877376, 'w1': 0.1876754595124181}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:08,125] Trial 97 finished with value: 0.03693439545332289 and parameters: {'w0': 0.9716752929631931, 'w1': 0.08944383274355361}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:08,140] Trial 98 finished with value: 0.03686861971385991 and parameters: {'w0': 0.9894055309196679, 'w1': 0.1166383026141291}. Best is trial 32 with value: 0.036666443121464276.\n",
            "[I 2025-06-16 10:44:08,155] Trial 99 finished with value: 0.03679403964659744 and parameters: {'w0': 0.4861936275818654, 'w1': 0.18546863163104993}. Best is trial 32 with value: 0.036666443121464276.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 5): 0.9633\n",
            "\n",
            "--- Training combination ('lgbm', 'mlp', 'logreg') ---\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003172 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335535\n",
            "[LightGBM] [Info] Start training from score -3.552799\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.490314\n",
            "[LightGBM] [Info] Start training from score -3.098153\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.889398\n",
            "[LightGBM] [Info] Start training from score -3.745491\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -3.560449\n",
            "[LightGBM] [Info] Start training from score -3.296677\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.013314\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.864647\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.912613\n",
            "[LightGBM] [Info] Start training from score -2.909527\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Info] Start training from score -2.865236\n",
            "[LightGBM] [Info] Start training from score -3.521069\n",
            "[LightGBM] [Info] Start training from score -2.863175\n",
            "[LightGBM] [Info] Start training from score -3.557500\n",
            "[LightGBM] [Info] Start training from score -3.457276\n",
            "[LightGBM] [Info] Start training from score -3.779466\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted lgbm (fold 5): 0.9621\n",
            "F1-weighted mlp (fold 5): 0.9632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 10:44:33,718] A new study created in memory with name: no-name-44a91345-e9ae-402e-9c20-c35fbc3e8709\n",
            "[I 2025-06-16 10:44:33,728] Trial 0 finished with value: 0.036508111490303086 and parameters: {'w0': 0.43673125514497513, 'w1': 0.8602880669520722, 'w2': 0.32934845146736613}. Best is trial 0 with value: 0.036508111490303086.\n",
            "[I 2025-06-16 10:44:33,736] Trial 1 finished with value: 0.0363543171863312 and parameters: {'w0': 0.6805147776389872, 'w1': 0.5755190951124847, 'w2': 0.3772183459968519}. Best is trial 1 with value: 0.0363543171863312.\n",
            "[I 2025-06-16 10:44:33,745] Trial 2 finished with value: 0.03691282644420024 and parameters: {'w0': 0.07224195384203846, 'w1': 0.8987244237011616, 'w2': 0.8222664336094931}. Best is trial 1 with value: 0.0363543171863312.\n",
            "[I 2025-06-16 10:44:33,753] Trial 3 finished with value: 0.0358074958517951 and parameters: {'w0': 0.9481397493567544, 'w1': 0.77603442140684, 'w2': 0.21048322917522322}. Best is trial 3 with value: 0.0358074958517951.\n",
            "[I 2025-06-16 10:44:33,768] Trial 4 finished with value: 0.03629914378247878 and parameters: {'w0': 0.23920173232409758, 'w1': 0.0803581017874434, 'w2': 0.6416733627990058}. Best is trial 3 with value: 0.0358074958517951.\n",
            "[I 2025-06-16 10:44:33,776] Trial 5 finished with value: 0.0355978583484069 and parameters: {'w0': 0.8986590136886046, 'w1': 0.17082022682351472, 'w2': 0.6268638046994396}. Best is trial 5 with value: 0.0355978583484069.\n",
            "[I 2025-06-16 10:44:33,785] Trial 6 finished with value: 0.03641431098608816 and parameters: {'w0': 0.6475011294147852, 'w1': 0.5598130409050381, 'w2': 0.25910971420182594}. Best is trial 5 with value: 0.0355978583484069.\n",
            "[I 2025-06-16 10:44:33,793] Trial 7 finished with value: 0.03650058848540383 and parameters: {'w0': 0.6699115941418867, 'w1': 0.7367120519642165, 'w2': 0.6870942386088709}. Best is trial 5 with value: 0.0355978583484069.\n",
            "[I 2025-06-16 10:44:33,801] Trial 8 finished with value: 0.036982226894997305 and parameters: {'w0': 0.055378107223689965, 'w1': 0.6333257127824785, 'w2': 0.6565224807091783}. Best is trial 5 with value: 0.0355978583484069.\n",
            "[I 2025-06-16 10:44:33,810] Trial 9 finished with value: 0.036365675406000886 and parameters: {'w0': 0.22237053338744317, 'w1': 0.3137675380989954, 'w2': 0.10856737215623169}. Best is trial 5 with value: 0.0355978583484069.\n",
            "[I 2025-06-16 10:44:33,833] Trial 10 finished with value: 0.03580924594301593 and parameters: {'w0': 0.9653561933851745, 'w1': 0.021288825806232703, 'w2': 0.9996223068598888}. Best is trial 5 with value: 0.0355978583484069.\n",
            "[I 2025-06-16 10:44:33,850] Trial 11 finished with value: 0.03632693549506982 and parameters: {'w0': 0.9916192830517937, 'w1': 0.302748261968275, 'w2': 0.006089644187195042}. Best is trial 5 with value: 0.0355978583484069.\n",
            "[I 2025-06-16 10:44:33,869] Trial 12 finished with value: 0.036083948560491796 and parameters: {'w0': 0.8184650036372018, 'w1': 0.3594569751322864, 'w2': 0.48786122359334966}. Best is trial 5 with value: 0.0355978583484069.\n",
            "[I 2025-06-16 10:44:33,888] Trial 13 finished with value: 0.035528468315953465 and parameters: {'w0': 0.8208915427220952, 'w1': 0.15186662056428013, 'w2': 0.49694263952476203}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:33,906] Trial 14 finished with value: 0.03566500425552521 and parameters: {'w0': 0.8078342643079014, 'w1': 0.16481795093161183, 'w2': 0.5118074684253239}. Best is trial 13 with value: 0.035528468315953465.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-weighted logreg (fold 5): 0.9626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:44:33,925] Trial 15 finished with value: 0.03581452735170809 and parameters: {'w0': 0.4953215369187597, 'w1': 0.2339184260012041, 'w2': 0.5264863907890406}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:33,946] Trial 16 finished with value: 0.035947930185280974 and parameters: {'w0': 0.8307507328605581, 'w1': 0.4401743331704516, 'w2': 0.8212301282205665}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:33,963] Trial 17 finished with value: 0.03594683808746735 and parameters: {'w0': 0.59256514620476, 'w1': 0.18549022697544634, 'w2': 0.7920778226945423}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:33,982] Trial 18 finished with value: 0.035679805559879374 and parameters: {'w0': 0.8638588360174722, 'w1': 0.4366840434157915, 'w2': 0.4255415186094591}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,001] Trial 19 finished with value: 0.036092008793450536 and parameters: {'w0': 0.37064019231366613, 'w1': 0.10347346936603045, 'w2': 0.9929358672267296}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,019] Trial 20 finished with value: 0.035794211252246466 and parameters: {'w0': 0.7590497175217766, 'w1': 0.03642056900186719, 'w2': 0.5858552874762992}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,037] Trial 21 finished with value: 0.03573015572202176 and parameters: {'w0': 0.7601701545140882, 'w1': 0.15686814440259186, 'w2': 0.47261393272671604}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,056] Trial 22 finished with value: 0.03592915473743763 and parameters: {'w0': 0.8820170340095475, 'w1': 0.22131009059704865, 'w2': 0.5536805865867209}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,075] Trial 23 finished with value: 0.03601413448272894 and parameters: {'w0': 0.7440976467431802, 'w1': 0.13394462534637638, 'w2': 0.7334887031178506}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,093] Trial 24 finished with value: 0.03601076233713951 and parameters: {'w0': 0.5783842512264241, 'w1': 0.24569351390601785, 'w2': 0.339454996868764}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,112] Trial 25 finished with value: 0.03588095336400443 and parameters: {'w0': 0.8822873080665312, 'w1': 0.3943889725062108, 'w2': 0.42905926775653225}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,131] Trial 26 finished with value: 0.03600239820981421 and parameters: {'w0': 0.9165549376015463, 'w1': 0.2982896982726557, 'w2': 0.596381719580522}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,148] Trial 27 finished with value: 0.03567130029544152 and parameters: {'w0': 0.7639959280194893, 'w1': 0.010080441926251904, 'w2': 0.736881215573829}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,167] Trial 28 finished with value: 0.03664260622969129 and parameters: {'w0': 0.5440724409389557, 'w1': 0.9792604714993394, 'w2': 0.900618402819766}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,185] Trial 29 finished with value: 0.03566274070271547 and parameters: {'w0': 0.3617314644858651, 'w1': 0.08065934206438549, 'w2': 0.23737784031803733}. Best is trial 13 with value: 0.035528468315953465.\n",
            "[I 2025-06-16 10:44:34,203] Trial 30 finished with value: 0.0353977638417845 and parameters: {'w0': 0.4020574128754299, 'w1': 0.1000952713095852, 'w2': 0.20810282173521272}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,222] Trial 31 finished with value: 0.03566236614250351 and parameters: {'w0': 0.3899146994221695, 'w1': 0.09157851734576254, 'w2': 0.23534618576148933}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,241] Trial 32 finished with value: 0.03592391818165763 and parameters: {'w0': 0.42036249323386465, 'w1': 0.07682223627730721, 'w2': 0.1466904678859695}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,262] Trial 33 finished with value: 0.03574033770381857 and parameters: {'w0': 0.29551842750398505, 'w1': 0.19899179507542167, 'w2': 0.05616411145703798}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,281] Trial 34 finished with value: 0.0360887043782675 and parameters: {'w0': 0.4424358365263191, 'w1': 0.27655884013463883, 'w2': 0.293638172142933}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,301] Trial 35 finished with value: 0.03650102498551522 and parameters: {'w0': 0.14117668730591648, 'w1': 0.1409076712321709, 'w2': 0.16803570016303218}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,322] Trial 36 finished with value: 0.03622183456739525 and parameters: {'w0': 0.2834065663164784, 'w1': 0.003679147644309211, 'w2': 0.38181127721158603}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,341] Trial 37 finished with value: 0.036297510555641344 and parameters: {'w0': 0.4818662116728157, 'w1': 0.5235228630817935, 'w2': 0.29302430945423136}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,364] Trial 38 finished with value: 0.03705049162445195 and parameters: {'w0': 0.14839111849317052, 'w1': 0.6363130731573665, 'w2': 0.18439713900986865}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,382] Trial 39 finished with value: 0.036524267533053933 and parameters: {'w0': 0.6296365746040377, 'w1': 0.10136788171511751, 'w2': 0.07433948776073956}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,400] Trial 40 finished with value: 0.035658305056434636 and parameters: {'w0': 0.7103229875834426, 'w1': 0.05358809311042821, 'w2': 0.36261214867033886}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,418] Trial 41 finished with value: 0.03587711408058958 and parameters: {'w0': 0.37814672408247374, 'w1': 0.0561833518186517, 'w2': 0.3602077838670521}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,437] Trial 42 finished with value: 0.03558587100564059 and parameters: {'w0': 0.7023806450245084, 'w1': 0.12981783668062252, 'w2': 0.2849915489294873}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,456] Trial 43 finished with value: 0.036087773300558124 and parameters: {'w0': 0.6922214117518476, 'w1': 0.35242188509579675, 'w2': 0.42023407495471066}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,475] Trial 44 finished with value: 0.03553175264621278 and parameters: {'w0': 0.7037362294955931, 'w1': 0.1874635710832079, 'w2': 0.3089635664521083}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,494] Trial 45 finished with value: 0.03572811112936847 and parameters: {'w0': 0.9553897279445521, 'w1': 0.2554627083113722, 'w2': 0.3056627215688283}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,513] Trial 46 finished with value: 0.03635108135902265 and parameters: {'w0': 0.6509554048247644, 'w1': 0.19761382705238945, 'w2': 0.6591827331349948}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,533] Trial 47 finished with value: 0.03638534209797217 and parameters: {'w0': 0.8019366478193711, 'w1': 0.1296560844375952, 'w2': 0.12124925812001419}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,552] Trial 48 finished with value: 0.03561169558063404 and parameters: {'w0': 0.545068597074014, 'w1': 0.3519431035203985, 'w2': 0.21233509480978852}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,571] Trial 49 finished with value: 0.0361470486584522 and parameters: {'w0': 0.9178479488916691, 'w1': 0.8040716084093414, 'w2': 0.2597711629209348}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,589] Trial 50 finished with value: 0.03546411846040842 and parameters: {'w0': 0.8424483608193222, 'w1': 0.17793797076646056, 'w2': 0.48572593225246535}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,608] Trial 51 finished with value: 0.03546249144201874 and parameters: {'w0': 0.8362073493770267, 'w1': 0.17164769031403482, 'w2': 0.4673550641125891}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,631] Trial 52 finished with value: 0.03552975200612862 and parameters: {'w0': 0.851117412944813, 'w1': 0.1729455729420059, 'w2': 0.47219767248450567}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,651] Trial 53 finished with value: 0.03546295946912992 and parameters: {'w0': 0.8346353138281919, 'w1': 0.20985978230389352, 'w2': 0.46657156149257445}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,670] Trial 54 finished with value: 0.03552666728370035 and parameters: {'w0': 0.8333765181265173, 'w1': 0.2170878853256326, 'w2': 0.46469175137774027}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,689] Trial 55 finished with value: 0.03626603032966147 and parameters: {'w0': 0.7963598001775688, 'w1': 0.22335796114138987, 'w2': 0.5441257063172913}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,708] Trial 56 finished with value: 0.03594085842576833 and parameters: {'w0': 0.8292994887248067, 'w1': 0.3077568039873986, 'w2': 0.4524691342663289}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,727] Trial 57 finished with value: 0.03552811301455716 and parameters: {'w0': 0.9817798809411618, 'w1': 0.2619884290384136, 'w2': 0.5092320394907812}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,746] Trial 58 finished with value: 0.035931151396573546 and parameters: {'w0': 0.9343196458247747, 'w1': 0.2588190592145165, 'w2': 0.5862313733057147}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,765] Trial 59 finished with value: 0.035809997499700374 and parameters: {'w0': 0.9867234822167892, 'w1': 0.40069957826939945, 'w2': 0.4016518501318112}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,784] Trial 60 finished with value: 0.03574854467043864 and parameters: {'w0': 0.9917429580206198, 'w1': 0.48018238139382574, 'w2': 0.5297363990310006}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,803] Trial 61 finished with value: 0.03572602026064575 and parameters: {'w0': 0.8613837553725959, 'w1': 0.2218077557919782, 'w2': 0.5009046191338598}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,822] Trial 62 finished with value: 0.035739513529841616 and parameters: {'w0': 0.8878434018729511, 'w1': 0.2840006138922322, 'w2': 0.4484024737796512}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,841] Trial 63 finished with value: 0.03607305099034652 and parameters: {'w0': 0.7802866180624335, 'w1': 0.15612038278803764, 'w2': 0.6178342481950408}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,860] Trial 64 finished with value: 0.035597988405930425 and parameters: {'w0': 0.7281458691426832, 'w1': 0.11393713803137262, 'w2': 0.5555196645291895}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,879] Trial 65 finished with value: 0.03566104610664067 and parameters: {'w0': 0.8329228794337581, 'w1': 0.20713107169423278, 'w2': 0.48335183150455285}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,900] Trial 66 finished with value: 0.03565839499947099 and parameters: {'w0': 0.9617846084417556, 'w1': 0.16415871250832859, 'w2': 0.5157466379257737}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,923] Trial 67 finished with value: 0.03586069581004214 and parameters: {'w0': 0.9079021770191272, 'w1': 0.0447809640010991, 'w2': 0.6854475022480171}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,943] Trial 68 finished with value: 0.036062652527561245 and parameters: {'w0': 0.8495201147953935, 'w1': 0.23560651788351045, 'w2': 0.5613479631219601}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,966] Trial 69 finished with value: 0.03581149711502063 and parameters: {'w0': 0.9374880362241172, 'w1': 0.3358863087487443, 'w2': 0.45563587679140183}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:34,985] Trial 70 finished with value: 0.03574154866441548 and parameters: {'w0': 0.7877371061390077, 'w1': 0.27008858794832413, 'w2': 0.401861368786358}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,004] Trial 71 finished with value: 0.03546249144201874 and parameters: {'w0': 0.8458944374434587, 'w1': 0.17059256815862392, 'w2': 0.4841202966877127}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,024] Trial 72 finished with value: 0.03585689589957419 and parameters: {'w0': 0.8850906513258381, 'w1': 0.08051415482261608, 'w2': 0.5005104364355866}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,043] Trial 73 finished with value: 0.036142416393420085 and parameters: {'w0': 0.7529409603721847, 'w1': 0.15048138267951738, 'w2': 0.6285537037176728}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,062] Trial 74 finished with value: 0.03712727973966756 and parameters: {'w0': 0.010659517067302393, 'w1': 0.19196503954879496, 'w2': 0.44020334442772213}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,081] Trial 75 finished with value: 0.03592120661891873 and parameters: {'w0': 0.8316608995816668, 'w1': 0.10182657182530773, 'w2': 0.33422184266028193}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,100] Trial 76 finished with value: 0.035801419439455695 and parameters: {'w0': 0.7340480194065946, 'w1': 0.11862752513100705, 'w2': 0.5715242494736021}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,119] Trial 77 finished with value: 0.03615119449299686 and parameters: {'w0': 0.33368717927381547, 'w1': 0.03070770600759254, 'w2': 0.41163674315922455}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,138] Trial 78 finished with value: 0.035947930185280974 and parameters: {'w0': 0.46617517709665024, 'w1': 0.23985708389671234, 'w2': 0.4797996951791204}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,157] Trial 79 finished with value: 0.03565274427113174 and parameters: {'w0': 0.8697857075953159, 'w1': 0.0666927637970486, 'w2': 0.6046373278848922}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,177] Trial 80 finished with value: 0.03592877486282864 and parameters: {'w0': 0.6663655669144517, 'w1': 0.17838850144482699, 'w2': 0.38671123575699273}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,196] Trial 81 finished with value: 0.035398314273770826 and parameters: {'w0': 0.818846902574954, 'w1': 0.16976840811954783, 'w2': 0.46766034940394385}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,215] Trial 82 finished with value: 0.03599586124069176 and parameters: {'w0': 0.8115147663348455, 'w1': 0.2076180951885342, 'w2': 0.5245170261294979}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,234] Trial 83 finished with value: 0.03572432641220458 and parameters: {'w0': 0.9043242462074891, 'w1': 0.14236517225602166, 'w2': 0.46406980554696997}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,253] Trial 84 finished with value: 0.03615515962651794 and parameters: {'w0': 0.7648336572872955, 'w1': 0.6274475108726534, 'w2': 0.49562588625917814}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,275] Trial 85 finished with value: 0.03587934715235053 and parameters: {'w0': 0.7825762710470902, 'w1': 0.3262667261935841, 'w2': 0.3646482640504997}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,295] Trial 86 finished with value: 0.0355357558324495 and parameters: {'w0': 0.9286920485504567, 'w1': 0.2804139152280056, 'w2': 0.4228750319468202}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,314] Trial 87 finished with value: 0.03566500425552521 and parameters: {'w0': 0.8545924765667068, 'w1': 0.1715483498681505, 'w2': 0.5377060483800343}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,333] Trial 88 finished with value: 0.03586032042993714 and parameters: {'w0': 0.8263416351938485, 'w1': 0.12325564335562796, 'w2': 0.5193555706249207}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,352] Trial 89 finished with value: 0.036393442030766776 and parameters: {'w0': 0.8063380262490014, 'w1': 0.21504511723550968, 'w2': 0.027373563903719256}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,372] Trial 90 finished with value: 0.03579513654959865 and parameters: {'w0': 0.9702326062905549, 'w1': 0.2465529056144548, 'w2': 0.5770791252207487}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,391] Trial 91 finished with value: 0.035398314273770826 and parameters: {'w0': 0.858495181250731, 'w1': 0.17952263685899386, 'w2': 0.486962844290659}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,411] Trial 92 finished with value: 0.03572350951293324 and parameters: {'w0': 0.8777764334211727, 'w1': 0.14854487172985356, 'w2': 0.475783883235084}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,430] Trial 93 finished with value: 0.03558412670955413 and parameters: {'w0': 0.8993597494712399, 'w1': 0.10210147607636329, 'w2': 0.43989323142061765}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,451] Trial 94 finished with value: 0.03553080005247233 and parameters: {'w0': 0.8395387003624035, 'w1': 0.17824994501525845, 'w2': 0.4993513348346421}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,472] Trial 95 finished with value: 0.0353977638417845 and parameters: {'w0': 0.7719860388452409, 'w1': 0.197628673659694, 'w2': 0.3922593762432164}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,491] Trial 96 finished with value: 0.03608839793584051 and parameters: {'w0': 0.5207382071319926, 'w1': 0.2953810132146313, 'w2': 0.38902332698200354}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,511] Trial 97 finished with value: 0.0358828476651063 and parameters: {'w0': 0.7800876846163157, 'w1': 0.3862201085233548, 'w2': 0.42516886474774146}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,530] Trial 98 finished with value: 0.03615230017830451 and parameters: {'w0': 0.43045219975761906, 'w1': 0.19514193715194264, 'w2': 0.35502187676123353}. Best is trial 30 with value: 0.0353977638417845.\n",
            "[I 2025-06-16 10:44:35,550] Trial 99 finished with value: 0.03635373780112483 and parameters: {'w0': 0.7255642017030505, 'w1': 0.2663216354126482, 'w2': 0.5472840003227223}. Best is trial 30 with value: 0.0353977638417845.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weighted fusion F1 (fold 5): 0.9646\n",
            "\n",
            "=== Combo ('lgbm',) CV mean F1: 0.9644 ± 0.0012 ===\n",
            "\n",
            "=== Combo ('mlp',) CV mean F1: 0.9655 ± 0.0014 ===\n",
            "\n",
            "=== Combo ('logreg',) CV mean F1: 0.9645 ± 0.0011 ===\n",
            "\n",
            "=== Combo ('lgbm', 'mlp') CV mean F1: 0.9666 ± 0.0013 ===\n",
            "\n",
            "=== Combo ('lgbm', 'logreg') CV mean F1: 0.9664 ± 0.0011 ===\n",
            "\n",
            "=== Combo ('mlp', 'logreg') CV mean F1: 0.9656 ± 0.0014 ===\n",
            "\n",
            "=== Combo ('lgbm', 'mlp', 'logreg') CV mean F1: 0.9665 ± 0.0013 ===\n",
            "\n",
            "=== Meilleure combinaison selon CV: ('lgbm', 'mlp') ===\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004167 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 74447, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.335905\n",
            "[LightGBM] [Info] Start training from score -3.553027\n",
            "[LightGBM] [Info] Start training from score -3.779459\n",
            "[LightGBM] [Info] Start training from score -3.779459\n",
            "[LightGBM] [Info] Start training from score -3.490308\n",
            "[LightGBM] [Info] Start training from score -3.098146\n",
            "[LightGBM] [Info] Start training from score -3.779459\n",
            "[LightGBM] [Info] Start training from score -2.889633\n",
            "[LightGBM] [Info] Start training from score -3.745342\n",
            "[LightGBM] [Info] Start training from score -2.863168\n",
            "[LightGBM] [Info] Start training from score -3.779459\n",
            "[LightGBM] [Info] Start training from score -3.560087\n",
            "[LightGBM] [Info] Start training from score -3.296670\n",
            "[LightGBM] [Info] Start training from score -2.863168\n",
            "[LightGBM] [Info] Start training from score -3.013444\n",
            "[LightGBM] [Info] Start training from score -3.779459\n",
            "[LightGBM] [Info] Start training from score -2.864581\n",
            "[LightGBM] [Info] Start training from score -3.779459\n",
            "[LightGBM] [Info] Start training from score -2.912359\n",
            "[LightGBM] [Info] Start training from score -2.909397\n",
            "[LightGBM] [Info] Start training from score -3.779459\n",
            "[LightGBM] [Info] Start training from score -2.865288\n",
            "[LightGBM] [Info] Start training from score -3.521176\n",
            "[LightGBM] [Info] Start training from score -2.863168\n",
            "[LightGBM] [Info] Start training from score -3.557728\n",
            "[LightGBM] [Info] Start training from score -3.456950\n",
            "[LightGBM] [Info] Start training from score -3.779459\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final train F1 lgbm: 0.9012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 10:45:06,080] A new study created in memory with name: no-name-3b4956d6-47fc-44af-a67e-3ad4e183f19f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final train F1 mlp: 0.8996\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e455079d782c499ca98f78a9b89ccafa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 10:45:06,097] Trial 0 finished with value: 0.09998261245190809 and parameters: {'w0': 0.15430146512873533, 'w1': 0.628790347414749}. Best is trial 0 with value: 0.09998261245190809.\n",
            "[I 2025-06-16 10:45:06,104] Trial 1 finished with value: 0.0995302150173174 and parameters: {'w0': 0.2862990827056222, 'w1': 0.19873721210566053}. Best is trial 1 with value: 0.0995302150173174.\n",
            "[I 2025-06-16 10:45:06,112] Trial 2 finished with value: 0.10003055977180608 and parameters: {'w0': 0.2923789330550216, 'w1': 0.5815917229423447}. Best is trial 1 with value: 0.0995302150173174.\n",
            "[I 2025-06-16 10:45:06,120] Trial 3 finished with value: 0.09994346432691326 and parameters: {'w0': 0.049854283821418655, 'w1': 0.1264442764879503}. Best is trial 1 with value: 0.0995302150173174.\n",
            "[I 2025-06-16 10:45:06,127] Trial 4 finished with value: 0.09777601012746417 and parameters: {'w0': 0.8088561548299071, 'w1': 0.06316666962180861}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,134] Trial 5 finished with value: 0.10010871489480644 and parameters: {'w0': 0.46143411608446305, 'w1': 0.9361162282612939}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,142] Trial 6 finished with value: 0.09834464823701228 and parameters: {'w0': 0.9002661962408985, 'w1': 0.13716059789552137}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,149] Trial 7 finished with value: 0.09934235555671089 and parameters: {'w0': 0.6993019239336379, 'w1': 0.3229513301257263}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,157] Trial 8 finished with value: 0.09967260968431446 and parameters: {'w0': 0.09625935589393475, 'w1': 0.08884151030489118}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,165] Trial 9 finished with value: 0.09945510558375792 and parameters: {'w0': 0.6253124105527689, 'w1': 0.5704487002727934}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,180] Trial 10 finished with value: 0.09897173666553816 and parameters: {'w0': 0.9858839764240184, 'w1': 0.37073757939144697}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,195] Trial 11 finished with value: 0.09899056919903482 and parameters: {'w0': 0.9730152992160397, 'w1': 0.0036506447507886203}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,211] Trial 12 finished with value: 0.09926395668375354 and parameters: {'w0': 0.8291739731079948, 'w1': 0.28442306139219165}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,224] Trial 13 finished with value: 0.09898625416124596 and parameters: {'w0': 0.7900494103981511, 'w1': 0.008852158012071287}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,239] Trial 14 finished with value: 0.09994683870452958 and parameters: {'w0': 0.5447316841151368, 'w1': 0.7394903637861722}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,254] Trial 15 finished with value: 0.09926886239966948 and parameters: {'w0': 0.8471705766341842, 'w1': 0.4387466576114294}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,275] Trial 16 finished with value: 0.09914940711929499 and parameters: {'w0': 0.729898999030606, 'w1': 0.20078848678447897}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,296] Trial 17 finished with value: 0.09922640344799394 and parameters: {'w0': 0.9106727945469864, 'w1': 0.24259826922492256}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,311] Trial 18 finished with value: 0.09900484676008903 and parameters: {'w0': 0.448821266191579, 'w1': 0.10845070516011546}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,326] Trial 19 finished with value: 0.0991561237644415 and parameters: {'w0': 0.5842552377854907, 'w1': 0.43592926890923267}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,341] Trial 20 finished with value: 0.09995042168425827 and parameters: {'w0': 0.690151247155815, 'w1': 0.7930586881091486}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,356] Trial 21 finished with value: 0.09904402398947254 and parameters: {'w0': 0.9796860226109647, 'w1': 0.3265863539647976}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,371] Trial 22 finished with value: 0.09926835304435921 and parameters: {'w0': 0.8993448490065411, 'w1': 0.40706068945022955}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,389] Trial 23 finished with value: 0.09856346675218086 and parameters: {'w0': 0.9132129469146035, 'w1': 0.1512863856381147}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,411] Trial 24 finished with value: 0.09892078312646657 and parameters: {'w0': 0.7739161760353407, 'w1': 0.16345461023436375}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,428] Trial 25 finished with value: 0.09784967435219116 and parameters: {'w0': 0.8890795600752293, 'w1': 0.06424110675828801}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,445] Trial 26 finished with value: 0.09864055236435243 and parameters: {'w0': 0.6478637499444473, 'w1': 0.028379574993912526}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,465] Trial 27 finished with value: 0.09784967435219116 and parameters: {'w0': 0.8427610898342526, 'w1': 0.06214351077098918}. Best is trial 4 with value: 0.09777601012746417.\n",
            "[I 2025-06-16 10:45:06,484] Trial 28 finished with value: 0.09762662136390299 and parameters: {'w0': 0.7951608592766827, 'w1': 0.08657975214483671}. Best is trial 28 with value: 0.09762662136390299.\n",
            "[I 2025-06-16 10:45:06,506] Trial 29 finished with value: 0.0991561237644415 and parameters: {'w0': 0.3601593987000362, 'w1': 0.27034854733304614}. Best is trial 28 with value: 0.09762662136390299.\n",
            "[I 2025-06-16 10:45:06,522] Trial 30 finished with value: 0.09981493481898052 and parameters: {'w0': 0.7601880298068964, 'w1': 0.49274478360679824}. Best is trial 28 with value: 0.09762662136390299.\n",
            "[I 2025-06-16 10:45:06,541] Trial 31 finished with value: 0.09784967435219116 and parameters: {'w0': 0.8292113578600294, 'w1': 0.06261595283536797}. Best is trial 28 with value: 0.09762662136390299.\n",
            "[I 2025-06-16 10:45:06,555] Trial 32 finished with value: 0.09792785510380664 and parameters: {'w0': 0.8504832311565573, 'w1': 0.06460417448382041}. Best is trial 28 with value: 0.09762662136390299.\n",
            "[I 2025-06-16 10:45:06,571] Trial 33 finished with value: 0.09929328478857335 and parameters: {'w0': 0.6581539110567718, 'w1': 0.19000398411591005}. Best is trial 28 with value: 0.09762662136390299.\n",
            "[I 2025-06-16 10:45:06,587] Trial 34 finished with value: 0.09755259013788586 and parameters: {'w0': 0.7832064723893846, 'w1': 0.07584928835133053}. Best is trial 34 with value: 0.09755259013788586.\n",
            "[I 2025-06-16 10:45:06,604] Trial 35 finished with value: 0.09912099664323115 and parameters: {'w0': 0.7472839638332323, 'w1': 0.2310578494146692}. Best is trial 34 with value: 0.09755259013788586.\n",
            "[I 2025-06-16 10:45:06,620] Trial 36 finished with value: 0.09926835304435921 and parameters: {'w0': 0.22903139189280053, 'w1': 0.1039909800339543}. Best is trial 34 with value: 0.09755259013788586.\n",
            "[I 2025-06-16 10:45:06,636] Trial 37 finished with value: 0.0991458051121673 and parameters: {'w0': 0.562992681135549, 'w1': 0.1604976129518976}. Best is trial 34 with value: 0.09755259013788586.\n",
            "[I 2025-06-16 10:45:06,653] Trial 38 finished with value: 0.09973074716606656 and parameters: {'w0': 0.925578776303159, 'w1': 0.9851997456693588}. Best is trial 34 with value: 0.09755259013788586.\n",
            "[I 2025-06-16 10:45:06,668] Trial 39 finished with value: 0.09900477883070835 and parameters: {'w0': 0.4902122381129163, 'w1': 0.11676237457158302}. Best is trial 34 with value: 0.09755259013788586.\n",
            "[I 2025-06-16 10:45:06,684] Trial 40 finished with value: 0.09824395700478017 and parameters: {'w0': 0.6982170977016497, 'w1': 0.03521442198423157}. Best is trial 34 with value: 0.09755259013788586.\n",
            "[I 2025-06-16 10:45:06,699] Trial 41 finished with value: 0.09740209119242405 and parameters: {'w0': 0.8000436303994439, 'w1': 0.06724729575358492}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,717] Trial 42 finished with value: 0.09884606815212371 and parameters: {'w0': 0.8031728747814896, 'w1': 0.000618091646031535}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,734] Trial 43 finished with value: 0.09754655996921047 and parameters: {'w0': 0.8902879333395807, 'w1': 0.08447323558608594}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,750] Trial 44 finished with value: 0.0989996803168205 and parameters: {'w0': 0.9489770150915392, 'w1': 0.20473873668001272}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,767] Trial 45 finished with value: 0.09886665008648898 and parameters: {'w0': 0.7232483924213096, 'w1': 0.13006166575556083}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,782] Trial 46 finished with value: 0.09929353564671672 and parameters: {'w0': 0.7956243322322997, 'w1': 0.6630949918882243}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,798] Trial 47 finished with value: 0.09950099806967394 and parameters: {'w0': 0.6152948405944636, 'w1': 0.3007323792651928}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,814] Trial 48 finished with value: 0.09762588675120554 and parameters: {'w0': 0.8743380770849867, 'w1': 0.08956839011733642}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,830] Trial 49 finished with value: 0.0976346864907075 and parameters: {'w0': 0.8782667875625533, 'w1': 0.0923924347492388}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,847] Trial 50 finished with value: 0.10006498203624947 and parameters: {'w0': 0.016788204696199793, 'w1': 0.23653204679225784}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,863] Trial 51 finished with value: 0.09777140941402851 and parameters: {'w0': 0.8643834672572694, 'w1': 0.10345743827083786}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,883] Trial 52 finished with value: 0.09908901356408106 and parameters: {'w0': 0.9435191736850291, 'w1': 0.1732538890549356}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,898] Trial 53 finished with value: 0.09848992186639804 and parameters: {'w0': 0.8865165611226855, 'w1': 0.04106780388417147}. Best is trial 41 with value: 0.09740209119242405.\n",
            "[I 2025-06-16 10:45:06,914] Trial 54 finished with value: 0.09739502326898974 and parameters: {'w0': 0.9908603783552798, 'w1': 0.09237393219669987}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:06,931] Trial 55 finished with value: 0.09792397479532522 and parameters: {'w0': 0.9889244874353769, 'w1': 0.13225587716899434}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:06,948] Trial 56 finished with value: 0.0990781415689973 and parameters: {'w0': 0.9645000394613523, 'w1': 0.21149337184057082}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:06,964] Trial 57 finished with value: 0.0991873172001545 and parameters: {'w0': 0.9944503068807424, 'w1': 0.34366563399203093}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:06,980] Trial 58 finished with value: 0.09904831060169106 and parameters: {'w0': 0.8027839696980803, 'w1': 0.26344797800452074}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:06,997] Trial 59 finished with value: 0.09959857084779689 and parameters: {'w0': 0.9369291305784552, 'w1': 0.8716889876497408}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,012] Trial 60 finished with value: 0.09878250109234288 and parameters: {'w0': 0.7699371784203004, 'w1': 0.017602096904222875}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,028] Trial 61 finished with value: 0.09755259013788586 and parameters: {'w0': 0.868414331636358, 'w1': 0.08289748758930245}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,048] Trial 62 finished with value: 0.09739762217408443 and parameters: {'w0': 0.8326753498120694, 'w1': 0.07892471995667175}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,063] Trial 63 finished with value: 0.09864052669851953 and parameters: {'w0': 0.8300028196186577, 'w1': 0.14069349192008906}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,079] Trial 64 finished with value: 0.09748174761563855 and parameters: {'w0': 0.9181659179684227, 'w1': 0.07423670576209378}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,096] Trial 65 finished with value: 0.0983039001686854 and parameters: {'w0': 0.9168916155190459, 'w1': 0.049641555346624934}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,114] Trial 66 finished with value: 0.09878164080164176 and parameters: {'w0': 0.8592866584973967, 'w1': 0.17650467662402478}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,137] Trial 67 finished with value: 0.09740209119242405 and parameters: {'w0': 0.9539079312370087, 'w1': 0.08046226945891186}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,158] Trial 68 finished with value: 0.09907176569750487 and parameters: {'w0': 0.9486827980042238, 'w1': 0.007102835546527728}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,174] Trial 69 finished with value: 0.09973935683756519 and parameters: {'w0': 0.9147622111647097, 'w1': 0.5470929006951455}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,190] Trial 70 finished with value: 0.09834464823701228 and parameters: {'w0': 0.9651893517898608, 'w1': 0.1469006203408333}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,206] Trial 71 finished with value: 0.09770071218892074 and parameters: {'w0': 0.9987619220770074, 'w1': 0.07877979982810983}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,222] Trial 72 finished with value: 0.09848346100178618 and parameters: {'w0': 0.9006727709837532, 'w1': 0.03157775749314229}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,239] Trial 73 finished with value: 0.09805814479683006 and parameters: {'w0': 0.8243867121660662, 'w1': 0.11710320628082532}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,254] Trial 74 finished with value: 0.09762588675120554 and parameters: {'w0': 0.7405809233113488, 'w1': 0.07587757223340383}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,277] Trial 75 finished with value: 0.09792397479532522 and parameters: {'w0': 0.34747215429057426, 'w1': 0.04567214287989263}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,300] Trial 76 finished with value: 0.09820708845999648 and parameters: {'w0': 0.8589558953091578, 'w1': 0.12357383370690478}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,315] Trial 77 finished with value: 0.10008762569372842 and parameters: {'w0': 0.11951859939016896, 'w1': 0.18574977580228105}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,334] Trial 78 finished with value: 0.09762588675120554 and parameters: {'w0': 0.6735739404834917, 'w1': 0.06858153801668714}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,351] Trial 79 finished with value: 0.09856190394739728 and parameters: {'w0': 0.9621534042746938, 'w1': 0.15656402489273924}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,368] Trial 80 finished with value: 0.09833215858623112 and parameters: {'w0': 0.7104927608297871, 'w1': 0.026965296939740063}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,383] Trial 81 finished with value: 0.09762588675120554 and parameters: {'w0': 0.8876657675106449, 'w1': 0.08939085693973656}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,400] Trial 82 finished with value: 0.09791803989661585 and parameters: {'w0': 0.8204936513817161, 'w1': 0.09999436162836806}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,416] Trial 83 finished with value: 0.09823048326753148 and parameters: {'w0': 0.9312088505731746, 'w1': 0.055387329266127605}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,432] Trial 84 finished with value: 0.09891738999396082 and parameters: {'w0': 0.8726276343485119, 'w1': 0.0024845676354331436}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,448] Trial 85 finished with value: 0.09792397479532522 and parameters: {'w0': 0.8418615478151792, 'w1': 0.1107814404881548}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,465] Trial 86 finished with value: 0.09914940711929499 and parameters: {'w0': 0.7837136657675318, 'w1': 0.21603414943975704}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,482] Trial 87 finished with value: 0.09740209119242405 and parameters: {'w0': 0.9031444202578021, 'w1': 0.08141663943496001}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,502] Trial 88 finished with value: 0.09856346675218086 and parameters: {'w0': 0.9032508656364895, 'w1': 0.14901923324379338}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,517] Trial 89 finished with value: 0.09824395700478017 and parameters: {'w0': 0.9300119479925528, 'w1': 0.04641232641422157}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,532] Trial 90 finished with value: 0.09784967435219116 and parameters: {'w0': 0.9724976287151423, 'w1': 0.07350572812800461}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,547] Trial 91 finished with value: 0.09762662136390299 and parameters: {'w0': 0.8862493408360349, 'w1': 0.09755629981927091}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,563] Trial 92 finished with value: 0.09820708845999648 and parameters: {'w0': 0.8514265182496119, 'w1': 0.1228269982242756}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,586] Trial 93 finished with value: 0.09762588675120554 and parameters: {'w0': 0.810079679411877, 'w1': 0.08275074617843808}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,601] Trial 94 finished with value: 0.09839769269146081 and parameters: {'w0': 0.7610192320278072, 'w1': 0.02520262483008734}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,617] Trial 95 finished with value: 0.09930983375000135 and parameters: {'w0': 0.8726039022624765, 'w1': 0.634946617098483}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,633] Trial 96 finished with value: 0.09894526118457192 and parameters: {'w0': 0.912370985738952, 'w1': 0.16471895951547857}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,648] Trial 97 finished with value: 0.09798483970653049 and parameters: {'w0': 0.9595351197392383, 'w1': 0.13463698526474}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,663] Trial 98 finished with value: 0.0980077999952842 and parameters: {'w0': 0.8400188656569156, 'w1': 0.05945030482939792}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,679] Trial 99 finished with value: 0.09899925143910326 and parameters: {'w0': 0.4274074696714423, 'w1': 0.09336856549952088}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,696] Trial 100 finished with value: 0.09869639342859005 and parameters: {'w0': 0.9444393535184112, 'w1': 0.18294924917055935}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,713] Trial 101 finished with value: 0.09754618480256116 and parameters: {'w0': 0.7873252636817899, 'w1': 0.07486794514551984}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,735] Trial 102 finished with value: 0.09864055236435243 and parameters: {'w0': 0.7869053876460516, 'w1': 0.03446303093320481}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,753] Trial 103 finished with value: 0.09791803989661585 and parameters: {'w0': 0.8917292471152268, 'w1': 0.10856613775776355}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,769] Trial 104 finished with value: 0.09747927486478158 and parameters: {'w0': 0.7474583615853212, 'w1': 0.06184720970939496}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,785] Trial 105 finished with value: 0.09740209119242405 and parameters: {'w0': 0.7287105111076713, 'w1': 0.06377925967348418}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,802] Trial 106 finished with value: 0.09748174761563855 and parameters: {'w0': 0.7206213426695838, 'w1': 0.05778229433375956}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,817] Trial 107 finished with value: 0.09740209119242405 and parameters: {'w0': 0.625124214097498, 'w1': 0.052307318600443575}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,833] Trial 108 finished with value: 0.0984033915360738 and parameters: {'w0': 0.6084117095187604, 'w1': 0.01662264257363811}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,849] Trial 109 finished with value: 0.09807729782344232 and parameters: {'w0': 0.7256022181837878, 'w1': 0.04993592808729214}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,865] Trial 110 finished with value: 0.09831925956555176 and parameters: {'w0': 0.6469480031760232, 'w1': 0.020768757125850197}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,881] Trial 111 finished with value: 0.09770071218892074 and parameters: {'w0': 0.6811500170077084, 'w1': 0.053622898828553776}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,896] Trial 112 finished with value: 0.09907176569750487 and parameters: {'w0': 0.7488048750189829, 'w1': 0.00397437399116958}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,912] Trial 113 finished with value: 0.09739502326898974 and parameters: {'w0': 0.7202478652991428, 'w1': 0.06712739935179535}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,927] Trial 114 finished with value: 0.09739762217408443 and parameters: {'w0': 0.6950015291205778, 'w1': 0.06548750622207183}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,943] Trial 115 finished with value: 0.098775767857609 and parameters: {'w0': 0.6577245928997911, 'w1': 0.12768840100921908}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,958] Trial 116 finished with value: 0.09822076499523524 and parameters: {'w0': 0.7119544418475511, 'w1': 0.03887867294571278}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,974] Trial 117 finished with value: 0.09740209119242405 and parameters: {'w0': 0.6341395589260538, 'w1': 0.0579217764495615}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:07,990] Trial 118 finished with value: 0.098775767857609 and parameters: {'w0': 0.5460083059862302, 'w1': 0.10654387438142882}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,006] Trial 119 finished with value: 0.09838100096864266 and parameters: {'w0': 0.5963562846619535, 'w1': 0.031489785706716435}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,023] Trial 120 finished with value: 0.10002181746197836 and parameters: {'w0': 0.566727753796329, 'w1': 0.7842576282098626}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,038] Trial 121 finished with value: 0.0976346864907075 and parameters: {'w0': 0.6300718955400939, 'w1': 0.06668620573576436}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,053] Trial 122 finished with value: 0.09740209119242405 and parameters: {'w0': 0.6700433645935873, 'w1': 0.058891426542824955}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,069] Trial 123 finished with value: 0.09878164080164176 and parameters: {'w0': 0.6898425292174748, 'w1': 0.14056072834681305}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,085] Trial 124 finished with value: 0.09879388265663602 and parameters: {'w0': 0.6317515950716283, 'w1': 0.11282712228697556}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,101] Trial 125 finished with value: 0.09891738999396082 and parameters: {'w0': 0.6707353585944437, 'w1': 0.0011996250315212606}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,117] Trial 126 finished with value: 0.09791803989661585 and parameters: {'w0': 0.7450806313183957, 'w1': 0.09129257494620037}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,136] Trial 127 finished with value: 0.09974131456509894 and parameters: {'w0': 0.7005914282945733, 'w1': 0.46152195545123265}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,153] Trial 128 finished with value: 0.09792491444368667 and parameters: {'w0': 0.5103047560143494, 'w1': 0.06618128776380472}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,170] Trial 129 finished with value: 0.09950099806967394 and parameters: {'w0': 0.7705689726116054, 'w1': 0.37714980576340157}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,187] Trial 130 finished with value: 0.09841021771859337 and parameters: {'w0': 0.6438203436911916, 'w1': 0.025224432991320427}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,204] Trial 131 finished with value: 0.0980077999952842 and parameters: {'w0': 0.7271130170559246, 'w1': 0.05130419717160936}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,221] Trial 132 finished with value: 0.09740209119242405 and parameters: {'w0': 0.7097211010265814, 'w1': 0.060041709401646035}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,238] Trial 133 finished with value: 0.09783862607063665 and parameters: {'w0': 0.6769149314600552, 'w1': 0.08172626681413522}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,257] Trial 134 finished with value: 0.09838100096864266 and parameters: {'w0': 0.7564157598902498, 'w1': 0.039318776266566616}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,274] Trial 135 finished with value: 0.09797510999498193 and parameters: {'w0': 0.6968983560575055, 'w1': 0.10317447392254636}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,291] Trial 136 finished with value: 0.0990781415689973 and parameters: {'w0': 0.5866551785168965, 'w1': 0.1285304226562749}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,309] Trial 137 finished with value: 0.09777140941402851 and parameters: {'w0': 0.6574867764732337, 'w1': 0.0764874296807046}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,326] Trial 138 finished with value: 0.09740209119242405 and parameters: {'w0': 0.731507758559501, 'w1': 0.06075826260704951}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,344] Trial 139 finished with value: 0.09832470287994477 and parameters: {'w0': 0.728349107043733, 'w1': 0.02194677893833303}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,363] Trial 140 finished with value: 0.09899925143910326 and parameters: {'w0': 0.7050559982075252, 'w1': 0.15394922612656972}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,382] Trial 141 finished with value: 0.09838100096864266 and parameters: {'w0': 0.984625825415559, 'w1': 0.051722020033964776}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,400] Trial 142 finished with value: 0.09755259013788586 and parameters: {'w0': 0.7400931603218203, 'w1': 0.07163387302877988}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,417] Trial 143 finished with value: 0.09777140941402851 and parameters: {'w0': 0.8045342430363565, 'w1': 0.09576670481236538}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,435] Trial 144 finished with value: 0.09838100096864266 and parameters: {'w0': 0.7729910111830652, 'w1': 0.04012904802571964}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,452] Trial 145 finished with value: 0.09856346675218086 and parameters: {'w0': 0.6823805067031458, 'w1': 0.11295362227437858}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,469] Trial 146 finished with value: 0.09777140941402851 and parameters: {'w0': 0.6163530680149385, 'w1': 0.07037561349039807}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,488] Trial 147 finished with value: 0.09886432039874504 and parameters: {'w0': 0.7536843070365652, 'w1': 0.016243279931159774}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,505] Trial 148 finished with value: 0.09791983210768451 and parameters: {'w0': 0.6659283493607071, 'w1': 0.08919172002840947}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,521] Trial 149 finished with value: 0.09740209119242405 and parameters: {'w0': 0.7137720648186029, 'w1': 0.059718016268702115}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,538] Trial 150 finished with value: 0.09784967435219116 and parameters: {'w0': 0.7149805827675364, 'w1': 0.05379787934238505}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,556] Trial 151 finished with value: 0.09822755889396817 and parameters: {'w0': 0.6905439488197356, 'w1': 0.03888389732466972}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,573] Trial 152 finished with value: 0.09740209119242405 and parameters: {'w0': 0.7339090249590119, 'w1': 0.06151322154380021}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,591] Trial 153 finished with value: 0.09856190394739728 and parameters: {'w0': 0.7345335848168221, 'w1': 0.12045567866454165}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,608] Trial 154 finished with value: 0.09740209119242405 and parameters: {'w0': 0.7091360523648096, 'w1': 0.06143081852266995}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,627] Trial 155 finished with value: 0.09806086873088882 and parameters: {'w0': 0.6379350660900258, 'w1': 0.0899820138787325}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,644] Trial 156 finished with value: 0.09855379276137477 and parameters: {'w0': 0.708256476979956, 'w1': 0.017936996356298057}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,661] Trial 157 finished with value: 0.09770071218892074 and parameters: {'w0': 0.6637330455581656, 'w1': 0.052648799854036255}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,684] Trial 158 finished with value: 0.09798483970653049 and parameters: {'w0': 0.6919301442583417, 'w1': 0.09637769576108467}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,705] Trial 159 finished with value: 0.09856190394739728 and parameters: {'w0': 0.21605716168807626, 'w1': 0.035032187235433984}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,721] Trial 160 finished with value: 0.09740209119242405 and parameters: {'w0': 0.7743374293594201, 'w1': 0.06993227337229688}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,737] Trial 161 finished with value: 0.09740209119242405 and parameters: {'w0': 0.8096201819065038, 'w1': 0.06939241005713029}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,753] Trial 162 finished with value: 0.09891738999396082 and parameters: {'w0': 0.7820625099060429, 'w1': 0.002290475474259937}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,771] Trial 163 finished with value: 0.09820708845999648 and parameters: {'w0': 0.7619594055110508, 'w1': 0.10993712230100826}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,787] Trial 164 finished with value: 0.09762620893549856 and parameters: {'w0': 0.7240608508296371, 'w1': 0.057551412503318494}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,809] Trial 165 finished with value: 0.09762662136390299 and parameters: {'w0': 0.7406336788247888, 'w1': 0.08069531831283178}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,826] Trial 166 finished with value: 0.09831243142719237 and parameters: {'w0': 0.7033730082774267, 'w1': 0.035965163565331644}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,843] Trial 167 finished with value: 0.09856190394739728 and parameters: {'w0': 0.8252519413666961, 'w1': 0.13211288653440065}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,867] Trial 168 finished with value: 0.09748174761563855 and parameters: {'w0': 0.794321579924322, 'w1': 0.06487659413282498}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,884] Trial 169 finished with value: 0.0995302150173174 and parameters: {'w0': 0.7668452719027009, 'w1': 0.5395699554314463}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,899] Trial 170 finished with value: 0.0979166800991379 and parameters: {'w0': 0.720323335994204, 'w1': 0.0923994642456902}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,916] Trial 171 finished with value: 0.09755627741195394 and parameters: {'w0': 0.6822858891113133, 'w1': 0.07143393156971319}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,931] Trial 172 finished with value: 0.0994396403420078 and parameters: {'w0': 0.8174893135707053, 'w1': 0.7099358771174762}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,947] Trial 173 finished with value: 0.09824395700478017 and parameters: {'w0': 0.8034690429078903, 'w1': 0.04051124117293321}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,963] Trial 174 finished with value: 0.09762588675120554 and parameters: {'w0': 0.7602613391979243, 'w1': 0.07625825322106632}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,979] Trial 175 finished with value: 0.0982221983294399 and parameters: {'w0': 0.9980686140305137, 'w1': 0.0577840990246152}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:08,998] Trial 176 finished with value: 0.09827436343219242 and parameters: {'w0': 0.7308281490625212, 'w1': 0.10873161379319882}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,015] Trial 177 finished with value: 0.09995020724725112 and parameters: {'w0': 0.7806459316673542, 'w1': 0.8922206538252659}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,034] Trial 178 finished with value: 0.0984877014595853 and parameters: {'w0': 0.646803599998309, 'w1': 0.023349156271388616}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,049] Trial 179 finished with value: 0.09792555484922782 and parameters: {'w0': 0.705282144493237, 'w1': 0.08812347173135963}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,066] Trial 180 finished with value: 0.09822755889396817 and parameters: {'w0': 0.8364687777352231, 'w1': 0.04726408553291764}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,084] Trial 181 finished with value: 0.09740209119242405 and parameters: {'w0': 0.7463527836428135, 'w1': 0.06554246494463414}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,104] Trial 182 finished with value: 0.09739762217408443 and parameters: {'w0': 0.7501542461659437, 'w1': 0.07044057652655558}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,127] Trial 183 finished with value: 0.09755627741195394 and parameters: {'w0': 0.9737088816605972, 'w1': 0.10171665765872344}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,147] Trial 184 finished with value: 0.09777140941402851 and parameters: {'w0': 0.6829847732598655, 'w1': 0.08025004847268916}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,164] Trial 185 finished with value: 0.09832470287994477 and parameters: {'w0': 0.7735957676877698, 'w1': 0.02390129091838543}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,186] Trial 186 finished with value: 0.09814916328263001 and parameters: {'w0': 0.7323745445652265, 'w1': 0.0490025081066669}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,206] Trial 187 finished with value: 0.09841722464904579 and parameters: {'w0': 0.8100437416576726, 'w1': 0.12436069707849534}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,223] Trial 188 finished with value: 0.09762662136390299 and parameters: {'w0': 0.6141911013652719, 'w1': 0.06710991642609554}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,241] Trial 189 finished with value: 0.09832047168350355 and parameters: {'w0': 0.6684446177431718, 'w1': 0.0328674422191007}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,259] Trial 190 finished with value: 0.09799511730288868 and parameters: {'w0': 0.7148425219854416, 'w1': 0.09668441464186879}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,275] Trial 191 finished with value: 0.09740209119242405 and parameters: {'w0': 0.7499176643264354, 'w1': 0.06826480932424242}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,293] Trial 192 finished with value: 0.0980077999952842 and parameters: {'w0': 0.7515428417051021, 'w1': 0.05343669120117899}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,311] Trial 193 finished with value: 0.09762588675120554 and parameters: {'w0': 0.7413657311512126, 'w1': 0.07424883745605965}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,327] Trial 194 finished with value: 0.09791803989661585 and parameters: {'w0': 0.7033516555441383, 'w1': 0.08595763086141525}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,344] Trial 195 finished with value: 0.09807025880326214 and parameters: {'w0': 0.7885148138746138, 'w1': 0.050047539990094085}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,363] Trial 196 finished with value: 0.09827436343219242 and parameters: {'w0': 0.7688225173228741, 'w1': 0.11503716971657042}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,380] Trial 197 finished with value: 0.09869578056779216 and parameters: {'w0': 0.9506413195703122, 'w1': 0.013816728834164023}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,398] Trial 198 finished with value: 0.09739762217408443 and parameters: {'w0': 0.7226898268554575, 'w1': 0.06814046208428572}. Best is trial 54 with value: 0.09739502326898974.\n",
            "[I 2025-06-16 10:45:09,416] Trial 199 finished with value: 0.09870383653634074 and parameters: {'w0': 0.7184427961916793, 'w1': 0.1445032015584112}. Best is trial 54 with value: 0.09739502326898974.\n",
            "\n",
            "=== Résultats finaux ===\n",
            "Combinaison utilisée : ('lgbm', 'mlp')\n",
            "F1-weighted final : 0.9026\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "                      Livres     0.7152    0.7259    0.7205       467\n",
            "                  Jeux Vidéo     0.8231    0.8537    0.8381       376\n",
            "     Accessoires jeux vidéos     0.9201    0.9600    0.9396       300\n",
            "       Jeux vidéo & Consoles     0.9966    0.9833    0.9899       300\n",
            "                   Figurines     0.8487    0.8254    0.8369       401\n",
            "              Cartes de jeux     0.9565    0.9646    0.9605       593\n",
            "Jeux de rôle et de figurines     0.9295    0.9667    0.9477       300\n",
            "             Jouets & Enfant     0.7745    0.7893    0.7818       731\n",
            "             Jeux de société     0.7597    0.6913    0.7239       311\n",
            "   Véhicules RC & miniatures     0.9760    0.9773    0.9767       750\n",
            "            Chaussettes bébé     1.0000    0.9933    0.9967       300\n",
            "            Sports & Loisirs     0.8710    0.8663    0.8686       374\n",
            "                Puériculture     0.8679    0.8519    0.8598       486\n",
            "                      Maison     0.8889    0.8853    0.8871       750\n",
            "             Linge de maison     0.9372    0.9474    0.9423       646\n",
            "              Petit déjeuner     1.0000    0.9867    0.9933       300\n",
            "                  Décoration     0.8495    0.8745    0.8618       749\n",
            "                  Animalerie     0.9708    0.9967    0.9836       300\n",
            "                       Revue     0.9379    0.9314    0.9346       714\n",
            "        Lots Livres & Revues     0.8752    0.8715    0.8733       716\n",
            "        Lots consoles & jeux     0.9243    0.9767    0.9498       300\n",
            "       Fournitures Papeterie     0.9481    0.9519    0.9500       748\n",
            "          Mobilier de jardin     0.8922    0.8531    0.8722       388\n",
            "    Équipement piscine & spa     0.9722    0.9800    0.9761       750\n",
            "         Outillage de jardin     0.9630    0.9037    0.9324       374\n",
            "                      eBooks     0.8586    0.8213    0.8395       414\n",
            "      Jeux en téléchargement     1.0000    1.0000    1.0000       300\n",
            "\n",
            "                    accuracy                         0.9028     13138\n",
            "                   macro avg     0.9058    0.9048    0.9051     13138\n",
            "                weighted avg     0.9027    0.9028    0.9026     13138\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import lightgbm as lgb\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import optuna\n",
        "import joblib\n",
        "\n",
        "# --- Config chemins ---\n",
        "BASE = \"/content/drive/MyDrive/Colab Notebooks/fahim/final\"\n",
        "PATH_LOGITS = \"/content/modeles_importes\"\n",
        "VAL_INDICES_PATH = os.path.join(BASE, \"val_indices.json\")\n",
        "LABEL_MAPPING_PATH = os.path.join(BASE, \"label_mapping_final.json\")\n",
        "LABELS_PATH = os.path.join(PATH_LOGITS, \"true_labels_final.pt\")\n",
        "\n",
        "OUTPUT_DIR = os.path.join(BASE, \"modeles_texte_V2\")  # Dossier principal\n",
        "META_DIR = os.path.join(OUTPUT_DIR, \"meta_modele_texte\")\n",
        "os.makedirs(META_DIR, exist_ok=True)\n",
        "\n",
        "best_models = [\n",
        "    \"booster_texte_logits.pt\",\n",
        "    \"camembert2_logits.pt\",\n",
        "    \"flaubert2_logits.pt\",\n",
        "]\n",
        "\n",
        "fixed_weights = np.array([0.97793276, 0.02240674, 0.29904325])\n",
        "\n",
        "# --- Chargement indices, labels ---\n",
        "with open(VAL_INDICES_PATH, \"r\") as f:\n",
        "    val_idx = np.array(json.load(f))\n",
        "with open(LABEL_MAPPING_PATH, \"r\") as f:\n",
        "    label_mapping = json.load(f)\n",
        "class_names = [label_mapping[str(i)][\"label_name\"] for i in range(len(label_mapping))]\n",
        "\n",
        "labels_full = torch.load(LABELS_PATH).numpy()\n",
        "n_samples = labels_full.shape[0]\n",
        "all_indices = np.arange(n_samples)\n",
        "train_idx = np.setdiff1d(all_indices, val_idx)\n",
        "\n",
        "y_train = labels_full[train_idx]\n",
        "y_val = labels_full[val_idx]\n",
        "\n",
        "def load_logits(fnames, indices):\n",
        "    logits_list = []\n",
        "    for fname in fnames:\n",
        "        logits = torch.load(os.path.join(PATH_LOGITS, fname)).cpu().numpy()\n",
        "        if logits.ndim == 2 and (np.abs(np.sum(logits, axis=1) - 1) > 1e-4).any():\n",
        "            logits = softmax(logits, axis=1)\n",
        "        logits = logits[indices]\n",
        "        logits_list.append(logits)\n",
        "    return logits_list\n",
        "\n",
        "logits_train_list = load_logits(best_models, train_idx)\n",
        "logits_val_list = load_logits(best_models, val_idx)\n",
        "\n",
        "def weighted_fusion(logits_list, weights):\n",
        "    stacked = np.stack(logits_list, axis=0)\n",
        "    weighted = np.tensordot(weights, stacked, axes=(0, 0))\n",
        "    return weighted\n",
        "\n",
        "# Fusion objective pour Optuna\n",
        "def objective_fusion(trial, probas_list, y_true):\n",
        "    n_weights = len(probas_list)\n",
        "    weights = []\n",
        "    for i in range(n_weights):\n",
        "        weights.append(trial.suggest_float(f'w{i}', 0.0, 1.0))\n",
        "    weights = np.array(weights)\n",
        "    if weights.sum() == 0:\n",
        "        return 1.0\n",
        "    weights /= weights.sum()\n",
        "    fusion = weighted_fusion(probas_list, weights)\n",
        "    preds = np.argmax(fusion, axis=1)\n",
        "    return 1 - f1_score(y_true, preds, average='weighted')\n",
        "\n",
        "def save_model(model, path):\n",
        "    if isinstance(model, nn.Module):\n",
        "        torch.save(model.state_dict(), path)\n",
        "    else:\n",
        "        joblib.dump(model, path)\n",
        "\n",
        "def load_model(path, model_type, model_class=None, *args, **kwargs):\n",
        "    if model_type == 'mlp':\n",
        "        model = model_class(*args, **kwargs)\n",
        "        model.load_state_dict(torch.load(path))\n",
        "        model.eval()\n",
        "        return model\n",
        "    else:\n",
        "        return joblib.load(path)\n",
        "\n",
        "# LightGBM\n",
        "def train_lgb_optuna(trial, X_train, y_train, X_val, y_val, fold_idx=None):\n",
        "    learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
        "    num_leaves = trial.suggest_int('lgb_num_leaves', 20, 50)\n",
        "    max_depth = trial.suggest_int('lgb_max_depth', 3, 10)\n",
        "\n",
        "    classes = np.unique(y_train)\n",
        "    class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
        "    sample_weights = np.array([class_weights[np.where(classes == y)[0][0]] for y in y_train])\n",
        "\n",
        "    model = lgb.LGBMClassifier(\n",
        "        objective=\"multiclass\",\n",
        "        num_class=len(class_names),\n",
        "        metric=\"multi_logloss\",\n",
        "        learning_rate=learning_rate,\n",
        "        num_leaves=num_leaves,\n",
        "        max_depth=max_depth,\n",
        "        n_jobs=12,\n",
        "        random_state=42,\n",
        "    )\n",
        "    model.fit(X_train, y_train, sample_weight=sample_weights, eval_set=[(X_val, y_val)])\n",
        "    preds_proba = model.predict_proba(X_val)\n",
        "    f1 = f1_score(y_val, np.argmax(preds_proba, axis=1), average='weighted')\n",
        "\n",
        "    if fold_idx is not None:\n",
        "        save_path = os.path.join(OUTPUT_DIR, f\"lgbm_fold{fold_idx}.joblib\")\n",
        "        joblib.dump(model, save_path)\n",
        "\n",
        "    return model, preds_proba, f1\n",
        "\n",
        "# MLP\n",
        "class MetaMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_classes, class_weights_tensor):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, n_classes)\n",
        "        )\n",
        "        self.criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def train_mlp_optuna(trial, X_train, y_train, X_val, y_val, fold_idx=None, epochs=20, batch_size=256):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    hidden_dim = trial.suggest_int('mlp_hidden_dim', 256, 1024)\n",
        "    lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
        "    weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n",
        "\n",
        "    classes = np.unique(y_train)\n",
        "    class_weights_np = compute_class_weight('balanced', classes=classes, y=y_train)\n",
        "    class_weights_tensor = torch.zeros(len(class_names), dtype=torch.float32)\n",
        "    for c, w in zip(classes, class_weights_np):\n",
        "        class_weights_tensor[c] = w\n",
        "    class_weights_tensor = class_weights_tensor.to(device)\n",
        "\n",
        "    model = MetaMLP(X_train.shape[1], hidden_dim, len(class_names), class_weights_tensor).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32).to(device), torch.tensor(y_train, dtype=torch.long).to(device))\n",
        "    val_ds = TensorDataset(torch.tensor(X_val, dtype=torch.float32).to(device), torch.tensor(y_val, dtype=torch.long).to(device))\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
        "\n",
        "    best_f1 = 0\n",
        "    best_state = None\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = model.criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                logits = model(xb)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                all_preds.append(preds.cpu().numpy())\n",
        "                all_targets.append(yb.cpu().numpy())\n",
        "        all_preds = np.concatenate(all_preds)\n",
        "        all_targets = np.concatenate(all_targets)\n",
        "        f1 = f1_score(all_targets, all_preds, average='weighted')\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_state = model.state_dict()\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_probs = model(torch.tensor(X_val, dtype=torch.float32).to(device)).cpu().numpy()\n",
        "\n",
        "    if fold_idx is not None:\n",
        "        torch.save(best_state, os.path.join(OUTPUT_DIR, f\"mlp_fold{fold_idx}.pth\"))\n",
        "\n",
        "    return model, val_probs, best_f1\n",
        "\n",
        "# Threshold tuning\n",
        "def threshold_tuning(y_true, probas, n_classes, initial_thresholds=None):\n",
        "    thresholds = initial_thresholds if initial_thresholds is not None else np.ones(n_classes) * 0.5\n",
        "    best_thresholds = thresholds.copy()\n",
        "    best_f1 = 0\n",
        "\n",
        "    for c in range(n_classes):\n",
        "        thresh_range = np.linspace(0.1, 0.9, 9)\n",
        "        for thr in thresh_range:\n",
        "            thresholds[c] = thr\n",
        "            preds = apply_thresholds(probas, thresholds)\n",
        "            f1 = f1_score(y_true, preds, average='weighted')\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_thresholds = thresholds.copy()\n",
        "        thresholds[c] = best_thresholds[c]\n",
        "    return best_thresholds\n",
        "\n",
        "def apply_thresholds(probas, thresholds):\n",
        "    n_samples, n_classes = probas.shape\n",
        "    preds = np.zeros(n_samples, dtype=int)\n",
        "    for i in range(n_samples):\n",
        "        probs = probas[i]\n",
        "        passed = np.where(probs >= thresholds)[0]\n",
        "        if len(passed) == 0:\n",
        "            preds[i] = np.argmax(probs)\n",
        "        else:\n",
        "            preds[i] = passed[np.argmax(probs[passed])]\n",
        "    return preds\n",
        "\n",
        "# Validation croisée sur combinaison fixe\n",
        "def cross_val_train_tune_threshold_fixedcombo(logits_train_list, y_train, fixed_weights, classifiers, best_combo,\n",
        "                                              n_splits=5, n_trials_hyper=50, n_trials_fusion=50):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    cv_scores = []\n",
        "\n",
        "    for fold_idx, (train_fold_idx, val_fold_idx) in enumerate(skf.split(np.zeros(len(y_train)), y_train)):\n",
        "        print(f\"\\n=== Fold {fold_idx+1}/{n_splits} ===\")\n",
        "\n",
        "        X_train_fold = weighted_fusion([logits[train_fold_idx] for logits in logits_train_list], fixed_weights)\n",
        "        y_train_fold = y_train[train_fold_idx]\n",
        "\n",
        "        X_val_fold = weighted_fusion([logits[val_fold_idx] for logits in logits_train_list], fixed_weights)\n",
        "        y_val_fold = y_train[val_fold_idx]\n",
        "\n",
        "        probas_list = []\n",
        "        models_fold = {}\n",
        "\n",
        "        for clf_name in best_combo:\n",
        "            study = optuna.create_study(direction=\"maximize\")\n",
        "            func = lambda trial: classifiers[clf_name](trial, X_train_fold, y_train_fold, X_val_fold, y_val_fold, fold_idx)[2]\n",
        "            # Parallélisation pour LightGBM et LogReg uniquement\n",
        "            n_jobs_optuna = 12 if clf_name != \"mlp\" else 1\n",
        "            study.optimize(func, n_trials=n_trials_hyper, show_progress_bar=True, n_jobs=n_jobs_optuna)\n",
        "            best_trial = study.best_trial\n",
        "\n",
        "            model, val_proba, f1 = classifiers[clf_name](best_trial, X_train_fold, y_train_fold, X_val_fold, y_val_fold, fold_idx)\n",
        "            probas_list.append(val_proba)\n",
        "            models_fold[clf_name] = model\n",
        "            print(f\"Fold {fold_idx+1} - F1 weighted {clf_name}: {f1:.4f}\")\n",
        "\n",
        "        study_fusion = optuna.create_study(direction=\"minimize\")\n",
        "        study_fusion.optimize(lambda trial: objective_fusion(trial, probas_list, y_val_fold), n_trials=n_trials_fusion, show_progress_bar=True)\n",
        "        best_weights = np.array([study_fusion.best_params[f'w{i}'] for i in range(len(probas_list))])\n",
        "        best_weights /= best_weights.sum()\n",
        "\n",
        "        fusion_probas = weighted_fusion(probas_list, best_weights)\n",
        "        best_thresholds = threshold_tuning(y_val_fold, fusion_probas, len(class_names))\n",
        "        preds = apply_thresholds(fusion_probas, best_thresholds)\n",
        "        f1 = f1_score(y_val_fold, preds, average='weighted')\n",
        "        cv_scores.append(f1)\n",
        "\n",
        "        print(f\"Fold {fold_idx+1} - F1 weighted fusion: {f1:.4f}\")\n",
        "        print(classification_report(y_val_fold, preds, target_names=class_names, digits=4))\n",
        "\n",
        "        # Sauvegarde\n",
        "\n",
        "    print(f\"\\n=== CV mean F1 weighted: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f} ===\")\n",
        "    return np.mean(cv_scores), np.std(cv_scores)\n",
        "\n",
        "# Entraînement final sur tout train+val\n",
        "def train_final_with_tuning(logits_train_list, y_train, logits_val_list, y_val, fixed_weights, classifiers, best_combo,\n",
        "                            n_trials_hyper=100, n_trials_fusion=100):\n",
        "    X_train = weighted_fusion(logits_train_list, fixed_weights)\n",
        "    X_val = weighted_fusion(logits_val_list, fixed_weights)\n",
        "\n",
        "    probas_list = []\n",
        "\n",
        "    for clf_name in best_combo:\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        func = lambda trial: classifiers[clf_name](trial, X_train, y_train, X_val, y_val)[2]\n",
        "        n_jobs_optuna = 1 if clf_name == \"mlp\" else 12\n",
        "        study.optimize(func, n_trials=n_trials_hyper, show_progress_bar=True, n_jobs=n_jobs_optuna)\n",
        "        best_trial = study.best_trial\n",
        "\n",
        "        model, val_proba, f1 = classifiers[clf_name](best_trial, X_train, y_train, X_val, y_val)\n",
        "        if clf_name == \"mlp\":\n",
        "            torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, f\"final_{clf_name}.pth\"))\n",
        "        else:\n",
        "            joblib.dump(model, os.path.join(OUTPUT_DIR, f\"final_{clf_name}.joblib\"))\n",
        "        probas_list.append(val_proba)\n",
        "        print(f\"Final train F1 {clf_name}: {f1:.4f}\")\n",
        "\n",
        "    study_fusion = optuna.create_study(direction=\"minimize\")\n",
        "    study_fusion.optimize(lambda trial: objective_fusion(trial, probas_list, y_val), n_trials=n_trials_fusion, show_progress_bar=True)\n",
        "    best_weights = np.array([study_fusion.best_params[f'w{i}'] for i in range(len(probas_list))])\n",
        "    best_weights /= best_weights.sum()\n",
        "\n",
        "    fusion_probas = weighted_fusion(probas_list, best_weights)\n",
        "    best_thresholds = threshold_tuning(y_val, fusion_probas, len(class_names))\n",
        "\n",
        "    preds = apply_thresholds(fusion_probas, best_thresholds)\n",
        "    final_f1 = f1_score(y_val, preds, average='weighted')\n",
        "\n",
        "    print(\"\\n=== Résultats finaux avec tuning et seuils ===\")\n",
        "    print(f\"Combinaison utilisée : {best_combo}\")\n",
        "    print(f\"F1-weighted final : {final_f1:.4f}\")\n",
        "    print(classification_report(y_val, preds, target_names=class_names, digits=4))\n",
        "\n",
        "    np.save(os.path.join(OUTPUT_DIR, \"final_best_weights.npy\"), best_weights)\n",
        "    np.save(os.path.join(OUTPUT_DIR, \"final_best_thresholds.npy\"), best_thresholds)\n",
        "\n",
        "    return best_weights, best_thresholds, final_f1\n",
        "\n",
        "# Définition des classifieurs (uniquement ceux du meilleur combo)\n",
        "classifiers = {\n",
        "    \"lgbm\": train_lgb_optuna,\n",
        "    \"mlp\": train_mlp_optuna,\n",
        "}\n",
        "\n",
        "best_combo = [\"lgbm\", \"mlp\"]\n",
        "\n",
        "# --- Lancer validation croisée uniquement sur la meilleure combinaison ---\n",
        "mean_f1, std_f1 = cross_val_train_tune_threshold_fixedcombo(\n",
        "    logits_train_list, y_train, fixed_weights,\n",
        "    classifiers,\n",
        "    best_combo=best_combo,\n",
        "    n_splits=5,\n",
        "    n_trials_hyper=50,\n",
        "    n_trials_fusion=50\n",
        ")\n",
        "\n",
        "print(f\"Validation croisée terminée : F1 moyen {mean_f1:.4f} ± {std_f1:.4f}\")\n",
        "\n",
        "# --- Entraînement final ---\n",
        "best_weights, best_thresholds, final_f1 = train_final_with_tuning(\n",
        "    logits_train_list, y_train, logits_val_list, y_val, fixed_weights,\n",
        "    classifiers,\n",
        "    best_combo=best_combo,\n",
        "    n_trials_hyper=100,\n",
        "    n_trials_fusion=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5bb1ec5a4fa64afc80cdf95acc8d2a81",
            "8a17648f18c6489e853cff28038bc438",
            "72331e7de505463e8b8ecb311e7ad540",
            "8a5830f03165479684c2df2e274af4f6",
            "c5fb723e2d2f4fba882855fa37035478",
            "e343ee4f9acb4c11b9c236ac82decfac",
            "1ccc75f2b6234829a7ae9f2aac8fbf8b",
            "1de2c09621bf46fc93ccebfed40d7d98",
            "687690832850490f85e884e6ff53e2d5",
            "25ee4626ce6a42f48a10a49e109fcd0d",
            "2051fec5c624465aaea6e7cccc9a5ee2",
            "c57b0cf67cf24b59a7d5a9e661ecee1d",
            "35ab650a5310460abdc1891088d7a088",
            "ff918278e512433898183b2d48cffb84",
            "6da7aff15c5a4fe58c86b7ededc8a487",
            "84c62c43c2004eb4b99e37384c848474",
            "4da9e8314a1a4e13aee5fcd1cbae3388",
            "60ba36e9556241eaac8713f2e8c94e9d",
            "563ca0f9ac9f4e03a5701f8f4d2e3354",
            "f35da0f88ac647c3bec4bb816577fe96",
            "ad8d72b7fa6a4159b0ecbcc3afb30008",
            "8f728a81c4c64ffd817b96e23e8ca6a1",
            "c1d3fa9bd79548928c3e4e909f7f4dc1",
            "57c279f64bcd4833a3214543ed6bf05d",
            "bd69695d261b470ea7f90b65798cfcca",
            "01f3b828ed3241a18112aa9e18b01f69",
            "622303db12a144839031c631c14c35e1",
            "6487e4e90ec44745966106de5cf2edcc",
            "f7d80b201bc9495fb8ae16a8f82bfe47",
            "a1845f4b29384daa9581038dfeaf5ac5",
            "ee580faba59b4dbf8fc1d07877745c15",
            "569e1347d586425e99b7fdf0e74cfb48",
            "e791569ee01c4533888bc67a7673f37f",
            "1f4c843fd8d44d909f4cc5f7ef21f488",
            "3f18612751a745dda4717a910e7e950d",
            "554c6572e73547c1a04886bc1f1e78b5",
            "51a6e53f45cd421e881f873f83bb1f67",
            "5764ee18f3274535a74a952dc9096f5a",
            "581c5396e1e1401fb91eddcae8ff93aa",
            "126b4858c3c7443ea19182bfc874f80d",
            "7f003cb60fd2445ca777e72739974511",
            "da1cc9727ea542bb8ba86c30ef107a34",
            "757b3e78ab5b40f7aed222e2b6de996f",
            "ffc6bf7178a24cf6a580dd99a332f213",
            "f0a58d2288f04311a86b423384df1a7b",
            "8a51f028b2c148f8aecd5796c6f689a2",
            "dca02eb6d54d447988b2ccc89e0719e5",
            "947897e06a464e55a6ba84ba74a5ae10",
            "f5fc211f96674bf099a9b2ea213b2d3f",
            "d0371ffde5ab49bb9209e7a86b052763",
            "2bcbee936a6e4945a02ef84ed6fb8194",
            "aa401062448e41ff8d375684461a1be9",
            "ba6b087b61864665958c80a88fbc0317",
            "6ffc32be611f47e6aac24ec697bc5637",
            "81c836fd86904217952c76d0b6065cfb",
            "043809372410486f85b81affdaa9013a",
            "b13a580a65a045c18b74c316f10c705b",
            "c1caa38f7eaa400bbe8b678601098327",
            "972fd4f5b7744fb4a25550b9110654c0",
            "5098f1d27071491989472544ae4c863f",
            "68506a9b303b487294785b68570401de",
            "e5ead5d245fe4819bce164c5fbe9b21d",
            "c33e10a2ef634f55a88cd1a2e7ca7eb9",
            "1f5fb5196fa642b085d8da27b6058323",
            "4e9e8f4dfec749778f954878d0af2393",
            "9b8231cdee23450eaf94ae5627e52d22",
            "a3aa289ff41a4531bc77e7f658bb551a",
            "385dbc0dbf544d61a0c783ca77324e66",
            "d98e80d0823045aea9dc9c5d3f2d58df",
            "0bfb5c91911f4698965162d880a8ef3d",
            "ba433c21dde04a91bf88d6df41a3a746",
            "7017f2d6cbf943d3a895b17cee26c709",
            "6fbacec13c2944ad873431c1a95322cc",
            "a04ac6856a2a4270862f197d0f85ca24",
            "3e8d29b1be034d848fa843461c968a5a",
            "4124eec6426f432082244136014e905b",
            "cb2bbe7f363d4dc892415c6526c3b1a4",
            "00a15e7b18de474fa1d27d75097a38fa",
            "46381340a51b4f06a545ec05e3d2592f",
            "c164819badb448299adee6f96a26455b",
            "91491491f638499cb0cbc4d7e36ac9bd",
            "7a734d09305747e68d0d1fd38915b809",
            "50411bda86e741a5b5429d2689443d21",
            "e432d1c021bb4d0f8254040602b5ca91",
            "0cdf871277214c5d923c1f4fe8bb1d6c",
            "050ee6fff3da40f4b6d14aa694cd8d83",
            "561f8a89045d451da15051f9fb08aaec",
            "fdcc55ba850b443e9729fa1ae3fac12a",
            "28226bd4cc064e0c8807545b5b56e65d",
            "bc6fe0d40acd44caa718114b0753244d",
            "e254438f437545ef8bffb856fe3a213d",
            "6ac7f6de3cff4c09b55406377f92d548",
            "05e184a9c15e43afa09314b3c8fd4488",
            "5bbf704d1e5e48648a41e3a4d5f79751",
            "4f22d26fb7a7412db2c8453db8070825",
            "ebc0ba69a5984af596d087b3b19c28a5",
            "c00f0a6bebab482d8f2559c0e67e5fda",
            "036072bf92a947d2b3ef21a4a5dff84e",
            "e3630300f43e4473987c65f1bcbcc040",
            "239fc6bd2c7f4b689e30df85dbc10a38",
            "c1621be6933f46dba3bbd0b71239b53d",
            "693c1f01256a4256ba73a2380d231c8b",
            "36583cfadc774557a6cec76b8515d5e4",
            "165a6213166746e4a7fd7b5d994efa60",
            "fa3bf221e3ab4d4d918ab8288ffd8469",
            "bd067320db154f4eaeb4dc0d7d38355a",
            "f621170872c14126aebae6ca70b83545",
            "2504765652614d8da3d528fb2a8a9d60",
            "5d3f4d9272364e7ab2d5d26af4a7899f",
            "be659209bef143118c7ffc7f4bfeaf2e",
            "6041e89c2f044fb9aa0f53a6cc4a5ec7",
            "899142504e69441a884881729f63e118",
            "626329dd68d24e3691300ca670c0b1b1",
            "0ac023b0441b479cbb764408c182c2a0",
            "c121bb9edbbd41848e06edab66f0f693",
            "2ab25f8c68814d38bd1c1a00ff48b386",
            "b23e2e331cd2437aaac200e635874640",
            "59afcbc8e2b34f27bd5e2d3bea6f9924",
            "e564509233784f5697798ba117ffdcb2",
            "c2347cea7e7448fabfe99d6a2a3f7349",
            "b2fd2366b4ce4e1f84435ca9f9b6e7d6",
            "44cb2970f0cc4eb98202540520886fee",
            "bd80bdc68b184b02aa0e6bc64cfc8172",
            "17db1ee1ec9240a08657d3cda7610923",
            "df0dc4caa8a44560a382ba7917ee2b34",
            "541d85d39882477db6ea45cf76a77cef",
            "d66cda952a614ad8aa3e7f92938b8c60",
            "4d199324a80241f68d7d93649f663ff3",
            "69ac660e4590445f919e4622fde20478",
            "483b2fcc0bde46628820798f207ef05d",
            "af540026cd8c419882b768ed842bf3a7",
            "fcdba08288ea4c87b3ae42090cd46274",
            "3fd3be0a114b46bca7b5f754609d697c",
            "b1ccc8b550a44ec88a18b4627dd451cd",
            "62370000579a458a97d495fb7730fe06",
            "c7ed38c754df442d9e6faa538c8fd12d",
            "9da0389370194f898f09f61876b49a9b",
            "0fe856284778430d82d06383ea605d29",
            "aa8aaa5f9f83468b855743707941a608",
            "755c8fd404784eadb231c4e107459c6a",
            "9a732976294c459796058549502e6265",
            "1bd375929cde4a6aa1e840c92d992e56",
            "cbba199a33d646e582269a4ec2317597",
            "fc804e5993b1478e9efa28403a9c894e",
            "4ee9a219fdb24aa2b6088906b324f384",
            "26568db2b1074ed4bff4426fd08143dd",
            "58ca2543c6af462c810622a3b267a41f",
            "c05e1649d14f44298b0b98747220db54",
            "c919a2b49db44bd2bc29be18a0f9e188",
            "cfe013ceb1824f17b5176ec5e509e40e",
            "e7c6a566e1574a37958959c8949d79f2",
            "2f81951d21d843a39ed732dcbcc737aa",
            "40c2e593bd4544c8bbe10806ea592c2f",
            "fdea5a997d1041b0a4732b0b8865dc1a",
            "417c04caaf634982994a83128099f473",
            "46ecb456095c45c5879234405240cdd2",
            "e7f61c70fd4e403db98608bf3caed6eb",
            "9085b0d9020b46518b8980d00395e1dd",
            "63f3d84f319c415684233804a800ea58",
            "0ecd7787a6a944af905bcefd119c8b88",
            "ccb9a11cfab64d83bef972528ac5e228",
            "3c92fbaa87ec41f4b1b1094d84c6f7ca",
            "42be92c3ed2940a898e07e2030027ea1",
            "584a42c414524d24add2576c49bb0605",
            "c6c8604ad27e4280846c8086a8cff2df",
            "7716b75be3c34cdb8bea71f66e9c3504",
            "f35d7ca21d4d4584af32ff2539994a08",
            "c74e8e573e6b4dbf9ba65c6666c65bd9",
            "40e3ea274a28476c81cfc53e8feb50f2",
            "e468fb4aedfc4ee4a3f9bbffde35295e",
            "0840086fee55462e8b31c6eb73ca3750",
            "471bea78c3a34f0b9ede50568d0db46b",
            "ce5a60ed28324f3085688aa47b0bd87f",
            "7a592945d6574ce883f5fc354d1cc7b4",
            "1af2a3e7e9364be09592aeac74f19121",
            "8f770e7aea3340efa8cc789f4de70353",
            "36c5ea9fd5ad4054971613e27773d31c",
            "725c302771ba4f16b95c98867a1384ea",
            "bf53b69de8e249669715c3013dc84c9d",
            "611b4750f5d044f7ac1ce3f18fb0a033",
            "2dfbdc0776cd47a69a2083c2d3970b80",
            "c342d2bd47a74cb788ea6f3cbff1118e",
            "336eb8f5075f43e087aae24bfdec9a21",
            "66582595c6814b1ab642dfa93633c45e",
            "6048dcfa001247d0b04ddcc9b1bb7eb3",
            "eb898e09a2c74b95a25abf29535a9fd2",
            "b57bea9ab0a347e68070f0c8c0f49139",
            "a7c9d430235f4ef593213008ab5c5ebf",
            "d1165da476854ee6b38afc3206c3c097",
            "85bdae8dd4f644fa9237a42e5f2c626c",
            "23da79a271ec4f7990d1ed5e654c72c7",
            "f04be76e61694685aae5724cca61df39",
            "fc8fb0c23494436a8222b7d3b0c291e0",
            "2d9b5eb007b0441bb188e8d4cf8376ba",
            "fe22b55fbac4480397dacf107e972bf4",
            "82bed2a355aa42aebaa46027c338128f",
            "ad6baa3d828945e19b3662661b437129",
            "059903f785194f55b3bf93c4ff375084"
          ]
        },
        "id": "wYKaFfEOKSKN",
        "outputId": "09dd133d-50d3-4ad6-e742-b5fe75c13926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 22:26:10,737] A new study created in memory with name: no-name-dd27c024-6222-4c09-a23f-4642fac2829d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1/5 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bb1ec5a4fa64afc80cdf95acc8d2a81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:26:59,435] Trial 6 finished with value: 0.9642493654501838 and parameters: {'lgb_lr': 0.003194445843804319, 'lgb_num_leaves': 27, 'lgb_max_depth': 4}. Best is trial 6 with value: 0.9642493654501838.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:00,284] Trial 4 finished with value: 0.9657913518700109 and parameters: {'lgb_lr': 0.010150829266842167, 'lgb_num_leaves': 41, 'lgb_max_depth': 4}. Best is trial 4 with value: 0.9657913518700109.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:06,302] Trial 0 finished with value: 0.9653844712595673 and parameters: {'lgb_lr': 0.009197710329691335, 'lgb_num_leaves': 23, 'lgb_max_depth': 4}. Best is trial 4 with value: 0.9657913518700109.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:08,311] Trial 7 finished with value: 0.9658641930066219 and parameters: {'lgb_lr': 0.01164828811006291, 'lgb_num_leaves': 23, 'lgb_max_depth': 4}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:30,801] Trial 5 finished with value: 0.9655746220089408 and parameters: {'lgb_lr': 0.08835298848092896, 'lgb_num_leaves': 28, 'lgb_max_depth': 7}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:31,414] Trial 11 finished with value: 0.964826755090227 and parameters: {'lgb_lr': 0.027854430381333027, 'lgb_num_leaves': 29, 'lgb_max_depth': 7}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:35,899] Trial 9 finished with value: 0.9645487924881542 and parameters: {'lgb_lr': 0.02247879977603871, 'lgb_num_leaves': 32, 'lgb_max_depth': 7}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:42,224] Trial 1 finished with value: 0.9651515899088152 and parameters: {'lgb_lr': 0.09086956099192676, 'lgb_num_leaves': 33, 'lgb_max_depth': 8}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:48,248] Trial 3 finished with value: 0.9650867427180845 and parameters: {'lgb_lr': 0.022275687184045188, 'lgb_num_leaves': 39, 'lgb_max_depth': 8}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:50,108] Trial 10 finished with value: 0.9641443603042436 and parameters: {'lgb_lr': 0.03455956703519142, 'lgb_num_leaves': 41, 'lgb_max_depth': 6}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:55,326] Trial 2 finished with value: 0.9642341758869237 and parameters: {'lgb_lr': 0.04491845399915247, 'lgb_num_leaves': 36, 'lgb_max_depth': 6}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:27:56,960] Trial 14 finished with value: 0.965318549868482 and parameters: {'lgb_lr': 0.009131199551249225, 'lgb_num_leaves': 41, 'lgb_max_depth': 4}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:28:14,214] Trial 13 finished with value: 0.9647316100989473 and parameters: {'lgb_lr': 0.0034133946163499244, 'lgb_num_leaves': 40, 'lgb_max_depth': 5}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:28:18,731] Trial 16 finished with value: 0.9649815993166797 and parameters: {'lgb_lr': 0.008439203194593485, 'lgb_num_leaves': 21, 'lgb_max_depth': 4}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:28:21,209] Trial 8 finished with value: 0.9644128296154947 and parameters: {'lgb_lr': 0.05990717417357883, 'lgb_num_leaves': 46, 'lgb_max_depth': 7}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:28:30,815] Trial 22 finished with value: 0.9642739266034465 and parameters: {'lgb_lr': 0.006400219590593585, 'lgb_num_leaves': 47, 'lgb_max_depth': 3}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:28:33,384] Trial 23 finished with value: 0.9644088346743068 and parameters: {'lgb_lr': 0.0031078993359933108, 'lgb_num_leaves': 50, 'lgb_max_depth': 3}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:28:33,707] Trial 12 finished with value: 0.9645262913911207 and parameters: {'lgb_lr': 0.015467162663055712, 'lgb_num_leaves': 45, 'lgb_max_depth': 6}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:28:35,241] Trial 15 finished with value: 0.9642773899680674 and parameters: {'lgb_lr': 0.004376349378033911, 'lgb_num_leaves': 35, 'lgb_max_depth': 10}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:28:45,347] Trial 19 finished with value: 0.9648565414749247 and parameters: {'lgb_lr': 0.006591122520291925, 'lgb_num_leaves': 22, 'lgb_max_depth': 5}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:28:56,264] Trial 18 finished with value: 0.9641522509032849 and parameters: {'lgb_lr': 0.08999187687037279, 'lgb_num_leaves': 23, 'lgb_max_depth': 9}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:29:10,124] Trial 17 finished with value: 0.964122015706188 and parameters: {'lgb_lr': 0.0018294213266027153, 'lgb_num_leaves': 43, 'lgb_max_depth': 10}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:29:10,842] Trial 20 finished with value: 0.9648971268915808 and parameters: {'lgb_lr': 0.043007394619743074, 'lgb_num_leaves': 31, 'lgb_max_depth': 7}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:29:36,562] Trial 30 finished with value: 0.9642500122391124 and parameters: {'lgb_lr': 0.0013086565898500367, 'lgb_num_leaves': 24, 'lgb_max_depth': 5}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:29:37,485] Trial 21 finished with value: 0.9641887554483013 and parameters: {'lgb_lr': 0.0014659045381947631, 'lgb_num_leaves': 50, 'lgb_max_depth': 10}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:29:38,592] Trial 28 finished with value: 0.9641223149284702 and parameters: {'lgb_lr': 0.0011993171890769413, 'lgb_num_leaves': 25, 'lgb_max_depth': 10}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:29:48,355] Trial 29 finished with value: 0.9635870615113271 and parameters: {'lgb_lr': 0.001048099890109779, 'lgb_num_leaves': 24, 'lgb_max_depth': 10}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:29:51,902] Trial 31 finished with value: 0.9649919926719519 and parameters: {'lgb_lr': 0.014714398135049614, 'lgb_num_leaves': 25, 'lgb_max_depth': 5}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:29:59,576] Trial 32 finished with value: 0.9641119117096163 and parameters: {'lgb_lr': 0.0014559028543818765, 'lgb_num_leaves': 27, 'lgb_max_depth': 5}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:01,810] Trial 25 finished with value: 0.9639902396534157 and parameters: {'lgb_lr': 0.0012121343330262668, 'lgb_num_leaves': 47, 'lgb_max_depth': 10}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:16,654] Trial 27 finished with value: 0.965061054796158 and parameters: {'lgb_lr': 0.015154801302405412, 'lgb_num_leaves': 44, 'lgb_max_depth': 10}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:16,891] Trial 35 finished with value: 0.9650355967727761 and parameters: {'lgb_lr': 0.013930412508787566, 'lgb_num_leaves': 26, 'lgb_max_depth': 3}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:17,355] Trial 36 finished with value: 0.964899872596841 and parameters: {'lgb_lr': 0.014485354626362835, 'lgb_num_leaves': 28, 'lgb_max_depth': 3}. Best is trial 7 with value: 0.9658641930066219.\n",
            "[I 2025-06-16 22:30:17,399] Trial 34 finished with value: 0.9642582648870424 and parameters: {'lgb_lr': 0.0011802921013054713, 'lgb_num_leaves': 27, 'lgb_max_depth': 5}. Best is trial 7 with value: 0.9658641930066219.\n",
            "[I 2025-06-16 22:30:17,399] Trial 24 finished with value: 0.9639738450556601 and parameters: {'lgb_lr': 0.006164956045332291, 'lgb_num_leaves': 46, 'lgb_max_depth': 10}. Best is trial 7 with value: 0.9658641930066219.\n",
            "[I 2025-06-16 22:30:17,437] Trial 26 finished with value: 0.9641145411327623 and parameters: {'lgb_lr': 0.005335989095520931, 'lgb_num_leaves': 50, 'lgb_max_depth': 10}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:18,188] Trial 37 finished with value: 0.964824990810623 and parameters: {'lgb_lr': 0.0160159369093716, 'lgb_num_leaves': 20, 'lgb_max_depth': 3}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:21,049] Trial 33 finished with value: 0.9651091711276478 and parameters: {'lgb_lr': 0.0155100380031329, 'lgb_num_leaves': 27, 'lgb_max_depth': 5}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:27,897] Trial 38 finished with value: 0.9646856169690349 and parameters: {'lgb_lr': 0.017307414211627577, 'lgb_num_leaves': 20, 'lgb_max_depth': 3}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:36,189] Trial 39 finished with value: 0.9655289086134698 and parameters: {'lgb_lr': 0.06458351380379934, 'lgb_num_leaves': 28, 'lgb_max_depth': 3}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:38,513] Trial 40 finished with value: 0.9651010582319984 and parameters: {'lgb_lr': 0.012514595074775968, 'lgb_num_leaves': 20, 'lgb_max_depth': 3}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:39,340] Trial 41 finished with value: 0.9649662684729075 and parameters: {'lgb_lr': 0.014306023154152562, 'lgb_num_leaves': 30, 'lgb_max_depth': 3}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:30:51,804] Trial 42 finished with value: 0.9643441094135379 and parameters: {'lgb_lr': 0.005730917013250933, 'lgb_num_leaves': 20, 'lgb_max_depth': 3}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:31:02,036] Trial 43 finished with value: 0.9650507263619269 and parameters: {'lgb_lr': 0.005407476352545169, 'lgb_num_leaves': 20, 'lgb_max_depth': 4}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:31:12,511] Trial 44 finished with value: 0.9652799312376198 and parameters: {'lgb_lr': 0.010476832766950089, 'lgb_num_leaves': 20, 'lgb_max_depth': 8}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:31:13,744] Trial 45 finished with value: 0.9649567641311598 and parameters: {'lgb_lr': 0.020142945424831294, 'lgb_num_leaves': 20, 'lgb_max_depth': 8}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:31:13,970] Trial 46 finished with value: 0.9651392589661112 and parameters: {'lgb_lr': 0.01061095497367589, 'lgb_num_leaves': 20, 'lgb_max_depth': 8}. Best is trial 7 with value: 0.9658641930066219.\n",
            "[I 2025-06-16 22:31:14,355] Trial 47 finished with value: 0.9641549539822387 and parameters: {'lgb_lr': 0.07976640585421432, 'lgb_num_leaves': 20, 'lgb_max_depth': 8}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:31:28,028] Trial 48 finished with value: 0.964713016174797 and parameters: {'lgb_lr': 0.010643372684069485, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:31:29,976] Trial 49 finished with value: 0.9642941493503733 and parameters: {'lgb_lr': 0.06720273102378063, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 7 with value: 0.9658641930066219.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003168 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59557, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 22:31:34,598] A new study created in memory with name: no-name-3d1eb244-2517-472b-a6b9-badc6498b018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 - F1 weighted lgbm: 0.9659\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c57b0cf67cf24b59a7d5a9e661ecee1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:31:58,763] Trial 0 finished with value: 0.9643541085944682 and parameters: {'mlp_hidden_dim': 313, 'mlp_lr': 0.00915958551261046, 'mlp_wd': 0.0005465672171145383}. Best is trial 0 with value: 0.9643541085944682.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:32:17,672] Trial 1 finished with value: 0.9656442061821394 and parameters: {'mlp_hidden_dim': 340, 'mlp_lr': 0.0016085172643479635, 'mlp_wd': 1.3344879034991316e-05}. Best is trial 1 with value: 0.9656442061821394.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:32:36,450] Trial 2 finished with value: 0.9646261326458676 and parameters: {'mlp_hidden_dim': 871, 'mlp_lr': 0.00013148830622166255, 'mlp_wd': 1.492847427515668e-05}. Best is trial 1 with value: 0.9656442061821394.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:32:55,418] Trial 3 finished with value: 0.9641597192522299 and parameters: {'mlp_hidden_dim': 950, 'mlp_lr': 0.00034235460806407306, 'mlp_wd': 0.0002353218151563498}. Best is trial 1 with value: 0.9656442061821394.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:33:14,400] Trial 4 finished with value: 0.963943792396762 and parameters: {'mlp_hidden_dim': 796, 'mlp_lr': 0.0007194101247571444, 'mlp_wd': 0.00047726610145063826}. Best is trial 1 with value: 0.9656442061821394.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:33:33,450] Trial 5 finished with value: 0.9661515408329115 and parameters: {'mlp_hidden_dim': 910, 'mlp_lr': 0.0018735499679625044, 'mlp_wd': 1.1338334329530298e-06}. Best is trial 5 with value: 0.9661515408329115.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:33:52,390] Trial 6 finished with value: 0.966489533060317 and parameters: {'mlp_hidden_dim': 875, 'mlp_lr': 0.001634564764879592, 'mlp_wd': 4.519194404407171e-05}. Best is trial 6 with value: 0.966489533060317.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:34:11,371] Trial 7 finished with value: 0.9650542779872758 and parameters: {'mlp_hidden_dim': 627, 'mlp_lr': 0.003054151232094002, 'mlp_wd': 0.00024355520809242186}. Best is trial 6 with value: 0.966489533060317.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:34:30,351] Trial 8 finished with value: 0.9645881444812694 and parameters: {'mlp_hidden_dim': 793, 'mlp_lr': 0.004798581044381797, 'mlp_wd': 0.0005347190899854211}. Best is trial 6 with value: 0.966489533060317.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:34:49,406] Trial 9 finished with value: 0.963942283399405 and parameters: {'mlp_hidden_dim': 379, 'mlp_lr': 0.0005459610920798747, 'mlp_wd': 0.00024862884184275775}. Best is trial 6 with value: 0.966489533060317.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:35:08,535] Trial 10 finished with value: 0.9642765871265756 and parameters: {'mlp_hidden_dim': 542, 'mlp_lr': 0.00019056785781792145, 'mlp_wd': 5.1988719222390965e-05}. Best is trial 6 with value: 0.966489533060317.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:35:27,646] Trial 11 finished with value: 0.9663907615820208 and parameters: {'mlp_hidden_dim': 1018, 'mlp_lr': 0.0018793564727044498, 'mlp_wd': 1.7811724858125263e-06}. Best is trial 6 with value: 0.966489533060317.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:35:46,554] Trial 12 finished with value: 0.9666073988341234 and parameters: {'mlp_hidden_dim': 1019, 'mlp_lr': 0.001316258620416408, 'mlp_wd': 1.0520578782461918e-06}. Best is trial 12 with value: 0.9666073988341234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:36:05,753] Trial 13 finished with value: 0.9654725752264229 and parameters: {'mlp_hidden_dim': 746, 'mlp_lr': 0.0009057888233447958, 'mlp_wd': 3.74454080466097e-06}. Best is trial 12 with value: 0.9666073988341234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:36:24,929] Trial 14 finished with value: 0.9662965737873439 and parameters: {'mlp_hidden_dim': 996, 'mlp_lr': 0.004909303389249712, 'mlp_wd': 5.364398454435338e-05}. Best is trial 12 with value: 0.9666073988341234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:36:44,041] Trial 15 finished with value: 0.9653369713520951 and parameters: {'mlp_hidden_dim': 869, 'mlp_lr': 0.00038046168764624747, 'mlp_wd': 7.534173205897397e-06}. Best is trial 12 with value: 0.9666073988341234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:37:03,311] Trial 16 finished with value: 0.9652508514436258 and parameters: {'mlp_hidden_dim': 673, 'mlp_lr': 0.0011994848289632795, 'mlp_wd': 9.019527877871498e-05}. Best is trial 12 with value: 0.9666073988341234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:37:22,532] Trial 17 finished with value: 0.9659006830961211 and parameters: {'mlp_hidden_dim': 586, 'mlp_lr': 0.0035201145743505003, 'mlp_wd': 1.772542303495613e-05}. Best is trial 12 with value: 0.9666073988341234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:37:41,674] Trial 18 finished with value: 0.9661560813046629 and parameters: {'mlp_hidden_dim': 457, 'mlp_lr': 0.009901197281500983, 'mlp_wd': 3.3453238262126377e-06}. Best is trial 12 with value: 0.9666073988341234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:38:00,773] Trial 19 finished with value: 0.9651646705112724 and parameters: {'mlp_hidden_dim': 741, 'mlp_lr': 0.002773065919920206, 'mlp_wd': 0.00010561208487221085}. Best is trial 12 with value: 0.9666073988341234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:38:19,830] Trial 20 finished with value: 0.9657489375603331 and parameters: {'mlp_hidden_dim': 966, 'mlp_lr': 0.0005365691348289873, 'mlp_wd': 5.626582946721652e-06}. Best is trial 12 with value: 0.9666073988341234.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:38:38,883] Trial 21 finished with value: 0.9666613081834193 and parameters: {'mlp_hidden_dim': 1012, 'mlp_lr': 0.0017848181291794578, 'mlp_wd': 1.5581474023618679e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:38:58,197] Trial 22 finished with value: 0.9657950856826747 and parameters: {'mlp_hidden_dim': 903, 'mlp_lr': 0.0012727826508769635, 'mlp_wd': 1.8099438621688925e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:39:17,280] Trial 23 finished with value: 0.9659601955758463 and parameters: {'mlp_hidden_dim': 1022, 'mlp_lr': 0.0020654994746053547, 'mlp_wd': 1.0253043289302181e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:39:36,491] Trial 24 finished with value: 0.9653315856610595 and parameters: {'mlp_hidden_dim': 832, 'mlp_lr': 0.0009005460339458342, 'mlp_wd': 2.999398983471254e-05}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:39:55,454] Trial 25 finished with value: 0.965789775220526 and parameters: {'mlp_hidden_dim': 938, 'mlp_lr': 0.0013324391967739846, 'mlp_wd': 3.0782008257210185e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:40:14,463] Trial 26 finished with value: 0.9658931329653143 and parameters: {'mlp_hidden_dim': 962, 'mlp_lr': 0.005249611051741199, 'mlp_wd': 1.9199091957573407e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:40:33,653] Trial 27 finished with value: 0.9657064958963675 and parameters: {'mlp_hidden_dim': 839, 'mlp_lr': 0.0024052641408491343, 'mlp_wd': 7.87910206720907e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:40:52,777] Trial 28 finished with value: 0.965117879349094 and parameters: {'mlp_hidden_dim': 706, 'mlp_lr': 0.0007168255272275069, 'mlp_wd': 2.8172775035302965e-05}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:41:11,916] Trial 29 finished with value: 0.965453299509526 and parameters: {'mlp_hidden_dim': 271, 'mlp_lr': 0.0035066748768071095, 'mlp_wd': 6.777376826959341e-05}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:41:31,046] Trial 30 finished with value: 0.9661383723658026 and parameters: {'mlp_hidden_dim': 908, 'mlp_lr': 0.0014638789374624207, 'mlp_wd': 5.110389057496084e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:41:50,005] Trial 31 finished with value: 0.9665285730857847 and parameters: {'mlp_hidden_dim': 1016, 'mlp_lr': 0.0021845674777266144, 'mlp_wd': 1.5718165661006615e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:42:09,177] Trial 32 finished with value: 0.9660300262149004 and parameters: {'mlp_hidden_dim': 1024, 'mlp_lr': 0.0010153234406638635, 'mlp_wd': 2.170140040250874e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:42:28,630] Trial 33 finished with value: 0.9663210972610177 and parameters: {'mlp_hidden_dim': 974, 'mlp_lr': 0.001658716542569042, 'mlp_wd': 1.4104310602001658e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:42:47,903] Trial 34 finished with value: 0.966131330088307 and parameters: {'mlp_hidden_dim': 940, 'mlp_lr': 0.006854410326479066, 'mlp_wd': 9.60484699176765e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:43:06,970] Trial 35 finished with value: 0.9659772099458123 and parameters: {'mlp_hidden_dim': 870, 'mlp_lr': 0.002764566791419543, 'mlp_wd': 1.792663405936775e-05}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:43:26,105] Trial 36 finished with value: 0.9658794565801794 and parameters: {'mlp_hidden_dim': 982, 'mlp_lr': 0.0022508239603455707, 'mlp_wd': 2.3173259884426514e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:43:45,385] Trial 37 finished with value: 0.9637945573318061 and parameters: {'mlp_hidden_dim': 916, 'mlp_lr': 0.0006366014217780798, 'mlp_wd': 0.0008641891855114477}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:44:04,386] Trial 38 finished with value: 0.9660649972311047 and parameters: {'mlp_hidden_dim': 800, 'mlp_lr': 0.0010485626614145725, 'mlp_wd': 1.0285455119708272e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:44:23,567] Trial 39 finished with value: 0.9651083119240794 and parameters: {'mlp_hidden_dim': 875, 'mlp_lr': 0.004052040187180129, 'mlp_wd': 0.000134645917367768}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:44:42,728] Trial 40 finished with value: 0.9656971319853409 and parameters: {'mlp_hidden_dim': 987, 'mlp_lr': 0.0015249343805630075, 'mlp_wd': 1.391824069711134e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:45:01,894] Trial 41 finished with value: 0.9660080529849313 and parameters: {'mlp_hidden_dim': 991, 'mlp_lr': 0.001798643469052214, 'mlp_wd': 1.3967169229314591e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:45:21,094] Trial 42 finished with value: 0.9654832109860078 and parameters: {'mlp_hidden_dim': 1023, 'mlp_lr': 0.0019911233230487865, 'mlp_wd': 2.7136250607565067e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:45:40,322] Trial 43 finished with value: 0.9660832341470051 and parameters: {'mlp_hidden_dim': 926, 'mlp_lr': 0.002268171446327233, 'mlp_wd': 5.026580587725316e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:45:59,304] Trial 44 finished with value: 0.9660154592669719 and parameters: {'mlp_hidden_dim': 1013, 'mlp_lr': 0.001774285617349546, 'mlp_wd': 1.577904863714072e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:46:18,596] Trial 45 finished with value: 0.9666366286196587 and parameters: {'mlp_hidden_dim': 952, 'mlp_lr': 0.0027904994177735724, 'mlp_wd': 3.893260925942177e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:46:37,750] Trial 46 finished with value: 0.9645576517772825 and parameters: {'mlp_hidden_dim': 958, 'mlp_lr': 0.00013560646747584097, 'mlp_wd': 1.2303338442021706e-05}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:46:56,960] Trial 47 finished with value: 0.9661065286549835 and parameters: {'mlp_hidden_dim': 891, 'mlp_lr': 0.0034597907084185676, 'mlp_wd': 4.173327142030368e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:47:16,274] Trial 48 finished with value: 0.9658872870757048 and parameters: {'mlp_hidden_dim': 835, 'mlp_lr': 0.0073915667603097505, 'mlp_wd': 4.686410401207295e-05}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:47:35,707] Trial 49 finished with value: 0.9658509040043982 and parameters: {'mlp_hidden_dim': 484, 'mlp_lr': 0.0026612967359971214, 'mlp_wd': 2.7067117485498884e-06}. Best is trial 21 with value: 0.9666613081834193.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n",
            "[I 2025-06-16 22:47:54,603] A new study created in memory with name: no-name-fdd4fbb2-ac22-4e4f-b0e8-85ca70832ae2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 - F1 weighted mlp: 0.9661\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1d3fa9bd79548928c3e4e909f7f4dc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:47:54,625] Trial 0 finished with value: 0.03550962316704287 and parameters: {'w0': 0.49974416566706303, 'w1': 0.2691537465705798}. Best is trial 0 with value: 0.03550962316704287.\n",
            "[I 2025-06-16 22:47:54,637] Trial 1 finished with value: 0.034955804242702726 and parameters: {'w0': 0.729090074880679, 'w1': 0.10078875809931964}. Best is trial 1 with value: 0.034955804242702726.\n",
            "[I 2025-06-16 22:47:54,682] Trial 2 finished with value: 0.035634529955276606 and parameters: {'w0': 0.1088297488933353, 'w1': 0.8255352387933346}. Best is trial 1 with value: 0.034955804242702726.\n",
            "[I 2025-06-16 22:47:54,700] Trial 3 finished with value: 0.03523252510705177 and parameters: {'w0': 0.9739012129065266, 'w1': 0.23317540837912187}. Best is trial 1 with value: 0.034955804242702726.\n",
            "[I 2025-06-16 22:47:54,732] Trial 4 finished with value: 0.03538019604792031 and parameters: {'w0': 0.772787580209289, 'w1': 0.3770674775456644}. Best is trial 1 with value: 0.034955804242702726.\n",
            "[I 2025-06-16 22:47:54,757] Trial 5 finished with value: 0.035027128566285426 and parameters: {'w0': 0.654930312196661, 'w1': 0.11057022415098816}. Best is trial 1 with value: 0.034955804242702726.\n",
            "[I 2025-06-16 22:47:54,769] Trial 6 finished with value: 0.035638894992738424 and parameters: {'w0': 0.12180416082574241, 'w1': 0.7528059615339568}. Best is trial 1 with value: 0.034955804242702726.\n",
            "[I 2025-06-16 22:47:54,791] Trial 7 finished with value: 0.03516071169648738 and parameters: {'w0': 0.5567107649360461, 'w1': 0.11156525010598517}. Best is trial 1 with value: 0.034955804242702726.\n",
            "[I 2025-06-16 22:47:54,804] Trial 8 finished with value: 0.035315241023489485 and parameters: {'w0': 0.9407123197101669, 'w1': 0.4800135389649992}. Best is trial 1 with value: 0.034955804242702726.\n",
            "[I 2025-06-16 22:47:54,816] Trial 9 finished with value: 0.03530265299405766 and parameters: {'w0': 0.38306510506942304, 'w1': 0.15509986853609903}. Best is trial 1 with value: 0.034955804242702726.\n",
            "[I 2025-06-16 22:47:54,838] Trial 10 finished with value: 0.03550355758086743 and parameters: {'w0': 0.32276747602005496, 'w1': 0.6045449845914466}. Best is trial 1 with value: 0.034955804242702726.\n",
            "[I 2025-06-16 22:47:54,857] Trial 11 finished with value: 0.03420561723515603 and parameters: {'w0': 0.7470043641612909, 'w1': 0.012674398433836165}. Best is trial 11 with value: 0.03420561723515603.\n",
            "[I 2025-06-16 22:47:54,886] Trial 12 finished with value: 0.03441744389872481 and parameters: {'w0': 0.7546701106337836, 'w1': 0.02155302190660137}. Best is trial 11 with value: 0.03420561723515603.\n",
            "[I 2025-06-16 22:47:54,925] Trial 13 finished with value: 0.03400533090630231 and parameters: {'w0': 0.7843038864126475, 'w1': 0.009190692043162807}. Best is trial 13 with value: 0.03400533090630231.\n",
            "[I 2025-06-16 22:47:54,962] Trial 14 finished with value: 0.035163312803840774 and parameters: {'w0': 0.8470602083437647, 'w1': 0.33742278550954824}. Best is trial 13 with value: 0.03400533090630231.\n",
            "[I 2025-06-16 22:47:54,996] Trial 15 finished with value: 0.034003396510410844 and parameters: {'w0': 0.6194182109818395, 'w1': 0.0015612330224337063}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,045] Trial 16 finished with value: 0.03542766349277793 and parameters: {'w0': 0.5789482853265651, 'w1': 0.589629719983332}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,074] Trial 17 finished with value: 0.03530217377502276 and parameters: {'w0': 0.4136574849764866, 'w1': 0.9560007616914165}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,098] Trial 18 finished with value: 0.03523252510705177 and parameters: {'w0': 0.8962215697902861, 'w1': 0.22080841137996235}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,149] Trial 19 finished with value: 0.03536793816133865 and parameters: {'w0': 0.21566983790372096, 'w1': 0.4296697351915084}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,228] Trial 20 finished with value: 0.03476650467640274 and parameters: {'w0': 0.6272249572214726, 'w1': 0.03560239729287591}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,262] Trial 21 finished with value: 0.03482959555980536 and parameters: {'w0': 0.8257523119847258, 'w1': 0.038781743583251704}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,287] Trial 22 finished with value: 0.03516624496878695 and parameters: {'w0': 0.6791881283752793, 'w1': 0.1721345359935722}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,314] Trial 23 finished with value: 0.034558780051870075 and parameters: {'w0': 0.4771039296198968, 'w1': 0.017484758513108392}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,357] Trial 24 finished with value: 0.03503460269122105 and parameters: {'w0': 0.856324477682485, 'w1': 0.32783662538866803}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,377] Trial 25 finished with value: 0.03400713949304823 and parameters: {'w0': 0.703525534229794, 'w1': 0.0024136235278174045}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,404] Trial 26 finished with value: 0.03483310799042372 and parameters: {'w0': 0.60589495220795, 'w1': 0.1750474609663292}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,429] Trial 27 finished with value: 0.03523499064956914 and parameters: {'w0': 0.6707930120689802, 'w1': 0.2686836933331673}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,460] Trial 28 finished with value: 0.035027128566285426 and parameters: {'w0': 0.5032256741370054, 'w1': 0.08657611335121497}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,482] Trial 29 finished with value: 0.035443012601843016 and parameters: {'w0': 0.5233770811392684, 'w1': 0.2916923842004231}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,522] Trial 30 finished with value: 0.03516624496878695 and parameters: {'w0': 0.8025398358230841, 'w1': 0.2040670241420936}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,550] Trial 31 finished with value: 0.03509742556159434 and parameters: {'w0': 0.7155816615071815, 'w1': 0.07770994086628671}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,575] Trial 32 finished with value: 0.0344207905511148 and parameters: {'w0': 0.7183286842161188, 'w1': 0.023455895733513255}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,595] Trial 33 finished with value: 0.034003396510410844 and parameters: {'w0': 0.9029876270978483, 'w1': 0.002069786963394089}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,628] Trial 34 finished with value: 0.0351636328504189 and parameters: {'w0': 0.9420783290021888, 'w1': 0.11151153504242615}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,658] Trial 35 finished with value: 0.03495348158283784 and parameters: {'w0': 0.8976449860047085, 'w1': 0.13713358660332886}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,688] Trial 36 finished with value: 0.03483211323958624 and parameters: {'w0': 0.9716157951800253, 'w1': 0.08159032885166384}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,716] Trial 37 finished with value: 0.03496459262206708 and parameters: {'w0': 0.7898444317424135, 'w1': 0.24891976555336862}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,757] Trial 38 finished with value: 0.03413580699337815 and parameters: {'w0': 0.9987822791259177, 'w1': 0.0006188696625848786}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,787] Trial 39 finished with value: 0.03536741647511621 and parameters: {'w0': 0.8704786709422059, 'w1': 0.7831954580877034}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,823] Trial 40 finished with value: 0.03564654767337627 and parameters: {'w0': 0.0197337484614013, 'w1': 0.06684222006365742}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,848] Trial 41 finished with value: 0.03400713949304823 and parameters: {'w0': 0.9750358444535918, 'w1': 0.0032226196196681795}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,879] Trial 42 finished with value: 0.035027128566285426 and parameters: {'w0': 0.9092861884331223, 'w1': 0.14565793945422467}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,920] Trial 43 finished with value: 0.03483211323958624 and parameters: {'w0': 0.781428847669303, 'w1': 0.06806592894458044}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,950] Trial 44 finished with value: 0.03495871033263109 and parameters: {'w0': 0.9422209363727265, 'w1': 0.11974650004887026}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:55,974] Trial 45 finished with value: 0.03509815010288775 and parameters: {'w0': 0.6777465856514961, 'w1': 0.18408077166748482}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:56,005] Trial 46 finished with value: 0.03490137244577973 and parameters: {'w0': 0.8232803037095472, 'w1': 0.04996272545191489}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:56,034] Trial 47 finished with value: 0.0353631842444696 and parameters: {'w0': 0.7383074498206316, 'w1': 0.6536859859440693}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:56,070] Trial 48 finished with value: 0.034071848878376776 and parameters: {'w0': 0.638013268160216, 'w1': 0.0010271711800198414}. Best is trial 15 with value: 0.034003396510410844.\n",
            "[I 2025-06-16 22:47:56,096] Trial 49 finished with value: 0.03522892386890064 and parameters: {'w0': 0.570306186649786, 'w1': 0.1151127527145685}. Best is trial 15 with value: 0.034003396510410844.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 22:48:10,194] A new study created in memory with name: no-name-40933846-6819-413b-a63c-638496af3d76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 - F1 weighted fusion: 0.9677\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "                      Livres     0.8846    0.9113    0.8978       530\n",
            "                  Jeux Vidéo     0.9604    0.9671    0.9637       426\n",
            "     Accessoires jeux vidéos     0.9912    0.9971    0.9941       340\n",
            "       Jeux vidéo & Consoles     1.0000    0.9941    0.9971       340\n",
            "                   Figurines     0.9091    0.9471    0.9277       454\n",
            "              Cartes de jeux     0.9852    0.9881    0.9866       672\n",
            "Jeux de rôle et de figurines     0.9741    0.9941    0.9840       340\n",
            "             Jouets & Enfant     0.9345    0.8961    0.9149       828\n",
            "             Jeux de société     0.9207    0.9233    0.9220       352\n",
            "   Véhicules RC & miniatures     0.9906    0.9906    0.9906       850\n",
            "            Chaussettes bébé     1.0000    1.0000    1.0000       340\n",
            "            Sports & Loisirs     0.9742    0.9835    0.9788       423\n",
            "                Puériculture     0.9835    0.9728    0.9781       551\n",
            "                      Maison     0.9853    0.9459    0.9652       850\n",
            "             Linge de maison     0.9626    0.9850    0.9736       731\n",
            "              Petit déjeuner     0.9971    1.0000    0.9985       340\n",
            "                  Décoration     0.9553    0.9576    0.9565       849\n",
            "                  Animalerie     1.0000    0.9971    0.9985       340\n",
            "                       Revue     0.9503    0.9691    0.9596       809\n",
            "        Lots Livres & Revues     0.9623    0.9126    0.9368       812\n",
            "        Lots consoles & jeux     0.9741    0.9971    0.9855       340\n",
            "       Fournitures Papeterie     0.9812    0.9847    0.9829       848\n",
            "          Mobilier de jardin     0.9709    0.9864    0.9786       440\n",
            "    Équipement piscine & spa     0.9976    0.9929    0.9953       850\n",
            "         Outillage de jardin     0.9883    0.9976    0.9930       425\n",
            "                      eBooks     0.9293    0.9511    0.9401       470\n",
            "      Jeux en téléchargement     1.0000    1.0000    1.0000       340\n",
            "\n",
            "                    accuracy                         0.9677     14890\n",
            "                   macro avg     0.9690    0.9719    0.9704     14890\n",
            "                weighted avg     0.9679    0.9677    0.9677     14890\n",
            "\n",
            "\n",
            "=== Fold 2/5 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f4c843fd8d44d909f4cc5f7ef21f488"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:48:44,897] Trial 1 finished with value: 0.964170368204356 and parameters: {'lgb_lr': 0.005806988401329885, 'lgb_num_leaves': 25, 'lgb_max_depth': 3}. Best is trial 1 with value: 0.964170368204356.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:49:01,786] Trial 4 finished with value: 0.9657775704882169 and parameters: {'lgb_lr': 0.046990061603282965, 'lgb_num_leaves': 40, 'lgb_max_depth': 4}. Best is trial 4 with value: 0.9657775704882169.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:49:21,680] Trial 11 finished with value: 0.9656265491072775 and parameters: {'lgb_lr': 0.06992638082637512, 'lgb_num_leaves': 23, 'lgb_max_depth': 5}. Best is trial 4 with value: 0.9657775704882169.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:49:22,933] Trial 10 finished with value: 0.9638640960772775 and parameters: {'lgb_lr': 0.0806304059945325, 'lgb_num_leaves': 25, 'lgb_max_depth': 9}. Best is trial 4 with value: 0.9657775704882169.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:49:23,168] Trial 5 finished with value: 0.9656644061860975 and parameters: {'lgb_lr': 0.0020604489604441833, 'lgb_num_leaves': 28, 'lgb_max_depth': 7}. Best is trial 4 with value: 0.9657775704882169.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:49:24,484] Trial 7 finished with value: 0.9662245612433951 and parameters: {'lgb_lr': 0.011049871937945552, 'lgb_num_leaves': 22, 'lgb_max_depth': 10}. Best is trial 7 with value: 0.9662245612433951.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:49:25,890] Trial 6 finished with value: 0.9649883129652064 and parameters: {'lgb_lr': 0.0013834178812532217, 'lgb_num_leaves': 29, 'lgb_max_depth': 7}. Best is trial 7 with value: 0.9662245612433951.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:49:44,186] Trial 9 finished with value: 0.9665149165893618 and parameters: {'lgb_lr': 0.023555412063978095, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 9 with value: 0.9665149165893618.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:49:45,360] Trial 0 finished with value: 0.9641406748348885 and parameters: {'lgb_lr': 0.06524329448872195, 'lgb_num_leaves': 38, 'lgb_max_depth': 8}. Best is trial 9 with value: 0.9665149165893618.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:49:46,503] Trial 2 finished with value: 0.9659036357933535 and parameters: {'lgb_lr': 0.03239368222295553, 'lgb_num_leaves': 39, 'lgb_max_depth': 9}. Best is trial 9 with value: 0.9665149165893618.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:49:51,232] Trial 8 finished with value: 0.9664221284278436 and parameters: {'lgb_lr': 0.025445621375702644, 'lgb_num_leaves': 50, 'lgb_max_depth': 6}. Best is trial 9 with value: 0.9665149165893618.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:50:02,247] Trial 3 finished with value: 0.9659657959477838 and parameters: {'lgb_lr': 0.04338566011307751, 'lgb_num_leaves': 46, 'lgb_max_depth': 7}. Best is trial 9 with value: 0.9665149165893618.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:50:03,048] Trial 18 finished with value: 0.9657221315952764 and parameters: {'lgb_lr': 0.021386844606534616, 'lgb_num_leaves': 45, 'lgb_max_depth': 3}. Best is trial 9 with value: 0.9665149165893618.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:50:06,343] Trial 12 finished with value: 0.9663752779526704 and parameters: {'lgb_lr': 0.023181107106566557, 'lgb_num_leaves': 46, 'lgb_max_depth': 5}. Best is trial 9 with value: 0.9665149165893618.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:50:10,743] Trial 14 finished with value: 0.9647207022798086 and parameters: {'lgb_lr': 0.0012326813958615287, 'lgb_num_leaves': 44, 'lgb_max_depth': 4}. Best is trial 9 with value: 0.9665149165893618.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:50:13,999] Trial 17 finished with value: 0.9652020578595537 and parameters: {'lgb_lr': 0.009488735100954552, 'lgb_num_leaves': 30, 'lgb_max_depth': 4}. Best is trial 9 with value: 0.9665149165893618.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:50:16,201] Trial 13 finished with value: 0.9655538084176022 and parameters: {'lgb_lr': 0.03435877182674257, 'lgb_num_leaves': 37, 'lgb_max_depth': 5}. Best is trial 9 with value: 0.9665149165893618.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:50:46,933] Trial 16 finished with value: 0.9669538513022345 and parameters: {'lgb_lr': 0.007050219287614871, 'lgb_num_leaves': 32, 'lgb_max_depth': 8}. Best is trial 16 with value: 0.9669538513022345.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:50:52,622] Trial 15 finished with value: 0.9664222090732836 and parameters: {'lgb_lr': 0.01309783725949132, 'lgb_num_leaves': 28, 'lgb_max_depth': 8}. Best is trial 16 with value: 0.9669538513022345.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:50:53,413] Trial 19 finished with value: 0.9658853662302058 and parameters: {'lgb_lr': 0.012283753370761768, 'lgb_num_leaves': 39, 'lgb_max_depth': 5}. Best is trial 16 with value: 0.9669538513022345.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:50:57,873] Trial 20 finished with value: 0.9656919344095216 and parameters: {'lgb_lr': 0.018343353877349915, 'lgb_num_leaves': 29, 'lgb_max_depth': 5}. Best is trial 16 with value: 0.9669538513022345.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:51:13,396] Trial 24 finished with value: 0.9655509982498628 and parameters: {'lgb_lr': 0.013716856796258352, 'lgb_num_leaves': 50, 'lgb_max_depth': 5}. Best is trial 16 with value: 0.9669538513022345.\n",
            "[I 2025-06-16 22:51:13,400] Trial 23 finished with value: 0.9660190976178278 and parameters: {'lgb_lr': 0.017672372178769394, 'lgb_num_leaves': 48, 'lgb_max_depth': 5}. Best is trial 16 with value: 0.9669538513022345.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:51:26,271] Trial 21 finished with value: 0.9666982055501991 and parameters: {'lgb_lr': 0.019968683488796667, 'lgb_num_leaves': 49, 'lgb_max_depth': 6}. Best is trial 16 with value: 0.9669538513022345.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:51:27,032] Trial 22 finished with value: 0.966080390061462 and parameters: {'lgb_lr': 0.017878182574900862, 'lgb_num_leaves': 49, 'lgb_max_depth': 6}. Best is trial 16 with value: 0.9669538513022345.\n",
            "[I 2025-06-16 22:51:27,146] Trial 25 finished with value: 0.9660254139631163 and parameters: {'lgb_lr': 0.012304507754710673, 'lgb_num_leaves': 32, 'lgb_max_depth': 6}. Best is trial 16 with value: 0.9669538513022345.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:51:31,973] Trial 26 finished with value: 0.9669624317224308 and parameters: {'lgb_lr': 0.011199736166421517, 'lgb_num_leaves': 33, 'lgb_max_depth': 6}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:51:50,786] Trial 28 finished with value: 0.9662202667735624 and parameters: {'lgb_lr': 0.013237206967018418, 'lgb_num_leaves': 50, 'lgb_max_depth': 6}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:51:58,342] Trial 27 finished with value: 0.9660197792869729 and parameters: {'lgb_lr': 0.013113204764001655, 'lgb_num_leaves': 50, 'lgb_max_depth': 6}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:52:09,600] Trial 29 finished with value: 0.9659457502040696 and parameters: {'lgb_lr': 0.0038765461392334948, 'lgb_num_leaves': 33, 'lgb_max_depth': 8}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:52:12,708] Trial 30 finished with value: 0.9658724710252132 and parameters: {'lgb_lr': 0.0034104388573100116, 'lgb_num_leaves': 33, 'lgb_max_depth': 10}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:52:15,363] Trial 31 finished with value: 0.9663528045412141 and parameters: {'lgb_lr': 0.004423323793442502, 'lgb_num_leaves': 33, 'lgb_max_depth': 10}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:52:18,736] Trial 32 finished with value: 0.9664236576861519 and parameters: {'lgb_lr': 0.00421181235274756, 'lgb_num_leaves': 33, 'lgb_max_depth': 8}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:52:37,042] Trial 33 finished with value: 0.9661436812842165 and parameters: {'lgb_lr': 0.0057153112608376525, 'lgb_num_leaves': 33, 'lgb_max_depth': 8}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:52:49,954] Trial 34 finished with value: 0.9668228564558881 and parameters: {'lgb_lr': 0.005612540550202768, 'lgb_num_leaves': 33, 'lgb_max_depth': 8}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:52:50,380] Trial 37 finished with value: 0.9663578045322684 and parameters: {'lgb_lr': 0.004158319646509875, 'lgb_num_leaves': 34, 'lgb_max_depth': 8}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:53:01,343] Trial 35 finished with value: 0.9664901302000727 and parameters: {'lgb_lr': 0.005872663869280654, 'lgb_num_leaves': 33, 'lgb_max_depth': 8}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:53:02,305] Trial 36 finished with value: 0.9665559613271522 and parameters: {'lgb_lr': 0.0055746450209483815, 'lgb_num_leaves': 33, 'lgb_max_depth': 8}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:53:08,868] Trial 38 finished with value: 0.9664154113150908 and parameters: {'lgb_lr': 0.005038422552380741, 'lgb_num_leaves': 34, 'lgb_max_depth': 9}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:53:19,899] Trial 40 finished with value: 0.9664881817696471 and parameters: {'lgb_lr': 0.006006850423718381, 'lgb_num_leaves': 33, 'lgb_max_depth': 9}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:53:25,673] Trial 39 finished with value: 0.9666234881067302 and parameters: {'lgb_lr': 0.006306108403605583, 'lgb_num_leaves': 34, 'lgb_max_depth': 9}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:53:31,824] Trial 41 finished with value: 0.9664819574699394 and parameters: {'lgb_lr': 0.006625859884597994, 'lgb_num_leaves': 34, 'lgb_max_depth': 9}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:53:38,183] Trial 42 finished with value: 0.9664794893078328 and parameters: {'lgb_lr': 0.007769825385110277, 'lgb_num_leaves': 36, 'lgb_max_depth': 8}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:53:39,600] Trial 43 finished with value: 0.9666165952773575 and parameters: {'lgb_lr': 0.00798318704054384, 'lgb_num_leaves': 36, 'lgb_max_depth': 9}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:53:50,910] Trial 44 finished with value: 0.9669459726431135 and parameters: {'lgb_lr': 0.007322830229747623, 'lgb_num_leaves': 42, 'lgb_max_depth': 9}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:53:57,867] Trial 45 finished with value: 0.9668224133062893 and parameters: {'lgb_lr': 0.007797289046610264, 'lgb_num_leaves': 36, 'lgb_max_depth': 9}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:54:11,739] Trial 47 finished with value: 0.9665519598924843 and parameters: {'lgb_lr': 0.00823186223545406, 'lgb_num_leaves': 41, 'lgb_max_depth': 9}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:54:13,753] Trial 48 finished with value: 0.9662132723163575 and parameters: {'lgb_lr': 0.008950851416708702, 'lgb_num_leaves': 36, 'lgb_max_depth': 9}. Best is trial 26 with value: 0.9669624317224308.\n",
            "[I 2025-06-16 22:54:14,007] Trial 46 finished with value: 0.9665546474309764 and parameters: {'lgb_lr': 0.007906787872408137, 'lgb_num_leaves': 35, 'lgb_max_depth': 9}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:54:21,799] Trial 49 finished with value: 0.9662192206093577 and parameters: {'lgb_lr': 0.007900993921066943, 'lgb_num_leaves': 42, 'lgb_max_depth': 7}. Best is trial 26 with value: 0.9669624317224308.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003200 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59557, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 22:54:31,324] A new study created in memory with name: no-name-e07d14fd-6b30-42bb-a8ca-a8e3c9bccb5f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 - F1 weighted lgbm: 0.9670\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0a58d2288f04311a86b423384df1a7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:54:50,313] Trial 0 finished with value: 0.9639656972141826 and parameters: {'mlp_hidden_dim': 952, 'mlp_lr': 0.00010259686861051746, 'mlp_wd': 0.00021576003755376417}. Best is trial 0 with value: 0.9639656972141826.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:55:09,441] Trial 1 finished with value: 0.9656314483574274 and parameters: {'mlp_hidden_dim': 1017, 'mlp_lr': 0.0010707959972811438, 'mlp_wd': 2.1694487290114166e-05}. Best is trial 1 with value: 0.9656314483574274.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:55:28,491] Trial 2 finished with value: 0.9656550741861718 and parameters: {'mlp_hidden_dim': 839, 'mlp_lr': 0.0007001136558052602, 'mlp_wd': 1.1688571552723455e-05}. Best is trial 2 with value: 0.9656550741861718.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:55:47,430] Trial 3 finished with value: 0.9652858027410103 and parameters: {'mlp_hidden_dim': 953, 'mlp_lr': 0.0010509393511841975, 'mlp_wd': 6.003391030262971e-05}. Best is trial 2 with value: 0.9656550741861718.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:56:06,476] Trial 4 finished with value: 0.9658325741857474 and parameters: {'mlp_hidden_dim': 817, 'mlp_lr': 0.0013722011000702377, 'mlp_wd': 1.988052770186077e-06}. Best is trial 4 with value: 0.9658325741857474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:56:25,335] Trial 5 finished with value: 0.9641584017198663 and parameters: {'mlp_hidden_dim': 496, 'mlp_lr': 0.00024856142731753515, 'mlp_wd': 5.45639319969505e-06}. Best is trial 4 with value: 0.9658325741857474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:56:44,530] Trial 6 finished with value: 0.9658268636121206 and parameters: {'mlp_hidden_dim': 415, 'mlp_lr': 0.004973492324428454, 'mlp_wd': 2.127370633422157e-05}. Best is trial 4 with value: 0.9658325741857474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:57:03,641] Trial 7 finished with value: 0.9638994793112434 and parameters: {'mlp_hidden_dim': 297, 'mlp_lr': 0.00020724619636544505, 'mlp_wd': 0.00016967377260338889}. Best is trial 4 with value: 0.9658325741857474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:57:22,634] Trial 8 finished with value: 0.9639761548812948 and parameters: {'mlp_hidden_dim': 971, 'mlp_lr': 0.00015136349973454355, 'mlp_wd': 0.0002679113415785796}. Best is trial 4 with value: 0.9658325741857474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:57:41,770] Trial 9 finished with value: 0.9641969351435447 and parameters: {'mlp_hidden_dim': 591, 'mlp_lr': 0.004378434633067846, 'mlp_wd': 0.0004361405507463263}. Best is trial 4 with value: 0.9658325741857474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:58:00,886] Trial 10 finished with value: 0.9655372447461306 and parameters: {'mlp_hidden_dim': 740, 'mlp_lr': 0.009778915020378585, 'mlp_wd': 1.1508235078760865e-06}. Best is trial 4 with value: 0.9658325741857474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:58:19,752] Trial 11 finished with value: 0.9654071891364212 and parameters: {'mlp_hidden_dim': 365, 'mlp_lr': 0.003419131774272672, 'mlp_wd': 1.1873764182107275e-06}. Best is trial 4 with value: 0.9658325741857474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:58:38,837] Trial 12 finished with value: 0.9654763015523332 and parameters: {'mlp_hidden_dim': 705, 'mlp_lr': 0.0024883462234996188, 'mlp_wd': 3.858202981216491e-06}. Best is trial 4 with value: 0.9658325741857474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:58:58,176] Trial 13 finished with value: 0.9654347956187231 and parameters: {'mlp_hidden_dim': 490, 'mlp_lr': 0.009964702610192966, 'mlp_wd': 5.117178595897653e-05}. Best is trial 4 with value: 0.9658325741857474.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:59:17,319] Trial 14 finished with value: 0.9659419187203001 and parameters: {'mlp_hidden_dim': 814, 'mlp_lr': 0.0020911347588307857, 'mlp_wd': 4.353748837783687e-06}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:59:36,478] Trial 15 finished with value: 0.9656243484497478 and parameters: {'mlp_hidden_dim': 825, 'mlp_lr': 0.00048317348377344404, 'mlp_wd': 3.7615946813940518e-06}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 22:59:55,462] Trial 16 finished with value: 0.9656695698874079 and parameters: {'mlp_hidden_dim': 847, 'mlp_lr': 0.00188840731400881, 'mlp_wd': 2.071430050892139e-06}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:00:14,270] Trial 17 finished with value: 0.9658201568690404 and parameters: {'mlp_hidden_dim': 609, 'mlp_lr': 0.0016478499512909924, 'mlp_wd': 8.269805635589075e-06}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:00:33,422] Trial 18 finished with value: 0.9655414691513625 and parameters: {'mlp_hidden_dim': 748, 'mlp_lr': 0.00048072263308460183, 'mlp_wd': 2.2640817318379332e-06}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:00:52,644] Trial 19 finished with value: 0.9654402306952772 and parameters: {'mlp_hidden_dim': 868, 'mlp_lr': 0.0015020024348546008, 'mlp_wd': 7.491418094598617e-06}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:01:11,827] Trial 20 finished with value: 0.9653461662885964 and parameters: {'mlp_hidden_dim': 683, 'mlp_lr': 0.0006731907298598458, 'mlp_wd': 2.507489581163684e-06}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:01:30,870] Trial 21 finished with value: 0.9657842072672418 and parameters: {'mlp_hidden_dim': 507, 'mlp_lr': 0.0051037214916722, 'mlp_wd': 1.7655260248769556e-05}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:01:49,866] Trial 22 finished with value: 0.9657505358056203 and parameters: {'mlp_hidden_dim': 389, 'mlp_lr': 0.006335937044438778, 'mlp_wd': 4.174501450192142e-05}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:02:08,807] Trial 23 finished with value: 0.9657034323051105 and parameters: {'mlp_hidden_dim': 789, 'mlp_lr': 0.002881872696921643, 'mlp_wd': 1.8070626949845455e-05}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:02:27,843] Trial 24 finished with value: 0.9651728952468186 and parameters: {'mlp_hidden_dim': 261, 'mlp_lr': 0.0020843528324311763, 'mlp_wd': 0.00010695188735067952}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:02:47,035] Trial 25 finished with value: 0.9657483950130353 and parameters: {'mlp_hidden_dim': 564, 'mlp_lr': 0.006856119369300128, 'mlp_wd': 1.0956813413087743e-05}. Best is trial 14 with value: 0.9659419187203001.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:03:06,161] Trial 26 finished with value: 0.9661568988209062 and parameters: {'mlp_hidden_dim': 672, 'mlp_lr': 0.003858945005016956, 'mlp_wd': 5.078508623429993e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:03:25,266] Trial 27 finished with value: 0.965816863428141 and parameters: {'mlp_hidden_dim': 662, 'mlp_lr': 0.003382074160038317, 'mlp_wd': 4.234532628463588e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:03:44,352] Trial 28 finished with value: 0.9658611026427686 and parameters: {'mlp_hidden_dim': 921, 'mlp_lr': 0.0013763192026890162, 'mlp_wd': 1.7090694727168316e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:04:03,323] Trial 29 finished with value: 0.9636547583124557 and parameters: {'mlp_hidden_dim': 892, 'mlp_lr': 0.0007967522725873382, 'mlp_wd': 0.0008338908198765303}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:04:22,476] Trial 30 finished with value: 0.9659179452960347 and parameters: {'mlp_hidden_dim': 898, 'mlp_lr': 0.0024134473781226053, 'mlp_wd': 1.028578511594673e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:04:41,680] Trial 31 finished with value: 0.9651664815289974 and parameters: {'mlp_hidden_dim': 890, 'mlp_lr': 0.002444249921961289, 'mlp_wd': 1.0542484178037544e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:05:00,925] Trial 32 finished with value: 0.9661228680856151 and parameters: {'mlp_hidden_dim': 1018, 'mlp_lr': 0.0011741611938147639, 'mlp_wd': 1.4541738010813108e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:05:20,096] Trial 33 finished with value: 0.965693658207071 and parameters: {'mlp_hidden_dim': 1023, 'mlp_lr': 0.003482147899106476, 'mlp_wd': 3.104289255864613e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:05:39,329] Trial 34 finished with value: 0.9659012324043142 and parameters: {'mlp_hidden_dim': 973, 'mlp_lr': 0.0010540573195618147, 'mlp_wd': 1.4807157185208962e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:05:58,217] Trial 35 finished with value: 0.9654212256381766 and parameters: {'mlp_hidden_dim': 776, 'mlp_lr': 0.0019925815385366343, 'mlp_wd': 5.937792312221546e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:06:17,465] Trial 36 finished with value: 0.9655586330919672 and parameters: {'mlp_hidden_dim': 945, 'mlp_lr': 0.0008831083126050587, 'mlp_wd': 2.8604943414216417e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:06:36,586] Trial 37 finished with value: 0.9658803307353055 and parameters: {'mlp_hidden_dim': 1002, 'mlp_lr': 0.001283718320527611, 'mlp_wd': 5.71006419766611e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:06:55,657] Trial 38 finished with value: 0.965539331387446 and parameters: {'mlp_hidden_dim': 923, 'mlp_lr': 0.0005679483117762326, 'mlp_wd': 1.505581175249387e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:07:14,791] Trial 39 finished with value: 0.964862270812282 and parameters: {'mlp_hidden_dim': 789, 'mlp_lr': 0.0003040511171402133, 'mlp_wd': 1.035716989578607e-05}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:07:33,945] Trial 40 finished with value: 0.9660328803685816 and parameters: {'mlp_hidden_dim': 715, 'mlp_lr': 0.0044562044143359875, 'mlp_wd': 2.656800522896396e-05}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:07:52,898] Trial 41 finished with value: 0.965776774768225 and parameters: {'mlp_hidden_dim': 715, 'mlp_lr': 0.004396690980542269, 'mlp_wd': 2.8751614829106036e-05}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:08:12,024] Trial 42 finished with value: 0.9657226604882718 and parameters: {'mlp_hidden_dim': 831, 'mlp_lr': 0.007155148975407998, 'mlp_wd': 0.00011147782149795136}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:08:31,150] Trial 43 finished with value: 0.965194595861986 and parameters: {'mlp_hidden_dim': 636, 'mlp_lr': 0.002888518875891053, 'mlp_wd': 1.5416070735766463e-05}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:08:50,344] Trial 44 finished with value: 0.9658471369271147 and parameters: {'mlp_hidden_dim': 750, 'mlp_lr': 0.003926819600149025, 'mlp_wd': 1.0305518972900635e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:09:09,487] Trial 45 finished with value: 0.965654715224136 and parameters: {'mlp_hidden_dim': 986, 'mlp_lr': 0.002613529721066741, 'mlp_wd': 2.7659155489701783e-05}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:09:28,687] Trial 46 finished with value: 0.9660375833216182 and parameters: {'mlp_hidden_dim': 706, 'mlp_lr': 0.0011624287718191985, 'mlp_wd': 1.7181598757569099e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:09:47,689] Trial 47 finished with value: 0.965532780755381 and parameters: {'mlp_hidden_dim': 546, 'mlp_lr': 0.0011870409098651852, 'mlp_wd': 4.6429554464509966e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:10:06,884] Trial 48 finished with value: 0.9658313302149113 and parameters: {'mlp_hidden_dim': 637, 'mlp_lr': 0.0016495943138894707, 'mlp_wd': 3.4392137703135396e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:10:25,992] Trial 49 finished with value: 0.9657771853731766 and parameters: {'mlp_hidden_dim': 696, 'mlp_lr': 0.0009367844534797391, 'mlp_wd': 8.032209755958876e-06}. Best is trial 26 with value: 0.9661568988209062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n",
            "[I 2025-06-16 23:10:45,146] A new study created in memory with name: no-name-8de161fd-090b-4590-8624-a7472f4fae4e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 - F1 weighted mlp: 0.9666\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "043809372410486f85b81affdaa9013a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:10:45,165] Trial 0 finished with value: 0.03291561779718899 and parameters: {'w0': 0.9622858892197731, 'w1': 0.6670125453542151}. Best is trial 0 with value: 0.03291561779718899.\n",
            "[I 2025-06-16 23:10:45,176] Trial 1 finished with value: 0.03323780083123973 and parameters: {'w0': 0.4074161236192805, 'w1': 0.7244520443367027}. Best is trial 0 with value: 0.03291561779718899.\n",
            "[I 2025-06-16 23:10:45,192] Trial 2 finished with value: 0.033107625709316246 and parameters: {'w0': 0.3628737663258157, 'w1': 0.4960667033930132}. Best is trial 0 with value: 0.03291561779718899.\n",
            "[I 2025-06-16 23:10:45,211] Trial 3 finished with value: 0.03323780083123973 and parameters: {'w0': 0.4563896577251, 'w1': 0.8159885534393508}. Best is trial 0 with value: 0.03291561779718899.\n",
            "[I 2025-06-16 23:10:45,225] Trial 4 finished with value: 0.03303316096156894 and parameters: {'w0': 0.09392585317970359, 'w1': 0.6365781609860885}. Best is trial 0 with value: 0.03291561779718899.\n",
            "[I 2025-06-16 23:10:45,242] Trial 5 finished with value: 0.032617712222343886 and parameters: {'w0': 0.23293924056918947, 'w1': 0.033832598234549316}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,268] Trial 6 finished with value: 0.033107625709316246 and parameters: {'w0': 0.6187996547672797, 'w1': 0.8540110576929932}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,276] Trial 7 finished with value: 0.03290877763544342 and parameters: {'w0': 0.8409628501957929, 'w1': 0.9527895195790086}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,296] Trial 8 finished with value: 0.03291561779718899 and parameters: {'w0': 0.4840905393322179, 'w1': 0.33656490404247774}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,327] Trial 9 finished with value: 0.03330746212382851 and parameters: {'w0': 0.3349596786377885, 'w1': 0.6585262361379055}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,356] Trial 10 finished with value: 0.033237396684105636 and parameters: {'w0': 0.026555961479313606, 'w1': 0.06491920331164747}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,384] Trial 11 finished with value: 0.03296233077911126 and parameters: {'w0': 0.8484643043487003, 'w1': 0.03480609170463649}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,415] Trial 12 finished with value: 0.03297278754997235 and parameters: {'w0': 0.7491414547779629, 'w1': 0.9947705844795549}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,436] Trial 13 finished with value: 0.03290640957365398 and parameters: {'w0': 0.20837198826946265, 'w1': 0.2496091694178518}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,466] Trial 14 finished with value: 0.032845424986783334 and parameters: {'w0': 0.22837475464385026, 'w1': 0.21972375297010488}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,498] Trial 15 finished with value: 0.032843192459403814 and parameters: {'w0': 0.1698550715244121, 'w1': 0.18685717542378516}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,525] Trial 16 finished with value: 0.032982664099936665 and parameters: {'w0': 0.20818053483095342, 'w1': 0.1503358824968417}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,562] Trial 17 finished with value: 0.03291561779718899 and parameters: {'w0': 0.5976067369919451, 'w1': 0.40535072614063605}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,592] Trial 18 finished with value: 0.0327544574603198 and parameters: {'w0': 0.11236522855015511, 'w1': 0.009867660809606327}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,620] Trial 19 finished with value: 0.032737616769676126 and parameters: {'w0': 0.2954522216442172, 'w1': 0.0907444978834181}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,659] Trial 20 finished with value: 0.03290877763544342 and parameters: {'w0': 0.2994998854374325, 'w1': 0.3516996207940668}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,686] Trial 21 finished with value: 0.03307847864095792 and parameters: {'w0': 0.0060375809914874345, 'w1': 0.001171181089171379}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,723] Trial 22 finished with value: 0.032845424986783334 and parameters: {'w0': 0.11539806263615113, 'w1': 0.11014381765809905}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,758] Trial 23 finished with value: 0.03279982095579659 and parameters: {'w0': 0.2862057005971209, 'w1': 0.10531883513889338}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,781] Trial 24 finished with value: 0.03316921498350689 and parameters: {'w0': 0.09973548706481317, 'w1': 0.27062983362721527}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,823] Trial 25 finished with value: 0.032692021272486826 and parameters: {'w0': 0.25472903689237364, 'w1': 0.014428831084756639}. Best is trial 5 with value: 0.032617712222343886.\n",
            "[I 2025-06-16 23:10:45,847] Trial 26 finished with value: 0.032603081202661977 and parameters: {'w0': 0.5681043946579216, 'w1': 0.13612835806674764}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:45,882] Trial 27 finished with value: 0.03266888873321183 and parameters: {'w0': 0.6494785577953881, 'w1': 0.1644450119932528}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:45,923] Trial 28 finished with value: 0.03291363308470574 and parameters: {'w0': 0.5812600067642841, 'w1': 0.497147828927975}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:45,949] Trial 29 finished with value: 0.03260638502247826 and parameters: {'w0': 0.7087262149469942, 'w1': 0.16413476987653294}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:45,986] Trial 30 finished with value: 0.03279771609544346 and parameters: {'w0': 0.7069347215501474, 'w1': 0.30620697778659034}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:46,032] Trial 31 finished with value: 0.03260347009650222 and parameters: {'w0': 0.6920046071124717, 'w1': 0.1689947695321526}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:46,061] Trial 32 finished with value: 0.032982664099936665 and parameters: {'w0': 0.5409253297232132, 'w1': 0.39101861461888326}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:46,085] Trial 33 finished with value: 0.03295018703135466 and parameters: {'w0': 0.9195144610604665, 'w1': 0.14997336240821446}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:46,115] Trial 34 finished with value: 0.03273579351006972 and parameters: {'w0': 0.71963245488286, 'w1': 0.20881891931317986}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:46,222] Trial 35 finished with value: 0.032845424986783334 and parameters: {'w0': 0.4463640502354168, 'w1': 0.43287401517945556}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:46,257] Trial 36 finished with value: 0.03305123692629797 and parameters: {'w0': 0.7870096320094768, 'w1': 0.6094203798566388}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:46,282] Trial 37 finished with value: 0.033107625709316246 and parameters: {'w0': 0.39485694582260655, 'w1': 0.5684035473281809}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:46,305] Trial 38 finished with value: 0.03272976512582071 and parameters: {'w0': 0.6657762230300912, 'w1': 0.2848015025172792}. Best is trial 26 with value: 0.032603081202661977.\n",
            "[I 2025-06-16 23:10:46,337] Trial 39 finished with value: 0.03247978060194889 and parameters: {'w0': 0.5246550046934623, 'w1': 0.06622274197411615}. Best is trial 39 with value: 0.03247978060194889.\n",
            "[I 2025-06-16 23:10:46,363] Trial 40 finished with value: 0.033107625709316246 and parameters: {'w0': 0.5316847457793994, 'w1': 0.7244333803299099}. Best is trial 39 with value: 0.03247978060194889.\n",
            "[I 2025-06-16 23:10:46,398] Trial 41 finished with value: 0.032686976469692874 and parameters: {'w0': 0.4341056397388121, 'w1': 0.05987304870531296}. Best is trial 39 with value: 0.03247978060194889.\n",
            "[I 2025-06-16 23:10:46,427] Trial 42 finished with value: 0.03260347009650222 and parameters: {'w0': 0.539542916503815, 'w1': 0.13037070329978656}. Best is trial 39 with value: 0.03247978060194889.\n",
            "[I 2025-06-16 23:10:46,462] Trial 43 finished with value: 0.03266888873321183 and parameters: {'w0': 0.5153937773971221, 'w1': 0.12799769711364453}. Best is trial 39 with value: 0.03247978060194889.\n",
            "[I 2025-06-16 23:10:46,485] Trial 44 finished with value: 0.032731091822291725 and parameters: {'w0': 0.5650381598670419, 'w1': 0.2279781175503285}. Best is trial 39 with value: 0.03247978060194889.\n",
            "[I 2025-06-16 23:10:46,525] Trial 45 finished with value: 0.032686976469692874 and parameters: {'w0': 0.63511107580914, 'w1': 0.08668512362134742}. Best is trial 39 with value: 0.03247978060194889.\n",
            "[I 2025-06-16 23:10:46,557] Trial 46 finished with value: 0.03260638502247826 and parameters: {'w0': 0.7939408957404545, 'w1': 0.18445924454641563}. Best is trial 39 with value: 0.03247978060194889.\n",
            "[I 2025-06-16 23:10:46,581] Trial 47 finished with value: 0.032547254988762875 and parameters: {'w0': 0.49136456740292006, 'w1': 0.0643456677334549}. Best is trial 39 with value: 0.03247978060194889.\n",
            "[I 2025-06-16 23:10:46,602] Trial 48 finished with value: 0.03288135266663139 and parameters: {'w0': 0.3854889982104242, 'w1': 0.061646654956067394}. Best is trial 39 with value: 0.03247978060194889.\n",
            "[I 2025-06-16 23:10:46,626] Trial 49 finished with value: 0.03275457896307765 and parameters: {'w0': 0.4841982113214503, 'w1': 0.051986650959133004}. Best is trial 39 with value: 0.03247978060194889.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 23:11:00,991] A new study created in memory with name: no-name-11974d2d-b51a-4447-a5e6-aa723d2c82af\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 - F1 weighted fusion: 0.9685\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "                      Livres     0.8695    0.9302    0.8988       530\n",
            "                  Jeux Vidéo     0.9560    0.9672    0.9616       427\n",
            "     Accessoires jeux vidéos     0.9825    0.9912    0.9868       340\n",
            "       Jeux vidéo & Consoles     0.9971    1.0000    0.9985       340\n",
            "                   Figurines     0.9310    0.9515    0.9412       454\n",
            "              Cartes de jeux     0.9911    0.9911    0.9911       672\n",
            "Jeux de rôle et de figurines     0.9855    1.0000    0.9927       340\n",
            "             Jouets & Enfant     0.9484    0.9106    0.9291       828\n",
            "             Jeux de société     0.9019    0.9659    0.9328       352\n",
            "   Véhicules RC & miniatures     0.9953    0.9965    0.9959       850\n",
            "            Chaussettes bébé     1.0000    1.0000    1.0000       340\n",
            "            Sports & Loisirs     0.9832    0.9669    0.9750       423\n",
            "                Puériculture     0.9726    0.9655    0.9690       551\n",
            "                      Maison     0.9724    0.9529    0.9626       850\n",
            "             Linge de maison     0.9517    0.9699    0.9607       731\n",
            "              Petit déjeuner     1.0000    1.0000    1.0000       340\n",
            "                  Décoration     0.9605    0.9458    0.9531       848\n",
            "                  Animalerie     0.9971    0.9971    0.9971       340\n",
            "                       Revue     0.9513    0.9654    0.9583       809\n",
            "        Lots Livres & Revues     0.9576    0.9175    0.9371       812\n",
            "        Lots consoles & jeux     0.9797    0.9941    0.9869       340\n",
            "       Fournitures Papeterie     0.9858    0.9847    0.9853       849\n",
            "          Mobilier de jardin     0.9516    0.9841    0.9676       440\n",
            "    Équipement piscine & spa     0.9976    0.9988    0.9982       850\n",
            "         Outillage de jardin     1.0000    0.9929    0.9965       425\n",
            "                      eBooks     0.9687    0.9232    0.9454       469\n",
            "      Jeux en téléchargement     1.0000    1.0000    1.0000       340\n",
            "\n",
            "                    accuracy                         0.9684     14890\n",
            "                   macro avg     0.9699    0.9727    0.9712     14890\n",
            "                weighted avg     0.9688    0.9684    0.9685     14890\n",
            "\n",
            "\n",
            "=== Fold 3/5 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3aa289ff41a4531bc77e7f658bb551a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:11:36,597] Trial 2 finished with value: 0.9652229515164689 and parameters: {'lgb_lr': 0.001228879140431036, 'lgb_num_leaves': 42, 'lgb_max_depth': 3}. Best is trial 2 with value: 0.9652229515164689.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:11:37,546] Trial 8 finished with value: 0.9657508817502776 and parameters: {'lgb_lr': 0.007911181667276614, 'lgb_num_leaves': 38, 'lgb_max_depth': 3}. Best is trial 8 with value: 0.9657508817502776.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:11:57,370] Trial 3 finished with value: 0.9661072123211395 and parameters: {'lgb_lr': 0.013371748840612468, 'lgb_num_leaves': 27, 'lgb_max_depth': 4}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:00,448] Trial 10 finished with value: 0.9657604945437778 and parameters: {'lgb_lr': 0.0023486602166702835, 'lgb_num_leaves': 20, 'lgb_max_depth': 8}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:05,847] Trial 1 finished with value: 0.9651405451998911 and parameters: {'lgb_lr': 0.0011660201642343009, 'lgb_num_leaves': 23, 'lgb_max_depth': 10}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:09,149] Trial 4 finished with value: 0.9653566983485963 and parameters: {'lgb_lr': 0.0012823883506147262, 'lgb_num_leaves': 25, 'lgb_max_depth': 10}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:17,690] Trial 6 finished with value: 0.9651624432894458 and parameters: {'lgb_lr': 0.002319910807864734, 'lgb_num_leaves': 30, 'lgb_max_depth': 10}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:40,169] Trial 5 finished with value: 0.9655740443087826 and parameters: {'lgb_lr': 0.006309802840878442, 'lgb_num_leaves': 33, 'lgb_max_depth': 9}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:42,741] Trial 11 finished with value: 0.964889454209877 and parameters: {'lgb_lr': 0.0018048091394222466, 'lgb_num_leaves': 37, 'lgb_max_depth': 7}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:44,291] Trial 17 finished with value: 0.9652903832952373 and parameters: {'lgb_lr': 0.0011367721921652198, 'lgb_num_leaves': 38, 'lgb_max_depth': 3}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:46,984] Trial 13 finished with value: 0.9660322250671497 and parameters: {'lgb_lr': 0.002995112988220397, 'lgb_num_leaves': 26, 'lgb_max_depth': 9}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:47,277] Trial 0 finished with value: 0.9657654951379187 and parameters: {'lgb_lr': 0.0025427597140395925, 'lgb_num_leaves': 39, 'lgb_max_depth': 7}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:50,796] Trial 14 finished with value: 0.9657807166877963 and parameters: {'lgb_lr': 0.04732956710693802, 'lgb_num_leaves': 31, 'lgb_max_depth': 4}. Best is trial 3 with value: 0.9661072123211395.\n",
            "[I 2025-06-16 23:12:50,797] Trial 7 finished with value: 0.9660289271630489 and parameters: {'lgb_lr': 0.025320667219149107, 'lgb_num_leaves': 45, 'lgb_max_depth': 10}. Best is trial 3 with value: 0.9661072123211395.\n",
            "[I 2025-06-16 23:12:50,885] Trial 9 finished with value: 0.9657248357413557 and parameters: {'lgb_lr': 0.01279322547603349, 'lgb_num_leaves': 46, 'lgb_max_depth': 8}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:12:52,722] Trial 16 finished with value: 0.9655446295462902 and parameters: {'lgb_lr': 0.0018231379822533159, 'lgb_num_leaves': 42, 'lgb_max_depth': 4}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:13:10,451] Trial 12 finished with value: 0.9658468110952716 and parameters: {'lgb_lr': 0.006521701811805066, 'lgb_num_leaves': 31, 'lgb_max_depth': 10}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:13:15,519] Trial 15 finished with value: 0.9655748867337963 and parameters: {'lgb_lr': 0.003314542216931889, 'lgb_num_leaves': 28, 'lgb_max_depth': 7}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:13:19,300] Trial 18 finished with value: 0.96568089113232 and parameters: {'lgb_lr': 0.0014754259289539826, 'lgb_num_leaves': 21, 'lgb_max_depth': 8}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:13:57,757] Trial 27 finished with value: 0.965493358895404 and parameters: {'lgb_lr': 0.00402205531744991, 'lgb_num_leaves': 27, 'lgb_max_depth': 5}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:00,299] Trial 25 finished with value: 0.965977269190046 and parameters: {'lgb_lr': 0.017619510944799605, 'lgb_num_leaves': 26, 'lgb_max_depth': 5}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:01,640] Trial 22 finished with value: 0.9659234398918807 and parameters: {'lgb_lr': 0.038929649465003276, 'lgb_num_leaves': 28, 'lgb_max_depth': 5}. Best is trial 3 with value: 0.9661072123211395.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:02,059] Trial 23 finished with value: 0.9663299764240214 and parameters: {'lgb_lr': 0.03862496484802629, 'lgb_num_leaves': 48, 'lgb_max_depth': 5}. Best is trial 23 with value: 0.9663299764240214.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:06,458] Trial 26 finished with value: 0.9652972301827412 and parameters: {'lgb_lr': 0.00508300394553308, 'lgb_num_leaves': 28, 'lgb_max_depth': 5}. Best is trial 23 with value: 0.9663299764240214.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:08,655] Trial 21 finished with value: 0.9668761166772137 and parameters: {'lgb_lr': 0.07125331717615392, 'lgb_num_leaves': 49, 'lgb_max_depth': 5}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:10,650] Trial 24 finished with value: 0.9665297943113758 and parameters: {'lgb_lr': 0.017142179667260685, 'lgb_num_leaves': 27, 'lgb_max_depth': 5}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:15,512] Trial 20 finished with value: 0.9651034213179152 and parameters: {'lgb_lr': 0.004820482451644618, 'lgb_num_leaves': 37, 'lgb_max_depth': 10}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:21,324] Trial 19 finished with value: 0.9659042109215749 and parameters: {'lgb_lr': 0.035277905598431226, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:24,027] Trial 29 finished with value: 0.9659275067595029 and parameters: {'lgb_lr': 0.015311851624724081, 'lgb_num_leaves': 26, 'lgb_max_depth': 5}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:27,623] Trial 28 finished with value: 0.9657192374947204 and parameters: {'lgb_lr': 0.014410747050074852, 'lgb_num_leaves': 27, 'lgb_max_depth': 5}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:14:28,050] Trial 30 finished with value: 0.9658587084329129 and parameters: {'lgb_lr': 0.01437188953675993, 'lgb_num_leaves': 27, 'lgb_max_depth': 5}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:15:08,551] Trial 31 finished with value: 0.9657887099208649 and parameters: {'lgb_lr': 0.014136534655726148, 'lgb_num_leaves': 50, 'lgb_max_depth': 5}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:15:22,077] Trial 37 finished with value: 0.9665588919154292 and parameters: {'lgb_lr': 0.0934138186659645, 'lgb_num_leaves': 50, 'lgb_max_depth': 5}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:15:42,575] Trial 34 finished with value: 0.9653631449491664 and parameters: {'lgb_lr': 0.0856081243592877, 'lgb_num_leaves': 49, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:15:46,196] Trial 35 finished with value: 0.965965457190931 and parameters: {'lgb_lr': 0.09687252370356339, 'lgb_num_leaves': 34, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:15:47,922] Trial 36 finished with value: 0.9660901016522969 and parameters: {'lgb_lr': 0.08999948327665873, 'lgb_num_leaves': 49, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:15:54,160] Trial 38 finished with value: 0.9656985006093999 and parameters: {'lgb_lr': 0.08860305383183953, 'lgb_num_leaves': 50, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:15:55,644] Trial 32 finished with value: 0.9657565244613991 and parameters: {'lgb_lr': 0.027336466463090868, 'lgb_num_leaves': 50, 'lgb_max_depth': 9}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:16:00,141] Trial 39 finished with value: 0.9662249855276923 and parameters: {'lgb_lr': 0.08277408491093377, 'lgb_num_leaves': 49, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:16:02,953] Trial 40 finished with value: 0.9649587954433231 and parameters: {'lgb_lr': 0.09430832193763071, 'lgb_num_leaves': 50, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:16:06,382] Trial 42 finished with value: 0.9654355686791921 and parameters: {'lgb_lr': 0.09371984637919649, 'lgb_num_leaves': 49, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:16:08,854] Trial 41 finished with value: 0.9656044093954033 and parameters: {'lgb_lr': 0.07431979977245246, 'lgb_num_leaves': 50, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n",
            "[I 2025-06-16 23:16:09,520] Trial 33 finished with value: 0.9661621302842086 and parameters: {'lgb_lr': 0.02672676062121971, 'lgb_num_leaves': 46, 'lgb_max_depth': 9}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:16:34,267] Trial 47 finished with value: 0.9663118405903907 and parameters: {'lgb_lr': 0.06198214997717722, 'lgb_num_leaves': 46, 'lgb_max_depth': 4}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:16:39,228] Trial 48 finished with value: 0.9663763355051935 and parameters: {'lgb_lr': 0.062108889256814216, 'lgb_num_leaves': 46, 'lgb_max_depth': 4}. Best is trial 21 with value: 0.9668761166772137.\n",
            "[I 2025-06-16 23:16:40,090] Trial 43 finished with value: 0.9663268381381755 and parameters: {'lgb_lr': 0.025409311013039976, 'lgb_num_leaves': 49, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:16:43,528] Trial 49 finished with value: 0.9659816439780763 and parameters: {'lgb_lr': 0.06741631859557645, 'lgb_num_leaves': 46, 'lgb_max_depth': 4}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:16:49,512] Trial 44 finished with value: 0.965751996014296 and parameters: {'lgb_lr': 0.09175254509515829, 'lgb_num_leaves': 50, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:16:57,285] Trial 45 finished with value: 0.9654272441767991 and parameters: {'lgb_lr': 0.0965652777554597, 'lgb_num_leaves': 47, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:17:00,008] Trial 46 finished with value: 0.9661322886540198 and parameters: {'lgb_lr': 0.06902645131255995, 'lgb_num_leaves': 47, 'lgb_max_depth': 6}. Best is trial 21 with value: 0.9668761166772137.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003399 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 23:17:06,552] A new study created in memory with name: no-name-20165609-b160-4ae9-93c6-35d738633f00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 - F1 weighted lgbm: 0.9669\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00a15e7b18de474fa1d27d75097a38fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:17:25,742] Trial 0 finished with value: 0.9669239843348905 and parameters: {'mlp_hidden_dim': 468, 'mlp_lr': 0.00897415158205338, 'mlp_wd': 4.1171499375819934e-05}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:17:44,836] Trial 1 finished with value: 0.9666203804400921 and parameters: {'mlp_hidden_dim': 827, 'mlp_lr': 0.005418113147066033, 'mlp_wd': 3.116868113062809e-05}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:18:03,808] Trial 2 finished with value: 0.966004632579431 and parameters: {'mlp_hidden_dim': 450, 'mlp_lr': 0.0010276747513729308, 'mlp_wd': 0.0003477997371030754}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:18:22,911] Trial 3 finished with value: 0.96615754185433 and parameters: {'mlp_hidden_dim': 554, 'mlp_lr': 0.00922702263909918, 'mlp_wd': 5.4595019250098655e-05}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:18:42,219] Trial 4 finished with value: 0.9663584882851888 and parameters: {'mlp_hidden_dim': 962, 'mlp_lr': 0.007577288917073779, 'mlp_wd': 6.400246747261723e-05}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:19:01,530] Trial 5 finished with value: 0.966515451865032 and parameters: {'mlp_hidden_dim': 745, 'mlp_lr': 0.008898567559239975, 'mlp_wd': 1.7509896697302268e-06}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:19:20,646] Trial 6 finished with value: 0.9668196364143266 and parameters: {'mlp_hidden_dim': 630, 'mlp_lr': 0.0012888433443696457, 'mlp_wd': 4.730512384605822e-06}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:19:39,754] Trial 7 finished with value: 0.9661512492364404 and parameters: {'mlp_hidden_dim': 851, 'mlp_lr': 0.00017402905435022866, 'mlp_wd': 1.6440402439462365e-05}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:19:58,682] Trial 8 finished with value: 0.9653466226806576 and parameters: {'mlp_hidden_dim': 547, 'mlp_lr': 0.00477744115322593, 'mlp_wd': 0.0008578943806717902}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:20:18,016] Trial 9 finished with value: 0.9661450608732401 and parameters: {'mlp_hidden_dim': 573, 'mlp_lr': 0.00017729122366900166, 'mlp_wd': 3.208269320722783e-05}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:20:37,275] Trial 10 finished with value: 0.9661512721328319 and parameters: {'mlp_hidden_dim': 306, 'mlp_lr': 0.002585546642185459, 'mlp_wd': 0.00018982316587593553}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:20:56,548] Trial 11 finished with value: 0.9662849912879566 and parameters: {'mlp_hidden_dim': 379, 'mlp_lr': 0.0007230950768352247, 'mlp_wd': 4.983707877403882e-06}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:21:15,650] Trial 12 finished with value: 0.9662790971615102 and parameters: {'mlp_hidden_dim': 699, 'mlp_lr': 0.001135306937712881, 'mlp_wd': 6.96304385637616e-06}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:21:34,535] Trial 13 finished with value: 0.9662775185938643 and parameters: {'mlp_hidden_dim': 488, 'mlp_lr': 0.00042242916327435014, 'mlp_wd': 1.172430750476414e-06}. Best is trial 0 with value: 0.9669239843348905.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:21:53,860] Trial 14 finished with value: 0.9669375357264919 and parameters: {'mlp_hidden_dim': 653, 'mlp_lr': 0.002317841799917272, 'mlp_wd': 5.373868042181773e-06}. Best is trial 14 with value: 0.9669375357264919.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:22:12,997] Trial 15 finished with value: 0.9669230909385249 and parameters: {'mlp_hidden_dim': 415, 'mlp_lr': 0.002630628644153852, 'mlp_wd': 1.0651358528832836e-05}. Best is trial 14 with value: 0.9669375357264919.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:22:32,467] Trial 16 finished with value: 0.9674322419361854 and parameters: {'mlp_hidden_dim': 685, 'mlp_lr': 0.00250900484758541, 'mlp_wd': 2.869838105813335e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:22:51,696] Trial 17 finished with value: 0.9666748743736205 and parameters: {'mlp_hidden_dim': 785, 'mlp_lr': 0.0021937286297101987, 'mlp_wd': 2.6494880103252375e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:23:10,952] Trial 18 finished with value: 0.9669695950183754 and parameters: {'mlp_hidden_dim': 944, 'mlp_lr': 0.0005775454794419984, 'mlp_wd': 2.407770803678489e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:23:29,887] Trial 19 finished with value: 0.9663484155928898 and parameters: {'mlp_hidden_dim': 1020, 'mlp_lr': 0.00043523068195842397, 'mlp_wd': 1.922773877801526e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:23:49,087] Trial 20 finished with value: 0.9662174906061717 and parameters: {'mlp_hidden_dim': 913, 'mlp_lr': 0.00011119572114526604, 'mlp_wd': 1.4814436637654394e-05}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:24:08,202] Trial 21 finished with value: 0.967266998412295 and parameters: {'mlp_hidden_dim': 686, 'mlp_lr': 0.0019115061480748895, 'mlp_wd': 3.5481908629942937e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:24:27,207] Trial 22 finished with value: 0.9667006329584897 and parameters: {'mlp_hidden_dim': 891, 'mlp_lr': 0.0006370577172896255, 'mlp_wd': 3.0335496574608396e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:24:46,286] Trial 23 finished with value: 0.9667734077642739 and parameters: {'mlp_hidden_dim': 736, 'mlp_lr': 0.0017344117546086908, 'mlp_wd': 1.179236669774614e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:25:05,418] Trial 24 finished with value: 0.9666536839346328 and parameters: {'mlp_hidden_dim': 649, 'mlp_lr': 0.0036683398821686203, 'mlp_wd': 3.3692008938267067e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:25:24,388] Trial 25 finished with value: 0.966579776134616 and parameters: {'mlp_hidden_dim': 798, 'mlp_lr': 0.0006460816007643747, 'mlp_wd': 1.0629881858941484e-05}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:25:43,479] Trial 26 finished with value: 0.9672381564503973 and parameters: {'mlp_hidden_dim': 1015, 'mlp_lr': 0.0014354508545444218, 'mlp_wd': 1.0383019444032384e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:26:02,803] Trial 27 finished with value: 0.9669848653116766 and parameters: {'mlp_hidden_dim': 1012, 'mlp_lr': 0.0014794625245277996, 'mlp_wd': 1.0710708494528397e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:26:22,009] Trial 28 finished with value: 0.9670540939663695 and parameters: {'mlp_hidden_dim': 705, 'mlp_lr': 0.003920329134388916, 'mlp_wd': 1.950128270769158e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:26:41,200] Trial 29 finished with value: 0.966579756610458 and parameters: {'mlp_hidden_dim': 593, 'mlp_lr': 0.0017724052546609793, 'mlp_wd': 8.206272091822157e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:27:00,337] Trial 30 finished with value: 0.9670965413308419 and parameters: {'mlp_hidden_dim': 354, 'mlp_lr': 0.0032968375971756734, 'mlp_wd': 3.7958445578840494e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:27:19,306] Trial 31 finished with value: 0.9669645636596154 and parameters: {'mlp_hidden_dim': 335, 'mlp_lr': 0.003573370454759818, 'mlp_wd': 3.900660075777707e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:27:38,372] Trial 32 finished with value: 0.9672889598969493 and parameters: {'mlp_hidden_dim': 272, 'mlp_lr': 0.006352261281380367, 'mlp_wd': 1.6498879470054944e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:27:57,521] Trial 33 finished with value: 0.967082780891235 and parameters: {'mlp_hidden_dim': 507, 'mlp_lr': 0.005508449924852362, 'mlp_wd': 1.4418899474121876e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:28:16,699] Trial 34 finished with value: 0.9664501793723826 and parameters: {'mlp_hidden_dim': 859, 'mlp_lr': 0.006005022880831135, 'mlp_wd': 1.7437026585909461e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:28:35,862] Trial 35 finished with value: 0.9660020515170451 and parameters: {'mlp_hidden_dim': 268, 'mlp_lr': 0.0008805483684444827, 'mlp_wd': 0.00013327210147370393}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:28:54,819] Trial 36 finished with value: 0.9670298110079438 and parameters: {'mlp_hidden_dim': 430, 'mlp_lr': 0.007193093863749434, 'mlp_wd': 2.6664534017727414e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:29:13,898] Trial 37 finished with value: 0.9668035452221092 and parameters: {'mlp_hidden_dim': 772, 'mlp_lr': 0.0018427548778765493, 'mlp_wd': 1.694590608794924e-05}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:29:33,120] Trial 38 finished with value: 0.9664318283398604 and parameters: {'mlp_hidden_dim': 690, 'mlp_lr': 0.0008818016305496851, 'mlp_wd': 1.5835472504369187e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:29:52,286] Trial 39 finished with value: 0.9665695300903362 and parameters: {'mlp_hidden_dim': 519, 'mlp_lr': 0.001392724021568623, 'mlp_wd': 1.0012952489553517e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:30:11,609] Trial 40 finished with value: 0.9668049920657279 and parameters: {'mlp_hidden_dim': 615, 'mlp_lr': 0.0028663879334399553, 'mlp_wd': 7.156866059757422e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:30:30,985] Trial 41 finished with value: 0.9673855210807035 and parameters: {'mlp_hidden_dim': 266, 'mlp_lr': 0.004394514226386144, 'mlp_wd': 4.4647143271187445e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:30:50,040] Trial 42 finished with value: 0.9665759012805328 and parameters: {'mlp_hidden_dim': 259, 'mlp_lr': 0.0044033104780170735, 'mlp_wd': 2.09113854102685e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:31:09,165] Trial 43 finished with value: 0.9673115384521753 and parameters: {'mlp_hidden_dim': 317, 'mlp_lr': 0.00703913695984612, 'mlp_wd': 4.823502243049507e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:31:28,315] Trial 44 finished with value: 0.9664099190918779 and parameters: {'mlp_hidden_dim': 289, 'mlp_lr': 0.009371672069908858, 'mlp_wd': 5.367322360728143e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:31:47,487] Trial 45 finished with value: 0.9665966026005188 and parameters: {'mlp_hidden_dim': 318, 'mlp_lr': 0.006811547751835716, 'mlp_wd': 4.34887117037494e-05}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:32:06,678] Trial 46 finished with value: 0.966636069454195 and parameters: {'mlp_hidden_dim': 400, 'mlp_lr': 0.004379855482444787, 'mlp_wd': 2.3699326111222717e-05}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:32:25,804] Trial 47 finished with value: 0.96669468487357 and parameters: {'mlp_hidden_dim': 459, 'mlp_lr': 0.008106750977173718, 'mlp_wd': 4.529744659577363e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:32:44,774] Trial 48 finished with value: 0.9664045743879567 and parameters: {'mlp_hidden_dim': 381, 'mlp_lr': 0.005273458386207311, 'mlp_wd': 6.4583767568058195e-06}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:33:03,992] Trial 49 finished with value: 0.9653744037433837 and parameters: {'mlp_hidden_dim': 312, 'mlp_lr': 0.0032408512645597685, 'mlp_wd': 0.0009187532795587283}. Best is trial 16 with value: 0.9674322419361854.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n",
            "[I 2025-06-16 23:33:23,083] A new study created in memory with name: no-name-30e4313e-113e-428e-9203-dac6682ab35b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 - F1 weighted mlp: 0.9671\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28226bd4cc064e0c8807545b5b56e65d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:33:23,103] Trial 0 finished with value: 0.032323049307853347 and parameters: {'w0': 0.8020589197936724, 'w1': 0.8707445316986423}. Best is trial 0 with value: 0.032323049307853347.\n",
            "[I 2025-06-16 23:33:23,115] Trial 1 finished with value: 0.03218759501335189 and parameters: {'w0': 0.7452548318739358, 'w1': 0.7103508199474275}. Best is trial 1 with value: 0.03218759501335189.\n",
            "[I 2025-06-16 23:33:23,127] Trial 2 finished with value: 0.032742246115956886 and parameters: {'w0': 0.1604744482873096, 'w1': 0.3958365499595946}. Best is trial 1 with value: 0.03218759501335189.\n",
            "[I 2025-06-16 23:33:23,152] Trial 3 finished with value: 0.03219039497031828 and parameters: {'w0': 0.8534162456989133, 'w1': 0.6013252052137886}. Best is trial 1 with value: 0.03218759501335189.\n",
            "[I 2025-06-16 23:33:23,177] Trial 4 finished with value: 0.033278278853231535 and parameters: {'w0': 0.019470153793970768, 'w1': 0.20582621450204686}. Best is trial 1 with value: 0.03218759501335189.\n",
            "[I 2025-06-16 23:33:23,198] Trial 5 finished with value: 0.0333445710617013 and parameters: {'w0': 0.07552210118769298, 'w1': 0.44677694415325275}. Best is trial 1 with value: 0.03218759501335189.\n",
            "[I 2025-06-16 23:33:23,218] Trial 6 finished with value: 0.03348350276792833 and parameters: {'w0': 0.021677487101674275, 'w1': 0.6925574833764587}. Best is trial 1 with value: 0.03218759501335189.\n",
            "[I 2025-06-16 23:33:23,228] Trial 7 finished with value: 0.0330003691858175 and parameters: {'w0': 0.8568462596737052, 'w1': 0.00963792345221115}. Best is trial 1 with value: 0.03218759501335189.\n",
            "[I 2025-06-16 23:33:23,241] Trial 8 finished with value: 0.0322594634303186 and parameters: {'w0': 0.5652074153358224, 'w1': 0.7509687395103517}. Best is trial 1 with value: 0.03218759501335189.\n",
            "[I 2025-06-16 23:33:23,259] Trial 9 finished with value: 0.03334665703924533 and parameters: {'w0': 0.06162301151354299, 'w1': 0.7647618077560181}. Best is trial 1 with value: 0.03218759501335189.\n",
            "[I 2025-06-16 23:33:23,291] Trial 10 finished with value: 0.03253443428484548 and parameters: {'w0': 0.5639786501803001, 'w1': 0.9455011510019987}. Best is trial 1 with value: 0.03218759501335189.\n",
            "[I 2025-06-16 23:33:23,326] Trial 11 finished with value: 0.03198629573455003 and parameters: {'w0': 0.9383726251321007, 'w1': 0.5757271706845655}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,358] Trial 12 finished with value: 0.032127509779264485 and parameters: {'w0': 0.7252934664783681, 'w1': 0.5506347648734619}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,379] Trial 13 finished with value: 0.032459903602979345 and parameters: {'w0': 0.9993092544091697, 'w1': 0.3115518548788498}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,405] Trial 14 finished with value: 0.03246522516789618 and parameters: {'w0': 0.37259125246198393, 'w1': 0.5465521528186583}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,431] Trial 15 finished with value: 0.032262406741683236 and parameters: {'w0': 0.9957898567408221, 'w1': 0.23374040095126647}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,455] Trial 16 finished with value: 0.03198976013183685 and parameters: {'w0': 0.6735671304642663, 'w1': 0.5455119083024889}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,484] Trial 17 finished with value: 0.03238995814368695 and parameters: {'w0': 0.38565880271022557, 'w1': 0.38245841767063626}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,507] Trial 18 finished with value: 0.03218759501335189 and parameters: {'w0': 0.644783778346175, 'w1': 0.620811244294789}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,534] Trial 19 finished with value: 0.0325375825970855 and parameters: {'w0': 0.4522245808399651, 'w1': 0.860241818385886}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,559] Trial 20 finished with value: 0.032189449934105774 and parameters: {'w0': 0.9123868280525179, 'w1': 0.10056759922470415}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,589] Trial 21 finished with value: 0.03212301987731536 and parameters: {'w0': 0.6911655238059227, 'w1': 0.47108952061088805}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,628] Trial 22 finished with value: 0.03212301987731536 and parameters: {'w0': 0.7141920711630116, 'w1': 0.48156490039183464}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,647] Trial 23 finished with value: 0.032390505284959015 and parameters: {'w0': 0.638036980338243, 'w1': 0.6481333149171458}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,671] Trial 24 finished with value: 0.03218624178147311 and parameters: {'w0': 0.6386502314614073, 'w1': 0.32739978352635}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,710] Trial 25 finished with value: 0.032390505284959015 and parameters: {'w0': 0.4836049008350169, 'w1': 0.5068089598549723}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,734] Trial 26 finished with value: 0.03218624178147311 and parameters: {'w0': 0.8100087506058606, 'w1': 0.43557939137938906}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,759] Trial 27 finished with value: 0.032606887560118314 and parameters: {'w0': 0.25481066377759454, 'w1': 0.5540907992586621}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,783] Trial 28 finished with value: 0.03253293360547482 and parameters: {'w0': 0.9000638053463262, 'w1': 0.32424160449774664}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,807] Trial 29 finished with value: 0.032323049307853347 and parameters: {'w0': 0.7802653348546398, 'w1': 0.8514033010954796}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,833] Trial 30 finished with value: 0.03239574874545137 and parameters: {'w0': 0.5648405788331453, 'w1': 0.8133419360338612}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,866] Trial 31 finished with value: 0.03212301987731536 and parameters: {'w0': 0.7035140944992267, 'w1': 0.47934240914890647}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,898] Trial 32 finished with value: 0.03218759501335189 and parameters: {'w0': 0.6897402937428928, 'w1': 0.6600516648264677}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,936] Trial 33 finished with value: 0.03218624178147311 and parameters: {'w0': 0.753655936786587, 'w1': 0.3936052069728227}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:23,993] Trial 34 finished with value: 0.032192831937824073 and parameters: {'w0': 0.8247574762027221, 'w1': 0.5964105887016892}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,044] Trial 35 finished with value: 0.03218624178147311 and parameters: {'w0': 0.9361743290530712, 'w1': 0.5098691389162737}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,074] Trial 36 finished with value: 0.032127509779264485 and parameters: {'w0': 0.5959055852618054, 'w1': 0.4470994373063118}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,109] Trial 37 finished with value: 0.0323280681070538 and parameters: {'w0': 0.6838318570406717, 'w1': 0.2751965471889546}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,151] Trial 38 finished with value: 0.03198976013183685 and parameters: {'w0': 0.8701173687360139, 'w1': 0.7075722024787301}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,189] Trial 39 finished with value: 0.03198976013183685 and parameters: {'w0': 0.8574509156136205, 'w1': 0.7029822731142126}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,235] Trial 40 finished with value: 0.03198976013183685 and parameters: {'w0': 0.8660672633334062, 'w1': 0.7000095151532001}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,263] Trial 41 finished with value: 0.032053749535973286 and parameters: {'w0': 0.8641452032818475, 'w1': 0.740177963106294}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,298] Trial 42 finished with value: 0.032192831937824073 and parameters: {'w0': 0.9593405580772132, 'w1': 0.7034811493078973}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,332] Trial 43 finished with value: 0.03211836549932412 and parameters: {'w0': 0.8727761991182392, 'w1': 0.7997990910654393}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,368] Trial 44 finished with value: 0.032189568669735324 and parameters: {'w0': 0.7979321398191122, 'w1': 0.999109420955067}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,453] Trial 45 finished with value: 0.03219039497031828 and parameters: {'w0': 0.9508793314845525, 'w1': 0.6739915122498343}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,500] Trial 46 finished with value: 0.03219039497031828 and parameters: {'w0': 0.837690858467331, 'w1': 0.5960314490519617}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,530] Trial 47 finished with value: 0.03218759501335189 and parameters: {'w0': 0.7647575416595539, 'w1': 0.727195012484247}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,551] Trial 48 finished with value: 0.032390505284959015 and parameters: {'w0': 0.8919233824192557, 'w1': 0.9133845448473356}. Best is trial 11 with value: 0.03198629573455003.\n",
            "[I 2025-06-16 23:33:24,578] Trial 49 finished with value: 0.03198976013183685 and parameters: {'w0': 0.964851004514761, 'w1': 0.7867079288269283}. Best is trial 11 with value: 0.03198629573455003.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 23:33:38,774] A new study created in memory with name: no-name-2ee0201f-79fb-498f-b15e-8c733bb38205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 - F1 weighted fusion: 0.9682\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "                      Livres     0.9013    0.8962    0.8988       530\n",
            "                  Jeux Vidéo     0.9599    0.9532    0.9565       427\n",
            "     Accessoires jeux vidéos     0.9741    0.9971    0.9855       340\n",
            "       Jeux vidéo & Consoles     1.0000    1.0000    1.0000       340\n",
            "                   Figurines     0.9326    0.9758    0.9537       454\n",
            "              Cartes de jeux     0.9895    0.9851    0.9873       672\n",
            "Jeux de rôle et de figurines     0.9797    0.9912    0.9854       340\n",
            "             Jouets & Enfant     0.9576    0.9010    0.9284       828\n",
            "             Jeux de société     0.9205    0.9573    0.9385       351\n",
            "   Véhicules RC & miniatures     0.9883    0.9929    0.9906       850\n",
            "            Chaussettes bébé     1.0000    1.0000    1.0000       340\n",
            "            Sports & Loisirs     0.9609    0.9882    0.9744       423\n",
            "                Puériculture     0.9643    0.9819    0.9730       551\n",
            "                      Maison     0.9769    0.9459    0.9611       850\n",
            "             Linge de maison     0.9573    0.9809    0.9690       732\n",
            "              Petit déjeuner     1.0000    1.0000    1.0000       340\n",
            "                  Décoration     0.9700    0.9529    0.9614       849\n",
            "                  Animalerie     1.0000    1.0000    1.0000       340\n",
            "                       Revue     0.9489    0.9642    0.9565       809\n",
            "        Lots Livres & Revues     0.9406    0.9174    0.9288       811\n",
            "        Lots consoles & jeux     0.9882    0.9853    0.9867       340\n",
            "       Fournitures Papeterie     0.9858    0.9800    0.9829       848\n",
            "          Mobilier de jardin     0.9647    0.9909    0.9776       441\n",
            "    Équipement piscine & spa     0.9988    1.0000    0.9994       850\n",
            "         Outillage de jardin     0.9952    0.9882    0.9917       424\n",
            "                      eBooks     0.9189    0.9424    0.9305       469\n",
            "      Jeux en téléchargement     1.0000    1.0000    1.0000       340\n",
            "\n",
            "                    accuracy                         0.9683     14889\n",
            "                   macro avg     0.9694    0.9729    0.9710     14889\n",
            "                weighted avg     0.9684    0.9683    0.9682     14889\n",
            "\n",
            "\n",
            "=== Fold 4/5 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "239fc6bd2c7f4b689e30df85dbc10a38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:34:14,315] Trial 0 finished with value: 0.9631303255161484 and parameters: {'lgb_lr': 0.0010643027491755626, 'lgb_num_leaves': 23, 'lgb_max_depth': 3}. Best is trial 0 with value: 0.9631303255161484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:34:28,105] Trial 4 finished with value: 0.9636333562953102 and parameters: {'lgb_lr': 0.009395030887122862, 'lgb_num_leaves': 39, 'lgb_max_depth': 4}. Best is trial 4 with value: 0.9636333562953102.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:34:37,310] Trial 1 finished with value: 0.9630955825243287 and parameters: {'lgb_lr': 0.0017514268484963823, 'lgb_num_leaves': 20, 'lgb_max_depth': 7}. Best is trial 4 with value: 0.9636333562953102.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:34:40,313] Trial 7 finished with value: 0.96398028211089 and parameters: {'lgb_lr': 0.005539209281979678, 'lgb_num_leaves': 21, 'lgb_max_depth': 6}. Best is trial 7 with value: 0.96398028211089.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:34:43,968] Trial 2 finished with value: 0.9635889037707358 and parameters: {'lgb_lr': 0.06868324156436945, 'lgb_num_leaves': 22, 'lgb_max_depth': 9}. Best is trial 7 with value: 0.96398028211089.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:34:45,520] Trial 5 finished with value: 0.9635668752957373 and parameters: {'lgb_lr': 0.0032005262945788947, 'lgb_num_leaves': 24, 'lgb_max_depth': 9}. Best is trial 7 with value: 0.96398028211089.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:34:50,563] Trial 3 finished with value: 0.9639127658354588 and parameters: {'lgb_lr': 0.0071842968081921605, 'lgb_num_leaves': 27, 'lgb_max_depth': 7}. Best is trial 7 with value: 0.96398028211089.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:34:53,775] Trial 10 finished with value: 0.9645348351313824 and parameters: {'lgb_lr': 0.032515635050393045, 'lgb_num_leaves': 21, 'lgb_max_depth': 8}. Best is trial 10 with value: 0.9645348351313824.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:34:57,406] Trial 9 finished with value: 0.9640218664714705 and parameters: {'lgb_lr': 0.00611537490033135, 'lgb_num_leaves': 30, 'lgb_max_depth': 9}. Best is trial 10 with value: 0.9645348351313824.\n",
            "[I 2025-06-16 23:34:57,502] Trial 8 finished with value: 0.9637546520153627 and parameters: {'lgb_lr': 0.0012818410542149937, 'lgb_num_leaves': 30, 'lgb_max_depth': 10}. Best is trial 10 with value: 0.9645348351313824.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:35:18,457] Trial 11 finished with value: 0.9625959531849074 and parameters: {'lgb_lr': 0.09064766244777021, 'lgb_num_leaves': 47, 'lgb_max_depth': 6}. Best is trial 10 with value: 0.9645348351313824.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:35:29,192] Trial 6 finished with value: 0.9645727221274046 and parameters: {'lgb_lr': 0.04791275255535708, 'lgb_num_leaves': 36, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:35:29,526] Trial 15 finished with value: 0.9637554040563125 and parameters: {'lgb_lr': 0.008012219705223915, 'lgb_num_leaves': 34, 'lgb_max_depth': 4}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:35:32,489] Trial 14 finished with value: 0.9634969761945253 and parameters: {'lgb_lr': 0.008511094142567028, 'lgb_num_leaves': 43, 'lgb_max_depth': 4}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:35:36,473] Trial 13 finished with value: 0.9634792220180897 and parameters: {'lgb_lr': 0.005019288482553565, 'lgb_num_leaves': 50, 'lgb_max_depth': 5}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:35:38,862] Trial 12 finished with value: 0.9644545256122756 and parameters: {'lgb_lr': 0.04529962667409812, 'lgb_num_leaves': 31, 'lgb_max_depth': 7}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:35:54,184] Trial 18 finished with value: 0.9642246786220307 and parameters: {'lgb_lr': 0.009444986579618043, 'lgb_num_leaves': 23, 'lgb_max_depth': 5}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:36:09,785] Trial 21 finished with value: 0.9644623575036415 and parameters: {'lgb_lr': 0.03581969601841529, 'lgb_num_leaves': 49, 'lgb_max_depth': 5}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:36:12,851] Trial 16 finished with value: 0.9639724715693385 and parameters: {'lgb_lr': 0.002610248753952392, 'lgb_num_leaves': 31, 'lgb_max_depth': 7}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:36:21,963] Trial 17 finished with value: 0.9642245505866326 and parameters: {'lgb_lr': 0.006386496401744167, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:36:33,708] Trial 20 finished with value: 0.9643704238543583 and parameters: {'lgb_lr': 0.003039655862785816, 'lgb_num_leaves': 45, 'lgb_max_depth': 6}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:36:45,593] Trial 22 finished with value: 0.9637114341322667 and parameters: {'lgb_lr': 0.030968395985648517, 'lgb_num_leaves': 35, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:36:52,255] Trial 19 finished with value: 0.9641187000920269 and parameters: {'lgb_lr': 0.015212628660409221, 'lgb_num_leaves': 46, 'lgb_max_depth': 7}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:37:02,495] Trial 23 finished with value: 0.9640450716412962 and parameters: {'lgb_lr': 0.03085227557325008, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:37:03,597] Trial 24 finished with value: 0.963444709277704 and parameters: {'lgb_lr': 0.03037102749235459, 'lgb_num_leaves': 39, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:37:09,689] Trial 27 finished with value: 0.9639758145703556 and parameters: {'lgb_lr': 0.02243251419559866, 'lgb_num_leaves': 38, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:37:16,042] Trial 25 finished with value: 0.963172374449242 and parameters: {'lgb_lr': 0.03213841420097281, 'lgb_num_leaves': 36, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:37:20,125] Trial 26 finished with value: 0.9633810996480227 and parameters: {'lgb_lr': 0.03307806205131917, 'lgb_num_leaves': 36, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:37:27,338] Trial 28 finished with value: 0.9641137649225784 and parameters: {'lgb_lr': 0.0221543384493782, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:37:53,420] Trial 31 finished with value: 0.9644643147491766 and parameters: {'lgb_lr': 0.018471911637837946, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:37:56,872] Trial 30 finished with value: 0.9643936148729609 and parameters: {'lgb_lr': 0.019270807677881883, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:37:59,327] Trial 29 finished with value: 0.9644662546841933 and parameters: {'lgb_lr': 0.019715402028966437, 'lgb_num_leaves': 39, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:06,001] Trial 40 finished with value: 0.9645624795134609 and parameters: {'lgb_lr': 0.05470769332690188, 'lgb_num_leaves': 50, 'lgb_max_depth': 3}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:12,678] Trial 36 finished with value: 0.9639670368854615 and parameters: {'lgb_lr': 0.018382347766433986, 'lgb_num_leaves': 26, 'lgb_max_depth': 5}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:16,789] Trial 33 finished with value: 0.9641195567059653 and parameters: {'lgb_lr': 0.019298708212868554, 'lgb_num_leaves': 38, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:19,499] Trial 32 finished with value: 0.9645208018923028 and parameters: {'lgb_lr': 0.02148055082408342, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 6 with value: 0.9645727221274046.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:25,342] Trial 34 finished with value: 0.9645979265706479 and parameters: {'lgb_lr': 0.020322410452477145, 'lgb_num_leaves': 38, 'lgb_max_depth': 8}. Best is trial 34 with value: 0.9645979265706479.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:25,723] Trial 38 finished with value: 0.9643084078916694 and parameters: {'lgb_lr': 0.01688854521626041, 'lgb_num_leaves': 26, 'lgb_max_depth': 5}. Best is trial 34 with value: 0.9645979265706479.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:33,004] Trial 37 finished with value: 0.964640178407927 and parameters: {'lgb_lr': 0.05047295073224046, 'lgb_num_leaves': 48, 'lgb_max_depth': 5}. Best is trial 37 with value: 0.964640178407927.\n",
            "[I 2025-06-16 23:38:34,280] Trial 39 finished with value: 0.9645859454389808 and parameters: {'lgb_lr': 0.05460026311962355, 'lgb_num_leaves': 27, 'lgb_max_depth': 5}. Best is trial 37 with value: 0.964640178407927.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:36,481] Trial 42 finished with value: 0.9642373087581424 and parameters: {'lgb_lr': 0.05210799137252907, 'lgb_num_leaves': 27, 'lgb_max_depth': 3}. Best is trial 37 with value: 0.964640178407927.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:44,043] Trial 44 finished with value: 0.9644379180010713 and parameters: {'lgb_lr': 0.05704932677309067, 'lgb_num_leaves': 42, 'lgb_max_depth': 3}. Best is trial 37 with value: 0.964640178407927.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:50,030] Trial 45 finished with value: 0.9643627384286265 and parameters: {'lgb_lr': 0.05912836928688792, 'lgb_num_leaves': 41, 'lgb_max_depth': 3}. Best is trial 37 with value: 0.964640178407927.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:53,671] Trial 46 finished with value: 0.9641038160941853 and parameters: {'lgb_lr': 0.05280016636832077, 'lgb_num_leaves': 33, 'lgb_max_depth': 3}. Best is trial 37 with value: 0.964640178407927.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:56,102] Trial 47 finished with value: 0.9643668748807193 and parameters: {'lgb_lr': 0.05250492118403298, 'lgb_num_leaves': 43, 'lgb_max_depth': 3}. Best is trial 37 with value: 0.964640178407927.\n",
            "[I 2025-06-16 23:38:56,501] Trial 35 finished with value: 0.9636490104519932 and parameters: {'lgb_lr': 0.019718801718924355, 'lgb_num_leaves': 50, 'lgb_max_depth': 8}. Best is trial 37 with value: 0.964640178407927.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:58,465] Trial 49 finished with value: 0.9643604907612038 and parameters: {'lgb_lr': 0.05133235666783238, 'lgb_num_leaves': 33, 'lgb_max_depth': 3}. Best is trial 37 with value: 0.964640178407927.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:38:59,995] Trial 48 finished with value: 0.9650358094111582 and parameters: {'lgb_lr': 0.06556495720003741, 'lgb_num_leaves': 42, 'lgb_max_depth': 3}. Best is trial 48 with value: 0.9650358094111582.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:39:07,317] Trial 41 finished with value: 0.9644588204737878 and parameters: {'lgb_lr': 0.014085764268099517, 'lgb_num_leaves': 33, 'lgb_max_depth': 9}. Best is trial 48 with value: 0.9650358094111582.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:39:19,762] Trial 43 finished with value: 0.9638384994672439 and parameters: {'lgb_lr': 0.013757266445220762, 'lgb_num_leaves': 41, 'lgb_max_depth': 9}. Best is trial 48 with value: 0.9650358094111582.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014221 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-16 23:39:24,755] A new study created in memory with name: no-name-c2a93c3f-e723-4ec5-a40b-a50fd8a8ef1c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 - F1 weighted lgbm: 0.9650\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6041e89c2f044fb9aa0f53a6cc4a5ec7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:39:44,088] Trial 0 finished with value: 0.9649715619252982 and parameters: {'mlp_hidden_dim': 597, 'mlp_lr': 0.0002470875317121983, 'mlp_wd': 3.814754075850981e-06}. Best is trial 0 with value: 0.9649715619252982.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:40:03,397] Trial 1 finished with value: 0.9649539907805887 and parameters: {'mlp_hidden_dim': 405, 'mlp_lr': 0.0009716770962305344, 'mlp_wd': 1.7613954899147542e-05}. Best is trial 0 with value: 0.9649715619252982.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:40:22,733] Trial 2 finished with value: 0.963993655197545 and parameters: {'mlp_hidden_dim': 797, 'mlp_lr': 0.0036428728937777737, 'mlp_wd': 0.000989658848862029}. Best is trial 0 with value: 0.9649715619252982.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:40:41,854] Trial 3 finished with value: 0.965025625025029 and parameters: {'mlp_hidden_dim': 795, 'mlp_lr': 0.0021940801316853308, 'mlp_wd': 5.176970259204353e-05}. Best is trial 3 with value: 0.965025625025029.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:41:01,247] Trial 4 finished with value: 0.9650401360514071 and parameters: {'mlp_hidden_dim': 307, 'mlp_lr': 0.0019151365629609884, 'mlp_wd': 4.7753419450861985e-05}. Best is trial 4 with value: 0.9650401360514071.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:41:20,598] Trial 5 finished with value: 0.9645743610294425 and parameters: {'mlp_hidden_dim': 989, 'mlp_lr': 0.0007421273762253882, 'mlp_wd': 0.00036796422833522695}. Best is trial 4 with value: 0.9650401360514071.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:41:39,899] Trial 6 finished with value: 0.9644383453342269 and parameters: {'mlp_hidden_dim': 976, 'mlp_lr': 0.0005238397726771169, 'mlp_wd': 0.0004113576296769452}. Best is trial 4 with value: 0.9650401360514071.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:41:59,168] Trial 7 finished with value: 0.9638450681754923 and parameters: {'mlp_hidden_dim': 731, 'mlp_lr': 0.005304504498738632, 'mlp_wd': 0.0007860368506556329}. Best is trial 4 with value: 0.9650401360514071.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:42:18,402] Trial 8 finished with value: 0.9650050904565294 and parameters: {'mlp_hidden_dim': 718, 'mlp_lr': 0.005778781231191315, 'mlp_wd': 3.3089795175720355e-05}. Best is trial 4 with value: 0.9650401360514071.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:42:37,429] Trial 9 finished with value: 0.9644322569999313 and parameters: {'mlp_hidden_dim': 912, 'mlp_lr': 0.0001808175255369643, 'mlp_wd': 0.00030261050562933065}. Best is trial 4 with value: 0.9650401360514071.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:42:56,673] Trial 10 finished with value: 0.9654400989494445 and parameters: {'mlp_hidden_dim': 259, 'mlp_lr': 0.001997900940809106, 'mlp_wd': 1.000574732015594e-06}. Best is trial 10 with value: 0.9654400989494445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:43:16,115] Trial 11 finished with value: 0.9651669288352337 and parameters: {'mlp_hidden_dim': 263, 'mlp_lr': 0.001973326823487992, 'mlp_wd': 1.1595514419101905e-06}. Best is trial 10 with value: 0.9654400989494445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:43:35,502] Trial 12 finished with value: 0.9649173143853231 and parameters: {'mlp_hidden_dim': 280, 'mlp_lr': 0.00951939347736605, 'mlp_wd': 1.0523308680167183e-06}. Best is trial 10 with value: 0.9654400989494445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:43:55,002] Trial 13 finished with value: 0.9652821942245888 and parameters: {'mlp_hidden_dim': 479, 'mlp_lr': 0.0017218967669090956, 'mlp_wd': 1.1334867891273034e-06}. Best is trial 10 with value: 0.9654400989494445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:44:14,117] Trial 14 finished with value: 0.9649072938049297 and parameters: {'mlp_hidden_dim': 501, 'mlp_lr': 0.0004028742470988433, 'mlp_wd': 3.980688912149965e-06}. Best is trial 10 with value: 0.9654400989494445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:44:33,480] Trial 15 finished with value: 0.9653827141176443 and parameters: {'mlp_hidden_dim': 414, 'mlp_lr': 0.0013164958437199721, 'mlp_wd': 3.911723415155678e-06}. Best is trial 10 with value: 0.9654400989494445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:44:52,910] Trial 16 finished with value: 0.9652708381939904 and parameters: {'mlp_hidden_dim': 385, 'mlp_lr': 0.0013591746064349276, 'mlp_wd': 3.6954939407725386e-06}. Best is trial 10 with value: 0.9654400989494445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:45:12,303] Trial 17 finished with value: 0.9655484212765069 and parameters: {'mlp_hidden_dim': 540, 'mlp_lr': 0.003423903709664654, 'mlp_wd': 9.072555203560176e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:45:31,590] Trial 18 finished with value: 0.9653827379578529 and parameters: {'mlp_hidden_dim': 595, 'mlp_lr': 0.0031417127725083143, 'mlp_wd': 9.964066824528875e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:45:50,872] Trial 19 finished with value: 0.964427858756315 and parameters: {'mlp_hidden_dim': 536, 'mlp_lr': 0.0001109096987929272, 'mlp_wd': 8.716702328259771e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:46:09,972] Trial 20 finished with value: 0.9645634119508963 and parameters: {'mlp_hidden_dim': 350, 'mlp_lr': 0.00950144409906595, 'mlp_wd': 0.00012267986872996228}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:46:29,304] Trial 21 finished with value: 0.9653289485829146 and parameters: {'mlp_hidden_dim': 624, 'mlp_lr': 0.0033553136645644577, 'mlp_wd': 1.3307364687389013e-05}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:46:48,577] Trial 22 finished with value: 0.9652604519497079 and parameters: {'mlp_hidden_dim': 559, 'mlp_lr': 0.0032297871506371226, 'mlp_wd': 8.59535064808285e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:47:08,004] Trial 23 finished with value: 0.9650675463743786 and parameters: {'mlp_hidden_dim': 659, 'mlp_lr': 0.005491310828571425, 'mlp_wd': 2.176003832982288e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:47:27,302] Trial 24 finished with value: 0.9652371530262553 and parameters: {'mlp_hidden_dim': 458, 'mlp_lr': 0.0024999103176431103, 'mlp_wd': 1.9641791017785152e-05}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:47:46,596] Trial 25 finished with value: 0.9649091541840509 and parameters: {'mlp_hidden_dim': 682, 'mlp_lr': 0.004402927307708266, 'mlp_wd': 2.3261509034757883e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:48:05,667] Trial 26 finished with value: 0.9650347805615697 and parameters: {'mlp_hidden_dim': 830, 'mlp_lr': 0.0009914061386093913, 'mlp_wd': 0.00010060615939095128}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:48:24,984] Trial 27 finished with value: 0.9650525305631886 and parameters: {'mlp_hidden_dim': 593, 'mlp_lr': 0.006941105669424739, 'mlp_wd': 8.68499584228785e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:48:44,492] Trial 28 finished with value: 0.9651976917653562 and parameters: {'mlp_hidden_dim': 536, 'mlp_lr': 0.0029229520253043423, 'mlp_wd': 6.138980156452945e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:49:03,758] Trial 29 finished with value: 0.9650459253487006 and parameters: {'mlp_hidden_dim': 331, 'mlp_lr': 0.0013898063155661968, 'mlp_wd': 2.182142381315697e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:49:23,003] Trial 30 finished with value: 0.965309171377171 and parameters: {'mlp_hidden_dim': 586, 'mlp_lr': 0.0006151009261469632, 'mlp_wd': 1.5583398630527513e-05}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:49:42,009] Trial 31 finished with value: 0.9655037435427847 and parameters: {'mlp_hidden_dim': 425, 'mlp_lr': 0.001370316652128416, 'mlp_wd': 3.908065943543111e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:50:01,310] Trial 32 finished with value: 0.965256119863267 and parameters: {'mlp_hidden_dim': 407, 'mlp_lr': 0.002488548549303918, 'mlp_wd': 5.841274860900087e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:50:20,579] Trial 33 finished with value: 0.9650861285158904 and parameters: {'mlp_hidden_dim': 465, 'mlp_lr': 0.003977733812662449, 'mlp_wd': 2.4567175542334734e-05}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:50:39,954] Trial 34 finished with value: 0.9650266982989747 and parameters: {'mlp_hidden_dim': 379, 'mlp_lr': 0.001552290751252042, 'mlp_wd': 1.941938769140329e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:50:59,227] Trial 35 finished with value: 0.9652215342722994 and parameters: {'mlp_hidden_dim': 437, 'mlp_lr': 0.0010510573707385835, 'mlp_wd': 1.0661553890232864e-05}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:51:18,526] Trial 36 finished with value: 0.9654630804872926 and parameters: {'mlp_hidden_dim': 503, 'mlp_lr': 0.0008370592213058402, 'mlp_wd': 3.324981015876555e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:51:37,609] Trial 37 finished with value: 0.96492519453677 and parameters: {'mlp_hidden_dim': 519, 'mlp_lr': 0.00037097295138391713, 'mlp_wd': 3.3357011724442066e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:51:56,850] Trial 38 finished with value: 0.9652724542777998 and parameters: {'mlp_hidden_dim': 319, 'mlp_lr': 0.0008883193133900628, 'mlp_wd': 1.5754641875294214e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:52:16,130] Trial 39 finished with value: 0.9650496852223864 and parameters: {'mlp_hidden_dim': 376, 'mlp_lr': 0.0006948628606676839, 'mlp_wd': 5.412478090774112e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:52:35,278] Trial 40 finished with value: 0.964654369250533 and parameters: {'mlp_hidden_dim': 284, 'mlp_lr': 0.00047244104948586233, 'mlp_wd': 2.957479371979847e-06}. Best is trial 17 with value: 0.9655484212765069.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:52:54,646] Trial 41 finished with value: 0.9658565467632342 and parameters: {'mlp_hidden_dim': 613, 'mlp_lr': 0.0020619530733020463, 'mlp_wd': 5.654224848306316e-06}. Best is trial 41 with value: 0.9658565467632342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:53:13,866] Trial 42 finished with value: 0.9658490941728529 and parameters: {'mlp_hidden_dim': 653, 'mlp_lr': 0.0022352336480503114, 'mlp_wd': 1.5637340714357247e-06}. Best is trial 41 with value: 0.9658565467632342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:53:32,808] Trial 43 finished with value: 0.9649894346242542 and parameters: {'mlp_hidden_dim': 730, 'mlp_lr': 0.002385871838128539, 'mlp_wd': 5.412575492121151e-06}. Best is trial 41 with value: 0.9658565467632342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:53:52,082] Trial 44 finished with value: 0.9650851281879897 and parameters: {'mlp_hidden_dim': 631, 'mlp_lr': 0.0010522009152004398, 'mlp_wd': 1.5460688058095066e-06}. Best is trial 41 with value: 0.9658565467632342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:54:11,319] Trial 45 finished with value: 0.9650932838000255 and parameters: {'mlp_hidden_dim': 780, 'mlp_lr': 0.0016633370349681007, 'mlp_wd': 2.6331479553219892e-06}. Best is trial 41 with value: 0.9658565467632342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:54:30,672] Trial 46 finished with value: 0.9653432973514615 and parameters: {'mlp_hidden_dim': 694, 'mlp_lr': 0.0008162961873712316, 'mlp_wd': 1.4678159230141414e-06}. Best is trial 41 with value: 0.9658565467632342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:54:49,895] Trial 47 finished with value: 0.9652227814271754 and parameters: {'mlp_hidden_dim': 489, 'mlp_lr': 0.0012463713454657975, 'mlp_wd': 4.651524828386685e-06}. Best is trial 41 with value: 0.9658565467632342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:55:09,113] Trial 48 finished with value: 0.9647035746790872 and parameters: {'mlp_hidden_dim': 548, 'mlp_lr': 0.000286061374207715, 'mlp_wd': 3.605773943915971e-05}. Best is trial 41 with value: 0.9658565467632342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:55:28,311] Trial 49 finished with value: 0.9650207094510463 and parameters: {'mlp_hidden_dim': 580, 'mlp_lr': 0.0018041306917057744, 'mlp_wd': 6.440074646707349e-06}. Best is trial 41 with value: 0.9658565467632342.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n",
            "[I 2025-06-16 23:55:47,550] A new study created in memory with name: no-name-013b70c3-f0b0-4786-a8bb-98dabc7e60e7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 - F1 weighted mlp: 0.9652\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44cb2970f0cc4eb98202540520886fee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:55:47,569] Trial 0 finished with value: 0.03462064775430518 and parameters: {'w0': 0.9890835464335725, 'w1': 0.14282569543110746}. Best is trial 0 with value: 0.03462064775430518.\n",
            "[I 2025-06-16 23:55:47,577] Trial 1 finished with value: 0.03440889723276974 and parameters: {'w0': 0.3821204721063215, 'w1': 0.3199214905617791}. Best is trial 1 with value: 0.03440889723276974.\n",
            "[I 2025-06-16 23:55:47,588] Trial 2 finished with value: 0.033919563746725334 and parameters: {'w0': 0.27672635779760746, 'w1': 0.7005929620415153}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:47,626] Trial 3 finished with value: 0.03441004557010907 and parameters: {'w0': 0.6476075710014481, 'w1': 0.8130343898401654}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:47,652] Trial 4 finished with value: 0.03440593542844794 and parameters: {'w0': 0.18204325618175787, 'w1': 0.23195318924015695}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:47,698] Trial 5 finished with value: 0.034797156184937617 and parameters: {'w0': 0.008420024127389736, 'w1': 0.9456658565735505}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:47,730] Trial 6 finished with value: 0.034122431978620194 and parameters: {'w0': 0.41576274201604657, 'w1': 0.8886854940316181}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:47,772] Trial 7 finished with value: 0.034339757132021864 and parameters: {'w0': 0.3845883201488819, 'w1': 0.2617731277493657}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:47,815] Trial 8 finished with value: 0.034797156184937617 and parameters: {'w0': 0.006150058076101805, 'w1': 0.3709209295857393}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:47,845] Trial 9 finished with value: 0.03447509077386168 and parameters: {'w0': 0.7501608671473908, 'w1': 0.2860382992550672}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:47,892] Trial 10 finished with value: 0.03405604966449893 and parameters: {'w0': 0.2176614586158477, 'w1': 0.6375332627262824}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:47,945] Trial 11 finished with value: 0.03405604966449893 and parameters: {'w0': 0.2163600693224199, 'w1': 0.6506875586109331}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:47,989] Trial 12 finished with value: 0.03405604966449893 and parameters: {'w0': 0.20575797491706194, 'w1': 0.6018035472176237}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,016] Trial 13 finished with value: 0.03441004557010907 and parameters: {'w0': 0.5706270837728085, 'w1': 0.6979092603124357}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,055] Trial 14 finished with value: 0.03426354862635783 and parameters: {'w0': 0.26699857216796336, 'w1': 0.4962220491253006}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,081] Trial 15 finished with value: 0.03425852697228071 and parameters: {'w0': 0.12860140728274888, 'w1': 0.4949397488021251}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,123] Trial 16 finished with value: 0.033920328417178625 and parameters: {'w0': 0.3190039984047793, 'w1': 0.799739439415066}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,162] Trial 17 finished with value: 0.03433270813071554 and parameters: {'w0': 0.5010326216470484, 'w1': 0.7798483251381444}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,184] Trial 18 finished with value: 0.0341234101104575 and parameters: {'w0': 0.32247147269108173, 'w1': 0.9916829386143771}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,233] Trial 19 finished with value: 0.03482592472992818 and parameters: {'w0': 0.7395727872012725, 'w1': 0.02332785061020315}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,263] Trial 20 finished with value: 0.03419027767588578 and parameters: {'w0': 0.10758750679422757, 'w1': 0.7742121455107006}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,304] Trial 21 finished with value: 0.03419523443210459 and parameters: {'w0': 0.30764299903540165, 'w1': 0.5792481081151509}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,342] Trial 22 finished with value: 0.03433270813071554 and parameters: {'w0': 0.44864602044557766, 'w1': 0.6982040811833089}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,369] Trial 23 finished with value: 0.03425781138385542 and parameters: {'w0': 0.11493504475559999, 'w1': 0.8830209739610911}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,396] Trial 24 finished with value: 0.0343359371200459 and parameters: {'w0': 0.28938169909070544, 'w1': 0.40245256061637685}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,421] Trial 25 finished with value: 0.03441004557010907 and parameters: {'w0': 0.5087503318901065, 'w1': 0.5720698657110116}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,449] Trial 26 finished with value: 0.034120106976395226 and parameters: {'w0': 0.33990140478697245, 'w1': 0.7319226963560056}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,475] Trial 27 finished with value: 0.03425852697228071 and parameters: {'w0': 0.24190525054892764, 'w1': 0.8487213182636943}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,505] Trial 28 finished with value: 0.03425852697228071 and parameters: {'w0': 0.1699952489261188, 'w1': 0.6296911317858812}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,541] Trial 29 finished with value: 0.03453600917505062 and parameters: {'w0': 0.9448588280802771, 'w1': 0.5226776171903836}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,576] Trial 30 finished with value: 0.03419027767588578 and parameters: {'w0': 0.06591009408465831, 'w1': 0.4535171938910946}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,641] Trial 31 finished with value: 0.033922368592931296 and parameters: {'w0': 0.24872223326614717, 'w1': 0.6625915259621531}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,721] Trial 32 finished with value: 0.034258913203243035 and parameters: {'w0': 0.33575596169560445, 'w1': 0.6838155272176683}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,753] Trial 33 finished with value: 0.0341234101104575 and parameters: {'w0': 0.23649776493404479, 'w1': 0.7538990005836819}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,803] Trial 34 finished with value: 0.034120106976395226 and parameters: {'w0': 0.3858713337966514, 'w1': 0.8340483255906896}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,845] Trial 35 finished with value: 0.03425852697228071 and parameters: {'w0': 0.15436622831305713, 'w1': 0.551970550361624}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,885] Trial 36 finished with value: 0.03445745010191337 and parameters: {'w0': 0.07335474798901695, 'w1': 0.6303288384545567}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,917] Trial 37 finished with value: 0.03419523443210459 and parameters: {'w0': 0.4255234265872303, 'w1': 0.8027456505090417}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,943] Trial 38 finished with value: 0.03433270813071554 and parameters: {'w0': 0.5932367985067535, 'w1': 0.959861081273646}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,963] Trial 39 finished with value: 0.03433270813071554 and parameters: {'w0': 0.4639221950612837, 'w1': 0.7226825333152319}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:48,991] Trial 40 finished with value: 0.03419164178421019 and parameters: {'w0': 0.2654495123095462, 'w1': 0.9151721070480328}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:49,019] Trial 41 finished with value: 0.0341234101104575 and parameters: {'w0': 0.21063981554569494, 'w1': 0.6609552813571419}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:49,050] Trial 42 finished with value: 0.03425852697228071 and parameters: {'w0': 0.18614815413030406, 'w1': 0.6460851428946695}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:49,072] Trial 43 finished with value: 0.034331977550523085 and parameters: {'w0': 0.3678406708502217, 'w1': 0.6155768086426345}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:49,103] Trial 44 finished with value: 0.03419164178421019 and parameters: {'w0': 0.2247124624899544, 'w1': 0.7424818843569906}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:49,135] Trial 45 finished with value: 0.03419190587194776 and parameters: {'w0': 0.07396965102849862, 'w1': 0.4379562228781857}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:49,181] Trial 46 finished with value: 0.03405604966449893 and parameters: {'w0': 0.29127492885185213, 'w1': 0.8445298569817266}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:49,202] Trial 47 finished with value: 0.034402719039708374 and parameters: {'w0': 0.374953154616785, 'w1': 0.540324462788883}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:49,243] Trial 48 finished with value: 0.03441004557010907 and parameters: {'w0': 0.17558992761367714, 'w1': 0.20502117469388081}. Best is trial 2 with value: 0.033919563746725334.\n",
            "[I 2025-06-16 23:55:49,273] Trial 49 finished with value: 0.03459489049410314 and parameters: {'w0': 0.0447398268558831, 'w1': 0.7977451035208722}. Best is trial 2 with value: 0.033919563746725334.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-16 23:56:03,617] A new study created in memory with name: no-name-04a2f6bd-066b-4285-9373-344e70ce943e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 - F1 weighted fusion: 0.9661\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "                      Livres     0.8663    0.9170    0.8909       530\n",
            "                  Jeux Vidéo     0.9471    0.9671    0.9570       426\n",
            "     Accessoires jeux vidéos     0.9854    0.9941    0.9898       340\n",
            "       Jeux vidéo & Consoles     1.0000    0.9971    0.9985       340\n",
            "                   Figurines     0.8923    0.9670    0.9281       454\n",
            "              Cartes de jeux     0.9955    0.9836    0.9895       672\n",
            "Jeux de rôle et de figurines     0.9797    0.9912    0.9854       340\n",
            "             Jouets & Enfant     0.9415    0.8937    0.9170       828\n",
            "             Jeux de société     0.8995    0.9403    0.9194       352\n",
            "   Véhicules RC & miniatures     0.9871    0.9906    0.9888       850\n",
            "            Chaussettes bébé     1.0000    1.0000    1.0000       340\n",
            "            Sports & Loisirs     0.9627    0.9741    0.9683       424\n",
            "                Puériculture     0.9726    0.9655    0.9690       551\n",
            "                      Maison     0.9728    0.9671    0.9699       850\n",
            "             Linge de maison     0.9716    0.9809    0.9762       732\n",
            "              Petit déjeuner     1.0000    1.0000    1.0000       340\n",
            "                  Décoration     0.9649    0.9399    0.9523       849\n",
            "                  Animalerie     0.9971    1.0000    0.9985       340\n",
            "                       Revue     0.9422    0.9666    0.9542       809\n",
            "        Lots Livres & Revues     0.9577    0.8927    0.9241       811\n",
            "        Lots consoles & jeux     0.9767    0.9853    0.9810       340\n",
            "       Fournitures Papeterie     0.9882    0.9870    0.9876       848\n",
            "          Mobilier de jardin     0.9863    0.9818    0.9841       440\n",
            "    Équipement piscine & spa     0.9988    0.9965    0.9976       850\n",
            "         Outillage de jardin     0.9907    1.0000    0.9953       424\n",
            "                      eBooks     0.9335    0.9275    0.9305       469\n",
            "      Jeux en téléchargement     1.0000    1.0000    1.0000       340\n",
            "\n",
            "                    accuracy                         0.9661     14889\n",
            "                   macro avg     0.9670    0.9706    0.9686     14889\n",
            "                weighted avg     0.9665    0.9661    0.9661     14889\n",
            "\n",
            "\n",
            "=== Fold 5/5 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fd3be0a114b46bca7b5f754609d697c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:56:43,644] Trial 10 finished with value: 0.9633184162296159 and parameters: {'lgb_lr': 0.002342574084199424, 'lgb_num_leaves': 20, 'lgb_max_depth': 3}. Best is trial 10 with value: 0.9633184162296159.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:56:47,988] Trial 5 finished with value: 0.9632686448208658 and parameters: {'lgb_lr': 0.05702513465867178, 'lgb_num_leaves': 23, 'lgb_max_depth': 3}. Best is trial 10 with value: 0.9633184162296159.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:56:51,874] Trial 6 finished with value: 0.9637141348563865 and parameters: {'lgb_lr': 0.0010191206653357514, 'lgb_num_leaves': 26, 'lgb_max_depth': 4}. Best is trial 6 with value: 0.9637141348563865.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:57:03,984] Trial 7 finished with value: 0.9626758541217566 and parameters: {'lgb_lr': 0.05866313158124479, 'lgb_num_leaves': 50, 'lgb_max_depth': 4}. Best is trial 6 with value: 0.9637141348563865.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:57:16,121] Trial 1 finished with value: 0.9634495499252771 and parameters: {'lgb_lr': 0.027816650113573524, 'lgb_num_leaves': 34, 'lgb_max_depth': 5}. Best is trial 6 with value: 0.9637141348563865.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:57:21,186] Trial 0 finished with value: 0.9635288465386768 and parameters: {'lgb_lr': 0.0020897963538155174, 'lgb_num_leaves': 25, 'lgb_max_depth': 6}. Best is trial 6 with value: 0.9637141348563865.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:57:24,897] Trial 8 finished with value: 0.9639859971846262 and parameters: {'lgb_lr': 0.0019494054421099216, 'lgb_num_leaves': 39, 'lgb_max_depth': 6}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:57:46,323] Trial 9 finished with value: 0.9638534762973435 and parameters: {'lgb_lr': 0.004158437233955292, 'lgb_num_leaves': 48, 'lgb_max_depth': 7}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:57:52,037] Trial 11 finished with value: 0.9639027307801985 and parameters: {'lgb_lr': 0.0033207863793420405, 'lgb_num_leaves': 50, 'lgb_max_depth': 8}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:57:54,467] Trial 15 finished with value: 0.963786591343645 and parameters: {'lgb_lr': 0.01246172954216173, 'lgb_num_leaves': 45, 'lgb_max_depth': 4}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:57:54,832] Trial 3 finished with value: 0.9635946687389972 and parameters: {'lgb_lr': 0.009822450154585376, 'lgb_num_leaves': 49, 'lgb_max_depth': 8}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:58:00,028] Trial 2 finished with value: 0.963066726108169 and parameters: {'lgb_lr': 0.02832516418830806, 'lgb_num_leaves': 50, 'lgb_max_depth': 9}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:58:08,273] Trial 4 finished with value: 0.9639111829709733 and parameters: {'lgb_lr': 0.003335633038875355, 'lgb_num_leaves': 46, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:58:11,662] Trial 18 finished with value: 0.9637304321142084 and parameters: {'lgb_lr': 0.0038767904310707973, 'lgb_num_leaves': 22, 'lgb_max_depth': 4}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:58:36,734] Trial 12 finished with value: 0.9618948438955874 and parameters: {'lgb_lr': 0.04998970451260833, 'lgb_num_leaves': 50, 'lgb_max_depth': 8}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:58:37,177] Trial 17 finished with value: 0.9625216725555713 and parameters: {'lgb_lr': 0.017201318054052096, 'lgb_num_leaves': 29, 'lgb_max_depth': 9}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:58:38,567] Trial 13 finished with value: 0.9624653410705003 and parameters: {'lgb_lr': 0.02712114044016407, 'lgb_num_leaves': 49, 'lgb_max_depth': 7}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:58:43,882] Trial 14 finished with value: 0.9627180823533732 and parameters: {'lgb_lr': 0.01476825755466537, 'lgb_num_leaves': 50, 'lgb_max_depth': 9}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:58:56,594] Trial 16 finished with value: 0.9622594764405004 and parameters: {'lgb_lr': 0.047805240898782325, 'lgb_num_leaves': 34, 'lgb_max_depth': 6}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:59:02,402] Trial 19 finished with value: 0.9633837322573818 and parameters: {'lgb_lr': 0.012405860624697196, 'lgb_num_leaves': 44, 'lgb_max_depth': 5}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:59:24,509] Trial 22 finished with value: 0.9635880165089242 and parameters: {'lgb_lr': 0.004989556684740442, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:59:30,628] Trial 23 finished with value: 0.9635178478032878 and parameters: {'lgb_lr': 0.0044429227983291695, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:59:31,700] Trial 21 finished with value: 0.963782572281262 and parameters: {'lgb_lr': 0.009608467873605059, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n",
            "[I 2025-06-16 23:59:31,711] Trial 20 finished with value: 0.9630288443971506 and parameters: {'lgb_lr': 0.06656674275994026, 'lgb_num_leaves': 41, 'lgb_max_depth': 9}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:59:37,924] Trial 24 finished with value: 0.9634394570156232 and parameters: {'lgb_lr': 0.0010381581284934363, 'lgb_num_leaves': 40, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-16 23:59:45,046] Trial 25 finished with value: 0.96364060313674 and parameters: {'lgb_lr': 0.0010732856020035323, 'lgb_num_leaves': 42, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:00:07,402] Trial 28 finished with value: 0.9635772675287959 and parameters: {'lgb_lr': 0.0010106309326322227, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:00:14,347] Trial 29 finished with value: 0.9633744663156074 and parameters: {'lgb_lr': 0.0010619057054465828, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:00:22,373] Trial 27 finished with value: 0.9635061472469874 and parameters: {'lgb_lr': 0.0010511601453922672, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n",
            "[I 2025-06-17 00:00:22,379] Trial 26 finished with value: 0.963508765217922 and parameters: {'lgb_lr': 0.0010615671261075322, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:00:30,896] Trial 30 finished with value: 0.9635894843459472 and parameters: {'lgb_lr': 0.006732945416433155, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:00:32,588] Trial 31 finished with value: 0.9634576326403144 and parameters: {'lgb_lr': 0.006765095974732418, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:00:52,218] Trial 32 finished with value: 0.9633836212199587 and parameters: {'lgb_lr': 0.001323813870601012, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:01:04,649] Trial 33 finished with value: 0.9633650690957626 and parameters: {'lgb_lr': 0.001112649291417175, 'lgb_num_leaves': 44, 'lgb_max_depth': 8}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:01:21,390] Trial 35 finished with value: 0.9636384546362317 and parameters: {'lgb_lr': 0.0011334125588937018, 'lgb_num_leaves': 45, 'lgb_max_depth': 8}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:01:22,089] Trial 37 finished with value: 0.9638337022258556 and parameters: {'lgb_lr': 0.0020373408763646617, 'lgb_num_leaves': 45, 'lgb_max_depth': 8}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:01:23,885] Trial 34 finished with value: 0.9633699558290062 and parameters: {'lgb_lr': 0.0012474340036581378, 'lgb_num_leaves': 45, 'lgb_max_depth': 8}. Best is trial 8 with value: 0.9639859971846262.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:01:30,721] Trial 36 finished with value: 0.9640332570792539 and parameters: {'lgb_lr': 0.002001496324758507, 'lgb_num_leaves': 46, 'lgb_max_depth': 8}. Best is trial 36 with value: 0.9640332570792539.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:01:46,420] Trial 41 finished with value: 0.9637153364652546 and parameters: {'lgb_lr': 0.0018211684927637096, 'lgb_num_leaves': 46, 'lgb_max_depth': 6}. Best is trial 36 with value: 0.9640332570792539.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:01:47,198] Trial 40 finished with value: 0.9638501992609665 and parameters: {'lgb_lr': 0.002003635087786786, 'lgb_num_leaves': 46, 'lgb_max_depth': 6}. Best is trial 36 with value: 0.9640332570792539.\n",
            "[I 2025-06-17 00:01:47,967] Trial 38 finished with value: 0.963964645447376 and parameters: {'lgb_lr': 0.0019797600449495394, 'lgb_num_leaves': 46, 'lgb_max_depth': 8}. Best is trial 36 with value: 0.9640332570792539.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:02:07,392] Trial 43 finished with value: 0.963973508208654 and parameters: {'lgb_lr': 0.00234187812209902, 'lgb_num_leaves': 46, 'lgb_max_depth': 7}. Best is trial 36 with value: 0.9640332570792539.\n",
            "[I 2025-06-17 00:02:07,611] Trial 39 finished with value: 0.9639644936578685 and parameters: {'lgb_lr': 0.001974587928586194, 'lgb_num_leaves': 46, 'lgb_max_depth': 8}. Best is trial 36 with value: 0.9640332570792539.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:02:09,688] Trial 42 finished with value: 0.9639104032450337 and parameters: {'lgb_lr': 0.0026448609058152012, 'lgb_num_leaves': 47, 'lgb_max_depth': 7}. Best is trial 36 with value: 0.9640332570792539.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:02:23,218] Trial 44 finished with value: 0.9638392565473378 and parameters: {'lgb_lr': 0.0025614344921908025, 'lgb_num_leaves': 45, 'lgb_max_depth': 7}. Best is trial 36 with value: 0.9640332570792539.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:02:32,795] Trial 48 finished with value: 0.9641970745887503 and parameters: {'lgb_lr': 0.0029636376689988237, 'lgb_num_leaves': 31, 'lgb_max_depth': 7}. Best is trial 48 with value: 0.9641970745887503.\n",
            "[I 2025-06-17 00:02:33,731] Trial 45 finished with value: 0.9639850495346243 and parameters: {'lgb_lr': 0.0025120504294113186, 'lgb_num_leaves': 47, 'lgb_max_depth': 7}. Best is trial 48 with value: 0.9641970745887503.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:02:44,971] Trial 47 finished with value: 0.9641166101230713 and parameters: {'lgb_lr': 0.00285015248290414, 'lgb_num_leaves': 47, 'lgb_max_depth': 7}. Best is trial 48 with value: 0.9641970745887503.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:02:46,462] Trial 49 finished with value: 0.9639243535502946 and parameters: {'lgb_lr': 0.002716484704726876, 'lgb_num_leaves': 47, 'lgb_max_depth': 6}. Best is trial 48 with value: 0.9641970745887503.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:02:49,859] Trial 46 finished with value: 0.9641729880301596 and parameters: {'lgb_lr': 0.0024909162889655465, 'lgb_num_leaves': 47, 'lgb_max_depth': 7}. Best is trial 48 with value: 0.9641970745887503.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003207 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 59558, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-17 00:02:55,882] A new study created in memory with name: no-name-4a221d8d-0746-476d-b378-ebda375d5360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 - F1 weighted lgbm: 0.9642\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc804e5993b1478e9efa28403a9c894e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:03:15,168] Trial 0 finished with value: 0.9640616362886363 and parameters: {'mlp_hidden_dim': 479, 'mlp_lr': 0.003954858488121016, 'mlp_wd': 4.023960375931503e-06}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:03:34,317] Trial 1 finished with value: 0.9623419620363324 and parameters: {'mlp_hidden_dim': 645, 'mlp_lr': 0.0001871931960744893, 'mlp_wd': 5.5348431251379326e-05}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:03:53,475] Trial 2 finished with value: 0.9621471538915503 and parameters: {'mlp_hidden_dim': 974, 'mlp_lr': 0.0029054500291636432, 'mlp_wd': 0.0005235849009031741}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:04:12,415] Trial 3 finished with value: 0.962330175276897 and parameters: {'mlp_hidden_dim': 704, 'mlp_lr': 0.00013047353944272612, 'mlp_wd': 0.00010841673846626293}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:04:31,643] Trial 4 finished with value: 0.9622092369234885 and parameters: {'mlp_hidden_dim': 441, 'mlp_lr': 0.002131882222351319, 'mlp_wd': 0.0004961414944666936}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:04:50,757] Trial 5 finished with value: 0.9624705529659954 and parameters: {'mlp_hidden_dim': 942, 'mlp_lr': 0.0001123511285503121, 'mlp_wd': 0.0001477041475140602}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:05:09,762] Trial 6 finished with value: 0.9624636824622068 and parameters: {'mlp_hidden_dim': 1008, 'mlp_lr': 0.00027523614684842344, 'mlp_wd': 0.00018621909979949736}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:05:28,821] Trial 7 finished with value: 0.9627375391367278 and parameters: {'mlp_hidden_dim': 946, 'mlp_lr': 0.00019405105598924383, 'mlp_wd': 2.0005602450994913e-05}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:05:47,949] Trial 8 finished with value: 0.9628786975200868 and parameters: {'mlp_hidden_dim': 569, 'mlp_lr': 0.004830041995778664, 'mlp_wd': 7.58031933177053e-05}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:06:07,191] Trial 9 finished with value: 0.9630717749045732 and parameters: {'mlp_hidden_dim': 395, 'mlp_lr': 0.0005678353599541662, 'mlp_wd': 1.6432281616003922e-06}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:06:26,240] Trial 10 finished with value: 0.9631996500953669 and parameters: {'mlp_hidden_dim': 256, 'mlp_lr': 0.001108984358731236, 'mlp_wd': 4.0118156481075404e-06}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:06:45,363] Trial 11 finished with value: 0.963412146909322 and parameters: {'mlp_hidden_dim': 257, 'mlp_lr': 0.009777657648914206, 'mlp_wd': 3.1080722432343322e-06}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:07:04,647] Trial 12 finished with value: 0.9635999589770217 and parameters: {'mlp_hidden_dim': 258, 'mlp_lr': 0.009832279521141428, 'mlp_wd': 7.754815429143813e-06}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:07:23,744] Trial 13 finished with value: 0.9626138212413832 and parameters: {'mlp_hidden_dim': 423, 'mlp_lr': 0.008904366378717516, 'mlp_wd': 1.3868457400712907e-05}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:07:43,079] Trial 14 finished with value: 0.9635888668762003 and parameters: {'mlp_hidden_dim': 541, 'mlp_lr': 0.004838275242413105, 'mlp_wd': 7.79245709610245e-06}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:08:02,292] Trial 15 finished with value: 0.9636463520577696 and parameters: {'mlp_hidden_dim': 807, 'mlp_lr': 0.0015947775489059427, 'mlp_wd': 1.4794644149518402e-06}. Best is trial 0 with value: 0.9640616362886363.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:08:21,637] Trial 16 finished with value: 0.9642238865911009 and parameters: {'mlp_hidden_dim': 789, 'mlp_lr': 0.001181029398326462, 'mlp_wd': 1.002604840089709e-06}. Best is trial 16 with value: 0.9642238865911009.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:08:40,831] Trial 17 finished with value: 0.9634543766073181 and parameters: {'mlp_hidden_dim': 778, 'mlp_lr': 0.0006513270745675733, 'mlp_wd': 1.1626177182415435e-06}. Best is trial 16 with value: 0.9642238865911009.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:08:59,938] Trial 18 finished with value: 0.9630768341428398 and parameters: {'mlp_hidden_dim': 814, 'mlp_lr': 0.0005725693304853024, 'mlp_wd': 3.0762062536852717e-06}. Best is trial 16 with value: 0.9642238865911009.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:09:19,132] Trial 19 finished with value: 0.9636149218838892 and parameters: {'mlp_hidden_dim': 523, 'mlp_lr': 0.003286187783369644, 'mlp_wd': 1.0188087272840162e-06}. Best is trial 16 with value: 0.9642238865911009.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:09:38,080] Trial 20 finished with value: 0.9634036754687418 and parameters: {'mlp_hidden_dim': 707, 'mlp_lr': 0.0012206608929928484, 'mlp_wd': 7.768586181274089e-06}. Best is trial 16 with value: 0.9642238865911009.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:09:57,331] Trial 21 finished with value: 0.9642976764729896 and parameters: {'mlp_hidden_dim': 840, 'mlp_lr': 0.001712351239754548, 'mlp_wd': 1.7860535524395097e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:10:16,547] Trial 22 finished with value: 0.9635512891013589 and parameters: {'mlp_hidden_dim': 830, 'mlp_lr': 0.001992556903948021, 'mlp_wd': 2.442187029227196e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:10:35,988] Trial 23 finished with value: 0.9632722719075867 and parameters: {'mlp_hidden_dim': 852, 'mlp_lr': 0.0008746680149953234, 'mlp_wd': 2.4284790012958725e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:10:55,372] Trial 24 finished with value: 0.9635035564346693 and parameters: {'mlp_hidden_dim': 897, 'mlp_lr': 0.004920839652223485, 'mlp_wd': 5.023332260573742e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:11:14,370] Trial 25 finished with value: 0.9631769120647666 and parameters: {'mlp_hidden_dim': 737, 'mlp_lr': 0.0028555520963385785, 'mlp_wd': 2.4566723400879714e-05}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:11:33,585] Trial 26 finished with value: 0.9638843826824576 and parameters: {'mlp_hidden_dim': 650, 'mlp_lr': 0.001428489050707802, 'mlp_wd': 1.91684416583072e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:11:52,759] Trial 27 finished with value: 0.9630754869739306 and parameters: {'mlp_hidden_dim': 581, 'mlp_lr': 0.000342715171128354, 'mlp_wd': 5.393891393069013e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:12:11,954] Trial 28 finished with value: 0.9632061802043346 and parameters: {'mlp_hidden_dim': 883, 'mlp_lr': 0.0008494715946591013, 'mlp_wd': 1.1302145051200473e-05}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:12:31,165] Trial 29 finished with value: 0.9639320633463446 and parameters: {'mlp_hidden_dim': 629, 'mlp_lr': 0.006253414742946204, 'mlp_wd': 1.8465631069102028e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:12:50,287] Trial 30 finished with value: 0.9629215908654353 and parameters: {'mlp_hidden_dim': 488, 'mlp_lr': 0.0019950065666964737, 'mlp_wd': 4.331379005911891e-05}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:13:09,389] Trial 31 finished with value: 0.963507729153834 and parameters: {'mlp_hidden_dim': 639, 'mlp_lr': 0.006640757824314924, 'mlp_wd': 1.0820003280678273e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:13:28,652] Trial 32 finished with value: 0.9637731568119123 and parameters: {'mlp_hidden_dim': 355, 'mlp_lr': 0.003321443732278682, 'mlp_wd': 1.8681290990480149e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:13:47,802] Trial 33 finished with value: 0.9634337971360574 and parameters: {'mlp_hidden_dim': 647, 'mlp_lr': 0.006336858004849882, 'mlp_wd': 3.816518999094576e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:14:07,093] Trial 34 finished with value: 0.9637243506514829 and parameters: {'mlp_hidden_dim': 749, 'mlp_lr': 0.002427085727400697, 'mlp_wd': 1.6712879103062443e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:14:26,330] Trial 35 finished with value: 0.963862542228599 and parameters: {'mlp_hidden_dim': 612, 'mlp_lr': 0.004235772997608143, 'mlp_wd': 2.571757132645907e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:14:45,564] Trial 36 finished with value: 0.9620486955000445 and parameters: {'mlp_hidden_dim': 690, 'mlp_lr': 0.006314103023743855, 'mlp_wd': 0.0003346166795803323}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:15:05,016] Trial 37 finished with value: 0.9636647788489893 and parameters: {'mlp_hidden_dim': 912, 'mlp_lr': 0.0015746426679445376, 'mlp_wd': 5.173978532457068e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:15:24,184] Trial 38 finished with value: 0.9633981194676006 and parameters: {'mlp_hidden_dim': 490, 'mlp_lr': 0.0038281660490959157, 'mlp_wd': 1.3679727098260397e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:15:43,601] Trial 39 finished with value: 0.963878585216158 and parameters: {'mlp_hidden_dim': 1021, 'mlp_lr': 0.0023806332542375534, 'mlp_wd': 1.0033163883801928e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:16:02,789] Trial 40 finished with value: 0.9629800837100793 and parameters: {'mlp_hidden_dim': 775, 'mlp_lr': 0.0004334065982509198, 'mlp_wd': 1.4911848442704495e-05}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:16:21,951] Trial 41 finished with value: 0.9632043295691739 and parameters: {'mlp_hidden_dim': 680, 'mlp_lr': 0.0009636688186456622, 'mlp_wd': 2.0285070929701014e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:16:41,201] Trial 42 finished with value: 0.9632058228723934 and parameters: {'mlp_hidden_dim': 607, 'mlp_lr': 0.001561694747540862, 'mlp_wd': 1.6760445822663293e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:17:00,560] Trial 43 finished with value: 0.9632760537876363 and parameters: {'mlp_hidden_dim': 726, 'mlp_lr': 0.001312169617757755, 'mlp_wd': 3.601950664105492e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:17:20,016] Trial 44 finished with value: 0.9641949305975313 and parameters: {'mlp_hidden_dim': 342, 'mlp_lr': 0.007528192907666649, 'mlp_wd': 2.134706431719847e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:17:39,215] Trial 45 finished with value: 0.9634194467742484 and parameters: {'mlp_hidden_dim': 394, 'mlp_lr': 0.007554206759419537, 'mlp_wd': 2.598766886262448e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:17:58,405] Trial 46 finished with value: 0.9635217204075018 and parameters: {'mlp_hidden_dim': 297, 'mlp_lr': 0.007649264463204383, 'mlp_wd': 6.17440286310346e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:18:17,401] Trial 47 finished with value: 0.9636504620428646 and parameters: {'mlp_hidden_dim': 465, 'mlp_lr': 0.005379381961087293, 'mlp_wd': 1.401540339778303e-06}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:18:36,791] Trial 48 finished with value: 0.962831901083683 and parameters: {'mlp_hidden_dim': 359, 'mlp_lr': 0.003981881068995022, 'mlp_wd': 8.434736524727104e-05}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:18:56,019] Trial 49 finished with value: 0.9634612756144889 and parameters: {'mlp_hidden_dim': 333, 'mlp_lr': 0.002895866724425793, 'mlp_wd': 1.0133014649040669e-05}. Best is trial 21 with value: 0.9642976764729896.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n",
            "[I 2025-06-17 00:19:15,176] A new study created in memory with name: no-name-ed62dcc0-28b1-4fd9-b483-eb1741931607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 - F1 weighted mlp: 0.9635\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "417c04caaf634982994a83128099f473"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:19:15,199] Trial 0 finished with value: 0.03635839538257479 and parameters: {'w0': 0.6612193256781169, 'w1': 0.8796095331643944}. Best is trial 0 with value: 0.03635839538257479.\n",
            "[I 2025-06-17 00:19:15,215] Trial 1 finished with value: 0.03594501974444675 and parameters: {'w0': 0.8714721718599963, 'w1': 0.23361288182428686}. Best is trial 1 with value: 0.03594501974444675.\n",
            "[I 2025-06-17 00:19:15,224] Trial 2 finished with value: 0.036499086689482874 and parameters: {'w0': 0.3163099252931193, 'w1': 0.788530416112518}. Best is trial 1 with value: 0.03594501974444675.\n",
            "[I 2025-06-17 00:19:15,247] Trial 3 finished with value: 0.03479544737169493 and parameters: {'w0': 0.8776327104765398, 'w1': 0.029314329064645817}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,292] Trial 4 finished with value: 0.03642625361487262 and parameters: {'w0': 0.36273638101437833, 'w1': 0.4540903647584288}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,336] Trial 5 finished with value: 0.03601388514507764 and parameters: {'w0': 0.6637999524601683, 'w1': 0.4827149295854669}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,377] Trial 6 finished with value: 0.035949000033509426 and parameters: {'w0': 0.6794261750001583, 'w1': 0.5124568392825116}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,391] Trial 7 finished with value: 0.03608765465538821 and parameters: {'w0': 0.8617588319239061, 'w1': 0.8228783874946438}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,413] Trial 8 finished with value: 0.036212385883505394 and parameters: {'w0': 0.802751817936858, 'w1': 0.2824234369472005}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,449] Trial 9 finished with value: 0.03628950987727364 and parameters: {'w0': 0.5103551017197097, 'w1': 0.6017278944310517}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,488] Trial 10 finished with value: 0.03588149410761843 and parameters: {'w0': 0.11421506455761199, 'w1': 0.017662608518487846}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,507] Trial 11 finished with value: 0.03486930267760491 and parameters: {'w0': 0.11129089929365832, 'w1': 0.005548930461425239}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,543] Trial 12 finished with value: 0.036839367090116926 and parameters: {'w0': 0.00047683813607601877, 'w1': 0.02612204425346785}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,581] Trial 13 finished with value: 0.036082193905802806 and parameters: {'w0': 0.2663329544489089, 'w1': 0.17708474648418215}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,625] Trial 14 finished with value: 0.0358859879853175 and parameters: {'w0': 0.5146142488608635, 'w1': 0.11023901710636286}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,646] Trial 15 finished with value: 0.03614278142218297 and parameters: {'w0': 0.9893707160493173, 'w1': 0.32004791990357884}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,672] Trial 16 finished with value: 0.0358045005648745 and parameters: {'w0': 0.11728800781093096, 'w1': 6.19848172752225e-05}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,699] Trial 17 finished with value: 0.035953704557038946 and parameters: {'w0': 0.4255126528680519, 'w1': 0.3527948590248932}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,728] Trial 18 finished with value: 0.036082193905802806 and parameters: {'w0': 0.22047031441416554, 'w1': 0.13683592739367173}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,755] Trial 19 finished with value: 0.036082193905802806 and parameters: {'w0': 0.9854369026717177, 'w1': 0.6520662038400471}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,787] Trial 20 finished with value: 0.036770813655243706 and parameters: {'w0': 0.005475442545109455, 'w1': 0.1431384334331876}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,815] Trial 21 finished with value: 0.03601530761415184 and parameters: {'w0': 0.13978479374803943, 'w1': 0.0333530288822759}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,853] Trial 22 finished with value: 0.03493627960115697 and parameters: {'w0': 0.11205630766117514, 'w1': 0.005999604591696919}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,910] Trial 23 finished with value: 0.036346684163442444 and parameters: {'w0': 0.19627905908687288, 'w1': 0.09577236012142032}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:15,961] Trial 24 finished with value: 0.036499086689482874 and parameters: {'w0': 0.4198166505402338, 'w1': 0.9886629441179176}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,000] Trial 25 finished with value: 0.03656687372668832 and parameters: {'w0': 0.07057662216604368, 'w1': 0.2110043132751465}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,034] Trial 26 finished with value: 0.036082193905802806 and parameters: {'w0': 0.5814529401646316, 'w1': 0.37843408274505186}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,054] Trial 27 finished with value: 0.03607816241363748 and parameters: {'w0': 0.2134945699207873, 'w1': 0.08328914101774887}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,082] Trial 28 finished with value: 0.03594813284195608 and parameters: {'w0': 0.3010625500962633, 'w1': 0.22994709050858694}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,113] Trial 29 finished with value: 0.03533961240682759 and parameters: {'w0': 0.7590622396667511, 'w1': 0.07252608393145661}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,144] Trial 30 finished with value: 0.03614278142218297 and parameters: {'w0': 0.5960576337726924, 'w1': 0.1900106352603906}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,167] Trial 31 finished with value: 0.03533861862779197 and parameters: {'w0': 0.7384597901556026, 'w1': 0.07667299052220047}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,192] Trial 32 finished with value: 0.036212385883505394 and parameters: {'w0': 0.7601430332277105, 'w1': 0.2740239772208959}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,231] Trial 33 finished with value: 0.03533969836246942 and parameters: {'w0': 0.9316289829313479, 'w1': 0.07006246072645786}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,270] Trial 34 finished with value: 0.03594813423750831 and parameters: {'w0': 0.889437433946303, 'w1': 0.15029081734542973}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,292] Trial 35 finished with value: 0.03526892276400695 and parameters: {'w0': 0.7953760438876658, 'w1': 0.05408525156592872}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,332] Trial 36 finished with value: 0.035796770468071726 and parameters: {'w0': 0.8293641464992848, 'w1': 0.0019655965137697073}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,387] Trial 37 finished with value: 0.03628950987727364 and parameters: {'w0': 0.3623625114560159, 'w1': 0.4279641425588302}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,455] Trial 38 finished with value: 0.036149418280725154 and parameters: {'w0': 0.6110678311523883, 'w1': 0.24433223895805062}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,515] Trial 39 finished with value: 0.036222078600810614 and parameters: {'w0': 0.705723652714562, 'w1': 0.7189606479835484}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,547] Trial 40 finished with value: 0.03670109203012639 and parameters: {'w0': 0.06565898979140286, 'w1': 0.5499494496767978}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,571] Trial 41 finished with value: 0.0352723523415398 and parameters: {'w0': 0.7379664260569271, 'w1': 0.06408853128393535}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,609] Trial 42 finished with value: 0.03520268378416813 and parameters: {'w0': 0.8116801381868332, 'w1': 0.05102321401143631}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,633] Trial 43 finished with value: 0.03574068447490708 and parameters: {'w0': 0.9165573061598815, 'w1': 0.11999128590794178}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,663] Trial 44 finished with value: 0.036020686308620875 and parameters: {'w0': 0.8011857364040048, 'w1': 0.17696051696328424}. Best is trial 3 with value: 0.03479544737169493.\n",
            "[I 2025-06-17 00:19:16,702] Trial 45 finished with value: 0.0346649059446712 and parameters: {'w0': 0.8387539679261422, 'w1': 0.03314040991503836}. Best is trial 45 with value: 0.0346649059446712.\n",
            "[I 2025-06-17 00:19:16,727] Trial 46 finished with value: 0.0347258564085593 and parameters: {'w0': 0.8767600525744739, 'w1': 0.02951816100922351}. Best is trial 45 with value: 0.0346649059446712.\n",
            "[I 2025-06-17 00:19:16,753] Trial 47 finished with value: 0.0357984184857324 and parameters: {'w0': 0.8617683880188705, 'w1': 0.002321224814256328}. Best is trial 45 with value: 0.0346649059446712.\n",
            "[I 2025-06-17 00:19:16,778] Trial 48 finished with value: 0.03561087175724087 and parameters: {'w0': 0.9364261632553218, 'w1': 0.11231589343215524}. Best is trial 45 with value: 0.0346649059446712.\n",
            "[I 2025-06-17 00:19:16,811] Trial 49 finished with value: 0.03587724351775279 and parameters: {'w0': 0.6600614471194741, 'w1': 0.17050791359953088}. Best is trial 45 with value: 0.0346649059446712.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-17 00:19:30,757] A new study created in memory with name: no-name-76ec5750-c44a-4794-b1bb-b1964e361a10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 - F1 weighted fusion: 0.9666\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "                      Livres     0.8551    0.9036    0.8787       529\n",
            "                  Jeux Vidéo     0.9344    0.9695    0.9516       426\n",
            "     Accessoires jeux vidéos     0.9796    0.9882    0.9839       340\n",
            "       Jeux vidéo & Consoles     0.9942    1.0000    0.9971       340\n",
            "                   Figurines     0.9335    0.9581    0.9457       454\n",
            "              Cartes de jeux     0.9911    0.9896    0.9903       672\n",
            "Jeux de rôle et de figurines     0.9684    0.9912    0.9797       340\n",
            "             Jouets & Enfant     0.9532    0.8863    0.9185       827\n",
            "             Jeux de société     0.9229    0.9517    0.9371       352\n",
            "   Véhicules RC & miniatures     0.9906    0.9906    0.9906       850\n",
            "            Chaussettes bébé     1.0000    1.0000    1.0000       340\n",
            "            Sports & Loisirs     0.9495    0.9764    0.9628       424\n",
            "                Puériculture     0.9625    0.9782    0.9703       551\n",
            "                      Maison     0.9715    0.9624    0.9669       850\n",
            "             Linge de maison     0.9728    0.9795    0.9761       731\n",
            "              Petit déjeuner     0.9971    1.0000    0.9985       340\n",
            "                  Décoration     0.9654    0.9541    0.9597       849\n",
            "                  Animalerie     0.9942    1.0000    0.9971       340\n",
            "                       Revue     0.9601    0.9506    0.9553       810\n",
            "        Lots Livres & Revues     0.9373    0.9212    0.9292       812\n",
            "        Lots consoles & jeux     0.9852    0.9794    0.9823       340\n",
            "       Fournitures Papeterie     0.9882    0.9882    0.9882       848\n",
            "          Mobilier de jardin     0.9753    0.9864    0.9808       440\n",
            "    Équipement piscine & spa     1.0000    1.0000    1.0000       850\n",
            "         Outillage de jardin     0.9906    0.9976    0.9941       424\n",
            "                      eBooks     0.9425    0.9064    0.9241       470\n",
            "      Jeux en téléchargement     1.0000    1.0000    1.0000       340\n",
            "\n",
            "                    accuracy                         0.9667     14889\n",
            "                   macro avg     0.9672    0.9707    0.9688     14889\n",
            "                weighted avg     0.9669    0.9667    0.9666     14889\n",
            "\n",
            "\n",
            "=== CV mean F1 weighted: 0.9674 ± 0.0009 ===\n",
            "Validation croisée terminée : F1 moyen 0.9674 ± 0.0009\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7716b75be3c34cdb8bea71f66e9c3504"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:20:15,989] Trial 5 finished with value: 0.9002445484725949 and parameters: {'lgb_lr': 0.0020368979036037432, 'lgb_num_leaves': 45, 'lgb_max_depth': 3}. Best is trial 5 with value: 0.9002445484725949.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:20:17,442] Trial 4 finished with value: 0.8999387205641343 and parameters: {'lgb_lr': 0.001192002147929944, 'lgb_num_leaves': 34, 'lgb_max_depth': 3}. Best is trial 5 with value: 0.9002445484725949.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:20:26,093] Trial 1 finished with value: 0.9000346858555762 and parameters: {'lgb_lr': 0.005549508196759609, 'lgb_num_leaves': 48, 'lgb_max_depth': 4}. Best is trial 5 with value: 0.9002445484725949.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:20:32,171] Trial 9 finished with value: 0.90086965541385 and parameters: {'lgb_lr': 0.05634011788756805, 'lgb_num_leaves': 35, 'lgb_max_depth': 4}. Best is trial 9 with value: 0.90086965541385.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:20:49,240] Trial 11 finished with value: 0.9001638241781751 and parameters: {'lgb_lr': 0.01124853506734224, 'lgb_num_leaves': 21, 'lgb_max_depth': 5}. Best is trial 9 with value: 0.90086965541385.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:20:51,725] Trial 3 finished with value: 0.9006887929352652 and parameters: {'lgb_lr': 0.008078886380103555, 'lgb_num_leaves': 26, 'lgb_max_depth': 7}. Best is trial 9 with value: 0.90086965541385.\n",
            "[I 2025-06-17 00:20:51,735] Trial 7 finished with value: 0.8999707213295958 and parameters: {'lgb_lr': 0.014718959744996471, 'lgb_num_leaves': 30, 'lgb_max_depth': 5}. Best is trial 9 with value: 0.90086965541385.\n",
            "[I 2025-06-17 00:20:52,141] Trial 10 finished with value: 0.9002512635164662 and parameters: {'lgb_lr': 0.015113889686552275, 'lgb_num_leaves': 27, 'lgb_max_depth': 6}. Best is trial 9 with value: 0.90086965541385.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:20:55,099] Trial 6 finished with value: 0.9004049762679122 and parameters: {'lgb_lr': 0.0033346345805155245, 'lgb_num_leaves': 23, 'lgb_max_depth': 8}. Best is trial 9 with value: 0.90086965541385.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:21:03,577] Trial 0 finished with value: 0.90050551832676 and parameters: {'lgb_lr': 0.04806116580190017, 'lgb_num_leaves': 30, 'lgb_max_depth': 6}. Best is trial 9 with value: 0.90086965541385.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:21:08,311] Trial 2 finished with value: 0.8998540894660376 and parameters: {'lgb_lr': 0.014527436575883167, 'lgb_num_leaves': 28, 'lgb_max_depth': 7}. Best is trial 9 with value: 0.90086965541385.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:21:19,436] Trial 8 finished with value: 0.900993612070663 and parameters: {'lgb_lr': 0.031587581820844146, 'lgb_num_leaves': 40, 'lgb_max_depth': 10}. Best is trial 8 with value: 0.900993612070663.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:21:30,263] Trial 14 finished with value: 0.9002739848881233 and parameters: {'lgb_lr': 0.025536370524554163, 'lgb_num_leaves': 23, 'lgb_max_depth': 4}. Best is trial 8 with value: 0.900993612070663.\n",
            "[I 2025-06-17 00:21:30,337] Trial 15 finished with value: 0.9001811854511528 and parameters: {'lgb_lr': 0.022193010369345668, 'lgb_num_leaves': 35, 'lgb_max_depth': 4}. Best is trial 8 with value: 0.900993612070663.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:21:33,394] Trial 18 finished with value: 0.8999361954864188 and parameters: {'lgb_lr': 0.0013214674348189107, 'lgb_num_leaves': 46, 'lgb_max_depth': 3}. Best is trial 8 with value: 0.900993612070663.\n",
            "[I 2025-06-17 00:21:33,494] Trial 16 finished with value: 0.9008731385654831 and parameters: {'lgb_lr': 0.02076619532001268, 'lgb_num_leaves': 40, 'lgb_max_depth': 3}. Best is trial 8 with value: 0.900993612070663.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:21:36,197] Trial 13 finished with value: 0.9007834515476147 and parameters: {'lgb_lr': 0.04201125302464513, 'lgb_num_leaves': 24, 'lgb_max_depth': 5}. Best is trial 8 with value: 0.900993612070663.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:21:39,573] Trial 12 finished with value: 0.9011550692549369 and parameters: {'lgb_lr': 0.02299397098844162, 'lgb_num_leaves': 22, 'lgb_max_depth': 8}. Best is trial 12 with value: 0.9011550692549369.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:22:13,712] Trial 19 finished with value: 0.9006779884545676 and parameters: {'lgb_lr': 0.007230365411429871, 'lgb_num_leaves': 29, 'lgb_max_depth': 9}. Best is trial 12 with value: 0.9011550692549369.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:22:50,750] Trial 21 finished with value: 0.9020864221180245 and parameters: {'lgb_lr': 0.09968118836255775, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 21 with value: 0.9020864221180245.\n",
            "[I 2025-06-17 00:22:50,753] Trial 20 finished with value: 0.9004816739071009 and parameters: {'lgb_lr': 0.005109239774729975, 'lgb_num_leaves': 50, 'lgb_max_depth': 10}. Best is trial 21 with value: 0.9020864221180245.\n",
            "[I 2025-06-17 00:22:51,259] Trial 22 finished with value: 0.9006970640383563 and parameters: {'lgb_lr': 0.09324039909156394, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 21 with value: 0.9020864221180245.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:22:52,939] Trial 17 finished with value: 0.9004371322363578 and parameters: {'lgb_lr': 0.0020112842334655376, 'lgb_num_leaves': 47, 'lgb_max_depth': 7}. Best is trial 21 with value: 0.9020864221180245.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:23:05,813] Trial 23 finished with value: 0.8999723184457994 and parameters: {'lgb_lr': 0.09430331462361345, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 21 with value: 0.9020864221180245.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:23:14,368] Trial 24 finished with value: 0.9029543539188707 and parameters: {'lgb_lr': 0.07429110079412743, 'lgb_num_leaves': 40, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:23:16,697] Trial 26 finished with value: 0.902046318685557 and parameters: {'lgb_lr': 0.0991166174182601, 'lgb_num_leaves': 40, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:23:17,669] Trial 27 finished with value: 0.9023803762865649 and parameters: {'lgb_lr': 0.09965975334948837, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:23:33,033] Trial 25 finished with value: 0.900663488168159 and parameters: {'lgb_lr': 0.09397970347705688, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:23:39,552] Trial 28 finished with value: 0.9027264156175744 and parameters: {'lgb_lr': 0.07981300042257133, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:23:40,938] Trial 29 finished with value: 0.9025567987393646 and parameters: {'lgb_lr': 0.08036016222438175, 'lgb_num_leaves': 40, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:23:55,914] Trial 30 finished with value: 0.9019304538747814 and parameters: {'lgb_lr': 0.07645849568640603, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:24:36,259] Trial 33 finished with value: 0.9010753306916692 and parameters: {'lgb_lr': 0.09871244225558233, 'lgb_num_leaves': 40, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:24:37,569] Trial 32 finished with value: 0.9023593476333529 and parameters: {'lgb_lr': 0.09627774209196406, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:24:39,145] Trial 34 finished with value: 0.9028141662052277 and parameters: {'lgb_lr': 0.07510682974941944, 'lgb_num_leaves': 42, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:24:52,296] Trial 35 finished with value: 0.9004725938881037 and parameters: {'lgb_lr': 0.03151447986234815, 'lgb_num_leaves': 42, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:24:53,434] Trial 31 finished with value: 0.9019098856621371 and parameters: {'lgb_lr': 0.09815831878151461, 'lgb_num_leaves': 41, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:25:03,823] Trial 37 finished with value: 0.9013366331876833 and parameters: {'lgb_lr': 0.07090437236721067, 'lgb_num_leaves': 43, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:25:05,229] Trial 36 finished with value: 0.9011814562849625 and parameters: {'lgb_lr': 0.07202018925919172, 'lgb_num_leaves': 43, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:25:20,455] Trial 38 finished with value: 0.9015567383234644 and parameters: {'lgb_lr': 0.06484633681965271, 'lgb_num_leaves': 43, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:25:30,421] Trial 41 finished with value: 0.9008156838166047 and parameters: {'lgb_lr': 0.0590848287289612, 'lgb_num_leaves': 44, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:25:37,744] Trial 39 finished with value: 0.9016903046854511 and parameters: {'lgb_lr': 0.06466500715387614, 'lgb_num_leaves': 43, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:25:45,260] Trial 42 finished with value: 0.9018296892966798 and parameters: {'lgb_lr': 0.05878990407650431, 'lgb_num_leaves': 44, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n",
            "[I 2025-06-17 00:25:45,427] Trial 40 finished with value: 0.9001245111443678 and parameters: {'lgb_lr': 0.060909045665710954, 'lgb_num_leaves': 44, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:26:25,110] Trial 43 finished with value: 0.9020152079043737 and parameters: {'lgb_lr': 0.05531687605586135, 'lgb_num_leaves': 43, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:26:26,441] Trial 44 finished with value: 0.9011599530153198 and parameters: {'lgb_lr': 0.05758053100025452, 'lgb_num_leaves': 44, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:26:30,435] Trial 46 finished with value: 0.9019103301099464 and parameters: {'lgb_lr': 0.055794334627631906, 'lgb_num_leaves': 37, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n",
            "[I 2025-06-17 00:26:30,632] Trial 45 finished with value: 0.901691668439439 and parameters: {'lgb_lr': 0.05377913377812302, 'lgb_num_leaves': 44, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:26:34,791] Trial 49 finished with value: 0.901644949003162 and parameters: {'lgb_lr': 0.05493349341934214, 'lgb_num_leaves': 32, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:26:52,777] Trial 48 finished with value: 0.9010796776464146 and parameters: {'lgb_lr': 0.047453709996212914, 'lgb_num_leaves': 44, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:26:57,568] Trial 50 finished with value: 0.9008946198224366 and parameters: {'lgb_lr': 0.0490761501742366, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:27:01,276] Trial 51 finished with value: 0.901764562591339 and parameters: {'lgb_lr': 0.04419975985179877, 'lgb_num_leaves': 33, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n",
            "[I 2025-06-17 00:27:01,330] Trial 47 finished with value: 0.901387969824384 and parameters: {'lgb_lr': 0.05632288707484523, 'lgb_num_leaves': 44, 'lgb_max_depth': 9}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:27:21,180] Trial 53 finished with value: 0.901049669800356 and parameters: {'lgb_lr': 0.04289746232202369, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n",
            "[I 2025-06-17 00:27:21,340] Trial 54 finished with value: 0.9006348427021603 and parameters: {'lgb_lr': 0.04136315809944636, 'lgb_num_leaves': 36, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:27:28,428] Trial 52 finished with value: 0.900486147090452 and parameters: {'lgb_lr': 0.045291679333529844, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:27:57,861] Trial 57 finished with value: 0.901016343354139 and parameters: {'lgb_lr': 0.042012199640907286, 'lgb_num_leaves': 32, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:28:01,113] Trial 58 finished with value: 0.9002952244915068 and parameters: {'lgb_lr': 0.03582620861931406, 'lgb_num_leaves': 32, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:28:01,639] Trial 55 finished with value: 0.9004292461581155 and parameters: {'lgb_lr': 0.04124190637376231, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:28:04,843] Trial 56 finished with value: 0.900968290594843 and parameters: {'lgb_lr': 0.04091847879675657, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:28:27,157] Trial 59 finished with value: 0.9007046701048914 and parameters: {'lgb_lr': 0.041027387587566695, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:28:29,694] Trial 60 finished with value: 0.9005014061572567 and parameters: {'lgb_lr': 0.03897580885458242, 'lgb_num_leaves': 37, 'lgb_max_depth': 8}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:28:37,729] Trial 63 finished with value: 0.900509074245005 and parameters: {'lgb_lr': 0.0369901997806849, 'lgb_num_leaves': 37, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:28:38,117] Trial 61 finished with value: 0.8997372558027517 and parameters: {'lgb_lr': 0.03926861044415474, 'lgb_num_leaves': 37, 'lgb_max_depth': 6}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:28:41,002] Trial 62 finished with value: 0.9013960768050836 and parameters: {'lgb_lr': 0.0768866467984466, 'lgb_num_leaves': 38, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:28:58,809] Trial 64 finished with value: 0.9005436899174188 and parameters: {'lgb_lr': 0.03580682343134427, 'lgb_num_leaves': 38, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:29:02,505] Trial 65 finished with value: 0.9013043445636935 and parameters: {'lgb_lr': 0.033820480430204344, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:29:22,701] Trial 66 finished with value: 0.9026471186138851 and parameters: {'lgb_lr': 0.07703920913355641, 'lgb_num_leaves': 46, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:29:52,511] Trial 68 finished with value: 0.9025303556267747 and parameters: {'lgb_lr': 0.080256822095067, 'lgb_num_leaves': 46, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:29:56,172] Trial 69 finished with value: 0.9015473940697962 and parameters: {'lgb_lr': 0.07936273364152317, 'lgb_num_leaves': 46, 'lgb_max_depth': 10}. Best is trial 24 with value: 0.9029543539188707.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:29:57,133] Trial 70 finished with value: 0.9030840013680289 and parameters: {'lgb_lr': 0.07451422379871855, 'lgb_num_leaves': 46, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:30:09,320] Trial 67 finished with value: 0.9021814302905342 and parameters: {'lgb_lr': 0.07806231457777182, 'lgb_num_leaves': 46, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:30:10,823] Trial 72 finished with value: 0.9016153429807079 and parameters: {'lgb_lr': 0.08086098590354825, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:30:21,771] Trial 71 finished with value: 0.9023078781635864 and parameters: {'lgb_lr': 0.07862798665221085, 'lgb_num_leaves': 46, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:30:33,378] Trial 73 finished with value: 0.9016387224772991 and parameters: {'lgb_lr': 0.08111113913777182, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:30:34,512] Trial 74 finished with value: 0.9024177950649243 and parameters: {'lgb_lr': 0.08142680217318973, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:30:36,386] Trial 75 finished with value: 0.9021737839986576 and parameters: {'lgb_lr': 0.08382301384998816, 'lgb_num_leaves': 39, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:30:52,236] Trial 76 finished with value: 0.9008478895108027 and parameters: {'lgb_lr': 0.08194461369500947, 'lgb_num_leaves': 47, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:31:12,610] Trial 77 finished with value: 0.901099806479264 and parameters: {'lgb_lr': 0.07965976311556985, 'lgb_num_leaves': 46, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:31:18,367] Trial 78 finished with value: 0.902447575684457 and parameters: {'lgb_lr': 0.08127805219433187, 'lgb_num_leaves': 48, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:31:48,035] Trial 79 finished with value: 0.9024620109078396 and parameters: {'lgb_lr': 0.08161645606081096, 'lgb_num_leaves': 48, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:31:54,852] Trial 81 finished with value: 0.902593783713505 and parameters: {'lgb_lr': 0.08530826013035649, 'lgb_num_leaves': 49, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:32:08,316] Trial 82 finished with value: 0.902965134978582 and parameters: {'lgb_lr': 0.08588339071143192, 'lgb_num_leaves': 50, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:32:08,972] Trial 83 finished with value: 0.9024856322304512 and parameters: {'lgb_lr': 0.08208177469098107, 'lgb_num_leaves': 49, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:32:10,266] Trial 80 finished with value: 0.9016160361955455 and parameters: {'lgb_lr': 0.08182215344356629, 'lgb_num_leaves': 47, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:32:21,733] Trial 84 finished with value: 0.9029732684856687 and parameters: {'lgb_lr': 0.08636468777184143, 'lgb_num_leaves': 50, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:32:28,172] Trial 85 finished with value: 0.9012632938597973 and parameters: {'lgb_lr': 0.0685210169178581, 'lgb_num_leaves': 48, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:32:31,676] Trial 86 finished with value: 0.9015103239325355 and parameters: {'lgb_lr': 0.0675993177393311, 'lgb_num_leaves': 49, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:32:33,206] Trial 87 finished with value: 0.9011326127405577 and parameters: {'lgb_lr': 0.06776063844638262, 'lgb_num_leaves': 48, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:32:47,439] Trial 88 finished with value: 0.9024021971547247 and parameters: {'lgb_lr': 0.06813276345525539, 'lgb_num_leaves': 48, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:33:05,880] Trial 89 finished with value: 0.9015902896480957 and parameters: {'lgb_lr': 0.06716936706319877, 'lgb_num_leaves': 49, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:33:14,747] Trial 90 finished with value: 0.9009658153378651 and parameters: {'lgb_lr': 0.06493302046633206, 'lgb_num_leaves': 50, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:33:46,267] Trial 91 finished with value: 0.9020193103552018 and parameters: {'lgb_lr': 0.06857555601747324, 'lgb_num_leaves': 49, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:34:05,250] Trial 95 finished with value: 0.9023397229403762 and parameters: {'lgb_lr': 0.0668129730059488, 'lgb_num_leaves': 49, 'lgb_max_depth': 9}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:34:07,117] Trial 93 finished with value: 0.9013387827820747 and parameters: {'lgb_lr': 0.06720537654418211, 'lgb_num_leaves': 50, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:34:07,909] Trial 94 finished with value: 0.9017802018968041 and parameters: {'lgb_lr': 0.06664720379496913, 'lgb_num_leaves': 50, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:34:10,566] Trial 92 finished with value: 0.9019890367951889 and parameters: {'lgb_lr': 0.0664098215192428, 'lgb_num_leaves': 50, 'lgb_max_depth': 10}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:34:16,964] Trial 98 finished with value: 0.9011339107270762 and parameters: {'lgb_lr': 0.005134575908140406, 'lgb_num_leaves': 49, 'lgb_max_depth': 9}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:34:17,707] Trial 97 finished with value: 0.9007976685748021 and parameters: {'lgb_lr': 0.01823094591053738, 'lgb_num_leaves': 50, 'lgb_max_depth': 9}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:34:19,852] Trial 99 finished with value: 0.9009768217893602 and parameters: {'lgb_lr': 0.027018534309853782, 'lgb_num_leaves': 49, 'lgb_max_depth': 9}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:34:23,470] Trial 96 finished with value: 0.9018011721796753 and parameters: {'lgb_lr': 0.07056289435460154, 'lgb_num_leaves': 49, 'lgb_max_depth': 9}. Best is trial 70 with value: 0.9030840013680289.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:100: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('lgb_lr', 1e-3, 0.1)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003858 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 6885\n",
            "[LightGBM] [Info] Number of data points in the train set: 74447, number of used features: 27\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Info] Start training from score -3.295837\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "[I 2025-06-17 00:34:32,011] A new study created in memory with name: no-name-7dcc74ae-9ea3-45bd-9221-5a003a1e9f36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final train F1 lgbm: 0.9031\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36c5ea9fd5ad4054971613e27773d31c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:34:54,613] Trial 0 finished with value: 0.8998228126568975 and parameters: {'mlp_hidden_dim': 844, 'mlp_lr': 0.0003910120884801242, 'mlp_wd': 1.6818378229016792e-05}. Best is trial 0 with value: 0.8998228126568975.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:35:17,339] Trial 1 finished with value: 0.9003455144368123 and parameters: {'mlp_hidden_dim': 806, 'mlp_lr': 0.00144825278202358, 'mlp_wd': 7.569824785548255e-05}. Best is trial 1 with value: 0.9003455144368123.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:35:40,312] Trial 2 finished with value: 0.9009461094541278 and parameters: {'mlp_hidden_dim': 741, 'mlp_lr': 0.003708606007941937, 'mlp_wd': 0.00012341668608510724}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:36:02,989] Trial 3 finished with value: 0.9000279028612823 and parameters: {'mlp_hidden_dim': 361, 'mlp_lr': 0.00026306368199880136, 'mlp_wd': 0.00035930100132590853}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:36:25,633] Trial 4 finished with value: 0.900778660063777 and parameters: {'mlp_hidden_dim': 632, 'mlp_lr': 0.0016800645733359982, 'mlp_wd': 3.727162267151457e-06}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:36:48,690] Trial 5 finished with value: 0.90002831902405 and parameters: {'mlp_hidden_dim': 573, 'mlp_lr': 0.0007639614263067297, 'mlp_wd': 1.7524680031701086e-05}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:37:11,303] Trial 6 finished with value: 0.9002263708706083 and parameters: {'mlp_hidden_dim': 396, 'mlp_lr': 0.0028447941152601065, 'mlp_wd': 2.0441251500373468e-05}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:37:34,004] Trial 7 finished with value: 0.9005598048224699 and parameters: {'mlp_hidden_dim': 925, 'mlp_lr': 0.003378974234853591, 'mlp_wd': 6.546115719387492e-05}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:37:56,854] Trial 8 finished with value: 0.899730736083905 and parameters: {'mlp_hidden_dim': 867, 'mlp_lr': 0.00033917678084492735, 'mlp_wd': 3.05601509420322e-06}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:38:19,417] Trial 9 finished with value: 0.9008117820461032 and parameters: {'mlp_hidden_dim': 554, 'mlp_lr': 0.0013199933800038272, 'mlp_wd': 4.672093936033653e-05}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:38:42,081] Trial 10 finished with value: 0.9002548994919743 and parameters: {'mlp_hidden_dim': 1017, 'mlp_lr': 0.006983441508373667, 'mlp_wd': 0.00038883041632303963}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:39:05,073] Trial 11 finished with value: 0.9004052899863175 and parameters: {'mlp_hidden_dim': 513, 'mlp_lr': 0.007757102612569086, 'mlp_wd': 0.00012716091321799815}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:39:27,986] Trial 12 finished with value: 0.899310512224895 and parameters: {'mlp_hidden_dim': 708, 'mlp_lr': 0.00013697311521060243, 'mlp_wd': 0.0001671781849957331}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:39:50,753] Trial 13 finished with value: 0.9002122710445062 and parameters: {'mlp_hidden_dim': 728, 'mlp_lr': 0.0035588764398760703, 'mlp_wd': 0.0006716573701332529}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:40:13,729] Trial 14 finished with value: 0.9003379292428084 and parameters: {'mlp_hidden_dim': 506, 'mlp_lr': 0.0007396694911828876, 'mlp_wd': 5.892734563482979e-06}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:40:36,603] Trial 15 finished with value: 0.9007139781198591 and parameters: {'mlp_hidden_dim': 711, 'mlp_lr': 0.0020727450546901183, 'mlp_wd': 1.0504228401245767e-06}. Best is trial 2 with value: 0.9009461094541278.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:40:59,408] Trial 16 finished with value: 0.901304846911445 and parameters: {'mlp_hidden_dim': 271, 'mlp_lr': 0.005096588675096344, 'mlp_wd': 4.116366132887469e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:41:22,112] Trial 17 finished with value: 0.8998431971761958 and parameters: {'mlp_hidden_dim': 303, 'mlp_lr': 0.0050603994740036394, 'mlp_wd': 0.00017649315834135682}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:41:45,217] Trial 18 finished with value: 0.9005889547916754 and parameters: {'mlp_hidden_dim': 271, 'mlp_lr': 0.0064809826037516595, 'mlp_wd': 2.831771298234731e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:42:08,001] Trial 19 finished with value: 0.9005911231251488 and parameters: {'mlp_hidden_dim': 428, 'mlp_lr': 0.009008704685154176, 'mlp_wd': 0.0009116107119909764}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:42:30,827] Trial 20 finished with value: 0.9005604326050254 and parameters: {'mlp_hidden_dim': 632, 'mlp_lr': 0.0024036237932231834, 'mlp_wd': 7.976904220952923e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:42:53,745] Trial 21 finished with value: 0.9003824564094823 and parameters: {'mlp_hidden_dim': 478, 'mlp_lr': 0.0011690385373450162, 'mlp_wd': 5.294450339508066e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:43:16,551] Trial 22 finished with value: 0.9002764980961182 and parameters: {'mlp_hidden_dim': 331, 'mlp_lr': 0.004867092667247641, 'mlp_wd': 4.155972761524434e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:43:39,322] Trial 23 finished with value: 0.8999805315001251 and parameters: {'mlp_hidden_dim': 792, 'mlp_lr': 0.0008321219357023544, 'mlp_wd': 0.00010434666366881964}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:44:02,330] Trial 24 finished with value: 0.9000313671851896 and parameters: {'mlp_hidden_dim': 576, 'mlp_lr': 0.004135213694708932, 'mlp_wd': 0.000326456819041023}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:44:25,472] Trial 25 finished with value: 0.8996773462576398 and parameters: {'mlp_hidden_dim': 447, 'mlp_lr': 0.0005268299445954895, 'mlp_wd': 3.2338588515134765e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:44:48,348] Trial 26 finished with value: 0.9000015656430805 and parameters: {'mlp_hidden_dim': 571, 'mlp_lr': 0.001938404868831836, 'mlp_wd': 0.0002213550213623396}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:45:11,631] Trial 27 finished with value: 0.9001664385438828 and parameters: {'mlp_hidden_dim': 260, 'mlp_lr': 0.0012313084745269166, 'mlp_wd': 9.757030736590266e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:45:34,420] Trial 28 finished with value: 0.9007303764257024 and parameters: {'mlp_hidden_dim': 756, 'mlp_lr': 0.002686495855480359, 'mlp_wd': 6.940117170093309e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:45:57,244] Trial 29 finished with value: 0.9007832252068873 and parameters: {'mlp_hidden_dim': 931, 'mlp_lr': 0.0054022918360751215, 'mlp_wd': 1.309824426258885e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:46:20,253] Trial 30 finished with value: 0.8995036628575679 and parameters: {'mlp_hidden_dim': 663, 'mlp_lr': 0.00010253969872157035, 'mlp_wd': 3.271052736714265e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:46:43,149] Trial 31 finished with value: 0.900795531657586 and parameters: {'mlp_hidden_dim': 934, 'mlp_lr': 0.005312121091160907, 'mlp_wd': 1.24927709433324e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:47:05,815] Trial 32 finished with value: 0.9004411735405545 and parameters: {'mlp_hidden_dim': 855, 'mlp_lr': 0.00997737707736337, 'mlp_wd': 0.00010985346621471758}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:47:28,782] Trial 33 finished with value: 0.9008661083554727 and parameters: {'mlp_hidden_dim': 965, 'mlp_lr': 0.003983067650079974, 'mlp_wd': 2.2045302939515822e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:47:51,479] Trial 34 finished with value: 0.9008523698986124 and parameters: {'mlp_hidden_dim': 1021, 'mlp_lr': 0.0016456652417793922, 'mlp_wd': 4.8520115045282846e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:48:14,380] Trial 35 finished with value: 0.9006858386096495 and parameters: {'mlp_hidden_dim': 1009, 'mlp_lr': 0.0034346770740778234, 'mlp_wd': 2.2734054342685045e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:48:37,064] Trial 36 finished with value: 0.9004966464608483 and parameters: {'mlp_hidden_dim': 973, 'mlp_lr': 0.00239596159254022, 'mlp_wd': 8.11982621800588e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:48:59,985] Trial 37 finished with value: 0.9002215822238202 and parameters: {'mlp_hidden_dim': 838, 'mlp_lr': 0.001952243464082709, 'mlp_wd': 1.6703749688113657e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:49:22,705] Trial 38 finished with value: 0.9004616195170466 and parameters: {'mlp_hidden_dim': 894, 'mlp_lr': 0.004155930540458883, 'mlp_wd': 4.344807776660781e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:49:45,645] Trial 39 finished with value: 0.9008620902642323 and parameters: {'mlp_hidden_dim': 961, 'mlp_lr': 0.0016566094378445732, 'mlp_wd': 7.741876771828373e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:50:08,624] Trial 40 finished with value: 0.8996480843114911 and parameters: {'mlp_hidden_dim': 806, 'mlp_lr': 0.003078285039890799, 'mlp_wd': 0.000308553365119155}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:50:31,440] Trial 41 finished with value: 0.9000066756756777 and parameters: {'mlp_hidden_dim': 972, 'mlp_lr': 0.001669573058381642, 'mlp_wd': 8.284560803607017e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:50:54,163] Trial 42 finished with value: 0.8996561115656573 and parameters: {'mlp_hidden_dim': 984, 'mlp_lr': 0.0015475425583809652, 'mlp_wd': 5.731415768512832e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:51:17,084] Trial 43 finished with value: 0.9009501401913531 and parameters: {'mlp_hidden_dim': 887, 'mlp_lr': 0.0009984266279720693, 'mlp_wd': 2.350519751149302e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:51:39,746] Trial 44 finished with value: 0.8998853263796166 and parameters: {'mlp_hidden_dim': 937, 'mlp_lr': 0.0005596251592794545, 'mlp_wd': 2.4810134584693912e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:52:02,353] Trial 45 finished with value: 0.9004068031650702 and parameters: {'mlp_hidden_dim': 881, 'mlp_lr': 0.0009816115916679025, 'mlp_wd': 1.8919537759031654e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:52:25,228] Trial 46 finished with value: 0.8998628586215085 and parameters: {'mlp_hidden_dim': 670, 'mlp_lr': 0.00024149813367781427, 'mlp_wd': 4.497679354889148e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:52:47,945] Trial 47 finished with value: 0.9002880566450646 and parameters: {'mlp_hidden_dim': 760, 'mlp_lr': 0.003928438386887704, 'mlp_wd': 0.0001489629326678033}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:53:10,997] Trial 48 finished with value: 0.9007323787876077 and parameters: {'mlp_hidden_dim': 827, 'mlp_lr': 0.006358650865079573, 'mlp_wd': 2.2579529511942347e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:53:34,095] Trial 49 finished with value: 0.9001986795259184 and parameters: {'mlp_hidden_dim': 896, 'mlp_lr': 0.007978484023567732, 'mlp_wd': 3.814243469784624e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:53:56,860] Trial 50 finished with value: 0.899891129522315 and parameters: {'mlp_hidden_dim': 909, 'mlp_lr': 0.0009945829718189952, 'mlp_wd': 9.134849737845745e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:54:19,714] Trial 51 finished with value: 0.9006337753316117 and parameters: {'mlp_hidden_dim': 1021, 'mlp_lr': 0.0006232862797123838, 'mlp_wd': 5.5377561161700314e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:54:42,460] Trial 52 finished with value: 0.9002083217492104 and parameters: {'mlp_hidden_dim': 964, 'mlp_lr': 0.0014207421537287908, 'mlp_wd': 0.00022011440372065542}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:55:05,463] Trial 53 finished with value: 0.9005613907201954 and parameters: {'mlp_hidden_dim': 1005, 'mlp_lr': 0.002773573737889709, 'mlp_wd': 1.5040892164949487e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:55:28,284] Trial 54 finished with value: 0.9000761483403763 and parameters: {'mlp_hidden_dim': 375, 'mlp_lr': 0.002157034265074828, 'mlp_wd': 2.4559082519574974e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:55:51,122] Trial 55 finished with value: 0.8997949919728915 and parameters: {'mlp_hidden_dim': 953, 'mlp_lr': 0.0007556797790231457, 'mlp_wd': 3.204878819603714e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:56:14,212] Trial 56 finished with value: 0.8997722408278808 and parameters: {'mlp_hidden_dim': 992, 'mlp_lr': 0.0004508043678363458, 'mlp_wd': 6.598701802783296e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:56:37,078] Trial 57 finished with value: 0.9002001418485656 and parameters: {'mlp_hidden_dim': 610, 'mlp_lr': 0.0017815129746234593, 'mlp_wd': 0.00011822199742033356}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:57:00,080] Trial 58 finished with value: 0.9002036097826176 and parameters: {'mlp_hidden_dim': 913, 'mlp_lr': 0.004718541137160975, 'mlp_wd': 9.754124964431171e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:57:23,017] Trial 59 finished with value: 0.9003876981028752 and parameters: {'mlp_hidden_dim': 862, 'mlp_lr': 0.0011783625697030684, 'mlp_wd': 4.300858240269244e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:57:45,816] Trial 60 finished with value: 0.8996477227176081 and parameters: {'mlp_hidden_dim': 766, 'mlp_lr': 0.003168671050906697, 'mlp_wd': 0.0004376195992732569}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:58:08,700] Trial 61 finished with value: 0.9004579626585588 and parameters: {'mlp_hidden_dim': 405, 'mlp_lr': 0.002329235021666569, 'mlp_wd': 5.030452106837418e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:58:31,850] Trial 62 finished with value: 0.8997299142101024 and parameters: {'mlp_hidden_dim': 510, 'mlp_lr': 0.0013432030541422858, 'mlp_wd': 0.00015185296138956313}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:58:54,770] Trial 63 finished with value: 0.9000436498768487 and parameters: {'mlp_hidden_dim': 695, 'mlp_lr': 0.0008843493953393758, 'mlp_wd': 3.788740755408587e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:59:17,847] Trial 64 finished with value: 0.9004510150712954 and parameters: {'mlp_hidden_dim': 559, 'mlp_lr': 0.0011261914577072327, 'mlp_wd': 2.0244869064201494e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 00:59:40,882] Trial 65 finished with value: 0.9007271534985778 and parameters: {'mlp_hidden_dim': 307, 'mlp_lr': 0.006051247002074878, 'mlp_wd': 2.9048638031645685e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:00:03,651] Trial 66 finished with value: 0.9000961600802558 and parameters: {'mlp_hidden_dim': 951, 'mlp_lr': 0.0013999871819757783, 'mlp_wd': 7.09855032541027e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:00:26,482] Trial 67 finished with value: 0.9000516048942155 and parameters: {'mlp_hidden_dim': 793, 'mlp_lr': 0.002645675781411342, 'mlp_wd': 0.00010056822374220599}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:00:49,439] Trial 68 finished with value: 0.8998933664630224 and parameters: {'mlp_hidden_dim': 480, 'mlp_lr': 0.0006874982621043852, 'mlp_wd': 4.6894748454303866e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:01:12,623] Trial 69 finished with value: 0.9000156147878202 and parameters: {'mlp_hidden_dim': 993, 'mlp_lr': 0.003805200740166738, 'mlp_wd': 0.00019795665823636475}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:01:35,635] Trial 70 finished with value: 0.9004305365755625 and parameters: {'mlp_hidden_dim': 599, 'mlp_lr': 0.007345234994411621, 'mlp_wd': 6.310166723433396e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:01:58,579] Trial 71 finished with value: 0.9000712563034416 and parameters: {'mlp_hidden_dim': 937, 'mlp_lr': 0.005593485934805132, 'mlp_wd': 1.2520157107421164e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:02:21,912] Trial 72 finished with value: 0.8999500450195858 and parameters: {'mlp_hidden_dim': 1022, 'mlp_lr': 0.0017358268506231548, 'mlp_wd': 1.0612404937615916e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:02:45,126] Trial 73 finished with value: 0.9005675540862634 and parameters: {'mlp_hidden_dim': 871, 'mlp_lr': 0.0047280127781919624, 'mlp_wd': 1.5346919659498056e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:03:08,308] Trial 74 finished with value: 0.9001779158330504 and parameters: {'mlp_hidden_dim': 921, 'mlp_lr': 0.003351132136269476, 'mlp_wd': 6.596373628085142e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:03:31,486] Trial 75 finished with value: 0.900580996610508 and parameters: {'mlp_hidden_dim': 828, 'mlp_lr': 0.0045116624571125, 'mlp_wd': 2.5422802740770362e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:03:54,405] Trial 76 finished with value: 0.900221421109579 and parameters: {'mlp_hidden_dim': 543, 'mlp_lr': 0.00849842124115853, 'mlp_wd': 3.6708475235673705e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:04:17,416] Trial 77 finished with value: 0.900181206201607 and parameters: {'mlp_hidden_dim': 726, 'mlp_lr': 0.0008788303138236241, 'mlp_wd': 2.0634697071466788e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:04:40,638] Trial 78 finished with value: 0.8998016406463645 and parameters: {'mlp_hidden_dim': 954, 'mlp_lr': 0.005567184169672762, 'mlp_wd': 8.467422748639688e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:05:03,569] Trial 79 finished with value: 0.9007473603344902 and parameters: {'mlp_hidden_dim': 893, 'mlp_lr': 0.006728395758225046, 'mlp_wd': 0.00013375617759989338}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:05:26,639] Trial 80 finished with value: 0.8998322271626671 and parameters: {'mlp_hidden_dim': 981, 'mlp_lr': 0.00027439385657504847, 'mlp_wd': 2.8751347357333563e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:05:49,729] Trial 81 finished with value: 0.900273352444063 and parameters: {'mlp_hidden_dim': 933, 'mlp_lr': 0.005431492181618529, 'mlp_wd': 1.251905051969185e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:06:12,751] Trial 82 finished with value: 0.9003378682934626 and parameters: {'mlp_hidden_dim': 969, 'mlp_lr': 0.0043119652614791, 'mlp_wd': 1.5832763539175713e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:06:35,706] Trial 83 finished with value: 0.9006621954090592 and parameters: {'mlp_hidden_dim': 912, 'mlp_lr': 0.001599103051282123, 'mlp_wd': 8.211014227918212e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:06:58,860] Trial 84 finished with value: 0.8999786470182232 and parameters: {'mlp_hidden_dim': 850, 'mlp_lr': 0.003706442171253183, 'mlp_wd': 1.2280531582767399e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:07:22,102] Trial 85 finished with value: 0.8997737939491534 and parameters: {'mlp_hidden_dim': 341, 'mlp_lr': 0.0010710257500967935, 'mlp_wd': 5.3221174641178164e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:07:45,182] Trial 86 finished with value: 0.9000985087987733 and parameters: {'mlp_hidden_dim': 995, 'mlp_lr': 0.0019826944167044844, 'mlp_wd': 2.2098481143641585e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:08:08,131] Trial 87 finished with value: 0.9004174761397564 and parameters: {'mlp_hidden_dim': 889, 'mlp_lr': 0.0012708628512179425, 'mlp_wd': 1.8026036428969402e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:08:31,441] Trial 88 finished with value: 0.9002621149433634 and parameters: {'mlp_hidden_dim': 945, 'mlp_lr': 0.007149924974965597, 'mlp_wd': 3.2308396739191965e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:08:54,476] Trial 89 finished with value: 0.9003312667831743 and parameters: {'mlp_hidden_dim': 668, 'mlp_lr': 0.0029961007263348575, 'mlp_wd': 6.7989145879759835e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:09:17,605] Trial 90 finished with value: 0.9005207907604917 and parameters: {'mlp_hidden_dim': 925, 'mlp_lr': 0.009509713056183944, 'mlp_wd': 5.027640987586767e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:09:40,827] Trial 91 finished with value: 0.9006232837585703 and parameters: {'mlp_hidden_dim': 626, 'mlp_lr': 0.0022292980651221514, 'mlp_wd': 1.977244058024279e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:10:03,702] Trial 92 finished with value: 0.9005877065774862 and parameters: {'mlp_hidden_dim': 538, 'mlp_lr': 0.002633848479278684, 'mlp_wd': 1.1734419506992509e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:10:26,753] Trial 93 finished with value: 0.9005870471235284 and parameters: {'mlp_hidden_dim': 697, 'mlp_lr': 0.005095086091148299, 'mlp_wd': 4.1347535679158524e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:10:49,929] Trial 94 finished with value: 0.9002728637203409 and parameters: {'mlp_hidden_dim': 649, 'mlp_lr': 0.0015246361176026717, 'mlp_wd': 5.853841597364541e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:11:12,869] Trial 95 finished with value: 0.9003219604289923 and parameters: {'mlp_hidden_dim': 1005, 'mlp_lr': 0.0018226415375822758, 'mlp_wd': 3.7278130629601735e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:11:35,853] Trial 96 finished with value: 0.9000699647155932 and parameters: {'mlp_hidden_dim': 444, 'mlp_lr': 0.0009699463539757845, 'mlp_wd': 2.7434864317078045e-06}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:11:59,030] Trial 97 finished with value: 0.9009058565287708 and parameters: {'mlp_hidden_dim': 738, 'mlp_lr': 0.006275434989008797, 'mlp_wd': 7.710332294671627e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:12:22,019] Trial 98 finished with value: 0.9004961495090427 and parameters: {'mlp_hidden_dim': 811, 'mlp_lr': 0.005734553793064774, 'mlp_wd': 7.525453352017084e-05}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:12:44,945] Trial 99 finished with value: 0.8998180077447301 and parameters: {'mlp_hidden_dim': 781, 'mlp_lr': 0.00639004674311316, 'mlp_wd': 0.00011397657503765559}. Best is trial 16 with value: 0.901304846911445.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2470289180>:147: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform('mlp_lr', 1e-4, 1e-2)\n",
            "<ipython-input-2-2470289180>:148: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('mlp_wd', 1e-6, 1e-3)\n",
            "[I 2025-06-17 01:13:07,771] A new study created in memory with name: no-name-0d41abea-3e91-46f9-a5b3-8f26e4d097aa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final train F1 mlp: 0.9008\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7c9d430235f4ef593213008ab5c5ebf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-17 01:13:07,793] Trial 0 finished with value: 0.09979917592189214 and parameters: {'w0': 0.26482455548095296, 'w1': 0.47078622277901083}. Best is trial 0 with value: 0.09979917592189214.\n",
            "[I 2025-06-17 01:13:07,807] Trial 1 finished with value: 0.09885238908420102 and parameters: {'w0': 0.723539668431451, 'w1': 0.6068827488747567}. Best is trial 1 with value: 0.09885238908420102.\n",
            "[I 2025-06-17 01:13:07,821] Trial 2 finished with value: 0.0994071715820889 and parameters: {'w0': 0.4424666125607366, 'w1': 0.5884221359710426}. Best is trial 1 with value: 0.09885238908420102.\n",
            "[I 2025-06-17 01:13:07,846] Trial 3 finished with value: 0.09877957777858282 and parameters: {'w0': 0.6397915728874306, 'w1': 0.47113288509725715}. Best is trial 3 with value: 0.09877957777858282.\n",
            "[I 2025-06-17 01:13:07,882] Trial 4 finished with value: 0.099789059270747 and parameters: {'w0': 0.5285234852579016, 'w1': 0.956010374883919}. Best is trial 3 with value: 0.09877957777858282.\n",
            "[I 2025-06-17 01:13:07,904] Trial 5 finished with value: 0.09971266124248879 and parameters: {'w0': 0.5562248512090073, 'w1': 0.8872562100628923}. Best is trial 3 with value: 0.09877957777858282.\n",
            "[I 2025-06-17 01:13:07,927] Trial 6 finished with value: 0.10010377102687396 and parameters: {'w0': 0.340014737106084, 'w1': 0.8491929688326948}. Best is trial 3 with value: 0.09877957777858282.\n",
            "[I 2025-06-17 01:13:07,942] Trial 7 finished with value: 0.09978985406333318 and parameters: {'w0': 0.18871959203825284, 'w1': 0.312072815955179}. Best is trial 3 with value: 0.09877957777858282.\n",
            "[I 2025-06-17 01:13:07,962] Trial 8 finished with value: 0.09642769992063194 and parameters: {'w0': 0.9176046086316227, 'w1': 0.06612125396788793}. Best is trial 8 with value: 0.09642769992063194.\n",
            "[I 2025-06-17 01:13:07,988] Trial 9 finished with value: 0.09947600049483896 and parameters: {'w0': 0.7197125063958035, 'w1': 0.89884576649059}. Best is trial 8 with value: 0.09642769992063194.\n",
            "[I 2025-06-17 01:13:08,014] Trial 10 finished with value: 0.09628610172429675 and parameters: {'w0': 0.9884076738490479, 'w1': 0.0593263246863202}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,040] Trial 11 finished with value: 0.0968443130022435 and parameters: {'w0': 0.9945241402803262, 'w1': 0.002506099731351602}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,064] Trial 12 finished with value: 0.09691599863197109 and parameters: {'w0': 0.9768210102166439, 'w1': 0.0007539332992554382}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,088] Trial 13 finished with value: 0.09830178497254494 and parameters: {'w0': 0.8329121179898822, 'w1': 0.20206424122315436}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,120] Trial 14 finished with value: 0.10010752636100695 and parameters: {'w0': 0.04859468217161822, 'w1': 0.16669481428370445}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,143] Trial 15 finished with value: 0.09739348600113173 and parameters: {'w0': 0.8809176048361765, 'w1': 0.15687211121758546}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,169] Trial 16 finished with value: 0.09800340989382605 and parameters: {'w0': 0.838689436377816, 'w1': 0.3176108082590033}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,209] Trial 17 finished with value: 0.09654600410894965 and parameters: {'w0': 0.910587523338197, 'w1': 0.09187540787261228}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,242] Trial 18 finished with value: 0.09807987167021004 and parameters: {'w0': 0.7107239912122842, 'w1': 0.30772895258899224}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,266] Trial 19 finished with value: 0.09802022873520944 and parameters: {'w0': 0.7968406581277093, 'w1': 0.2652977796321121}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,294] Trial 20 finished with value: 0.09878797086376545 and parameters: {'w0': 0.9930016442682672, 'w1': 0.743471771564234}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,319] Trial 21 finished with value: 0.09662824297993333 and parameters: {'w0': 0.902488155250018, 'w1': 0.08601180659418928}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,345] Trial 22 finished with value: 0.09671601087474935 and parameters: {'w0': 0.9056139266491253, 'w1': 0.07595738734037291}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,382] Trial 23 finished with value: 0.09678353973660281 and parameters: {'w0': 0.7669684131149955, 'w1': 0.0962465825778205}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,406] Trial 24 finished with value: 0.09800452529944537 and parameters: {'w0': 0.6052389984788866, 'w1': 0.23033547919857356}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,430] Trial 25 finished with value: 0.09784504811064099 and parameters: {'w0': 0.9588915844659902, 'w1': 0.39264275715156294}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,455] Trial 26 finished with value: 0.09685639180442551 and parameters: {'w0': 0.902370890053554, 'w1': 0.11862175586104258}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,480] Trial 27 finished with value: 0.09664619841143551 and parameters: {'w0': 0.4541850351215046, 'w1': 0.03539775173288369}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,509] Trial 28 finished with value: 0.09850208543504901 and parameters: {'w0': 0.6519615632254816, 'w1': 0.371932102414043}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,536] Trial 29 finished with value: 0.09745870963518477 and parameters: {'w0': 0.8178884455077227, 'w1': 0.1518810109903902}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,573] Trial 30 finished with value: 0.09800404400174245 and parameters: {'w0': 0.9185634810640659, 'w1': 0.39403532751031944}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,663] Trial 31 finished with value: 0.09648051664539536 and parameters: {'w0': 0.8822722671771632, 'w1': 0.10365207726429819}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,691] Trial 32 finished with value: 0.09629078805364277 and parameters: {'w0': 0.7492882951419584, 'w1': 0.04272998216021773}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,726] Trial 33 finished with value: 0.09801327557470063 and parameters: {'w0': 0.7686152265806555, 'w1': 0.22384824330792344}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,750] Trial 34 finished with value: 0.09872036355721092 and parameters: {'w0': 0.8552361529708559, 'w1': 0.5935491753095032}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,789] Trial 35 finished with value: 0.09671601087474935 and parameters: {'w0': 0.6823570679119371, 'w1': 0.056517100459496594}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,822] Trial 36 finished with value: 0.09857959871163802 and parameters: {'w0': 0.776470512218672, 'w1': 0.507076388991061}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,848] Trial 37 finished with value: 0.09953830603484282 and parameters: {'w0': 0.5759325141608813, 'w1': 0.6731215333456677}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,876] Trial 38 finished with value: 0.09746503403048778 and parameters: {'w0': 0.9422326700076873, 'w1': 0.1779869447095414}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,900] Trial 39 finished with value: 0.09793129746991303 and parameters: {'w0': 0.3573492021470378, 'w1': 0.13329017062747966}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,929] Trial 40 finished with value: 0.09643959601561414 and parameters: {'w0': 0.7380743245602631, 'w1': 0.037603784374093924}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,960] Trial 41 finished with value: 0.09652573607659365 and parameters: {'w0': 0.7337393819021192, 'w1': 0.037820224145087955}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:08,985] Trial 42 finished with value: 0.09669230604610446 and parameters: {'w0': 0.8547562966375369, 'w1': 0.005470418192722239}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,025] Trial 43 finished with value: 0.09662986441572352 and parameters: {'w0': 0.5135682232224187, 'w1': 0.047547152907896385}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,065] Trial 44 finished with value: 0.09648051664539536 and parameters: {'w0': 0.998859850842388, 'w1': 0.11901376654493029}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,093] Trial 45 finished with value: 0.09800189498803735 and parameters: {'w0': 0.6607873864796758, 'w1': 0.2620482112219998}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,129] Trial 46 finished with value: 0.09669230604610446 and parameters: {'w0': 0.9518713514464351, 'w1': 0.005487858684709232}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,161] Trial 47 finished with value: 0.09790799253247007 and parameters: {'w0': 0.862842320939917, 'w1': 0.19545499345121406}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,240] Trial 48 finished with value: 0.09939623937475428 and parameters: {'w0': 0.7325725866765773, 'w1': 0.9885930702215366}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,275] Trial 49 finished with value: 0.09886111330589187 and parameters: {'w0': 0.1787125408957787, 'w1': 0.12988871199526897}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,301] Trial 50 finished with value: 0.09671754892441042 and parameters: {'w0': 0.8165419865111664, 'w1': 0.06568286232487389}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,334] Trial 51 finished with value: 0.09654731142431372 and parameters: {'w0': 0.9990557719635473, 'w1': 0.1115165156270687}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,380] Trial 52 finished with value: 0.09676941778105896 and parameters: {'w0': 0.9497360721101038, 'w1': 0.14543563012487493}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,421] Trial 53 finished with value: 0.09652573607659365 and parameters: {'w0': 0.9303228168810067, 'w1': 0.047454769832260574}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,461] Trial 54 finished with value: 0.09654600410894965 and parameters: {'w0': 0.866810379054808, 'w1': 0.08655407993906684}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,515] Trial 55 finished with value: 0.09754179758501469 and parameters: {'w0': 0.972667358534468, 'w1': 0.18964816869226442}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,565] Trial 56 finished with value: 0.09794887703329291 and parameters: {'w0': 0.7973597279028845, 'w1': 0.24189865839473457}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,608] Trial 57 finished with value: 0.09850926199132126 and parameters: {'w0': 0.8938081497642238, 'w1': 0.5170926606659495}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,638] Trial 58 finished with value: 0.09691599863197109 and parameters: {'w0': 0.9945478193672868, 'w1': 0.00081591538905193}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,662] Trial 59 finished with value: 0.09676941778105896 and parameters: {'w0': 0.6934308894174879, 'w1': 0.10617982062933068}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,722] Trial 60 finished with value: 0.09786091346860382 and parameters: {'w0': 0.825998912414841, 'w1': 0.2824686647326645}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,771] Trial 61 finished with value: 0.09643959601561414 and parameters: {'w0': 0.7187888884950472, 'w1': 0.03657801646365381}. Best is trial 10 with value: 0.09628610172429675.\n",
            "[I 2025-06-17 01:13:09,819] Trial 62 finished with value: 0.09620981851990285 and parameters: {'w0': 0.6027659506731552, 'w1': 0.026307726993289808}. Best is trial 62 with value: 0.09620981851990285.\n",
            "[I 2025-06-17 01:13:09,846] Trial 63 finished with value: 0.09650917724013597 and parameters: {'w0': 0.606778689423877, 'w1': 0.029875837167916995}. Best is trial 62 with value: 0.09620981851990285.\n",
            "[I 2025-06-17 01:13:09,872] Trial 64 finished with value: 0.09662515308564879 and parameters: {'w0': 0.7462568114125596, 'w1': 0.0704737460661392}. Best is trial 62 with value: 0.09620981851990285.\n",
            "[I 2025-06-17 01:13:09,898] Trial 65 finished with value: 0.09644158284834792 and parameters: {'w0': 0.6220193812691168, 'w1': 0.033465661633883356}. Best is trial 62 with value: 0.09620981851990285.\n",
            "[I 2025-06-17 01:13:09,925] Trial 66 finished with value: 0.09619110215598825 and parameters: {'w0': 0.6297755172830745, 'w1': 0.022754181428041066}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:09,978] Trial 67 finished with value: 0.09837376029288025 and parameters: {'w0': 0.6687228123234026, 'w1': 0.16500324683831857}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,030] Trial 68 finished with value: 0.09970830445256529 and parameters: {'w0': 0.5433181821091656, 'w1': 0.8226797674814355}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,053] Trial 69 finished with value: 0.09670617626072853 and parameters: {'w0': 0.5687264903518554, 'w1': 0.07580253447917115}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,090] Trial 70 finished with value: 0.09619110215598825 and parameters: {'w0': 0.5974448971327939, 'w1': 0.02157276973191924}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,114] Trial 71 finished with value: 0.09628227740716777 and parameters: {'w0': 0.48151635494681844, 'w1': 0.02120954348049193}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,143] Trial 72 finished with value: 0.09619110215598825 and parameters: {'w0': 0.4778809276768802, 'w1': 0.017194381628584464}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,170] Trial 73 finished with value: 0.0963470855059323 and parameters: {'w0': 0.4716021829689741, 'w1': 0.019136709147416723}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,201] Trial 74 finished with value: 0.09669230604610446 and parameters: {'w0': 0.4573739489844013, 'w1': 0.002878710012526896}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,247] Trial 75 finished with value: 0.0974523418447456 and parameters: {'w0': 0.39944655045903665, 'w1': 0.0842667298715942}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,272] Trial 76 finished with value: 0.09628610172429675 and parameters: {'w0': 0.477122935090378, 'w1': 0.028928619551805965}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,308] Trial 77 finished with value: 0.09678353973660281 and parameters: {'w0': 0.4894908108875944, 'w1': 0.061842253427948475}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,351] Trial 78 finished with value: 0.09760011580111272 and parameters: {'w0': 0.5151945013829761, 'w1': 0.10306366855518428}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,384] Trial 79 finished with value: 0.09802509240380963 and parameters: {'w0': 0.43403972488625286, 'w1': 0.1360089869062261}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,419] Trial 80 finished with value: 0.09947600049483896 and parameters: {'w0': 0.4212875374452453, 'w1': 0.5460755975013645}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,453] Trial 81 finished with value: 0.09619110215598825 and parameters: {'w0': 0.4847319151413343, 'w1': 0.017714122944404567}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,484] Trial 82 finished with value: 0.09700443452164842 and parameters: {'w0': 0.37981098619858694, 'w1': 0.05473743648738648}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,510] Trial 83 finished with value: 0.09643959601561414 and parameters: {'w0': 0.5469825257350711, 'w1': 0.027124478797873077}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,534] Trial 84 finished with value: 0.09628610172429675 and parameters: {'w0': 0.3095380693409243, 'w1': 0.01873154153472819}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,562] Trial 85 finished with value: 0.09970830445256529 and parameters: {'w0': 0.2956271379897204, 'w1': 0.4484176303865288}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,592] Trial 86 finished with value: 0.09671601087474935 and parameters: {'w0': 0.20203153747120794, 'w1': 0.01724692787527558}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,620] Trial 87 finished with value: 0.0974628288931273 and parameters: {'w0': 0.4826521317019442, 'w1': 0.08781842398940123}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,648] Trial 88 finished with value: 0.09747055771810531 and parameters: {'w0': 0.3191551921138261, 'w1': 0.057402929813978}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,686] Trial 89 finished with value: 0.09865906808061697 and parameters: {'w0': 0.2406766659650477, 'w1': 0.15840006610533375}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,731] Trial 90 finished with value: 0.09946022834060364 and parameters: {'w0': 0.5719740524912547, 'w1': 0.6544262863208055}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,757] Trial 91 finished with value: 0.09620794402979727 and parameters: {'w0': 0.6326873576058574, 'w1': 0.026555942578022167}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,792] Trial 92 finished with value: 0.09691599863197109 and parameters: {'w0': 0.5186495684385279, 'w1': 0.0006034475115804447}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,825] Trial 93 finished with value: 0.09744767258783826 and parameters: {'w0': 0.10075490018247135, 'w1': 0.020918566992087554}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,852] Trial 94 finished with value: 0.09655633733088409 and parameters: {'w0': 0.6286404010142141, 'w1': 0.0724365274471523}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,889] Trial 95 finished with value: 0.09664212085288748 and parameters: {'w0': 0.5959033256423757, 'w1': 0.052912435648658676}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,932] Trial 96 finished with value: 0.09738966926032644 and parameters: {'w0': 0.6428047338562105, 'w1': 0.11027844155626221}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:10,963] Trial 97 finished with value: 0.09652573607659365 and parameters: {'w0': 0.4144516509925267, 'w1': 0.0213790432503752}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:11,021] Trial 98 finished with value: 0.0979931781977108 and parameters: {'w0': 0.36800800008059864, 'w1': 0.08742096599950461}. Best is trial 66 with value: 0.09619110215598825.\n",
            "[I 2025-06-17 01:13:11,073] Trial 99 finished with value: 0.0975279592072229 and parameters: {'w0': 0.595351114765488, 'w1': 0.12596905855586754}. Best is trial 66 with value: 0.09619110215598825.\n",
            "\n",
            "=== Résultats finaux avec tuning et seuils ===\n",
            "Combinaison utilisée : ['lgbm', 'mlp']\n",
            "F1-weighted final : 0.9052\n",
            "                              precision    recall  f1-score   support\n",
            "\n",
            "                      Livres     0.7010    0.7580    0.7284       467\n",
            "                  Jeux Vidéo     0.8249    0.8644    0.8442       376\n",
            "     Accessoires jeux vidéos     0.9443    0.9600    0.9521       300\n",
            "       Jeux vidéo & Consoles     0.9966    0.9833    0.9899       300\n",
            "                   Figurines     0.8442    0.8379    0.8411       401\n",
            "              Cartes de jeux     0.9630    0.9646    0.9638       593\n",
            "Jeux de rôle et de figurines     0.9477    0.9667    0.9571       300\n",
            "             Jouets & Enfant     0.8006    0.7798    0.7900       731\n",
            "             Jeux de société     0.7586    0.7074    0.7321       311\n",
            "   Véhicules RC & miniatures     0.9825    0.9720    0.9772       750\n",
            "            Chaussettes bébé     1.0000    0.9933    0.9967       300\n",
            "            Sports & Loisirs     0.8605    0.8743    0.8674       374\n",
            "                Puériculture     0.8574    0.8539    0.8557       486\n",
            "                      Maison     0.8967    0.8800    0.8883       750\n",
            "             Linge de maison     0.9432    0.9505    0.9468       646\n",
            "              Petit déjeuner     1.0000    0.9867    0.9933       300\n",
            "                  Décoration     0.8527    0.8732    0.8628       749\n",
            "                  Animalerie     0.9708    0.9967    0.9836       300\n",
            "                       Revue     0.9413    0.9426    0.9419       714\n",
            "        Lots Livres & Revues     0.8944    0.8520    0.8727       716\n",
            "        Lots consoles & jeux     0.9219    0.9833    0.9516       300\n",
            "       Fournitures Papeterie     0.9371    0.9559    0.9464       748\n",
            "          Mobilier de jardin     0.8862    0.8634    0.8747       388\n",
            "    Équipement piscine & spa     0.9787    0.9787    0.9787       750\n",
            "         Outillage de jardin     0.9500    0.9144    0.9319       374\n",
            "                      eBooks     0.8505    0.8382    0.8443       414\n",
            "      Jeux en téléchargement     1.0000    1.0000    1.0000       300\n",
            "\n",
            "                    accuracy                         0.9052     13138\n",
            "                   macro avg     0.9076    0.9086    0.9079     13138\n",
            "                weighted avg     0.9056    0.9052    0.9052     13138\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "def download_tokenizer_files(base_url, dest_folder, files_to_check):\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "    for filename in files_to_check:\n",
        "        filepath = os.path.join(dest_folder, filename)\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"Téléchargement de {filename} dans {dest_folder}...\")\n",
        "            url = base_url + filename\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 200:\n",
        "                with open(filepath, \"wb\") as f:\n",
        "                    f.write(response.content)\n",
        "                print(f\"✅ {filename} téléchargé.\")\n",
        "            else:\n",
        "                print(f\"❌ Fichier {filename} non trouvé sur le serveur (404). Ignoré.\")\n",
        "        else:\n",
        "            print(f\"⚠️ {filename} déjà présent dans {dest_folder}, téléchargement ignoré.\")\n",
        "\n",
        "def copy_files_to_drive(src_folder, drive_folder, files_list):\n",
        "    os.makedirs(drive_folder, exist_ok=True)\n",
        "    for f in files_list:\n",
        "        src = os.path.join(src_folder, f)\n",
        "        dst = os.path.join(drive_folder, f)\n",
        "        if os.path.exists(src):\n",
        "            if not os.path.exists(dst):\n",
        "                shutil.copy(src, dst)\n",
        "                print(f\"✅ Copié {f} vers Drive dans {drive_folder}\")\n",
        "            else:\n",
        "                print(f\"⚠️ {f} déjà présent dans Drive {drive_folder}, copie ignorée\")\n",
        "        else:\n",
        "            print(f\"❌ Fichier {f} absent dans {src_folder}, impossible de copier\")\n",
        "\n",
        "def prepare_tokenizers_and_copy_to_drive():\n",
        "    # Monter Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Dossiers locaux temporaires dans Colab\n",
        "    camembert_local = \"/content/camembert2_model\"\n",
        "    flaubert_local = \"/content/flaubert2_model\"\n",
        "\n",
        "    # URLs des tokenizers\n",
        "    camembert_base_url = \"https://huggingface.co/camembert-base/resolve/main/\"\n",
        "    camembert_files = [\n",
        "        \"tokenizer.json\",\n",
        "        \"tokenizer_config.json\"\n",
        "    ]\n",
        "\n",
        "    flaubert_base_url = \"https://huggingface.co/flaubert/flaubert_base_cased/resolve/main/\"\n",
        "    flaubert_files = [\n",
        "        \"tokenizer.json\",\n",
        "        \"vocab.json\",\n",
        "        \"tokenizer_config.json\"\n",
        "    ]\n",
        "\n",
        "    # Télécharger dans local Colab\n",
        "    download_tokenizer_files(camembert_base_url, camembert_local, camembert_files)\n",
        "    download_tokenizer_files(flaubert_base_url, flaubert_local, flaubert_files)\n",
        "\n",
        "    # Destination Drive\n",
        "    drive_base = \"/content/drive/MyDrive/Colab Notebooks/fahim/final\"\n",
        "    camembert_drive = os.path.join(drive_base, \"camembert2_model\")\n",
        "    flaubert_drive = os.path.join(drive_base, \"flaubert2_model\")\n",
        "\n",
        "    # Copier du local vers Drive\n",
        "    copy_files_to_drive(camembert_local, camembert_drive, camembert_files)\n",
        "    copy_files_to_drive(flaubert_local, flaubert_drive, flaubert_files)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    prepare_tokenizers_and_copy_to_drive()\n",
        "    print(\"\\n✅ Tous les fichiers tokenizer nécessaires sont téléchargés et copiés dans Drive.\")"
      ],
      "metadata": {
        "id": "oM5ohIUBzRnF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}