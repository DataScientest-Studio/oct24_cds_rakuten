{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2w_l7eMjGhE",
        "outputId": "a37bb6d7-7907-45bc-9623-20f67d7df800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxjGyLvEqRhV",
        "outputId": "1e26f020-f34a-46bc-97b2-a5ab39cd0608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Copi√© : efficientv2L_best.pt ‚Üí /content/modeles_importes/efficientv2L_best.pt\n",
            "‚úÖ Copi√© : convnextv2_best.pt ‚Üí /content/modeles_importes/convnextv2_best.pt\n",
            "‚úÖ Copi√© : coatnet2_best.pt ‚Üí /content/modeles_importes/coatnet2_best.pt\n",
            "‚úÖ Copi√© : Maxvit_best.pt ‚Üí /content/modeles_importes/Maxvit_best.pt\n",
            "‚úÖ Copi√© : gcvit_best.pt ‚Üí /content/modeles_importes/gcvit_best.pt\n",
            "‚úÖ Copi√© : config.json ‚Üí /content/modeles_importes/camembert2_model/config.json\n",
            "‚úÖ Copi√© : model.safetensors ‚Üí /content/modeles_importes/camembert2_model/model.safetensors\n",
            "‚úÖ Copi√© : config.json ‚Üí /content/modeles_importes/flaubert2_model/config.json\n",
            "‚úÖ Copi√© : model.safetensors ‚Üí /content/modeles_importes/flaubert2_model/model.safetensors\n",
            "‚úÖ Logits copi√© : efficientv2L_logits.pt\n",
            "‚úÖ Logits copi√© : convnextv2_logits.pt\n",
            "‚úÖ Logits copi√© : coatnet2_logits.pt\n",
            "‚úÖ Logits copi√© : Maxvit_logits.pt\n",
            "‚úÖ Logits copi√© : gcvit_logits.pt\n",
            "‚úÖ Logits copi√© : camembert2_logits.pt\n",
            "‚úÖ Logits copi√© : flaubert2_logits.pt\n",
            "‚úÖ Logits copi√© : true_labels_final.pt\n",
            "‚úÖ Mapping copi√© : label_mapping_final.json\n",
            "‚úÖ Label Encoder copi√© : label_encoder_final.pkl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "#  Monter Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#  Chemins\n",
        "drive_base_path = \"/content/drive/MyDrive/Colab Notebooks/fahim/final\"\n",
        "local_base_path = \"/content/modeles_importes\"\n",
        "os.makedirs(local_base_path, exist_ok=True)\n",
        "\n",
        "#  1. Mod√®les √† copier (images + textuels)\n",
        "model_folders = {\n",
        "    \"modeles_image_v2\": [\"efficientv2L_best.pt\", \"convnextv2_best.pt\", \"coatnet2_best.pt\",\"Maxvit_best.pt\", \"gcvit_best.pt\"],\n",
        "    \"camembert2_model\": [\"config.json\", \"model.safetensors\"],\n",
        "    \"flaubert2_model\": [\"config.json\", \"model.safetensors\"],\n",
        "}\n",
        "\n",
        "# üì•Copie des mod√®les\n",
        "for folder, files in model_folders.items():\n",
        "    src_dir = os.path.join(drive_base_path, folder)\n",
        "    is_text_model = \"camembert\" in folder or \"flaubert\" in folder\n",
        "    dst_subfolder = os.path.join(local_base_path, os.path.basename(folder)) if is_text_model else local_base_path\n",
        "    os.makedirs(dst_subfolder, exist_ok=True)\n",
        "\n",
        "    for filename in files:\n",
        "        src_file = os.path.join(src_dir, filename)\n",
        "        dst_file = os.path.join(dst_subfolder, filename)\n",
        "        if os.path.exists(src_file):\n",
        "            shutil.copy(src_file, dst_file)\n",
        "            print(f\"‚úÖ Copi√© : {filename} ‚Üí {dst_file}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Introuvable : {src_file}\")\n",
        "\n",
        "#  2. Logits √† copier (texte + image + labels)\n",
        "logits_files = [\n",
        "    \"efficientv2L_logits.pt\",\n",
        "    \"convnextv2_logits.pt\",\n",
        "    \"coatnet2_logits.pt\",\n",
        "    \"Maxvit_logits.pt\",\n",
        "    \"gcvit_logits.pt\",\n",
        "    \"camembert2_logits.pt\",\n",
        "    \"flaubert2_logits.pt\",\n",
        "    \"true_labels_final.pt\"\n",
        "]\n",
        "\n",
        "logits_drive_path = drive_base_path\n",
        "\n",
        "for filename in logits_files:\n",
        "    src_file = os.path.join(logits_drive_path, filename)\n",
        "    dst_file = os.path.join(local_base_path, filename)\n",
        "    if os.path.exists(src_file):\n",
        "        shutil.copy(src_file, dst_file)\n",
        "        print(f\"‚úÖ Logits copi√© : {filename}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Logits manquant : {src_file}\")\n",
        "# 3. Copier le fichier de mapping labels\n",
        "mapping_filename = \"label_mapping_final.json\"\n",
        "mapping_src = os.path.join(drive_base_path, mapping_filename)\n",
        "mapping_dst = os.path.join(local_base_path, mapping_filename)\n",
        "\n",
        "if os.path.exists(mapping_src):\n",
        "    shutil.copy(mapping_src, mapping_dst)\n",
        "    print(f\"‚úÖ Mapping copi√© : {mapping_filename}\")\n",
        "else:\n",
        "    print(f\"‚ùå Mapping manquant : {mapping_src}\")\n",
        "# 4. Copier le fichier label encoder\n",
        "label_encoder_filename = \"label_encoder_final.pkl\"\n",
        "label_encoder_src = os.path.join(drive_base_path, label_encoder_filename)\n",
        "label_encoder_dst = os.path.join(local_base_path, label_encoder_filename)\n",
        "\n",
        "if os.path.exists(label_encoder_src):\n",
        "    shutil.copy(label_encoder_src, label_encoder_dst)\n",
        "    print(f\"‚úÖ Label Encoder copi√© : {label_encoder_filename}\")\n",
        "else:\n",
        "    print(f\"‚ùå Label Encoder manquant : {label_encoder_src}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeBOmJZuQuMJ",
        "outputId": "1dabc1f2-301a-4ab1-90b0-623a50ade30d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-30-01b3eb855353>:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  all_logits = {name: torch.load(os.path.join(PATH_LOGITS, f\"{name}_logits.pt\")).cpu().numpy() for name in all_model_names}\n",
            "<ipython-input-30-01b3eb855353>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  labels = torch.load(LABELS_PATH).numpy()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[camembert2+flaubert2]  F1_weighted=0.89551  Weights=(0.5, 0.5)\n",
            "[camembert2+gcvit]  F1_weighted=0.89785  Weights=(0.5, 0.5)\n",
            "[camembert2+convnextv2]  F1_weighted=0.89901  Weights=(0.5, 0.5)\n",
            "[camembert2+Maxvit]  F1_weighted=0.89931  Weights=(0.5, 0.5)\n",
            "[camembert2+coatnet2]  F1_weighted=0.89452  Weights=(0.5, 0.5)\n",
            "[camembert2+efficientv2L]  F1_weighted=0.89803  Weights=(0.5, 0.5)\n",
            "[flaubert2+gcvit]  F1_weighted=0.90065  Weights=(0.5, 0.5)\n",
            "[flaubert2+convnextv2]  F1_weighted=0.89915  Weights=(0.5, 0.5)\n",
            "[flaubert2+Maxvit]  F1_weighted=0.89949  Weights=(0.5, 0.5)\n",
            "[flaubert2+coatnet2]  F1_weighted=0.89762  Weights=(0.5, 0.5)\n",
            "[flaubert2+efficientv2L]  F1_weighted=0.90023  Weights=(0.5, 0.5)\n",
            "[gcvit+convnextv2]  F1_weighted=0.78196  Weights=(0.5, 0.5)\n",
            "[gcvit+Maxvit]  F1_weighted=0.78286  Weights=(0.5, 0.5)\n",
            "[gcvit+coatnet2]  F1_weighted=0.77597  Weights=(0.6, 0.4)\n",
            "[gcvit+efficientv2L]  F1_weighted=0.77920  Weights=(0.5, 0.5)\n",
            "[convnextv2+Maxvit]  F1_weighted=0.78255  Weights=(0.5, 0.5)\n",
            "[convnextv2+coatnet2]  F1_weighted=0.77842  Weights=(0.6, 0.4)\n",
            "[convnextv2+efficientv2L]  F1_weighted=0.78035  Weights=(0.5, 0.5)\n",
            "[Maxvit+coatnet2]  F1_weighted=0.77638  Weights=(0.6, 0.4)\n",
            "[Maxvit+efficientv2L]  F1_weighted=0.78227  Weights=(0.5, 0.5)\n",
            "[coatnet2+efficientv2L]  F1_weighted=0.77224  Weights=(0.4, 0.6)\n",
            "[camembert2+flaubert2+gcvit]  F1_weighted=0.90720  Weights=(0.30000000000000004, 0.30000000000000004, 0.4)\n",
            "[camembert2+flaubert2+convnextv2]  F1_weighted=0.90770  Weights=(0.30000000000000004, 0.30000000000000004, 0.4)\n",
            "[camembert2+flaubert2+Maxvit]  F1_weighted=0.90857  Weights=(0.30000000000000004, 0.30000000000000004, 0.4)\n",
            "[camembert2+flaubert2+coatnet2]  F1_weighted=0.90595  Weights=(0.30000000000000004, 0.4, 0.30000000000000004)\n",
            "[camembert2+flaubert2+efficientv2L]  F1_weighted=0.90837  Weights=(0.30000000000000004, 0.30000000000000004, 0.4)\n",
            "[camembert2+gcvit+convnextv2]  F1_weighted=0.90112  Weights=(0.5, 0.2, 0.30000000000000004)\n",
            "[camembert2+gcvit+Maxvit]  F1_weighted=0.90128  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[camembert2+gcvit+coatnet2]  F1_weighted=0.89989  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[camembert2+gcvit+efficientv2L]  F1_weighted=0.89930  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[camembert2+convnextv2+Maxvit]  F1_weighted=0.90221  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[camembert2+convnextv2+coatnet2]  F1_weighted=0.89990  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[camembert2+convnextv2+efficientv2L]  F1_weighted=0.90136  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[camembert2+Maxvit+coatnet2]  F1_weighted=0.90085  Weights=(0.5, 0.4, 0.1)\n",
            "[camembert2+Maxvit+efficientv2L]  F1_weighted=0.90157  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[camembert2+coatnet2+efficientv2L]  F1_weighted=0.90017  Weights=(0.5, 0.2, 0.30000000000000004)\n",
            "[flaubert2+gcvit+convnextv2]  F1_weighted=0.90326  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[flaubert2+gcvit+Maxvit]  F1_weighted=0.90367  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[flaubert2+gcvit+coatnet2]  F1_weighted=0.90391  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[flaubert2+gcvit+efficientv2L]  F1_weighted=0.90417  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[flaubert2+convnextv2+Maxvit]  F1_weighted=0.90171  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[flaubert2+convnextv2+coatnet2]  F1_weighted=0.90343  Weights=(0.5, 0.2, 0.30000000000000004)\n",
            "[flaubert2+convnextv2+efficientv2L]  F1_weighted=0.90254  Weights=(0.5, 0.2, 0.30000000000000004)\n",
            "[flaubert2+Maxvit+coatnet2]  F1_weighted=0.90371  Weights=(0.5, 0.2, 0.30000000000000004)\n",
            "[flaubert2+Maxvit+efficientv2L]  F1_weighted=0.90402  Weights=(0.5, 0.2, 0.30000000000000004)\n",
            "[flaubert2+coatnet2+efficientv2L]  F1_weighted=0.90181  Weights=(0.5, 0.30000000000000004, 0.2)\n",
            "[gcvit+convnextv2+Maxvit]  F1_weighted=0.79086  Weights=(0.30000000000000004, 0.30000000000000004, 0.4)\n",
            "[gcvit+convnextv2+coatnet2]  F1_weighted=0.78453  Weights=(0.2, 0.5, 0.30000000000000004)\n",
            "[gcvit+convnextv2+efficientv2L]  F1_weighted=0.78945  Weights=(0.30000000000000004, 0.30000000000000004, 0.4)\n",
            "[gcvit+Maxvit+coatnet2]  F1_weighted=0.78646  Weights=(0.30000000000000004, 0.4, 0.30000000000000004)\n",
            "[gcvit+Maxvit+efficientv2L]  F1_weighted=0.79015  Weights=(0.30000000000000004, 0.30000000000000004, 0.4)\n",
            "[gcvit+coatnet2+efficientv2L]  F1_weighted=0.78444  Weights=(0.4, 0.2, 0.4)\n",
            "[convnextv2+Maxvit+coatnet2]  F1_weighted=0.78628  Weights=(0.4, 0.4, 0.2)\n",
            "[convnextv2+Maxvit+efficientv2L]  F1_weighted=0.79046  Weights=(0.4, 0.30000000000000004, 0.30000000000000004)\n",
            "[convnextv2+coatnet2+efficientv2L]  F1_weighted=0.78492  Weights=(0.30000000000000004, 0.30000000000000004, 0.4)\n",
            "[Maxvit+coatnet2+efficientv2L]  F1_weighted=0.78491  Weights=(0.4, 0.30000000000000004, 0.30000000000000004)\n",
            "[camembert2+flaubert2+gcvit+convnextv2]  F1_weighted=0.91085  Weights=(0.30000000000000004, 0.30000000000000004, 0.2, 0.2)\n",
            "[camembert2+flaubert2+gcvit+Maxvit]  F1_weighted=0.91053  Weights=(0.30000000000000004, 0.2, 0.2, 0.30000000000000004)\n",
            "[camembert2+flaubert2+gcvit+coatnet2]  F1_weighted=0.90914  Weights=(0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.1)\n",
            "[camembert2+flaubert2+gcvit+efficientv2L]  F1_weighted=0.91132  Weights=(0.30000000000000004, 0.30000000000000004, 0.2, 0.2)\n",
            "[camembert2+flaubert2+convnextv2+Maxvit]  F1_weighted=0.91058  Weights=(0.30000000000000004, 0.30000000000000004, 0.2, 0.2)\n",
            "[camembert2+flaubert2+convnextv2+coatnet2]  F1_weighted=0.90977  Weights=(0.30000000000000004, 0.2, 0.30000000000000004, 0.2)\n",
            "[camembert2+flaubert2+convnextv2+efficientv2L]  F1_weighted=0.91099  Weights=(0.30000000000000004, 0.30000000000000004, 0.2, 0.2)\n",
            "[camembert2+flaubert2+Maxvit+coatnet2]  F1_weighted=0.91030  Weights=(0.2, 0.30000000000000004, 0.30000000000000004, 0.2)\n",
            "[camembert2+flaubert2+Maxvit+efficientv2L]  F1_weighted=0.91200  Weights=(0.2, 0.30000000000000004, 0.2, 0.30000000000000004)\n",
            "[camembert2+flaubert2+coatnet2+efficientv2L]  F1_weighted=0.91010  Weights=(0.30000000000000004, 0.30000000000000004, 0.1, 0.30000000000000004)\n",
            "[camembert2+gcvit+convnextv2+Maxvit]  F1_weighted=0.90227  Weights=(0.5, 0.1, 0.2, 0.2)\n",
            "[camembert2+gcvit+convnextv2+coatnet2]  F1_weighted=0.90105  Weights=(0.5, 0.1, 0.30000000000000004, 0.1)\n",
            "[camembert2+gcvit+convnextv2+efficientv2L]  F1_weighted=0.90167  Weights=(0.5, 0.2, 0.2, 0.1)\n",
            "[camembert2+gcvit+Maxvit+coatnet2]  F1_weighted=0.90155  Weights=(0.5, 0.1, 0.30000000000000004, 0.1)\n",
            "[camembert2+gcvit+Maxvit+efficientv2L]  F1_weighted=0.90238  Weights=(0.5, 0.2, 0.2, 0.1)\n",
            "[camembert2+gcvit+coatnet2+efficientv2L]  F1_weighted=0.90044  Weights=(0.5, 0.30000000000000004, 0.1, 0.1)\n",
            "[camembert2+convnextv2+Maxvit+coatnet2]  F1_weighted=0.90318  Weights=(0.5, 0.2, 0.2, 0.1)\n",
            "[camembert2+convnextv2+Maxvit+efficientv2L]  F1_weighted=0.90283  Weights=(0.5, 0.2, 0.2, 0.1)\n",
            "[camembert2+convnextv2+coatnet2+efficientv2L]  F1_weighted=0.90157  Weights=(0.5, 0.2, 0.1, 0.2)\n",
            "[camembert2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.90236  Weights=(0.5, 0.2, 0.2, 0.1)\n",
            "[flaubert2+gcvit+convnextv2+Maxvit]  F1_weighted=0.90447  Weights=(0.5, 0.2, 0.1, 0.2)\n",
            "[flaubert2+gcvit+convnextv2+coatnet2]  F1_weighted=0.90389  Weights=(0.5, 0.2, 0.1, 0.2)\n",
            "[flaubert2+gcvit+convnextv2+efficientv2L]  F1_weighted=0.90438  Weights=(0.5, 0.2, 0.1, 0.2)\n",
            "[flaubert2+gcvit+Maxvit+coatnet2]  F1_weighted=0.90486  Weights=(0.5, 0.2, 0.1, 0.2)\n",
            "[flaubert2+gcvit+Maxvit+efficientv2L]  F1_weighted=0.90522  Weights=(0.5, 0.2, 0.1, 0.2)\n",
            "[flaubert2+gcvit+coatnet2+efficientv2L]  F1_weighted=0.90475  Weights=(0.5, 0.2, 0.2, 0.1)\n",
            "[flaubert2+convnextv2+Maxvit+coatnet2]  F1_weighted=0.90455  Weights=(0.5, 0.1, 0.2, 0.2)\n",
            "[flaubert2+convnextv2+Maxvit+efficientv2L]  F1_weighted=0.90373  Weights=(0.5, 0.1, 0.2, 0.2)\n",
            "[flaubert2+convnextv2+coatnet2+efficientv2L]  F1_weighted=0.90296  Weights=(0.5, 0.1, 0.2, 0.2)\n",
            "[flaubert2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.90385  Weights=(0.5, 0.1, 0.2, 0.2)\n",
            "[gcvit+convnextv2+Maxvit+coatnet2]  F1_weighted=0.79308  Weights=(0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.1)\n",
            "[gcvit+convnextv2+Maxvit+efficientv2L]  F1_weighted=0.79412  Weights=(0.2, 0.30000000000000004, 0.30000000000000004, 0.2)\n",
            "[gcvit+convnextv2+coatnet2+efficientv2L]  F1_weighted=0.79046  Weights=(0.30000000000000004, 0.30000000000000004, 0.2, 0.2)\n",
            "[gcvit+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.79313  Weights=(0.30000000000000004, 0.30000000000000004, 0.1, 0.30000000000000004)\n",
            "[convnextv2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.79138  Weights=(0.30000000000000004, 0.30000000000000004, 0.1, 0.30000000000000004)\n",
            "[camembert2+flaubert2+gcvit+convnextv2+Maxvit]  F1_weighted=0.91118  Weights=(0.30000000000000004, 0.30000000000000004, 0.1, 0.2, 0.1)\n",
            "[camembert2+flaubert2+gcvit+convnextv2+coatnet2]  F1_weighted=0.91137  Weights=(0.30000000000000004, 0.30000000000000004, 0.1, 0.2, 0.1)\n",
            "[camembert2+flaubert2+gcvit+convnextv2+efficientv2L]  F1_weighted=0.91179  Weights=(0.2, 0.30000000000000004, 0.1, 0.1, 0.30000000000000004)\n",
            "[camembert2+flaubert2+gcvit+Maxvit+coatnet2]  F1_weighted=0.91158  Weights=(0.30000000000000004, 0.2, 0.2, 0.2, 0.1)\n",
            "[camembert2+flaubert2+gcvit+Maxvit+efficientv2L]  F1_weighted=0.91307  Weights=(0.2, 0.30000000000000004, 0.1, 0.2, 0.2)\n",
            "[camembert2+flaubert2+gcvit+coatnet2+efficientv2L]  F1_weighted=0.91139  Weights=(0.2, 0.30000000000000004, 0.2, 0.1, 0.2)\n",
            "[camembert2+flaubert2+convnextv2+Maxvit+coatnet2]  F1_weighted=0.91195  Weights=(0.2, 0.30000000000000004, 0.2, 0.2, 0.1)\n",
            "[camembert2+flaubert2+convnextv2+Maxvit+efficientv2L]  F1_weighted=0.91321  Weights=(0.2, 0.30000000000000004, 0.1, 0.2, 0.2)\n",
            "[camembert2+flaubert2+convnextv2+coatnet2+efficientv2L]  F1_weighted=0.91164  Weights=(0.2, 0.30000000000000004, 0.2, 0.1, 0.2)\n",
            "[camembert2+flaubert2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.91248  Weights=(0.2, 0.30000000000000004, 0.2, 0.1, 0.2)\n",
            "[camembert2+gcvit+convnextv2+Maxvit+coatnet2]  F1_weighted=0.90256  Weights=(0.5, 0.1, 0.2, 0.1, 0.1)\n",
            "[camembert2+gcvit+convnextv2+Maxvit+efficientv2L]  F1_weighted=0.90258  Weights=(0.5, 0.1, 0.1, 0.2, 0.1)\n",
            "[camembert2+gcvit+convnextv2+coatnet2+efficientv2L]  F1_weighted=0.90156  Weights=(0.5, 0.1, 0.2, 0.1, 0.1)\n",
            "[camembert2+gcvit+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.90248  Weights=(0.5, 0.1, 0.2, 0.1, 0.1)\n",
            "[camembert2+convnextv2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.90299  Weights=(0.5, 0.2, 0.1, 0.1, 0.1)\n",
            "[flaubert2+gcvit+convnextv2+Maxvit+coatnet2]  F1_weighted=0.90464  Weights=(0.5, 0.2, 0.1, 0.1, 0.1)\n",
            "[flaubert2+gcvit+convnextv2+Maxvit+efficientv2L]  F1_weighted=0.90416  Weights=(0.5, 0.2, 0.1, 0.1, 0.1)\n",
            "[flaubert2+gcvit+convnextv2+coatnet2+efficientv2L]  F1_weighted=0.90398  Weights=(0.5, 0.2, 0.1, 0.1, 0.1)\n",
            "[flaubert2+gcvit+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.90516  Weights=(0.5, 0.2, 0.1, 0.1, 0.1)\n",
            "[flaubert2+convnextv2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.90313  Weights=(0.5, 0.2, 0.1, 0.1, 0.1)\n",
            "[gcvit+convnextv2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.79516  Weights=(0.2, 0.2, 0.30000000000000004, 0.1, 0.2)\n",
            "[camembert2+flaubert2+gcvit+convnextv2+Maxvit+coatnet2]  F1_weighted=0.91212  Weights=(0.30000000000000004, 0.2, 0.1, 0.2, 0.1, 0.1)\n",
            "[camembert2+flaubert2+gcvit+convnextv2+Maxvit+efficientv2L]  F1_weighted=0.91308  Weights=(0.2, 0.30000000000000004, 0.1, 0.1, 0.2, 0.1)\n",
            "[camembert2+flaubert2+gcvit+convnextv2+coatnet2+efficientv2L]  F1_weighted=0.91238  Weights=(0.2, 0.30000000000000004, 0.1, 0.1, 0.1, 0.2)\n",
            "[camembert2+flaubert2+gcvit+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.91336  Weights=(0.2, 0.30000000000000004, 0.1, 0.2, 0.1, 0.1)\n",
            "[camembert2+flaubert2+convnextv2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.91341  Weights=(0.30000000000000004, 0.2, 0.1, 0.2, 0.1, 0.1)\n",
            "[camembert2+gcvit+convnextv2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.90243  Weights=(0.5, 0.1, 0.1, 0.1, 0.1, 0.1)\n",
            "[flaubert2+gcvit+convnextv2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.90432  Weights=(0.5, 0.1, 0.1, 0.1, 0.1, 0.1)\n",
            "[camembert2+flaubert2+gcvit+convnextv2+Maxvit+coatnet2+efficientv2L]  F1_weighted=0.91329  Weights=(0.30000000000000004, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1)\n",
            "\n",
            "==== TOP COMBINAISONS ====\n",
            "camembert2+flaubert2+convnextv2+Maxvit+coatnet2+efficientv2L | F1=0.91341 | Weights=(0.30000000000000004, 0.2, 0.1, 0.2, 0.1, 0.1)\n",
            "camembert2+flaubert2+gcvit+Maxvit+coatnet2+efficientv2L | F1=0.91336 | Weights=(0.2, 0.30000000000000004, 0.1, 0.2, 0.1, 0.1)\n",
            "camembert2+flaubert2+gcvit+convnextv2+Maxvit+coatnet2+efficientv2L | F1=0.91329 | Weights=(0.30000000000000004, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1)\n",
            "camembert2+flaubert2+convnextv2+Maxvit+efficientv2L | F1=0.91321 | Weights=(0.2, 0.30000000000000004, 0.1, 0.2, 0.2)\n",
            "camembert2+flaubert2+gcvit+convnextv2+Maxvit+efficientv2L | F1=0.91308 | Weights=(0.2, 0.30000000000000004, 0.1, 0.1, 0.2, 0.1)\n",
            "camembert2+flaubert2+gcvit+Maxvit+efficientv2L | F1=0.91307 | Weights=(0.2, 0.30000000000000004, 0.1, 0.2, 0.2)\n",
            "camembert2+flaubert2+Maxvit+coatnet2+efficientv2L | F1=0.91248 | Weights=(0.2, 0.30000000000000004, 0.2, 0.1, 0.2)\n",
            "camembert2+flaubert2+gcvit+convnextv2+coatnet2+efficientv2L | F1=0.91238 | Weights=(0.2, 0.30000000000000004, 0.1, 0.1, 0.1, 0.2)\n",
            "camembert2+flaubert2+gcvit+convnextv2+Maxvit+coatnet2 | F1=0.91212 | Weights=(0.30000000000000004, 0.2, 0.1, 0.2, 0.1, 0.1)\n",
            "camembert2+flaubert2+Maxvit+efficientv2L | F1=0.91200 | Weights=(0.2, 0.30000000000000004, 0.2, 0.30000000000000004)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.metrics import f1_score\n",
        "import json\n",
        "\n",
        "# Chemins et config\n",
        "PATH_LOGITS = \"/content/modeles_importes\"\n",
        "LABELS_PATH = os.path.join(PATH_LOGITS, \"true_labels_final.pt\")\n",
        "VAL_INDICES_PATH = \"/content/drive/MyDrive/Colab Notebooks/fahim/final/val_indices.json\"\n",
        "\n",
        "# Liste des mod√®les √† tester (mets tous les noms exacts des logits, sans \"_logits.pt\")\n",
        "all_model_names = [\n",
        "    \"camembert2\", \"flaubert2\", \"gcvit\", \"convnextv2\", \"Maxvit\",\n",
        "    \"coatnet2\", \"efficientv2L\" # Ajoute/retire ici\n",
        "]\n",
        "\n",
        "# Chargement logits\n",
        "all_logits = {name: torch.load(os.path.join(PATH_LOGITS, f\"{name}_logits.pt\")).cpu().numpy() for name in all_model_names}\n",
        "labels = torch.load(LABELS_PATH).numpy()\n",
        "with open(VAL_INDICES_PATH, \"r\") as f:\n",
        "    val_idx = np.array(json.load(f), dtype=int)\n",
        "y_val = labels[val_idx]\n",
        "\n",
        "# Fonction pour pond√©rer\n",
        "def weighted_softmax(logits_list, weights):\n",
        "    \"\"\"Calcule la moyenne pond√©r√©e des logits softmax√©s.\"\"\"\n",
        "    softmaxed = [np.exp(logits)/np.exp(logits).sum(axis=1, keepdims=True) for logits in logits_list]\n",
        "    weighted = sum(w * s for w, s in zip(weights, softmaxed))\n",
        "    return weighted\n",
        "\n",
        "# Grid-search sur pond√©ration (pas de 0.1, tu peux affiner)\n",
        "def grid_weights(n):\n",
        "    \"\"\"G√©n√®re toutes les combinaisons de poids qui font 1 (step=0.1).\"\"\"\n",
        "    steps = np.arange(0.1, 1.0, 0.1)\n",
        "    grids = [x for x in itertools.product(steps, repeat=n) if abs(sum(x) - 1) < 1e-5]\n",
        "    return grids\n",
        "\n",
        "# Test de toutes les combinaisons de mod√®les\n",
        "results = []\n",
        "for n_models in range(2, len(all_model_names)+1):\n",
        "    for model_combo in itertools.combinations(all_model_names, n_models):\n",
        "        logits_list = [all_logits[name][val_idx] for name in model_combo]\n",
        "        best_f1, best_weights = 0, None\n",
        "        for weights in grid_weights(n_models):\n",
        "            y_pred = np.argmax(weighted_softmax(logits_list, weights), axis=1)\n",
        "            f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_weights = weights\n",
        "        results.append({\n",
        "            \"models\": model_combo,\n",
        "            \"f1_weighted\": best_f1,\n",
        "            \"weights\": best_weights\n",
        "        })\n",
        "        print(f\"[{'+'.join(model_combo)}]  F1_weighted={best_f1:.5f}  Weights={best_weights}\")\n",
        "\n",
        "# Affichage tri√©\n",
        "results = sorted(results, key=lambda x: x[\"f1_weighted\"], reverse=True)\n",
        "print(\"\\n==== TOP COMBINAISONS ====\")\n",
        "for res in results[:10]:\n",
        "    print(f\"{'+'.join(res['models']):40s} | F1={res['f1_weighted']:.5f} | Weights={res['weights']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAoEimCPh84S",
        "outputId": "9486509c-d94d-4c0a-c36f-1e4c55417998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Booster logits pond√©r√©s g√©n√©r√©s sur tout le dataset¬†!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Weights de la combinaison gagnante\n",
        "weights = np.array([0.3, 0.2, 0.1, 0.2, 0.1, 0.1]) # Issu de la cellule precedente\n",
        "\n",
        "# Charge logits de tous les mod√®les, full dataset\n",
        "logits_list = [\n",
        "    torch.load(\"/content/modeles_importes/camembert2_logits.pt\").cpu().numpy(),\n",
        "    torch.load(\"/content/modeles_importes/flaubert2_logits.pt\").cpu().numpy(),\n",
        "    torch.load(\"/content/modeles_importes/convnextv2_logits.pt\").cpu().numpy(),\n",
        "    torch.load(\"/content/modeles_importes/Maxvit_logits.pt\").cpu().numpy(),\n",
        "    torch.load(\"/content/modeles_importes/coatnet2_logits.pt\").cpu().numpy(),\n",
        "    torch.load(\"/content/modeles_importes/efficientv2L_logits.pt\").cpu().numpy(),\n",
        "]\n",
        "\n",
        "# Pond√©ration ‚Üí shape finale : (N, nb_classes)\n",
        "stacked = np.stack(logits_list, axis=0)  # (6, N, nb_classes)\n",
        "weighted_logits = np.tensordot(weights, stacked, axes=([0], [0]))  # (N, nb_classes)\n",
        "weighted_probs = torch.softmax(torch.tensor(weighted_logits), dim=1).numpy()\n",
        "\n",
        "# Sauvegarde sur tout le dataset\n",
        "torch.save(torch.tensor(weighted_probs), \"/content/drive/MyDrive/Colab Notebooks/fahim/final/booster_logits.pt\")\n",
        "print(\"Booster logits pond√©r√©s g√©n√©r√©s sur tout le dataset¬†!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
