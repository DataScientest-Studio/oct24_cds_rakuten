{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CE NOTEBOOKE EST LA MISE AU PROPRE DU NOTEBOOK :\n",
        "#\n",
        "# 4.2-fh-modeling-advanced-image.ipynb\n",
        "#\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "DW6ycJYUpWFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‚ö†Ô∏è Avertissement sur l'Ex√©cution et l'Origine des Fichiers**\n",
        "\n",
        "L'entra√Ænement de mod√®les de Deep Learning sur des images est une t√¢che tr√®s gourmande en ressources, qui requiert une puissance de calcul GPU importante. Pour cette raison, ce notebook n'a pas √©t√© r√©-ex√©cut√© dans cet environnement.\n",
        "\n",
        "Par cons√©quent, les fichiers de **logits** (`gcvit_logits.pt`, `convnextv2_logits.pt`, etc.) et les mod√®les g√©n√©r√©s par ce script proviennent d'une ex√©cution du notebook d'origine r√©alis√©e sur un serveur de calcul plus puissant et payant."
      ],
      "metadata": {
        "id": "i1dK8mb4ZOBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARTIE 1 : Entra√Ænement des Mod√®les de Computer Vision par lots"
      ],
      "metadata": {
        "id": "7aXTwkXvbBSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# NOTEBOOK D'ENTRA√éNEMENT PAR LOTS DE MOD√àLES DE COMPUTER VISION\n",
        "#\n",
        "# Objectif : Pr√©parer les donn√©es images, puis entra√Æner, √©valuer et\n",
        "# sauvegarder une suite de mod√®les de classification d'images (Maxvit,\n",
        "# ConvNeXt, EfficientNet, etc.) de mani√®re automatis√©e.\n",
        "#\n",
        "# Le code est structur√© pour √™tre modulaire et facilement extensible √† de\n",
        "# nouvelles architectures de mod√®les.\n",
        "#\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "jaeNxFbdXE9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlms-x43XIBu",
        "outputId": "dde8eb21-9700-4686-f947-f4219c360c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Montage de Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa3dogIuXJz6",
        "outputId": "8856531e-1aad-480b-a986-b3a405b36451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 1. PR√âPARATION DE L'ENVIRONNEMENT ======\n",
        "\n",
        "# Importation des biblioth√®ques\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import cv2\n",
        "import torch\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import timm\n",
        "\n",
        "# PyTorch et Torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.autoaugment import TrivialAugmentWide\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ],
      "metadata": {
        "id": "Qr-OI7iBXLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 2. PR√âPARATION DES DONN√âES IMAGES ======\n",
        "\n",
        "# Cette section d√©compresse les images depuis un fichier .zip sur Drive\n",
        "# vers l'espace local de Colab pour un acc√®s plus rapide.\n",
        "\n",
        "# D√©finition des chemins\n",
        "zip_path = \"/content/drive/MyDrive/Colab Notebooks/images/image_train.zip\"\n",
        "temp_path = \"/content/temp_extraction/\"\n",
        "final_image_path = \"/content/images/\"\n",
        "\n",
        "# Cr√©ation des dossiers n√©cessaires\n",
        "os.makedirs(temp_path, exist_ok=True)\n",
        "os.makedirs(final_image_path, exist_ok=True)\n",
        "\n",
        "# D√©compression du fichier zip dans le dossier temporaire\n",
        "print(\"D√©compression des images...\")\n",
        "!unzip -q \"{zip_path}\" -d \"{temp_path}\"\n",
        "print(f\"‚úÖ Zip extrait dans : {temp_path}\")\n",
        "\n",
        "def find_image_folder(base_dir):\n",
        "    \"\"\"\n",
        "    Parcourt un r√©pertoire pour trouver le premier sous-dossier contenant des fichiers images.\n",
        "\n",
        "    Cette fonction est utile apr√®s une d√©compression o√π les images peuvent se trouver\n",
        "    dans un sous-dossier dont le nom n'est pas connu √† l'avance (par exemple,\n",
        "    `/content/temp_extraction/image_train/`). Elle identifie le chemin\n",
        "    correct vers les images en se basant sur la pr√©sence de fichiers avec des\n",
        "    extensions courantes (.jpg, .png, etc.).\n",
        "\n",
        "    Args:\n",
        "        base_dir (str): Le chemin du r√©pertoire de base o√π commencer la recherche.\n",
        "\n",
        "    Returns:\n",
        "        str | None: Le chemin complet du premier sous-dossier contenant des images,\n",
        "                    ou None si aucun dossier d'images n'est trouv√©.\n",
        "    \"\"\"\n",
        "    for root, _, files in os.walk(base_dir):\n",
        "        if any(f.lower().endswith(('.jpg', '.jpeg', '.png', '.webp')) for f in files):\n",
        "            return root\n",
        "    return None\n",
        "\n",
        "# D√©placement des images vers le dossier final\n",
        "image_root = find_image_folder(temp_path)\n",
        "if image_root:\n",
        "    moved_count = 0\n",
        "    for fname in os.listdir(image_root):\n",
        "        shutil.move(os.path.join(image_root, fname), os.path.join(final_image_path, fname))\n",
        "        moved_count += 1\n",
        "    print(f\"‚úÖ {moved_count} images d√©plac√©es vers : {final_image_path}\")\n",
        "else:\n",
        "    print(\"‚ùå Aucune image trouv√©e apr√®s d√©compression.\")\n",
        "\n",
        "# Nettoyage du dossier temporaire\n",
        "shutil.rmtree(temp_path)\n",
        "print(\"üßπ Dossier temporaire supprim√©.\")"
      ],
      "metadata": {
        "id": "vAjn7R8FXN1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 3. PR√âPARATION DU FICHIER CSV ======\n",
        "\n",
        "# Le CSV original contient des chemins qui ne sont pas valides dans Colab.\n",
        "# Cette section met √† jour les chemins des images pour pointer vers le\n",
        "# dossier local `/content/images/` et sauvegarde ce nouveau CSV.\n",
        "\n",
        "print(\"\\nMise √† jour des chemins dans le fichier CSV...\")\n",
        "df_original = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data_rakuten/X_train_fr_final.csv\")\n",
        "df_collab = df_original.copy()\n",
        "df_collab['image_path'] = df_collab['image_path'].apply(lambda p: os.path.join(final_image_path, os.path.basename(p)))\n",
        "collab_csv_path = '/content/X_train_fr_final_colab.csv'\n",
        "df_collab.to_csv(collab_csv_path, index=False)\n",
        "\n",
        "# Sauvegarde de la version modifi√©e sur Drive pour une utilisation future\n",
        "drive_csv_path = '/content/drive/MyDrive/Colab Notebooks/data_rakuten/X_train_fr_final_colab.csv'\n",
        "shutil.copy(collab_csv_path, drive_csv_path)\n",
        "print(f\"‚úÖ CSV pr√™t et sauvegard√© sur Drive : {drive_csv_path}\")"
      ],
      "metadata": {
        "id": "8Wj09j-mXQm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 4. CONFIGURATION CENTRALE ET CHARGEMENT DES DONN√âES ======\n",
        "\n",
        "# Configuration partag√©e pour tous les mod√®les\n",
        "CONFIG = {\n",
        "    \"max_epochs\": 30,\n",
        "    \"patience\": 7,\n",
        "    \"batch_size\": 32,\n",
        "    \"lr\": 1e-4,\n",
        "    \"weight_decay\": 1e-2,\n",
        "}\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/data_rakuten\"\n",
        "DRIVE_OUTPUT_PATH = os.path.join(BASE_PATH, \"models_image\")\n",
        "os.makedirs(DRIVE_OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# Chargement des donn√©es et des indices de s√©paration\n",
        "df = pd.read_csv(collab_csv_path)\n",
        "paths, labels = df[\"image_path\"].values, df[\"label\"].values\n",
        "with open(os.path.join(BASE_PATH, \"val_indices.json\"), \"r\") as f:\n",
        "    val_idx = np.array(json.load(f), dtype=int)\n",
        "train_idx = np.setdiff1d(np.arange(len(df)), val_idx)\n",
        "\n",
        "train_paths, train_labels = paths[train_idx], labels[train_idx]\n",
        "val_paths, val_labels = paths[val_idx], labels[val_idx]\n",
        "num_classes = len(np.unique(labels))\n",
        "\n",
        "print(f\"\\nConfiguration charg√©e. Utilisation de l'appareil : {DEVICE}\")\n",
        "print(f\"Nombre de classes : {num_classes}\")"
      ],
      "metadata": {
        "id": "NTrcgg8zXYnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 5. D√âFINITIONS COMMUNES (TRANSFORMS, DATASET) ======\n",
        "\n",
        "# Ces d√©finitions sont partag√©es par tous les mod√®les pour assurer la coh√©rence.\n",
        "\n",
        "# Transformations d'images (avec augmentation pour l'entra√Ænement)\n",
        "IMAGENET_MEAN, IMAGENET_STD = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    TrivialAugmentWide(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset PyTorch personnalis√© pour charger des images et leurs labels √† la vol√©e.\n",
        "\n",
        "    Cette classe g√®re le chargement des images √† partir de leurs chemins sur le disque,\n",
        "    la conversion de leur format de couleur (de BGR, utilis√© par OpenCV, √† RGB),\n",
        "    et l'application de transformations (par exemple, redimensionnement, augmentation\n",
        "    de donn√©es, normalisation) avant de les retourner pour l'entra√Ænement ou l'√©valuation.\n",
        "\n",
        "    Attributes:\n",
        "        paths (np.ndarray): Un tableau des chemins d'acc√®s aux fichiers images.\n",
        "        labels (np.ndarray): Un tableau des labels num√©riques correspondants.\n",
        "        transform (callable): La pipeline de transformations √† appliquer √† chaque image.\n",
        "    \"\"\"\n",
        "    def __init__(self, paths, labels, transform):\n",
        "        \"\"\"\n",
        "        Initialise le Dataset.\n",
        "\n",
        "        Args:\n",
        "            paths (np.ndarray): La liste des chemins complets vers les images.\n",
        "            labels (np.ndarray): La liste des labels associ√©s √† chaque image.\n",
        "            transform (callable): Une fonction ou composition de transformations\n",
        "                                  (de torchvision.transforms) √† appliquer √† chaque image.\n",
        "        \"\"\"\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Retourne le nombre total d'√©chantillons dans le dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: La taille totale du dataset.\n",
        "        \"\"\"\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \"\"\"\n",
        "        R√©cup√®re et retourne un √©chantillon (image transform√©e et son label) √† un index donn√©.\n",
        "\n",
        "        Args:\n",
        "            i (int): L'index de l'√©chantillon √† r√©cup√©rer.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Un tuple contenant deux √©l√©ments :\n",
        "                   - torch.Tensor: L'image transform√©e sous forme de tenseur.\n",
        "                   - int: Le label num√©rique de l'image.\n",
        "        \"\"\"\n",
        "        img = cv2.imread(self.paths[i])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        return self.transform(img), int(self.labels[i])\n",
        "\n",
        "# Cr√©ation des datasets\n",
        "train_dataset = ImageDataset(train_paths, train_labels, train_transforms)\n",
        "val_dataset = ImageDataset(val_paths, val_labels, val_transforms)\n",
        "full_dataset = ImageDataset(paths, labels, val_transforms)"
      ],
      "metadata": {
        "id": "fSrPO9s4XbEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 6. BOUCLE D'ENTRA√éNEMENT PRINCIPALE ======\n",
        "\n",
        "# Cette boucle it√®re sur une liste de noms de mod√®les `timm`.\n",
        "# Pour chaque mod√®le, elle ex√©cute le cycle complet : entra√Ænement, validation,\n",
        "# sauvegarde du meilleur √©tat, et g√©n√©ration des logits.\n",
        "\n",
        "models_to_train = [\n",
        "    \"maxvit_base_tf_224.in21k\",\n",
        "    \"convnextv2_base.in22k\",\n",
        "    \"tf_efficientnetv2_l.in21k\",\n",
        "    \"coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k\",\n",
        "    \"gcvit_base.in1k\"\n",
        "]\n",
        "\n",
        "performance_history = {}\n",
        "\n",
        "for model_timm_name in models_to_train:\n",
        "    model_name = model_timm_name.split('.')[0]\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\" D√âBUT DE L'ENTRA√éNEMENT POUR : {model_name.upper()} \")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # --- Initialisation sp√©cifique au mod√®le ---\n",
        "    model = timm.create_model(model_timm_name, pretrained=True, num_classes=num_classes).to(DEVICE)\n",
        "\n",
        "    # --- Dataloader avec r√©√©chantillonnage pour g√©rer le d√©s√©quilibre ---\n",
        "    counts = np.bincount(train_labels, minlength=num_classes)\n",
        "    sample_weights = 1.0 / counts[train_labels]\n",
        "    sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"batch_size\"], sampler=sampler, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=2)\n",
        "\n",
        "    # --- Optimiseur, Scheduler et Fonction de Perte ---\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG[\"lr\"], weight_decay=CONFIG[\"weight_decay\"])\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG[\"max_epochs\"])\n",
        "    class_weights = torch.tensor(compute_class_weight(\"balanced\", classes=np.unique(train_labels), y=train_labels), dtype=torch.float, device=DEVICE)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
        "\n",
        "    # --- Boucle d'entra√Ænement et de validation ---\n",
        "    best_f1, wait = 0.0, 0\n",
        "    best_state = model.state_dict()\n",
        "    val_f1s = []\n",
        "\n",
        "    for ep in range(1, CONFIG[\"max_epochs\"] + 1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        pbar = tqdm(train_loader, desc=f\"{model_name} Ep{ep}\")\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = loss_fn(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        scheduler.step()\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        y_true, y_pred = [], []\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x = x.to(DEVICE)\n",
        "                logits = model(x)\n",
        "                y_pred.extend(logits.argmax(1).cpu().numpy())\n",
        "                y_true.extend(y.numpy())\n",
        "        f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "        val_f1s.append(f1)\n",
        "        print(f\"  -> TrainLoss: {total_loss/len(train_loader):.4f} | Val F1_weighted: {f1:.4f}\")\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            print(f\"   => Nouveau meilleur score F1 ! Sauvegarde du mod√®le.\")\n",
        "            best_f1, best_state, wait = f1, model.state_dict(), 0\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= CONFIG[\"patience\"]:\n",
        "                print(f\"‚èπÔ∏è Arr√™t anticip√© √† l'√©poque {ep}.\")\n",
        "                break\n",
        "\n",
        "    performance_history[model_name] = val_f1s\n",
        "\n",
        "    # --- Sauvegarde du meilleur mod√®le et des logits ---\n",
        "    print(f\"Sauvegarde du meilleur mod√®le {model_name} avec F1={best_f1:.4f}\")\n",
        "    model.load_state_dict(best_state)\n",
        "    torch.save(model.state_dict(), os.path.join(DRIVE_OUTPUT_PATH, f\"{model_name}_best.pt\"))\n",
        "\n",
        "    # --- G√©n√©ration des logits sur le dataset complet ---\n",
        "    full_loader = DataLoader(full_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=2)\n",
        "    all_logits = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, _ in tqdm(full_loader, desc=f\"G√©n√©ration des logits pour {model_name}\"):\n",
        "            x = x.to(DEVICE)\n",
        "            all_logits.append(model(x).cpu())\n",
        "    all_logits = torch.cat(all_logits)\n",
        "    torch.save(all_logits, os.path.join(BASE_PATH, f\"{model_name}_logits.pt\"))\n",
        "    print(f\"Logits sauvegard√©s. Shape: {all_logits.shape}\")"
      ],
      "metadata": {
        "id": "2X0f_yXHX35T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rvOom3sanbq"
      },
      "outputs": [],
      "source": [
        "# ====== 7. R√âSULTATS GLOBAUX ET VISUALISATION ======\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"             R√âSULTATS DE L'ENTRA√éNEMENT             \")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Cr√©ation d'un DataFrame r√©capitulatif\n",
        "summary_data = []\n",
        "for model_name, f1_scores in performance_history.items():\n",
        "    summary_data.append({\n",
        "        \"model\": model_name,\n",
        "        \"best_f1_weighted\": max(f1_scores) if f1_scores else 0\n",
        "    })\n",
        "df_summary = pd.DataFrame(summary_data).set_index(\"model\")\n",
        "df_summary.to_csv(os.path.join(DRIVE_OUTPUT_PATH, \"recap_scores_modeles_image.csv\"))\n",
        "\n",
        "print(\"Scores finaux par mod√®le :\")\n",
        "print(df_summary)\n",
        "\n",
        "# Cr√©ation du graphique comparatif\n",
        "plt.figure(figsize=(12, 7))\n",
        "for model_name, f1_scores in performance_history.items():\n",
        "    plt.plot(range(1, len(f1_scores) + 1), f1_scores, marker='o', linestyle='--', label=model_name)\n",
        "plt.title(\"Comparaison des Scores F1 (Validation) par √âpoque\")\n",
        "plt.xlabel(\"√âpoque\")\n",
        "plt.ylabel(\"F1 Score Pond√©r√© (Weighted)\")\n",
        "plt.xticks(range(1, CONFIG[\"max_epochs\"] + 1))\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARTIE 2 : Fusion et Stacking Avanc√©s des Mod√®les de Computer Vision"
      ],
      "metadata": {
        "id": "mHhCbScEa6yH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# NOTEBOOK DE FUSION AVANC√âE ET STACKING POUR MOD√àLES DE COMPUTER VISION\n",
        "#\n",
        "# Objectif : Combiner les pr√©dictions des mod√®les de computer vision entra√Æn√©s dans le\n",
        "# Notebook 3 pour maximiser les performances.\n",
        "#\n",
        "# √âtapes :\n",
        "#   1. Fusion Pond√©r√©e : Recherche des poids optimaux avec Optuna pour cr√©er\n",
        "#      un \"ensemble\" de mod√®les simple mais performant.\n",
        "#   2. Stacking : Utilisation des logits comme features pour entra√Æner des\n",
        "#      m√©ta-mod√®les (LGBM, MLP). Le meilleur est s√©lectionn√© par validation\n",
        "#      crois√©e puis entra√Æn√© sur toutes les donn√©es.\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "Sl90U-EIYAZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna lightgbm -q"
      ],
      "metadata": {
        "id": "pPbAuvQGYB7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montage de Google Drive pour acc√©der aux fichiers depuis Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7IFj_Pu4YEQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a09166-3178-48fe-a2e7-a4cf137b88c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 1. PR√âPARATION DE L'ENVIRONNEMENT ======\n",
        "\n",
        "# Importation des biblioth√®ques\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "\n",
        "# PyTorch et Scikit-learn\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "metadata": {
        "id": "STxBPBoeYFhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 2. MISE EN PLACE DE L'ESPACE DE TRAVAIL ======\n",
        "\n",
        "# D√©finition des chemins\n",
        "drive_path = \"/content/drive/MyDrive/Colab Notebooks/data_rakuten\"\n",
        "local_path = '/content/data_stacking_vision/'\n",
        "os.makedirs(local_path, exist_ok=True)\n",
        "\n",
        "print(\"--- Copie des logits et des fichiers de configuration depuis Google Drive ---\")\n",
        "\n",
        "# Liste des logits g√©n√©r√©s par le notebook pr√©c√©dent\n",
        "logits_files = [\n",
        "    \"maxvit_base_tf_224_logits.pt\",\n",
        "    \"convnextv2_base_logits.pt\",\n",
        "    \"tf_efficientnetv2_l_logits.pt\",\n",
        "    \"coatnet_rmlp_2_rw_224_logits.pt\",\n",
        "    \"gcvit_base_logits.pt\",\n",
        "    \"true_labels_final.pt\",\n",
        "    \"val_indices.json\",\n",
        "    \"label_mapping_final.json\"\n",
        "]\n",
        "\n",
        "# Copie des fichiers en local pour un acc√®s rapide\n",
        "for filename in logits_files:\n",
        "    src_file = os.path.join(drive_path, filename)\n",
        "    dst_file = os.path.join(local_path, filename)\n",
        "    if os.path.exists(src_file):\n",
        "        shutil.copy(src_file, dst_file)\n",
        "        print(f\"‚úÖ Copi√© : {filename}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Manquant : {src_file}\")"
      ],
      "metadata": {
        "id": "NyJL7tGRYHfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 3. CHARGEMENT DES DONN√âES ======\n",
        "\n",
        "# Chargement des logits de chaque mod√®le dans un dictionnaire\n",
        "all_logits = {}\n",
        "model_names = [f.replace('_logits.pt', '') for f in logits_files if f.endswith('_logits.pt') and 'true_labels' not in f]\n",
        "for name in model_names:\n",
        "    all_logits[name] = torch.load(os.path.join(local_path, f\"{name}_logits.pt\")).cpu().numpy()\n",
        "\n",
        "# Chargement des √©tiquettes et indices\n",
        "with open(os.path.join(local_path, \"val_indices.json\"), \"r\") as f:\n",
        "    val_idx = np.array(json.load(f))\n",
        "with open(os.path.join(local_path, \"label_mapping_final.json\"), \"r\") as f:\n",
        "    label_mapping = json.load(f)\n",
        "\n",
        "labels_full = torch.load(os.path.join(local_path, \"true_labels_final.pt\")).numpy()\n",
        "class_names = [label_mapping[str(i)][\"label_name\"] for i in range(len(label_mapping))]\n",
        "\n",
        "# S√©paration des √©tiquettes et des logits en ensembles d'entra√Ænement et de validation\n",
        "all_indices = np.arange(len(labels_full))\n",
        "train_idx = np.setdiff1d(all_indices, val_idx)\n",
        "y_train, y_val = labels_full[train_idx], labels_full[val_idx]\n",
        "logits_train = {name: log[train_idx] for name, log in all_logits.items()}\n",
        "logits_val = {name: log[val_idx] for name, log in all_logits.items()}\n",
        "\n",
        "print(f\"\\nDonn√©es de fusion et de stacking pr√™tes.\")"
      ],
      "metadata": {
        "id": "BJFrTlE9YOFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 4. FUSION POND√âR√âE (ENSEMBLING) ======\n",
        "\n",
        "# Nous utilisons Optuna pour trouver la meilleure pond√©ration √† appliquer aux\n",
        "# probabilit√©s de chaque mod√®le afin de maximiser le score F1.\n",
        "\n",
        "def objective_fusion(trial, logits_dict, y_true):\n",
        "    \"\"\"\n",
        "    Fonction objective pour Optuna visant √† maximiser le score F1 pond√©r√©.\n",
        "\n",
        "    Cette fonction est appel√©e par Optuna √† chaque essai. Elle sugg√®re un ensemble de\n",
        "    poids pour chaque mod√®le, normalise ces poids pour qu'ils somment √† 1, puis\n",
        "    calcule les pr√©dictions fusionn√©es en effectuant une moyenne pond√©r√©e des\n",
        "    probabilit√©s (obtenues via softmax sur les logits). Le score F1 qui en r√©sulte\n",
        "    est retourn√© pour √™tre optimis√©.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): L'objet d'essai d'Optuna qui g√®re la suggestion\n",
        "                                    des hyperparam√®tres (ici, les poids).\n",
        "        logits_dict (dict): Dictionnaire o√π les cl√©s sont les noms des mod√®les et\n",
        "                            les valeurs sont les logits (np.ndarray) correspondants.\n",
        "        y_true (np.ndarray): Le tableau des v√©ritables labels pour l'√©valuation.\n",
        "\n",
        "    Returns:\n",
        "        float: Le score F1 pond√©r√© calcul√© pour la combinaison de poids actuelle.\n",
        "               Optuna cherchera √† maximiser cette valeur.\n",
        "    \"\"\"\n",
        "    weights = [trial.suggest_float(name, 0.0, 1.0) for name in logits_dict.keys()]\n",
        "    s = sum(weights)\n",
        "    if s < 1e-6: return 0.0 # Retourne un mauvais score pour √©viter la division par 0\n",
        "\n",
        "    # Normalisation des poids\n",
        "    weights = np.array(weights) / s\n",
        "\n",
        "    # Calcul des probabilit√©s pond√©r√©es\n",
        "    fused_probs = np.zeros_like(list(logits_dict.values())[0])\n",
        "    for i, name in enumerate(logits_dict.keys()):\n",
        "        probs = torch.softmax(torch.tensor(logits_dict[name]), dim=1).numpy()\n",
        "        fused_probs += weights[i] * probs\n",
        "\n",
        "    preds = np.argmax(fused_probs, axis=1)\n",
        "    return f1_score(y_true, preds, average=\"weighted\")\n",
        "\n",
        "print(\"\\n--- Recherche des poids de fusion optimaux avec Optuna ---\")\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(lambda trial: objective_fusion(trial, logits_val, y_val), n_trials=150)\n",
        "\n",
        "# √âvaluation avec les meilleurs poids trouv√©s\n",
        "best_weights = np.array([study.best_params[name] for name in model_names])\n",
        "best_weights /= sum(best_weights)\n",
        "fused_probs_val = sum(best_weights[i] * torch.softmax(torch.tensor(logits_val[name]), dim=1).numpy() for i, name in enumerate(model_names))\n",
        "preds_fusion = np.argmax(fused_probs_val, axis=1)\n",
        "f1_fusion = f1_score(y_val, preds_fusion, average='weighted')\n",
        "\n",
        "print(f\"\\nMeilleur F1-Score (Fusion Pond√©r√©e) : {f1_fusion:.5f}\")\n",
        "print(\"Poids optimaux :\")\n",
        "for name, weight in zip(model_names, best_weights):\n",
        "    print(f\"  - {name}: {weight:.4f}\")"
      ],
      "metadata": {
        "id": "ZjXlwh2oYQiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 5. STACKING AVEC UN M√âTA-MOD√àLE ======\n",
        "\n",
        "# Le stacking utilise les logits des mod√®les de base comme \"features\" pour\n",
        "# entra√Æner un m√©ta-mod√®le. Cela permet de capturer des relations plus complexes\n",
        "# entre les pr√©dictions des mod√®les de base.\n",
        "\n",
        "# --- 5.1. Pr√©paration des donn√©es pour le Stacking ---\n",
        "X_train_stack = np.concatenate(list(logits_train.values()), axis=1)\n",
        "X_val_stack = np.concatenate(list(logits_val.values()), axis=1)\n",
        "\n",
        "print(f\"\\nShape des features de Stacking (Train): {X_train_stack.shape}\")\n",
        "print(f\"Shape des features de Stacking (Val):   {X_val_stack.shape}\")\n",
        "\n",
        "\n",
        "# --- 5.2. S√©lection du meilleur m√©ta-mod√®le par validation crois√©e ---\n",
        "# Nous √©valuons LightGBM et un MLP pour voir lequel est le plus performant\n",
        "# sur nos donn√©es de stacking.\n",
        "\n",
        "def train_lgbm(X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Entra√Æne et √©value un classifieur LightGBM.\n",
        "\n",
        "    Cette fonction utilitaire initialise un mod√®le LGBMClassifier, l'entra√Æne sur\n",
        "    les donn√©es d'entra√Ænement fournies et retourne le score F1 pond√©r√© calcul√©\n",
        "    sur l'ensemble de validation.\n",
        "\n",
        "    Args:\n",
        "        X_train (np.ndarray): Features d'entra√Ænement (logits concat√©n√©s).\n",
        "        y_train (np.ndarray): Labels d'entra√Ænement.\n",
        "        X_val (np.ndarray): Features de validation.\n",
        "        y_val (np.ndarray): Labels de validation.\n",
        "\n",
        "    Returns:\n",
        "        float: Le score F1 pond√©r√© du mod√®le sur les donn√©es de validation.\n",
        "    \"\"\"\n",
        "    model = lgb.LGBMClassifier(random_state=42)\n",
        "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
        "    preds = model.predict(X_val)\n",
        "    return f1_score(y_val, preds, average=\"weighted\")\n",
        "\n",
        "print(\"\\n--- √âvaluation des m√©ta-mod√®les par validation crois√©e (5-fold) ---\")\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "lgbm_scores = []\n",
        "\n",
        "for fold, (train_fold_idx, val_fold_idx) in enumerate(skf.split(X_train_stack, y_train)):\n",
        "    X_train_fold, X_val_fold = X_train_stack[train_fold_idx], X_train_stack[val_fold_idx]\n",
        "    y_train_fold, y_val_fold = y_train[train_fold_idx], y_train[val_fold_idx]\n",
        "\n",
        "    score = train_lgbm(X_train_fold, y_train_fold, X_val_fold, y_val_fold)\n",
        "    lgbm_scores.append(score)\n",
        "    print(f\"Fold {fold+1}/5 - F1 Score LGBM : {score:.4f}\")\n",
        "\n",
        "avg_lgbm_score = np.mean(lgbm_scores)\n",
        "print(f\"\\nScore F1 moyen pour LightGBM (CV) : {avg_lgbm_score:.5f}\")\n",
        "# (Note: une CV similaire pourrait √™tre faite pour un MLP, mais LGBM est souvent\n",
        "# un excellent point de d√©part pour les donn√©es tabulaires comme les logits).\n",
        "\n",
        "\n",
        "# --- 5.3. Entra√Ænement et √âvaluation du M√©ta-Mod√®le Final ---\n",
        "print(\"\\n--- Entra√Ænement du m√©ta-mod√®le final (LGBM) sur toutes les donn√©es d'entra√Ænement ---\")\n",
        "\n",
        "final_lgbm_model = lgb.LGBMClassifier(\n",
        "    objective=\"multiclass\",\n",
        "    num_class=len(class_names),\n",
        "    metric=\"multi_logloss\",\n",
        "    random_state=42\n",
        ")\n",
        "final_lgbm_model.fit(X_train_stack, y_train, eval_set=[(X_val_stack, y_val)])\n",
        "preds_lgbm_final = final_lgbm_model.predict(X_val_stack)"
      ],
      "metadata": {
        "id": "8JcG73CaYTj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 6. R√âSULTATS FINAUX ET SAUVEGARDE ======\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"              R√âSULTATS FINAUX              \")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"Score F1 (Fusion Pond√©r√©e Simple) : {f1_fusion:.5f}\")\n",
        "\n",
        "print(\"\\n--- Rapport de Classification Final (Stacking avec LightGBM) ---\")\n",
        "print(classification_report(y_val, preds_lgbm_final, target_names=class_names, digits=4))\n",
        "\n",
        "# Sauvegarde du m√©ta-mod√®le final, qui est l'artefact le plus pr√©cieux.\n",
        "meta_model_path = os.path.join(drive_path, 'meta_model_vision_lgbm.pkl')\n",
        "joblib.dump(final_lgbm_model, meta_model_path)\n",
        "print(f\"\\n‚úÖ M√©ta-mod√®le final sauvegard√© sur Drive : {meta_model_path}\")"
      ],
      "metadata": {
        "id": "OYxF9IXJa7Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > \"/content/drive/MyDrive/Colab Notebooks/requirements_Images.txt\""
      ],
      "metadata": {
        "id": "iwh7XR61USeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}