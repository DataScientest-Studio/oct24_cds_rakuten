{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CE NOTEBOOKE EST LA MISE AU PROPRE DES NOTEBOOK :\n",
        "#\n",
        "# 4.3-fh-meta-1.ipynb & 4.3-fh-meta-2.ipynb\n",
        "#\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "kijbeL_RPi82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**⚠️ Avertissement sur l'Exécution et l'Origine des Fichiers**\n",
        "\n",
        "En raison de contraintes de ressources de calcul (CPU/GPU), le code de ce notebook n'a pas été ré-exécuté dans cet environnement.\n",
        "\n",
        "Par conséquent, les fichiers de données utilisés comme entrées (ex: `camembert2_logits.pt`, `gcvit_logits.pt`) ainsi que les fichiers de sortie créés (ex: `booster_logits.pt`, modèles finaux) proviennent de la version originale du code, qui a été exécutée sur un serveur de calcul puissant et payant."
      ],
      "metadata": {
        "id": "xsznd6kMYg8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# NOTEBOOK FINAL : MÉTA-APPRENTISSAGE ET FUSION MULTIMODALE\n",
        "#\n",
        "# Objectif : Combiner les prédictions (logits) des modèles Texte et Image\n",
        "#            pour créer un classifieur final optimisé.\n",
        "#\n",
        "# Processus :\n",
        "#   - PARTIE 1 : Recherche par grille de la meilleure combinaison de modèles\n",
        "#     de base et création d'un fichier de logits \"booster\".\n",
        "#   - PARTIE 2 : Entraînement et fusion de méta-modèles (LGBM, MLP, LogReg)\n",
        "#     via une validation croisée, incluant une optimisation finale des seuils.\n",
        "#\n",
        "# =============================================================================="
      ],
      "metadata": {
        "id": "2IedSKqwa4wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARTIE 1 : RECHERCHE DE LA MEILLEURE COMBINAISON DE MODÈLES"
      ],
      "metadata": {
        "id": "xz30IcGRBl64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna -q"
      ],
      "metadata": {
        "id": "lvYrZHvAUw_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montage de Google Drive pour accéder aux fichiers depuis Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KBy6LP6xBZIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de173f24-88c7-4001-ec16-f85a0f0b4c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 1. BIBLIOTHÈQUES ET CONFIGURATION (PARTIE 1) ======\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import itertools\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import joblib\n",
        "from tqdm.notebook import tqdm\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import optuna"
      ],
      "metadata": {
        "id": "sV0QvxUaavEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_BASE_PATH = \"/content/drive/MyDrive/Colab Notebooks/data_rakuten/\"\n",
        "LOCAL_PATH_P1 = \"/content/grid_search_data\"\n",
        "os.makedirs(LOCAL_PATH_P1, exist_ok=True)\n",
        "\n",
        "# --- Copie des fichiers nécessaires ---\n",
        "print(\"--- Copie des fichiers pour la recherche par grille ---\")\n",
        "all_model_files = [\n",
        "    \"camembert2_logits.pt\", \"flaubert2_logits.pt\", \"gcvit_logits.pt\",\n",
        "    \"convnextv2_logits.pt\", \"Maxvit_logits.pt\", \"coatnet2_logits.pt\",\n",
        "    \"efficientv2L_logits.pt\", \"true_labels_final.pt\", \"val_indices.json\"\n",
        "]\n",
        "for filename in all_model_files:\n",
        "    src = os.path.join(DRIVE_BASE_PATH, filename)\n",
        "    dst = os.path.join(LOCAL_PATH_P1, filename)\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "    else:\n",
        "        print(f\"❌ Fichier manquant : {src}\")\n",
        "print(\"✅ Copie terminée.\")"
      ],
      "metadata": {
        "id": "qlg60FpgBWRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 2. RECHERCHE PAR GRILLE (GRID-SEARCH) ======\n",
        "\n",
        "def grid_search_best_ensemble(logits_path, labels_path, val_indices_path):\n",
        "    \"\"\"\n",
        "    Effectue une recherche par grille pour trouver la meilleure combinaison\n",
        "    de modèles et leurs poids de fusion respectifs.\n",
        "\n",
        "    Args:\n",
        "        logits_path (str): Chemin vers le dossier contenant les fichiers de logits.\n",
        "        labels_path (str): Chemin vers le fichier des vrais labels.\n",
        "        val_indices_path (str): Chemin vers le fichier JSON des indices de validation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: La meilleure combinaison (noms des modèles, poids optimaux, score F1).\n",
        "    \"\"\"\n",
        "    all_model_names = [f.replace('_logits.pt', '') for f in os.listdir(logits_path) if f.endswith('_logits.pt') and 'true_labels' not in f]\n",
        "\n",
        "    all_logits = {name: torch.load(os.path.join(logits_path, f\"{name}_logits.pt\")).cpu().numpy() for name in all_model_names}\n",
        "    labels = torch.load(labels_path).numpy()\n",
        "    with open(val_indices_path, \"r\") as f:\n",
        "        val_idx = np.array(json.load(f))\n",
        "    y_val = labels[val_idx]\n",
        "\n",
        "    def weighted_softmax(logits_list, weights):\n",
        "        \"\"\"\n",
        "        Calcule la moyenne pondérée des probabilités (obtenues par softmax)\n",
        "        à partir d'une liste de logits.\n",
        "\n",
        "        Args:\n",
        "            logits_list (list): Liste de tableaux numpy de logits.\n",
        "            weights (tuple): Tuple de poids correspondants.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Tableau numpy des probabilités fusionnées.\n",
        "        \"\"\"\n",
        "        probs = [softmax(logits, axis=1) for logits in logits_list]\n",
        "        return np.tensordot(weights, np.array(probs), axes=(0, 0))\n",
        "\n",
        "    def generate_weights(n, step=0.1):\n",
        "        \"\"\"\n",
        "        Génère des combinaisons de 'n' poids dont la somme est égale à 1.\n",
        "\n",
        "        Args:\n",
        "            n (int): Le nombre de poids à générer.\n",
        "            step (float): Le pas pour la génération des valeurs de poids.\n",
        "\n",
        "        Yields:\n",
        "            tuple: Une combinaison de poids.\n",
        "        \"\"\"\n",
        "        if n == 1:\n",
        "            yield (1.0,)\n",
        "            return\n",
        "        for i in np.arange(0, 1.01, step):\n",
        "            for rest in generate_weights(n - 1, step):\n",
        "                if abs(sum((i,) + rest) - 1.0) < 1e-9:\n",
        "                    yield (i,) + rest\n",
        "\n",
        "    results = []\n",
        "    print(\"\\n--- Début de la recherche par grille sur les combinaisons de modèles ---\")\n",
        "    for n_models in range(2, len(all_model_names) + 1):\n",
        "        for model_combo in itertools.combinations(all_model_names, n_models):\n",
        "            logits_list_val = [all_logits[name][val_idx] for name in model_combo]\n",
        "            best_f1, best_weights = 0, None\n",
        "\n",
        "            weight_candidates = list(generate_weights(n_models))\n",
        "            if not weight_candidates and n_models > 0:\n",
        "                weight_candidates = [tuple([1/n_models]*n_models)]\n",
        "\n",
        "            for weights in weight_candidates:\n",
        "                y_pred = np.argmax(weighted_softmax(logits_list_val, weights), axis=1)\n",
        "                f1 = f1_score(y_val, y_pred, average='weighted')\n",
        "                if f1 > best_f1:\n",
        "                    best_f1, best_weights = f1, weights\n",
        "\n",
        "            if best_weights:\n",
        "                results.append({\"models\": model_combo, \"f1_weighted\": best_f1, \"weights\": best_weights})\n",
        "\n",
        "    results = sorted(results, key=lambda x: x[\"f1_weighted\"], reverse=True)\n",
        "    best_result = results[0]\n",
        "\n",
        "    print(\"\\n==== MEILLEURE COMBINAISON TROUVÉE PAR GRID-SEARCH ====\")\n",
        "    print(f\"Modèles     : {best_result['models']}\")\n",
        "    print(f\"F1 Pondéré  : {best_result['f1_weighted']:.5f}\")\n",
        "    print(f\"Poids       : {np.round(best_result['weights'], 4)}\")\n",
        "\n",
        "    return best_result['models'], best_result['weights'], best_result['f1_weighted']\n",
        "\n",
        "# --- Exécution de la recherche ---\n",
        "# Pour la démo, on utilise des valeurs pré-calculées pour éviter une longue exécution\n",
        "best_combo_names = ('camembert2', 'flaubert2', 'convnextv2', 'Maxvit', 'coatnet2', 'efficientv2L')\n",
        "best_combo_weights = np.array([0.3, 0.2, 0.1, 0.2, 0.1, 0.1])"
      ],
      "metadata": {
        "id": "SYispGt1BOQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 3. CRÉATION DU FICHIER `booster_logits.pt` ======\n",
        "\n",
        "def create_booster_logits(model_names, weights, logits_path, save_path):\n",
        "    \"\"\"\n",
        "    Crée et sauvegarde un fichier de probabilités fusionnées (\"booster\")\n",
        "    à partir de la meilleure combinaison de modèles de base.\n",
        "\n",
        "    Args:\n",
        "        model_names (list): Noms des modèles de la meilleure combinaison.\n",
        "        weights (np.ndarray): Poids de fusion optimaux.\n",
        "        logits_path (str): Chemin du dossier des logits de base.\n",
        "        save_path (str): Chemin complet pour sauvegarder le fichier de sortie.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Création du fichier 'booster_logits.pt' ---\")\n",
        "    logits_list_full = [torch.load(os.path.join(logits_path, f\"{name}_logits.pt\")).cpu().numpy() for name in model_names]\n",
        "\n",
        "    probs_list_full = [softmax(logits, axis=1) for logits in logits_list_full]\n",
        "    weighted_probs = np.tensordot(weights, np.array(probs_list_full), axes=(0, 0))\n",
        "\n",
        "    torch.save(torch.tensor(weighted_probs), save_path)\n",
        "    print(f\"✅ Fichier 'booster_logits.pt' sauvegardé dans : {save_path}\")\n",
        "\n",
        "# --- Exécution de la création du booster ---\n",
        "booster_save_path = os.path.join(DRIVE_BASE_PATH, \"booster_logits.pt\")\n",
        "create_booster_logits(best_combo_names, best_combo_weights, LOCAL_PATH_P1, booster_save_path)"
      ],
      "metadata": {
        "id": "KPA3gA7VBHRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARTIE 2 : ENTRAÎNEMENT DU MÉTA-MODÈLE FINAL AVEC VALIDATION CROISÉE"
      ],
      "metadata": {
        "id": "RoO-zRZ8Bvpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REMARQUE :\n",
        "#\n",
        "# Le code original (META_1.ipynb) créait les features pour les méta-modèles en utilisant une\n",
        "# MOYENNE PONDÉRÉE des logits de base (variable `fixed_weights` qui\n",
        "# était copiée manuellement).\n",
        "#\n",
        "# Cette approche a été remplacée ici par une CONCATÉNATION de tous les logits :\n",
        "#\n",
        "# Ainsi l'intégralité de l'information de chaque modèle de base est donnée au\n",
        "# méta-modèle (LGBM, MLP, etc.), lui permettant d'apprendre par lui-même\n",
        "# les relations et l'importance de chaque prédiction sans perte de signal préalable."
      ],
      "metadata": {
        "id": "64KoOFE_az7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 1. CHARGEMENT DES DONNÉES POUR LE STACKING FINAL ======\n",
        "print(\"\\n--- Chargement des données pour la Partie 2 ---\")\n",
        "if not os.path.exists(os.path.join(LOCAL_PATH_P1, \"booster_logits.pt\")): #Chargement du Booster de la partie 1\n",
        "    shutil.copy(booster_save_path, LOCAL_PATH_P1)"
      ],
      "metadata": {
        "id": "JuUubcMZCFUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE SUR `booster_logits.pt` :\n",
        "#\n",
        "# Ce fichier est la fusion pondérée des prédictions des meilleurs modèles de base.\n",
        "# Il est utilisé dans cette partie comme une nouvelle \"feature\", aux côtés des\n",
        "# logits des autres modèles, pour entraîner les méta-modèles finaux.\n",
        "#\n",
        "# Utilisation (en tant que Feature) :\n",
        "#    - Ses prédictions sont chargées et \"concaténées\" avec les prédictions brutes de TOUS\n",
        "#      les autres modèles individuels (CamemBERT, Flaubert, MaxVit, etc.).\n",
        "#    - L'objectif est de donner aux méta-modèles finaux (LGBM, MLP, etc.) à la fois les\n",
        "#      informations de bas niveau (chaque modèle) et une information \"experte\" de haut\n",
        "#      niveau (le \"booster\")."
      ],
      "metadata": {
        "id": "Hkr-G_BqFOMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 2. FONCTIONS DE MÉTA-APPRENTISSAGE ======\n",
        "\n",
        "class MetaMLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Méta-modèle de type Perceptron Multi-Couches (MLP) pour le stacking.\n",
        "    Ce réseau de neurones prend en entrée les logits concaténés des modèles\n",
        "    de base et apprend à prédire la classe finale.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, n_classes, dropout_rate=0.3):\n",
        "        \"\"\"\n",
        "        Initialise les couches du réseau de neurones.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Dimensionnalité des features d'entrée.\n",
        "            hidden_dim (int): Nombre de neurones dans la couche cachée.\n",
        "            n_classes (int): Nombre de classes de sortie.\n",
        "            dropout_rate (float): Taux de dropout à appliquer.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim), nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate), nn.Linear(hidden_dim, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Définit la passe avant du modèle.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Le tenseur d'entrée.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Les logits de sortie.\n",
        "        \"\"\"\n",
        "        return self.net(x)\n",
        "\n",
        "def train_and_evaluate_lgbm(trial, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Entraîne un méta-modèle LightGBM avec les hyperparamètres suggérés par Optuna.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): Essai Optuna pour la recherche d'hyperparamètres.\n",
        "        X_train (np.ndarray): Données d'entraînement (features).\n",
        "        y_train (np.ndarray): Labels d'entraînement.\n",
        "        X_val (np.ndarray): Données de validation (features).\n",
        "        y_val (np.ndarray): Labels de validation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (modèle entraîné, probabilités de validation, score F1).\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        'objective': 'multiclass', 'metric': 'multi_logloss', 'random_state': 42, 'n_jobs': -1,\n",
        "        'learning_rate': trial.suggest_float('lr', 1e-3, 0.1, log=True),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 60),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "        'n_estimators': 1500\n",
        "    }\n",
        "    model = lgb.LGBMClassifier(**params)\n",
        "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(25, verbose=False)])\n",
        "    val_probas = model.predict_proba(X_val)\n",
        "    f1 = f1_score(y_val, np.argmax(val_probas, axis=1), average='weighted')\n",
        "    return model, val_probas, f1\n",
        "\n",
        "def train_and_evaluate_logreg(trial, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Entraîne un méta-modèle Régression Logistique avec Optuna.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): Essai Optuna.\n",
        "        X_train (np.ndarray): Données d'entraînement (features).\n",
        "        y_train (np.ndarray): Labels d'entraînement.\n",
        "        X_val (np.ndarray): Données de validation (features).\n",
        "        y_val (np.ndarray): Labels de validation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (modèle entraîné, probabilités de validation, score F1).\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        'C': trial.suggest_float('C', 1e-3, 1e2, log=True),\n",
        "        'solver': 'lbfgs', 'max_iter': 2000, 'random_state': 42, 'n_jobs': -1, 'class_weight': 'balanced'\n",
        "    }\n",
        "    model = LogisticRegression(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    val_probas = model.predict_proba(X_val)\n",
        "    f1 = f1_score(y_val, np.argmax(val_probas, axis=1), average='weighted')\n",
        "    return model, val_probas, f1\n",
        "\n",
        "def train_and_evaluate_mlp(trial, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Entraîne un méta-modèle MLP avec Optuna.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): Essai Optuna.\n",
        "        X_train (np.ndarray): Données d'entraînement (features).\n",
        "        y_train (np.ndarray): Labels d'entraînement.\n",
        "        X_val (np.ndarray): Données de validation (features).\n",
        "        y_val (np.ndarray): Labels de validation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (modèle entraîné, probabilités de validation, score F1).\n",
        "    \"\"\"\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    hidden_dim = trial.suggest_int('hidden_dim', 128, 512, step=64)\n",
        "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
        "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
        "\n",
        "    model = MetaMLP(X_train.shape[1], hidden_dim, len(np.unique(y_train)), dropout).to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "    train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "\n",
        "    for epoch in range(15):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(xb), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_probas = softmax(model(torch.tensor(X_val, dtype=torch.float32).to(DEVICE)).cpu().numpy(), axis=1)\n",
        "    f1 = f1_score(y_val, np.argmax(val_probas, axis=1), average='weighted')\n",
        "    return model, val_probas, f1\n",
        "\n",
        "def objective_fusion(trial, probas_list, y_true):\n",
        "    \"\"\"\n",
        "    Fonction objective pour la fusion pondérée des prédictions des méta-modèles.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): Essai Optuna.\n",
        "        probas_list (list): Liste des tableaux de probabilités des méta-modèles.\n",
        "        y_true (np.ndarray): Labels vrais pour l'évaluation.\n",
        "\n",
        "    Returns:\n",
        "        float: Score F1 pondéré de la fusion.\n",
        "    \"\"\"\n",
        "    weights = [trial.suggest_float(f'w_{i}', 0, 1) for i in range(len(probas_list))]\n",
        "    if sum(weights) < 1e-6: return 0.0\n",
        "\n",
        "    normalized_weights = np.array(weights) / sum(weights)\n",
        "    fused_probas = np.tensordot(normalized_weights, np.array(probas_list), axes=(0,0))\n",
        "    preds = np.argmax(fused_probas, axis=1)\n",
        "    return f1_score(y_true, preds, average='weighted')\n",
        "\n",
        "def threshold_tuning(y_true, probas, n_classes):\n",
        "    \"\"\"\n",
        "    Optimise les seuils de classification pour chaque classe afin de maximiser le F1-score.\n",
        "\n",
        "    Args:\n",
        "        y_true (np.ndarray): Labels vrais.\n",
        "        probas (np.ndarray): Probabilités prédites.\n",
        "        n_classes (int): Nombre de classes.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Tableau des seuils optimisés.\n",
        "    \"\"\"\n",
        "    best_thresholds = np.full(n_classes, 0.5)\n",
        "    best_f1 = f1_score(y_true, apply_thresholds(probas, best_thresholds), average='weighted')\n",
        "    for c in tqdm(range(n_classes), desc=\"Optimisation des seuils\"):\n",
        "        for thr in np.linspace(0.1, 0.9, 9):\n",
        "            current_thresholds = best_thresholds.copy()\n",
        "            current_thresholds[c] = thr\n",
        "            preds = apply_thresholds(probas, current_thresholds)\n",
        "            f1 = f1_score(y_true, preds, average='weighted')\n",
        "            if f1 > best_f1:\n",
        "                best_f1, best_thresholds = f1, current_thresholds.copy()\n",
        "    print(f\"Meilleur F1 après optimisation des seuils: {best_f1:.5f}\")\n",
        "    return best_thresholds\n",
        "\n",
        "def apply_thresholds(probas, thresholds):\n",
        "    \"\"\"\n",
        "    Applique des seuils de classification personnalisés pour obtenir les prédictions finales.\n",
        "\n",
        "    Args:\n",
        "        probas (np.ndarray): Tableau des probabilités.\n",
        "        thresholds (np.ndarray): Tableau des seuils par classe.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Tableau des prédictions finales.\n",
        "    \"\"\"\n",
        "    preds = np.zeros(probas.shape[0], dtype=int)\n",
        "    for i in range(probas.shape[0]):\n",
        "        passed = np.where(probas[i] >= thresholds)[0]\n",
        "        preds[i] = np.argmax(probas[i]) if len(passed) == 0 else passed[np.argmax(probas[i][passed])]\n",
        "    return preds"
      ],
      "metadata": {
        "id": "8px7GNjPCB69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 3. EXÉCUTION DU PIPELINE DE STACKING FINAL ======\n",
        "\n",
        "def final_pipeline_execution():\n",
        "    \"\"\"\n",
        "    Fonction principale qui pilote l'entraînement, la fusion et l'évaluation des méta-modèles.\n",
        "    \"\"\"\n",
        "    # Rechargement des données\n",
        "    X_train, y_train, X_val, y_val, class_names = load_stacking_data()\n",
        "\n",
        "    META_CLASSIFIERS = {\n",
        "        \"lgbm\": train_and_evaluate_lgbm,\n",
        "        \"logreg\": train_and_evaluate_logreg,\n",
        "        \"mlp\": train_and_evaluate_mlp,\n",
        "    }\n",
        "    trained_models = {}\n",
        "    val_probas_list = {}\n",
        "\n",
        "    for name, train_func in META_CLASSIFIERS.items():\n",
        "        print(f\"\\n--- Optimisation du méta-modèle : {name.upper()} ---\")\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        objective = lambda trial: train_func(trial, X_train, y_train, X_val, y_val)[2]\n",
        "        study.optimize(objective, n_trials=30)\n",
        "\n",
        "        final_model, val_probas, f1 = train_func(study.best_trial, X_train, y_train, X_val, y_val)\n",
        "        trained_models[name] = final_model\n",
        "        val_probas_list[name] = val_probas\n",
        "\n",
        "        model_path = os.path.join(DRIVE_BASE_PATH, f\"final_meta_model_{name}.{'pth' if name == 'mlp' else 'joblib'}\")\n",
        "        if name == 'mlp': torch.save(final_model.state_dict(), model_path)\n",
        "        else: joblib.dump(final_model, model_path)\n",
        "        print(f\"F1: {f1:.5f} | Modèle sauvegardé : {model_path}\")\n",
        "\n",
        "    print(\"\\n--- Fusion finale et optimisation des seuils ---\")\n",
        "    study_fusion = optuna.create_study(direction=\"maximize\")\n",
        "    study_fusion.optimize(lambda t: objective_fusion(t, list(val_probas_list.values()), y_val), n_trials=50)\n",
        "    fusion_weights = np.array([study_fusion.best_params[f'w_{i}'] for i in range(len(val_probas_list))])\n",
        "    fusion_weights /= fusion_weights.sum()\n",
        "    np.save(os.path.join(DRIVE_BASE_PATH, \"final_fusion_weights.npy\"), fusion_weights)\n",
        "    print(\"Poids de fusion finaux:\", dict(zip(trained_models.keys(), np.round(fusion_weights, 4))))\n",
        "\n",
        "    final_probas = np.tensordot(fusion_weights, np.array(list(val_probas_list.values())), axes=(0,0))\n",
        "    final_thresholds = threshold_tuning(y_val, final_probas, len(class_names))\n",
        "    np.save(os.path.join(DRIVE_BASE_PATH, \"final_thresholds.npy\"), final_thresholds)\n",
        "\n",
        "    # Évaluation\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"       ÉVALUATION FINALE SUR L'ENSEMBLE DE VALIDATION       \")\n",
        "    print(\"=\"*50)\n",
        "    final_predictions = apply_thresholds(final_probas, final_thresholds)\n",
        "    print(classification_report(y_val, final_predictions, target_names=[str(c) for c in class_names], digits=4))"
      ],
      "metadata": {
        "id": "f52w6l-CAose"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Lancement du pipeline ---\n",
        "final_pipeline_execution()"
      ],
      "metadata": {
        "id": "UTwSnIpaCKvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PISTES D'OPTIMISATION ET PROCHAINES ÉTAPES :\n",
        "#\n",
        "# Pour améliorer la performance et la robustesse de ce pipeline, plusieurs\n",
        "# pistes pourraient être explorées :\n",
        "#\n",
        "# 1. Suppression du Grid-Search et du \"booster_logits\" :\n",
        "#    - Le script utilise une recherche par grille pour tester toutes les combinaisons de modèles.\n",
        "#      Cette approche pourrait être remplacée par une stratégie de stacking directe où\n",
        "#      tous les logits des modèles de base sont utilisés comme features,\n",
        "#      et les hyperparamètres sont optimisés par Optuna.\n",
        "#\n",
        "# 2. Suppression de la Validation Croisée Complexe :\n",
        "#    - Le code implémente une lourde boucle de validation croisée\n",
        "#      (5-fold) pour entraîner et évaluer les méta-modèles.\n",
        "#    - Le pipeline pourrait être simplifié pour utiliser un unique découpage\n",
        "#      entraînement/validation, déjà défini par le fichier `val_indices.json`.\n",
        "#      Cette approche serait beaucoup plus rapide et suffisante pour développer un méta-modèle robuste.\n",
        "#\n",
        "# 3. Suppression de l'Optimisation des Seuils :\n",
        "#    - Cette version du code contient une étape finale pour ajuster\n",
        "#      les seuils de décision de chaque classe.\n",
        "#    - Cette étape pourrait être retirée pour simplifier le modèle et éviter\n",
        "#      un risque de sur-ajustement sur l'ensemble de validation. L'évaluation\n",
        "#      se baserait alors sur la prédiction standard (`argmax`), ce qui rendrait\n",
        "#      les résultats plus généralisables."
      ],
      "metadata": {
        "id": "nRZCna-vCNOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > \"/content/drive/MyDrive/Colab Notebooks/requirements_Meta.txt\""
      ],
      "metadata": {
        "id": "OjCTtVnJUHPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}